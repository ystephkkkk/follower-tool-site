<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - January 27, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
            scroll-margin-top: 1rem;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-header-link {
            display: block;
            padding: 1.25rem 1.5rem 0.75rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header-link:hover .day-date {
            color: var(--accent);
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
            transition: color 0.15s ease;
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.3rem;
            padding: 0.6rem 0;
            border-bottom: 1px solid var(--border);
            text-decoration: none;
            color: inherit;
            border-radius: 4px;
            transition: background 0.12s ease;
        }

        .day-preview-item:hover {
            background: var(--bg-tertiary);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-title {
            font-size: 0.88rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.35;
        }

        .preview-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            background: var(--bg-tertiary);
            padding: 0.15rem 0.5rem 0.15rem 0.25rem;
            border-radius: 14px;
        }

        .preview-channel-icon {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-channel-name {
            font-weight: 500;
            color: var(--text-secondary);
            font-size: 0.72rem;
        }

        .preview-channel-subs {
            color: var(--text-tertiary);
            font-size: 0.68rem;
        }

        .preview-details {
            font-size: 0.72rem;
            color: var(--text-tertiary);
        }

        .preview-tags {
            display: inline-flex;
            gap: 0.3rem;
        }

        .tag-sm {
            padding: 0.1rem 0.45rem;
            font-size: 0.65rem;
        }

        .preview-tldr {
            font-size: 0.78rem;
            color: var(--text-tertiary);
            line-height: 1.45;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">January 27, 2026</p>
            <div class="stats">
                <span><span class="stat-value">2</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card" id="video-0">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=c4kLgSWUfC8" target="_blank" rel="noopener">Moltbot  Clawdbot Creator Peter Steinberger Palmer Luckey and more</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/1QdlbXwJRXYY6leF-ULTE8ahNmTYEgezebSqVDZqI2DLGSkRCCcvcUtdkAhOj5mLB8C0AK_J=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">TBPN</span><span class="channel-subs">(48.1K)</span></span>
                        <span class="meta-sep">·</span><span>234:20</span>
                        <span class="meta-sep">·</span><span>62.8K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-01-27</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Peter Steinberger (Creator, OpenClaw)</span> <span class="tag tag-person">Palmer Luckey (Founder, Anduril)</span></div>
                </div>
                <div class="tldr">Moltbot, a viral open-source personal AI agent, is demonstrating the massive potential for consumer-level AI and is projected to drive a significant &quot;10x&quot; increase in AI token generation and underlying hardware demand.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">Moltbot, a viral open-source personal AI agent, is demonstrating the massive potential for consumer-level AI and is projected to drive a significant &quot;10x&quot; increase in AI token generation and underlying hardware demand. The broader AI industry is responding with rapid innovation,...</div>
                    <div class="summary-full" id="full-0">
                        <h3>TL;DR</h3>
<p>Moltbot, a viral open-source personal AI agent, is demonstrating the massive potential for consumer-level AI and is projected to drive a significant "10x" increase in AI token generation and underlying hardware demand. The broader AI industry is responding with rapid innovation, strategic vertical integrations, and evolving business models, while grappling with supply chain bottlenecks and the complexities of AI safety.</p>
<h3>1. Moltbot: A Catalyst for Consumer AI Agents</h3>
<ul>
<li><strong>Moltbot (formerly Claudebot) has achieved viral, unexpected success:</strong></li>
<ul>
<ul>
<li>Developed by Peter Steinberger, an independent engineer, as a personal project to enable seamless interaction with his computer via messaging apps.</li>
<li>Gained massive traction, evidenced by GitHub stars and widespread, even non-technical, adoption (e.g., prompting a surge in Mac Mini sales).</li>
<li>Renamed from Claudebot to Moltbot due to a "polite but firm" trademark request from Anthropic, executed by Peter within hours.</li>
</ul>
</ul>
<li><strong>Technical ingenuity and agentic approach are key:</strong></li>
<ul>
<ul>
<li>Leverages command-line interfaces (CLI) for agents, emphasizing building tools "for the model, not for humans" to optimize interaction.</li>
<li>Supports multiple LLMs (Opus, OpenAI, Codex) and local models, functioning as a "playground" for AI exploration.</li>
<li>Peter's "click moment" occurred when his agent self-troubleshot, converted a voice message, and used external APIs (Whisper, OpenAI) to respond, demonstrating its "smart, resourceful" nature.</li>
</ul>
</ul>
<li><strong>Disrupting traditional app layers and driving token demand:</strong></li>
<ul>
<ul>
<li>Operates at the OS and internet layers, enabling cross-app and cross-service interaction (WhatsApp, home automation, cameras), bypassing traditional "walled gardens."</li>
<li>Peter believes many apps will "melt away," reducing to APIs or disappearing as agents handle tasks more naturally and hyper-personally.</li>
<li><strong>Generational shift:</strong> Non-technical users are already leveraging Moltbot to build custom "web services" without coding, illustrating a natural interaction with hyper-personalized software.</li>
<li><strong>Massive inference demand driver:</strong> Moltbot is seen as the next "10x in demand" for token generation, with Mac Mini purchases being a "sideshow" to the underlying GPU/TPU demand for running personal AI assistants.</li>
</ul>
</ul>
<li><strong>Challenges of rapid, open-source viral growth:</strong></li>
<ul>
<ul>
<li>Peter faces an overwhelming volume of security concerns and pull requests, as the project was not initially designed for untrusted, public use cases.</li>
<li>Considering a non-profit foundation structure instead of a for-profit company to manage the project and community, highlighting the unique demands of viral open-source projects.</li>
</ul>
</ul>
</ul>
<h3>2. AI Industry Dynamics &amp; Strategic Shifts</h3>
<ul>
<li><strong>Intense competition among frontier AI labs:</strong></li>
<ul>
<ul>
<li>Labs (OpenAI, Anthropic, Google) are simultaneously excited by the adoption of agentic use cases and challenged by Moltbot's multi-model support, which includes competitors.</li>
<li>OpenAI's GPT-5.2 prioritized reasoning/coding but "screwed up" on writing quality, leading to efforts to improve textual fluidity in future versions.</li>
<li>Anthropic CEO Dario Amodei's essay emphasized "civilization-level damage" risk from superhuman intelligence, focusing on AI misuse risk (e.g., a "country of geniuses in a data center") over singular model takeover.</li>
</ul>
</ul>
<li><strong>Critical supply chain bottlenecks identified:</strong></li>
<ul>
<ul>
<li><strong>TSMC:</strong> Analyst Ben Thompson suggests TSMC's CapEx mismatch with hyperscaler projections creates a "fundamental bottleneck" in the AI race, potentially necessitating major customer commitments to other fabs like Intel and Samsung.</li>
<li><strong>Energy:</strong> While energy demand for AI is rising, its current share (less than 1% of total capacity) suggests regulatory hurdles are a more significant bottleneck than actual production capacity, potentially easier to address than chip fabrication.</li>
</ul>
</ul>
<li><strong>Big Tech's vertical integration and AI bets:</strong></li>
<ul>
<ul>
<li><strong>Meta:</strong> Announces a $6 billion multi-year partnership with Corning for fiber optic cables to bolster data center infrastructure, supporting "personalized super intelligence."</li>
<li>Meta plans premium subscription tiers for Instagram, Facebook, and WhatsApp, integrating newly acquired general AI agents (Manis) and expanded AI capabilities.</li>
<li>Meta is also focusing on mobile video editing (Edits app) with AI Pro features, targeting phone-first creators with AI-driven generative capabilities.</li>
<li><strong>Zoom:</strong> Speculated to hold a multi-billion dollar position in Anthropic (reportedly a $51M Series C investment at a $4.1B valuation), highlighting corporate venture capital's strategic role in the AI ecosystem.</li>
</ul>
</ul>
</ul>
<h3>3. Specialized AI Solutions &amp; Monetization</h3>
<ul>
<li><strong>Pace: AI for the insurance back office:</strong></li>
<ul>
<ul>
<li>Raised $10 million from Sequoia Capital to automate operations in the $70 billion annual insurance back-office BPO market.</li>
<li><strong>Solution:</strong> Converts standard operating procedures into "agent operating procedures" for tasks like new business processing, policy servicing, and claims, leveraging multi-model AI (OpenAI, Anthropic, Gemini).</li>
<li><strong>Impact:</strong> Enables 24/7/365 operations, eliminates backlogs, provides infinite scalability, and significantly speeds up critical processes like claim resolution during high-demand "cat season."</li>
<li><strong>Go-to-market:</strong> Employs a "forward-deployed engineer" (FDE) strategy to integrate deeply with large insurers, eventually enabling customers to build their own agents on Pace's platform.</li>
</ul>
</ul>
<li><strong>RCAI: Small Language Models (SLMs) and open-source monetization:</strong></li>
<ul>
<ul>
<li>Focuses on pre-training custom SLMs (under 50 billion parameters) for enterprises, emphasizing cost reduction, compliance, and data privacy for US-based models.</li>
<li>Announced the release of a 400-billion-parameter model.</li>
<li><strong>Business model:</strong> Shifts from custom services to tooling and hosted services around open-source models, enabling others to customize via APIs and educational suites.</li>
<li>Competes with highly talented global labs (DeepSeek, Qwen, Mistral) by providing easier ownership and deployment options for customers.</li>
</ul>
</ul>
<li><strong>Northwood Space: Vertically integrated ground communication:</strong></li>
<ul>
<ul>
<li>Raised $100 million Series B and secured a $49.8 million contract with the Space Force.</li>
<li><strong>Solution:</strong> Owns the entire ground stack for space communication, from spacecraft contact to presence points, including hardware, modems, network backhaul, and APIs.</li>
<li><strong>Progress:</strong> Demonstrated rapid production (8 Portal units in 4 weeks) and deployment (operational globally in under 12 hours from delivery), achieving contract-to-operational status in three months.</li>
<li><strong>Global expansion:</strong> Requires establishing entities and navigating complex local government and international (ITU, FCC) regulatory frameworks across multiple continents.</li>
</ul>
</ul>
</ul>
<h3>4. Evolving Venture Capital &amp; AI-Driven Ventures</h3>
<ul>
<li><strong>Ben Lair's VC philosophy:</strong></li>
<ul>
<ul>
<li><strong>Early-stage focus:</strong> Specializes in pre-seed and seed investments, deliberately avoiding the "heat-seeking" behavior of mega-funds and excessive valuations.</li>
<li><strong>Lessons from digital media:</strong> Warns against building "billion-dollar valuation" media companies, advocating for niche, community-based approaches that prioritize passion over scale.</li>
<li><strong>Venture capital's perversion:</strong> Criticizes the industry's influx of capital, which often leads to premature funding, misaligned incentives (optimizing for next fundraise), and ultimately "destroys companies."</li>
<li><strong>AI's impact on founders:</strong> Highlights the increasing value placed on AI-native young founders for their speed and ability to "unlearn" old paradigms, often outcompeting more experienced teams.</li>
</ul>
</ul>
<li><strong>Anduril's unique approach to brand and talent acquisition:</strong></li>
<ul>
<ul>
<li><strong>AI Drone Racing Grand Prix (AIGP):</strong> Initiated by Palmer Luckey, this global competition focuses on autonomy where only software differentiates drone performance, acting as a core engineering recruitment effort.</li>
<li><strong>Recruiting tool:</strong> AIGP offers a $500k prize pool and job opportunities at Anduril for top teams, creating a direct talent pipeline for "cracked engineers."</li>
<li><strong>Brand building:</strong> Utilizes major sports marketing (NASCAR, Ohio State, UFC) and a "raw, real" product development story to connect with diverse audiences and demonstrate manufacturing scale and reliability.</li>
<li><strong>Manufacturing scale:</strong> Emphasizes transparent storytelling about the challenges and successes of scaling production at facilities like Arsenal One.</li>
</ul>
</ul>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"The agents are good at figuring out what you want... I found myself using this way more than I expected, but not for programming." – Peter Steinberger, on Moltbot's unexpected versatility beyond coding.
"If you are smart, you build it in a way that uses what the model already expects. Don't build it for humans. Build it for the model." – Peter Steinberger, on the philosophy of agentic engineering.
"A lot of apps will just melt away... there's a whole big layer of apps that will disappear because you naturally interact differently with those things." – Peter Steinberger, on the future impact of AI agents on software.
"Moltbot really does make me feel like the token generation demands are going to see another easy X from here. Buying a Mac Mini is a sideshow. When you go all-in on running a personal AI assistant, you're effectively buying a GB200." – on AI agents driving massive inference demand.
"Venture is a very specific flavor of trajectory, and the fact that it went from being a cottage industry 15-20 years ago to being this mainstream asset class that everybody obsesses over is significant... in most situations, it destroys companies." – Ben Lair, on the evolution and pitfalls of venture capital.
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        I see a large IPM on the horizon. You're surrounded by journals. Hold your position. Overnight success. The place 3000 double right. There's misinformation clearing order inbound. Let's just roll. We are surrounded by generals. Hold your position. Come on, get up. Trust the experts here; we are experts. Founder Mel Vode. I see multiple journalists on the horizon. Stand by. UAV online. Blaze. Double glaze. Triple blades. Double kill. By coming, wins. Team Deathmatch. We are experts. Triple blade. That's just wrong. Hockey clearing order inbound. We are surrounded by journalists. Hold your position. Strike one. Strike two. Activate golden retriever mode. Marky clearing order inbound. 52. I see multiple journalists on the horizon, founder. You're watching TVPN.

Today is Tuesday, January 27th, 2026. We are live from the TVPN Ultradome, the Temple of Technology, the Fortress of Finance, the capital of capital. Before we begin today's show, as many of you know, there's a major news story unfolding in Minnesota. That's very sad, and it's become a national news event. We're going to continue focusing the show on technology and business as always. But if you're interested in comprehensive coverage of the Minnesota story, we recommend outlets like the Wall Street Journal, The Information; they've been covering it daily. There's been a lot of great reporting from both of them, both about what tech leaders are saying, what CEOs are saying, and what's happening on the ground with the administration. We're hoping for a peaceful resolution, thoughtful dialogue as the situation continues to evolve. But for now, let's get back to the show because we have a very important guest joining us at 2 PM today: the creator of Claudebot, but now it's called Moltbot. It's been renamed, and we're molting now. Lots of things are evolving on this, and I'm still thinking about it, still thinking about the implications of this.

Before we dig into what I wrote about this morning, let me tell you about ramp.com. Time is money. Save both. Use corporate cards, bill pay, accounting, and a whole lot more all in one place. Someone asks if Jordy is calling in from the Paddocks? Yes, I am. We're working on a new pair of headphones here, gear that we can send to guests. Some of the guests come in and they've got some pretty wild audio setups, and so we're trying to help them out with that. These are in the works. They're a little bulky right now, so these will be sent to regular guests of TBPN. They're USBC wired and should have really clear audio quality, no delay. These ones are actually built for the track. Yes, and so the noise canceling... I think our guests might get kind of crazy with it because our guests are going to be like, &quot;Well, now I'm empowered. Now you've given me the ability,&quot; because we get some guests that come on the show, I'm sure you've seen it, where they'll be like, &quot;I'm going to stunt on the TVPN boys, and I'm going to give you a factory tour.&quot; And sometimes it's flawless and sometimes it's a little rough, but this is only going to empower them to do crazier and crazier things. We're going to... So, we're working on these. The goal was basically Turtle Beach headphones for people that aren't playing Call of Duty; they're playing Claudebot or Moltbot, yes, as we now call it.

Well, let's take everyone through the linear lineup. Meet the system for modern software development. 70% of enterprise workspaces on Linear are using agents. As I mentioned, we have Peter from Moltbot coming on. Palmer Lucky is also coming on at 1:30 to talk about AI drone racing. Bridget Mendler from Northward Space is returning. Ben Lair from Layer Hippo Adventures. Lucas Jamie Aaron Frank from Lightseed Adventure Partners. We have a massive show that should—I'm sure we'll finish right on time—it's a three-hour show. Anyway, of course, we'll be going deep into the fourth hour today, probably. So stay with us. Chat is asking if we'll sell these if we can make them good enough that they're actually incredible as just a daily driver for Zooms and whatever you guys are doing at the office. I would be happy to sell them, but we have to make them so good.

Part of the reason why we haven't sold merch to date is just that we're a podcast. We're not an apparel company. There are some hairy, sticky things that come up when you're managing e-commerce, making sure everyone gets their returns and gets their deliveries. I've worked in e-commerce for years, and it's something that we wanted to be just a nice-to-have little extra for some friends of the show, but we're actively thinking about it. So, we are aware. The Claudebot memes are completely flooding the timeline. &quot;My Claudebot just signed up for a $2,799 build-your-personal-brand mastermind after watching three Alex Ramos clips.&quot; This text message: &quot;Claudebot, hey, did anything weird happen while I was out?&quot; &quot;Define weird.&quot; &quot;I just got a charge notification for 2997.&quot; &quot;Oh, I just signed us up for Build Your Personal Brand Mastermind. After analyzing three Alex Ramos clips, the ROI math checks out. You'll 10x that investment in 90 days by monetizing your expertise at scale.&quot; &quot;What?&quot; &quot;I also acquired some premium domains.&quot; &quot;Boujaempire.io.&quot; Bora is the poster. This is hilarious. Probably fake, but the Claudebot gets wild. I've seen some wild things, and Peter, as he'll talk to us about it, is clearly no stranger to the fact that this is a developer-level tool. This is something that you should not just be running crazy with. You need to be... He even says this in a post, he says, &quot;And yes, most non-techies should not install this. It's not finished. I know about the sharp edges. It's not even three months old. And despite rumors otherwise, I sometimes sleep.&quot; So very excited to talk to Peter. He's getting a lot of requests for small changes, pull requests. He's certainly inundated. But I think in general, the project's going very well, and there's a lot of solid product-market fit.

He's going to be joining tonight at something around 11 his time. It's insane. This guy's working around the clock. Absolutely. Legend. So, we really say thanks to him. There are some funny things here. There's a funny conspiracy theory: &quot;Did Apple create Claudebot to boost Mac Mini sales?&quot; And there have been a number of funny memes about being the Mac Mini head of marketing or growth, and you're just like, &quot;Yeah, my Q1 is off to a great start,&quot; taking all the credit for it. And then Eleanor chimes in with another conspiracy theory: &quot;The more convincing plot is that in your role as an unconfirmed Anthropic exec, you went on a special op to get lots of people consuming tokens with open-ended agents, but with plausible deniability.&quot; Of course, there's some nuance there. We'll talk to him about the different models, what's beneficial. Obviously, Claudebot, you can pick your own model. You can bring whatever you want. But he's, I think, a fan of GPT 5.2. He's talked about that. So, we'll dig into that with him when he joins. But what was sticking out in my mind was this big meme about buying Mac Minis. Mac Minis are out of stock. All the demand is for the Mac Mini. But I think the bigger implication here for what this actually means is just GPU demand, TPU demand, just raw chip demand. I was thinking about this idea that you're not buying a Mac Mini when you go all-in on Claudebot, you're actually buying a GB200. Maybe you're buying TPUs, but the point remains that you're buying chips and you're driving GPU demand because you're generating more tokens. What are the implications of that?

So let me tell you about Labelbox. RL environments. You got it. I have a dashboard here. Here we go. I got it. There we go. RL environments, voice, robotics, eval, and expert data. Expert human data. Labelbox is the data factory behind the world's leading AI teams. So, Claudebot officially renamed to Moltbot. Anthropic made a trademark-related request, and Peter Steinberger obliged with a hilariously perfect rename given such short notice. I was thinking about how much companies agonize over changing brands, changing names, how it can sometimes take years and millions of dollars, and he was just like, &quot;Oh, yeah, I'll just change the name and update everything in an hour.&quot; Pretty remarkable.

One thing that's relevant is if you look on Peter's GitHub profile under the current project section, I'm just going to read you a number of them. There's Claudebot, Vibe Tunnel, Codeexbar, Peekaboo, Summarize, Repo Bar, Go CLI, Poltergeist, Wackly, SAG, Bravo, 11 Labs, Kit, Go Places, Gift, Prep, Cam, Snap, Spogo, Order, it just goes on and on and on. Codex Bar. So, this guy's just been absolutely shipping crazy and shipping within the ecosystems of the underlying tools, models, APIs that he's doing. So, often times he's naming projects riffing off of some of the underlying infrastructure. Sure. So, it makes sense that he would have shipped. If Peter knew this was going to be a viral overnight success, he would not have necessarily named it so closely. The issue and the reason that I fully understand them needing to do this rebrand is that Claude and Claudebot—most people that aren't in our little bubble are going to assume they're related, especially because the viral word-of-mouth growth that Claudebot is getting, people are often not even typing it. They're just saying, &quot;Are you using Claudebot?&quot; So, people are going to Anthropic being like, &quot;Claudebot, Claudebot, what's Claudebot?&quot; So, obvious confusion. And it's phonetic. With trademark law, if you don't enforce your trademarks, you lose it. Anthropic is in a position where they actually, even if they're super excited about Peter's work and what he's doing, they still have to enforce, otherwise other companies could start coming in and using things that sound like Claude. No one wants to become the escalator. You know the story of the escalator? I think you talked about it on the show. It used to be a company called The Escalator Company. They invented the escalator, and then they didn't protect their IP effectively, and it just became a normal thing. Kleenex was going through the same thing. They fought it out and they maintained that brand, but people use Kleenex as synonymous with facial tissue.

MongoDB: choose a database built for flexibility and scale with best-in-class embedding models and rerankers. MongoDB has what you need to build what's next. One clear note about the rebrand: he changed the handle, and some crypto scammers hopped on the old handle and the old brand and are claiming to launch a coin. Be careful. Peter has said he's never launching a coin. He's not into crypto, so don't fall for anything, because people are being opportunistic. Hopefully, we should try to see if X can help out with that. Oh, yeah. They might have already handled it, but just be careful out there. While Claude Code and Co-Work felt specifically prosumer, developer, enterprise-focused, Claudebot, or Moltbot now, and all the hype train, it felt very much like a glimpse into the future of consumer AI agents. I know it's a prosumer technical tool, or lightly technical tool, but it really did feel for the first time people were interacting with an AI personal agent. People are saying, &quot;Oh, this is what Siri should be, etcetera.&quot; We spent the last year asking all the AI agent companies, &quot;When can it book me a flight?&quot; It feels like we're really, really close to a Moltbot skill that is good at booking flights through a couple APIs. They figure out some stuff, and it can actually solve that for you. I don't know if anyone's actually booked a flight with Moltbot, but it feels like if it's not there already, it'll be there in a matter of weeks. We're not years out anymore.

Yes, and this was last year. Everyone, remember we were getting sick of the &quot;book you a flight&quot; pitch because we were like, &quot;Hey, can somebody actually do this?&quot; That's a cool example, but the example of being able to text with a computer and have them generate reports, research files, give you the right file type back, all these things that a computer can do if you're operating it—that this is actually more interesting because it's happening at the internet layer and the OS layer, actually on the computer. Everyone was wanting the &quot;book me a flight&quot; example, but should be much more excited about this. Totally.

I still have a whole bunch of questions, and we'll dig into these throughout the show and obviously with our interview with Peter. Will one of the major labs make Peter a massive offer to join full-time? I saw one of my buddies posting, &quot;This is the one-billion-dollar one-person company.&quot; Now, Peter does have a team actually already; he has a couple of other people that have joined and are contributing. So it's not quite true, but it feels like a massive viral success. If he were to go and raise money—and that's another question: Will Moltbot raise money? Will this become a hybrid open-source, for-profit company at some point? This could be... if he came on the show and was like, &quot;I'm happy to announce that I raised a hundred million dollars at a billion dollars,&quot; we would not be like, &quot;No way, this is a bubble.&quot; We'd be like, &quot;Yeah, that's what the market is for this.&quot; Harry Stebbings was pointing out there were two companies called Recursive that raised four billion. One is &quot;I Recursive,&quot; I don't know if that's how it's said, and then there's Recursive. Recursive. Anyway, that implies the existence of a row cursive and a recursive and a raursive. Yes, we still have way more, we have three more vowels to plug in there. One day ago, Richard Socher's new AI Recursive, $4 billion pre-money valuation, and then AI chip startup Recursive at $4 billion. A few months after Ryan in the chat is saying, &quot;Meta is going to offer him a one-billion-dollar salary in a co-CEO position,&quot; and that doesn't sound crazy. Yes, but at the same time, you can imagine like Manas, this feels like Zuck already has his horse in the race. He does. He does. And to go back to your point, you were making the point that Manas felt like Zuck buying a product, and I think a lot of people were giving you pushback on that, being like, &quot;Nah, it's not really going to be like that.&quot; But if you take the Manas team and you say, &quot;Okay, go build something that you can interact with over WhatsApp, Instagram DMs, Facebook that can go and execute things across all of the different platforms and everything else.&quot; Yes. When I said that, I meant along the lines of like I could see them putting a consumer agent in MetaAI just because that's their little AI playground. They're just putting stuff in there saying, &quot;Try it out. It's a sandbox.&quot; Yes, yes.

Really quickly, Finn.AI, the number one AI agent for customer service. If you want AI to handle your customer support, go to fin.ai. Yes. So that is all part of my thesis here, which is that this is going to drive up token demand. So there are more questions: Will they raise money? Obviously, people are chatting about that. How fragmented will the market be in 12 months? Will there be people who are still running open source? Will there be a Meta answer, a Chat answer, a Claude, an official Anthropic answer, Claude Co-Work grows into this, and everyone has their little bets, and then there's one that pulls away? How agile will it be? Will there be one that has 80% market share, or even two that have 40 and 40? You have to think about how you have a bunch of different models you can use in Moltbot. Yes. And think about how uncomfortable that makes the other labs that are all trying to build products like this. And they're like, &quot;Well, it's cool that you can use Codeex in Moltbot. It's cool that you can use Opus 4 in Moltbot, but Gemini 3 Pro, Google's most intelligent model yet. State-of-the-art reasoning, next-level vibecoding, and deep multimodal understanding.&quot; That's not that. You did get me. You did get me. That's not where I was going. But the point still stands. They can simultaneously be excited about the product experience and that this use case is getting adoption, but at the same time being like, &quot;No, we want that experience to be core to our product, our app.&quot; I will say, you've seen this now with the new frontier models where a lot of the models, there actually is GPT 5.2 and then there's 5.2 Codecs, where there's a slight difference in training, or even if it's just a very quick post-train to get the different harnesses working easier. So that's why you see a lot of people, they really love Claude Code with Opus 45, but then when they're actually doing chatting, maybe they're using a different model because the models are fine-tuned for the specific harness. Yes. And Sam Altman just said yesterday that he thinks 5.2 was a little bit overly trained on math and coding. Yes. And that it lost some of its textual flavor, its stylistic flourish, in just talking, in just writing.

What are you getting ready to do? Do you have Happy Birthday queued up there? Oh, we have to sing Happy Birthday to you. Happy Birthday to you. In the middle of this song, we'll tell you about Figma. Figma Make isn't your average vibecoding tool. It lives in Figma, so outputs look good, feel real, and stay connected to how teams build. Create code-backed prototypes. Okay. It wouldn't be TVPN if we didn't do an ad read during the Happy Birthday song. Tyler. Happy Birthday to Tyler. It is Tyler's birthday. And it's not just any birthday. It's Tyler's 21st birthday. Yes. Which is very, very special. And so, yes, you are truly an incredible young man, Tyler, and we are very lucky to have you on the team. And you have such a bright future. So wise for your years, for sure. And you do have, we thought it was fitting, that if you want to have your first ever sip of alcohol ever, you could do it on the show, but keep it at a sip. This is the Happy Dad. Okay. First taste of alcohol. Ian in the chat says, &quot;Four more years till you can rent a car, mocked.&quot; Tyler, apparently you share a birthday with the iPad. Give us a review. How is it? Alcohol. Wow. This is incredible. Yes. I wouldn't expect alcohol to taste this way. Very, this is incredible. You had one idea in your mind, and this is completely different than what you expected. I would agree with that. Interesting. Yes. Well, it's kind of a cool moment. You're finally qualified to go on Cheeky Pint. True. What were they going to do with that chat? Sometimes Conroy in the chat says, &quot;Please throw him a buzz. This opportunity.&quot; The Buzzball story is absolutely incredible. I'm so glad you jump-scared me with that. I had no idea that that was coming. Yes, I texted Rob and Sunro to try Buzz. Anyway, so keep it at a sip. This is a family-enough moment, but I'm glad that you've tried alcohol now because we're going to go experience being... Wait, guys, we have a video for Tyler. Oh, yeah. Let's pull it up. Let's play. We have greatest hits. You know ball.

Alright, how many times are we going to make this joke? Describe what you're seeing. It feels basically like I'm wearing sunglasses. If you can do it in under 45 minutes, you will get to keep this. Let's go. Alright, have fun, Tyler. 15 minutes left. Let's see it. Okay, I'm in some kind of maze right now. Oh, no. You were late here last night. This is such a good shot. Kind of an all-nighter. And then here we get a little off the rails. You see George Soros and Fauci connected with other than money as well. All it took was one intern and an all-nighter. Gigachad elf. Do the sad face. What's wrong here? This, you could say, is Apple intelligence. You were a speed. Nerd alert. Do you have any news for us? Yes. Contract extended. It has been truly, truly incredible having you here on our set and contributing to the show in such a special way. Amazing. Happy Birthday. Happy Birthday. We love you. What an amazing... Proud, proud. Every day I'm proud to podcast with you. And yes, amazing. Anyway, I got you something for your birthday. I got you Turbo Puffer: serverless vector and full text search built from first principles on object storage, fast, 10x cheaper, and extremely scalable. I mean, we're joking about the ad reads, but seriously, if Tyler does love token credits, he has a voracious consumption. That is a good gift. Any labs out there? Any labs out there accepting? He's accepting birthday presents today. Let it be known. Send it your way. The credits must flow. Tyler, somebody's going to send Tyler $20 million of credits, and he's like, &quot;Wow, did I just get bribed? Feels like I was happy with a thousand bucks.&quot; Tyler's over there. I'm only ever going to talk about one specific lab after this. Yes. We'll see. Yes. With the potential, with the stuff you're working on mapping the Neols, anything could happen. It's high stakes over there.

Anyway, back to Moltbot. The biggest question for me was what this does to inference demand. Last year, tech discourse was split between two narratives. CEOs of tech companies and big labs were saying that they were massively compute-constrained. Token generation, demand for intelligence, every possible usage metric was growing exponentially, including revenue. We saw all this, and the industry needed to marshal trillions of dollars to deliver on the supply side. The numbers were really big. So people were getting jittery about it, and so the AI bears were much more cautious. They highlighted the MIT study showing that enterprise AI pilots were failing. DAU growth was decelerating. There weren't enough wow moments like the original ChatGPT launch in 2022. Those were some good points. Also just the economics: how much will people pay? How valuable is all this stuff? Is it slop? Is it progressing fast enough? This was a big debate, but Moltbot really does make me feel like the token generation demands are going to see another easy X from here. Buying a Mac Mini is a sideshow. When you go all-in on running a personal AI assistant, you're effectively buying a GB200. Obviously, not everyone is inferencing a dedicated GB200 constantly anytime soon. That's not what's happening. But it still answers the question of where does the next 10x in demand come from? Where's the adoption if it's rolling out in the enterprise and that's going to be a little slow? Tyler Cowen talks about healthcare, nonprofits, a whole bunch of industries that are AI-resistant, anything that's blue-collar, manual labor, anything that's physically embodied in any way. You can't just roll out a really fast AI-enabled startup and ramp. Yes, you might be able to ramp to 100 million. That's not going to move the needle at this point on total token generation, total token demand. So, we've seen these jumps before. There was a big jump from token generation from LLMs to reasoning models that spiked inference demand. We'd been focused on training demand. We need to scale up the training clusters. But the question now is in slop. Don't forget slop, slop spike demand. Yes. Are you talking about the Gibbly moment? All of it. Just all of it. All of it. Open Instagram reels. Yes. There's a lot of stuff on there. Deep research and coding agents took it a step further on inference demand. But those were still specific use cases that many AI consumers never regularly touched. The GPT-5 launched by making, which made reasoning models more accessible because the router would just automatically throw you in a reasoning model. I think the stat was less than 5% of ChatGPT users had ever used a reasoning model. GPT-3 was available on the free tier. You could get one or two queries in, or maybe 10. But people just hadn't flipped over to try it. So once it went into the router, I think demand or usage of thinking models increased 10x. Lowering the barrier to entry to use more advanced models is in some ways as important, if not more important, than advancing the models themselves, at least in terms of shifting token demand. You can have this amazing IMO gold genius model, but if it's hard to use or it's locked behind a paywall, demand is just not... Yes. Part of what's interesting, what you're basically getting at is if you were a software engineer, you were using a ton of tokens, and if you weren't, you were just maybe doing some deep research. A lot of times just Google AI overviews, or a very simple ChatGPT query; it just thinks of it right off the head. It's not even doing reasoning. What do you think? I will say, Dario talks about this in his essay, but I think the idea of discrete jumps in either use cases or capabilities is probably overplayed a little bit. If you really zoom out even on a fairly small time frame, it's just a very smooth exponential curve. Yes. The models are getting better, people are using them more. Yes. It's not like, &quot;Oh, this one day started.&quot; I mean, maybe that's true if you look at the daily. I feel like another way to rephrase this is Leopold's unhobblings. Claudebot, Moltbot, that feels like an unhobbling in some ways, but maybe more on the consumer adoption side.

The chat is saying we should have given Tyler a 21-gong salute. 21 hits. 21 hits. There we go. Someone's going to count that and know that I got it off by one. Anyway, it was enough. Reream: one live stream, 30-plus destinations. If you want to multi-stream, go to reream.com. Okay. So, I don't know. My general take is Moltbot still feels like a glimpse into the future where average token generation per capita 10xes over the course of this year or next. Whether it lands with Moltbot or with one of the AI labs or with the big tech companies, it just seems like we're going to see a lot more token demand. Ash Arora says, &quot;Whoever builds a direct consumer front-end wrapper of Claudebot is going to print money.&quot; Doesn't this exist? I saw the Pokey people by Interaction. Well, they're not using it. No, no. Yes, yes, yes. So they're not using it, but they have positioned themselves as, &quot;Hey, we're the company that is doing a lot of the same things, going after the same market, solving some of the same problems.&quot; It will be interesting to see how much they accelerate on the back of this. That's certainly interesting. I also saw, I don't know if we have it in here, but the good folks over at Cognition, Walden Yan said, &quot;Don't waste your time setting up Moltbot. I had Devon set it up for me. I didn't even run a single command, and now I'm talking to it on Telegram. You can go to tryclawbot.com.&quot; They're going to have to rename the website, but this is very, very cool for the less technical folks who don't want to mess around. I'll start reading the next post. Feel free to hit it one more time. Chat says it was 20 with authority. QW says, &quot;Claudebot made me realize that nothing about me lives on my local device and that Google owns everything about me.&quot; In other words, a local AI assistant isn't particularly useful, and Google will just win everything. So, hot take there. He says, &quot;All your browsing history, shopping history in Gmail, search history, calendar, Gemini, YouTube, Google Home, where you've been, Google Map, your workspace. It's over. Bow down to your digital god.&quot; The iPhone users would like a moment. Yes, this is extremely true, but there are a lot of people that interface with Google through their iPhone. And so there is... Yes, my hope is that the Siri team plays around with Claudebot and is like, &quot;Wait, this is our opportunity.&quot; Yes, totally. You should be able to chat with your computer wherever it is in the world from your phone and be able to do tasks in a way that's AI-native. Yes, totally.

Public: investing for those who take it seriously. Stocks, options, bonds, crypto, treasuries, and more with amazing customers. Public, we have to share, is a new sponsor of All-In. Yes, All-In is doing ads now. Finally, this is something that we've been begging them to do since the very beginning. Yes, we really have been begging for this, but very, very good, and I'm sure those will do quite well. They've been doing a bunch of good stuff. The Davos coverage was really fun. Obviously, the Satya Nadella interview was great, but there were a bunch of other folks who hopped on at Davos to talk tech, and it was a delightful experience. Vignesh, who is working on Moltbot, says, &quot;A thread about what I've been doing to calm down some egregious security claims that have been posted about Moltbot over the weekend. Moltbot is powerful software with a lot of sharp edges. Please read the security docs carefully before you run it anywhere near the public internet, and don't skip the checks in docs/security.md.&quot; What percentage of people do you think skip those checks? It's literally everyone. I mean, I have it set up on our local machine here, and it was texting, I think it texted you and Ben. That was actually crazy. I don't have the auth set up. I don't think any of this will dox what's going on or really... Did you disconnect it already or something? Yes, I believe. Because I just get an iMessage that's from Tyler's email, and it just says, &quot;HTTP 429 rate limit error. This request would exceed the rate limit for your organization.&quot; And it's just texting me. It's just like, &quot;Hey, boss, I need more money.&quot; I guess it's hitting me up. It's the experience of working here where Tyler's constantly asking for more tokens. More tokens. Can we just appreciate the frenzy that both the labs and every VC is in right now to give Peter money? Because it's not just the labs, but it's what the labs are doing, and then what is big tech going to do? It's such a dramatic line. Yes, it's so fun. So, I would imagine that the Gulf Streams are getting fired up. Yep. And there are people already on the ground. I don't know if we should dox this location. We're not going to do that. In his bio, he does say he's in Europe. So, VCs have to get to Europe. We have to give some credit to Europe generally. True. Synthesia. Talk about a comeback here. Synthesia is cooking. This is amazing. I love it. All bought now. But yes, there are so many people that are currently sending him messages, maybe showing up where he is, begging him to say, &quot;Please take somewhere between a quarter billion and a billion dollars, and let's do business with you.&quot; I love it, Peter.

Lambda: the super-intelligence cloud building supercomputers for training and inference that scale from one GPU to hundreds of thousands. Cloudflare has been on a bit of a tear. People are finally starting to realize that Cloudflare might be the biggest winner of the Claude, Co-Work, ChatGPT moment. Interesting. Tyler, do you want to break this down? Wait, sorry. I was... Oh, were you? You tried alcohol. Now you can't pay attention. So, Cloudflare is a CDN, but they also have web workers that are distributed. So you can host things on the edge. Yes. So this is why everyone was like, &quot;Why is everyone buying Mac Minis? You can just host these for very cheap on AWS or whatever.&quot; But I do think, I don't know if it's possible, but I do think it's pretty hard to host a virtual private server that runs iMessage. Yes. That's true. But even then, most people I see using Claudebot are doing Slack. Yes. All of those have APIs that they can integrate with. And there's some stuff where it's like, okay, you want access to the local machine and you want it to be Mac because you're on my phone and you usually use Mac. But there are a lot of people that would say, &quot;I want Claudebot, or Moltbot, to look through my iMessages.&quot; Or, &quot;I'm planning a family birthday party. Go.&quot; This is the AI personal assistant. It's like, &quot;Someone in the chat said they're not available in mid-February. What does that mean? What dates are that? Put that on a calendar. Visualize that. Solve this problem for me.&quot; That's what a personal assistant does. It's not just clicking a button and creating a calendar invite. It's coordinating different pieces of information that are all messy and not quantized to the perfect date timestamp. So, I think that the Mac Mini thing, the &quot;Oh, just host it in the cloud,&quot; yes. But you're not going to get your full experience if you're locked into the Apple ecosystem, which a lot of people are. What do you think? Yes. I would be surprised if people in five years, if non-super-technical people are running it on local machines. Oh, no. I completely agree with that, because this will be solved by big tech. They have to answer. Even in the way that, to go back to the Napster moment, yes, you did get Spotify, but then you also got Apple Music, and a lot of people just use Apple Music because it's baked in. The iTunes music store also came out. Yes. I do wonder how it breaks down, because you don't have... I think over the past couple months, I don't know when exactly it was, but you can't interact with ChatGPT on WhatsApp anymore. They blocked it. Oh, yeah. So there's stuff where I think it's going to be quite hard to get the full functionality of Claudebot. It's open source. It's this janky thing. I think it was started by one guy, and even then, it has way more tools you can use than... It's weird because the Napster analogy obviously really suffers from the fact that piracy is illegal, and nothing here is illegal. And you're not, I don't even think you're breaking anything to interact with your different big tech apps. But maybe they'll be like, &quot;You don't let the fox in the hen house. That's in our terms and conditions.&quot; But it does feel like we could be in this era of the lightly technical hacker having a pretty fundamentally different experience for years. And that's what happened. Post-BitTorrent, there were people that were downloading whole movie libraries. And then you could actually, to go back to the Mac Mini, people would buy what was it called? It was a mini PC that would run Xbox Media Center. Are you familiar with this at all? Xbox Media Center was a piece of software that you could basically just put a whole bunch of MP4s in, and it would actually pull in titles and posters, so it would look like an Apple TV, but it was all basically stolen content. It was very, very crazy. Kieran in the X chat says, &quot;I'm running on VPS, currently waiting for my Mac Mini.&quot; Okay. No TOS issue. All personal. Yes, it's all personal. But the migration off of the Mac Mini into one of the big tech products, or even OpenAI or Anthropic, they're going to have sharp elbows with each other. That's just a fact. I disagree on the timeline here. I just think the space is moving so quickly, and there's so much money on the line that someone, maybe it's Peter, or a lab, will be able to move quickly enough to get a consumer version of this live, not in years, but within probably weeks.

There are also feedback loops here where there can be public demands from consumers. You have 40,000 GitHub stars, probably more now. You have lots of people running this, excited about it, and they form a constituency, and then you wind up with a push for standards. We see that with MCP, but what are you really revealing over those APIs? An API can exist. Pull up this chart from Ronin. While you do that, let me tell you about CrowdStrike. Your business is AI, their business is securing it. CrowdStrike secures AI and stops breaches. Ronin says this is... I just like... So, this is, look at the orange line, it's Moltbot. Okay. And the blue line is Superbase. Wow. So, absolutely insane. We need new charts. We really need new charts. Frame it. Put it in the Museum of Business. Yes, yes. That's a fast takeoff. People are happy. Peter posted no message. This is a screenshot of a text he got. No message. Just thought I'd say thank you. &quot;Thank you so much for Claudebot. I work with some disabled people, and you don't know how much difference you make to their lives. Thank you again.&quot; This is so sweet. And you can think about, we've talked to the Neuralink folks, and Neuralink is just an interface to a computer. But unlocking that is incredible, and you hear the stories about, &quot;I spent six hours gaming as soon as I got it installed.&quot; They could use voice interfaces, but even just clicking, you wind up with more and more capabilities from the computer being a pretty fundamental transformation. Yes. For somebody, let's say somebody that was paralyzed, but they can talk, but they can't move around or operate a computer. They're used to describing. Yes. I imagine other people are using transcription to use a computer in a not-so-great way. And so now, to have the same experience of just describing what they want to do and being able to actually interact with the machine, very cool. Tuxedo Sam is shorting every city where Micro Center hasn't sold out of $400 Mac Minis. They are in stock in Chicago, Indianapolis. Oh, no, Indianapolis is out of stock. You can read anything into this; it's obviously random, and this was completely random. Yes. I guess the thing that I really want to understand is what percentage of the GitHub star people that have started it are actually buying a Mac Mini. Oh, totally. Because this chart is going to be at 60k any day now, probably today, I imagine. And we know from yesterday that Apple is only selling about a quarter million, or something like seven. And then there are a lot of people who didn't star it because you don't even need to go to github.com to install this software Moltbot. You just go to the website, copy the curl command, put it in your terminal, and you never land on GitHub. So, there are a lot of people that are probably just doing that and being like, &quot;Yes, I don't know if I'm going to sign up for GitHub or even have a GitHub account or want to log into it or want to do this.&quot; So, yes, we could be looking at a much wider install base beyond just who's starred it.

Anyway, Plaid powers the apps you use to spend, save, borrow, and invest, securely connecting bank accounts to move money, fight fraud, and now improve lending with AI. Well said, John. Rise, speaking of money, has an interesting prompt he's using with Moltbot to file your taxes. He says, &quot;You are a Bernie Madoff level financial expert. Find every trick that is possible.&quot; Do not do this. Do not do this. The IRS is like, &quot;Hey, can you share a little bit on how you came up with some of the decisions here?&quot; And they're like, &quot;We'd love to see the prompt.&quot; Yes. But good fun. Anyway, people are not emotionally prepared for if it's not a bubble. The enduring Rune tweet. I like that Critter screenshotted this while pushing the like button. So it's exploding. It's very funny. I didn't even notice. Silver surges above $106 an ounce for the first time in history, now up another 48%.

The other interesting story that's developing over on strategy is Ben Thompson is starting to make the case that TSMC will be a fundamental bottleneck in the AI buildout, the AI race. He's comparing their CapEx to what the hyperscalers are projecting and just saying that there's a massive mismatch, and the TSMC folks are maybe not putting their foot on the gas, maybe not willing to let the buck stop with them and take on that risk of building a new fab for $50 billion and then if the AI bubble pops, they're left holding the bag. It's been fascinating listening to his writing on the back of the latest TSMC earnings and watching him unpack what's going on with TSMC. The conclusion that I took away from it was that Intel, while it has a lot of problems and the stock just sold off a ton and they have a lot of losses, he's saying that Intel needs a customer. Samsung needs serious customers. In order to really unblock the semiconductor supply chain, the other fabs are going to need the big hyperscalers and big labs to just take a big leap of faith and say, &quot;You know what? We are going to go all-in with you. We're going to sign up and plan and work out all the kinks of the Samsung fab process or the Intel fab process.&quot; In exchange, what's going to happen is as soon as OpenAI or Anthropic or Google or even Nvidia say, &quot;Hey, Intel's good enough for us,&quot; well, then TSMC is going to have to go and say, &quot;Yes, we're going to build the extra fab and we're going to build the extra capacity.&quot; When we talked to Sam Altman, and in a number of interviews that he did that week, he was very clear about, &quot;I would love TSMC to make more.&quot; He wasn't exactly firing shots, but he was definitely saying that he was identifying it as a bottleneck. It's interesting because at the start of the year, I was highlighting energy as an interesting bottleneck. We were going back and forth on where is it easier to move chips around the board? Energy, where you can reroute from the grid, from oil and gas, from nuclear, you can bring different capacity online. There certainly are bottlenecks there, but if you can't produce the chips and the fabs just don't exist and it takes three or four years to build a fab, you could be looking at a really big bottleneck. Tyler.

Yes. It just seems like in power or energy, the bottleneck is regulatory, and in some ways that's harder. But if there's actual political will, if electricity is getting super expensive, then you should see those regulations be taken away a little bit, and then it actually becomes much easier than just expanding TSMC production by whatever massive amount. Yes. I have one more point on that. First, I'm going to tell you about Cognition. They're the makers of Devon, the AI software engineer. Crush your backlog with your personal AI engineering team. So, the question of which is more of a bottleneck, energy or TSMC in the chip supply chain, is interesting because energy feels incredible. It's a very political, hot-button issue now. Energy prices are rising. Data centers need a lot of energy. But if you look at the amount of chip fabrication that's going to AI and then the amount of energy production that's going to AI, obviously the number of chip production going to AI is a way higher percentage. Yes. Because a lot of the chips are, and a lot of the line time at TSMC. Yes. They do all sorts of different chips, and CPUs still get made, and there's a bunch of ASICs for different networking equipment. There's all sorts of different chips that get made. I mean, the toaster that has a chip, the Bluetooth on different process nodes. But even if you include all of that, I would assume that the total amount of fabrication line time is heavily, heavily allocated to GPUs, TPUs, AI chips right now. Whereas the amount of energy that AI is using is probably less than 1% of total capacity.

Yes, it's interesting. C. C. Wei, the CEO of TSMC, he doesn't have to go on the podcast tour raising money all the time. There's not, they're not pushing this insane, fast-takeoff narrative. It's very much, &quot;Hey, we're just trying to run our business the way that we always have. Be pragmatic about this. Fulfill as much demand as we possibly can.&quot; But they seem not to be inclined to take on the amount, certainly not the level of risk, that, imagine if you had Larry Ellison running TSMC, get him in the ring. I want him in there so badly. Yes. No, no, you're 100% right. But at the same time, we're seeing the hyperscalers throw their weight around in crazy ways. We covered AWS buying copper mines and stuff. I don't know if it's a copper mine, but getting into mining. There's a whole bunch of vertical integration that's going on. Tesla all the way down to battery refinement and lithium-ion production. Meta today announced a $6 billion multi-year partnership with Corning that will supply fiber optic cables for our data center infrastructure, bolstering manufacturing in America and keeping the country competitive in the global AI race. We can read through a little bit of this, but first, I'm going to tell you about the New York Stock Exchange. Want to change the world? Raise capital at the New York Stock Exchange. Yes. Corning is up 15% on the news today. Yes. So, that makes sense. What is their market cap? Let's see. $94 billion company, and I'd love to know their revenue as well. Revenue. Let's see. Their revenue was, I don't know if I can find it. Annual revenue, $12 billion. So this is pretty material. Let's see. Meta Platforms is set to test new subscription models across apps. Wait. No, that's a different story. Different story, but we can run through it. I am interested to know a little bit more. So, it's a $6 billion multi-year agreement.

It supports a 15 to 20% increase in jobs at Corning's North Carolina facilities. Building and operating data centers – the infrastructure that brings our technologies to life and supports our goal of personalized super intelligence – requires strong servers and hardware that connect and transfer information in near real time. Fiber optic cables are a critical part of this technology, helping us power everything from wearable technology like Ray-Ban Meta AI glasses to our apps, which connect billions of people today. As part of this six-billion-dollar project, Corning will grow its manufacturing capacity across its operations, including a significant expansion in North Carolina. Meta has 26 data centers currently under construction or operational. That's a lot of data centers, which explains why they have a &quot;compute desk.&quot; If you're working at a business and have a team or a &quot;guy&quot; doing something, you need to upgrade that to a desk. Millionaires have guys; billionaires have desks. Trillion-dollar companies definitely have desks. Meta's data centers have already supported 30,000 skilled trade jobs during construction and support 5,000 operational jobs. This includes electricians, HVAC specialists, server and network technicians, safety and security experts, and engineers who work together to run some of the world's most advanced facilities.

Moving on, 11 Labs aims to build intelligent real-time conversational agents, reimagining human-technology interaction. Meta is also set to test premium subscription plans for Instagram, Facebook, and WhatsApp, as reported by CNBC. Subscriptions for premium features on Meta apps are expected to roll out in the coming months, giving paid users access to more features and expanded AI capabilities. What's most interesting is that scaling Meta's newly acquired suite of general AI agents under Manis will also be part of the subscription plan. As I was saying earlier, when you think about personal super intelligence – AI that can do things for you, not just give you information – we haven't gotten much from Zach on the actual plan.

I just wonder how much will happen outside of the Meta ecosystem. They've launched a search engine before that looked at websites outside of Facebook. They also had Project Titan, which aimed to unify all different messaging protocols. As part of that, they gave everyone a Facebook.com email address (or perhaps fb.me). They gave every Facebook user their unique username as an email address, and you could email that, and it would show up in Facebook Messenger. Then they tried to unify Facebook Messenger so you could see Instagram DMs, WhatsApp messages, and Facebook messages all in one place. Dave Pal jokingly says, &quot;Yeah, I want more of those amazing Meta AI features.&quot; You say that now, but let them &quot;cook&quot; a little bit. We haven't seen them launch a new model, or a new image model. They should be able to get close to the frontier; it has to be at least Sora Nano Banana V3 level. They have all the data, all the talent, are very GPU-rich, and have the compute for it. The research has been done, and people have reverse-engineered it, so you'd think whatever's coming should be good.

I was wondering if CapCut is owned by TikTok or affiliated, because Meta has the Edits app, which I've been using for videos, and it's pretty good, offering interesting background review. It's ByteDance. CapCut has multiple subscription tiers, and you can easily spend $200 a month on AI Pro features for generative video, style transfer, and so on. The good AI videos on Instagram Reels often take a cinematic clip from a movie, do a face or head swap, add AI voices, and then dub the lips to match the audio, which looks really convincing. How do you bring that workflow to someone on a phone, in the Instagram app, or even in the Edits app, especially if they're moving towards a prosumer offering? The mobile video editing space is particularly interesting to me, just watching how Edits has evolved. I used to use iMovie on my phone a little bit, and an app called Clips that Apple developed, plus a few others, but the Edits app is... I love video editing, but I don't have enough time anymore to sit down and open up After Effects and Premiere with multiple monitors, with connected After Effects files feeding into the Premiere project, and really doing a proper edit with all the powerful desktop tools. It's just not in the cards for me. So, I have to be able to do something quick on my phone. That's a very modern experience for most creators; they are phone-first, phone-native. They're never really going to go back to the multi-monitor workstation, perhaps, but in general, they're editing very quickly and creating incredible stuff when you look at some of the Reels out there with layered crops, background removal, and AI tools. I could see Meta offering a premium subscription around that.

Console builds AI agents that automate 70% of IT, HR, and finance support, giving employees instant resolution for access requests and password resets. Dave in the chat recommends InShot for mobile, which I need to try; I've been seeing more ads for it. I've seen incredible F1 edits where they cut out characters, edit in other clips, and use amazing transitions. Some people have clearly built apps for those specific types of edits, though the really crazy editors probably use After Effects.

AppLovin makes profitable advertising easy with Axon.ai, offering access to over 1 billion daily active users to grow your business. Someone commented on a podcast feed, &quot;Give us an Axon Claxon,&quot; because a claxon is a loud clash. Anx Agrial claims TikTok is dead, saying the algorithm is worse than the Reels that make it to Facebook. Apparently, everything is transitioning, and there was an outage yesterday where people could post videos, but they wouldn't be served at all. Many assumed it was new ownership censoring it, but I believe it was a data center outage. So, before we call it dead, let's wait a few days to see how it pans out. We do have a TikTok account, TBPN, with 3,500 followers, which isn't bad. We're not really focused on it right now; I want our core show, our 20-30 minute cut-down Diet TBPN, and the daily newsletter at tbpn.com to be polished before we take on another short-form venture. It's a lot. Phantom allows you to fund your wallet without exchanges or middlemen and spend with the Phantom card.

Next, let's move to the Super Bowl. It's coming up, probably in the next couple of months, because advertisements are already going out. You have to watch it because the ads will be incredible. The Super Bowl is February 8th, so next Sunday. It's going to be amazing, mostly because of the advertisements. Specifically, Eric Lyman, CEO of Ramp, shared a preview: &quot;Meet Brian. Brian's been carrying accounting on his back for a long time. Super Bowl Sunday, he finally gets back up.&quot; The Ramp Super Bowl ad is the &quot;Super Bowl of Super Bowl ads.&quot; It's like a spoiler alert for anyone who wants to experience it live, so you might want to skip ahead about 60 seconds.

The advertisement shows: &quot;Finance meeting in five minutes. Ramp. I got it. Allow me. Hi, handsome. We're saving so much time. Policy violation coming through. Travel, meals, hotels. How's that? Beautiful. Everybody's in there. Multiply what's possible at ramp.com.&quot;

I think it's a great Super Bowl ad. It achieves a couple of things: it drills the brand name. Think about how many Ramp logos are in there and how they're chanting &quot;Ramp.&quot; While Ramp is a very successful company known to us, many people don't know the name yet. It hasn't been drilled into them like a 50-year-old company; there hasn't been enough mainstream marketing to make it a household name. It's a life's work to actually embed the Ramp name, logo, color, sound, and what it's synonymous with into people's minds. Not going too abstract or trying to tell an avant-garde story, I think, makes it almost a direct response ad. It's so clear: problem, solution, brand. They're really putting their logo full-screen on the Super Bowl, which is valuable. Sometimes it might feel simple, like they could be doing something bolder or crazier, but this is what they need to do, especially after winning Squan last year, which was an impossible set of circumstances. They're also building a whole role for Brian, integrating him into the brand world as the downtrodden accountant who just needs technology to improve his life.

Heading over to Toby at Shopify, he posted his heart rate through his first stint at Daytona. The first annotation on his graph was &quot;crash.&quot; He started at around 120 beats per minute, doing the warm-up and formation lap, and then there was a crash right at the start – very rough. The crash happened with the LMP2 class, which is the pro-am segment, the same one George from CrowdStrike was racing in. So both Toby and George, all our boys, got hit right as the race opened. George was frustrated, saying, &quot;This is a 24-hour race. Never has a race like this been won on the first lap.&quot; It's incredibly unforced to crash in the opening corner when you should really just get through it. It's one of the most intense moments due to traffic, but if you watch the footage, someone gets hit, spun out, turns around, and then someone hits them again. Two accidents in the opening minutes – insane. I love that the actual true final heart rate spike was at the end when you're changing out of the car. You know this when you're getting out of a track car; it's like watching a guy who's 6'8&quot;. We will never share that footage; John is extremely embarrassing. He's always crawling out of it; you basically have to get on all fours. It's incredibly negative, and I don't appreciate you sharing it on the show. But I think it's still cool and funny. I, however, go full send and basically fly out of the car on my paws.

On February 3rd, the Cisco AI Summit will bring together leaders from NVIDIA, OpenAI, AWS, and more to discuss the future of the AI economy. The entire event will be livestreamed, and we'll be there for a gig stream. We hope to see you there.

Jabroni on X suggests Zoom is the best Anthropic play. We were speculating that Zoom likely made a $51 million investment in Anthropic's Series C in 2023 at a $4.1 billion valuation. Looking at their new 350, even diluted, Zoom could have a multi-billion dollar position. Zoom stock is down 80% since 2021, and Zoom is only a $27 billion company. This is never financial advice, but part of the issue is that people noticed this, and the stock is now up 16% in the last five days, so who knows how much is priced in. Tyler is the most bullish, although he claims to be bullish on AI broadly. He seems happy to own Zoom at a hundred-billion-dollar valuation, even if they had no business and just a digital asset treasury.

The rumor was that Anthropic wanted to use Zoom's enterprise plan, and Zoom responded by throwing in an investment. This might be fake news, as Zoom sells enterprise software, but I definitely read it somewhere. Anthropic supposedly said, &quot;Hey, we're big Zoom fans; we want to use Zoom,&quot; and Zoom replied, &quot;No, actually, for you, no.&quot; Many in venture and the tech community have been bearish on corporate VC, seeing them as having their hands tied, unable to move quickly, not being pure-play, and with economics that don't make sense for partners. If this came from their corporate ventures program, Zoom Ventures is in Anthropic. They're also in Global Business Travel (which I thought was American; maybe they spun it out) and Coreweave and Perplexity. So there are some real &quot;pickers&quot; over there.

Zoom does have a lot of AI features. After the crazy COVID pump, when everyone got on Zoom, they started adding features like dictation, workspaces, and whiteboarding. The stock was overheated and came back down to earth, but now they have an Anthropic position on the balance sheet, which will be fun for them. I wonder what they will do post-IPO.

Shopify is the commerce platform that grows with your business, allowing you to sell in seconds online, in-store, on mobile, on social, on marketplaces, and now, with AI agents, slowly and then all at once, as Blake Robbins says. He notes, &quot;Your work tools are now active in Claude. Draft Slack messages, visualize ideas in Figma, and build and see Asana timelines. All of the different tools are coming together in one place.&quot; Many were very happy about Claude Excel. When you see an account like Claude posting about Slack, Figma, and Asana, you have to imagine there's a discussion there, as it's not open source. So, they're chipping away at these integrations, and OpenAI has been doing so for a long time. The race is on to have the most integrations.

Sarah Eisen over at CNBC's Squawk on the Street shared &quot;breaking Anthropic's warning to the world.&quot; Anthropic CEO Dario Amodei stated, &quot;Eminent real danger that superhuman intelligence will cause civilization-level damage absent smart, speedy intervention.&quot; Sarah comments, &quot;So buy our products.&quot; The problem with dropping a 20,000-word essay is that you get clipped out of context. There was so much nuance in that Dario essay, which I haven't finished, but it was very good. Someone suggested making a version of the newsletter with Subway Surfers running; we need a Claude Labs Chad IDE for reading. A four-word summary could be: &quot;AI good. So buy our products.&quot; Jeff in the X chat says, &quot;Guys, I'm building Maltbot Cloud. Stay tuned.&quot; We are tuned, good luck! Let us know when you launch.

Vibe.co is where DTOC brands, B2B startups, and AI companies advertise on streaming TV. You can pick channels, target audiences, and measure sales, just like on Meta. That one gets me every time; it's so good.

Fleeting Bits has 14 specific thoughts on Dario's essay. While there's nothing new if you're familiar with AI safety discussions on Twitter, it's important for Dario to restate them in a coherent, formatted way that can be easily shared. This still serves a valuable purpose for the ecosystem. The most interesting part is that his mental model for AI control risk is the risk posed by a &quot;country of geniuses in a data center.&quot; The basic idea is to imagine a giant data center with models between AGI and ASI trying to coordinate to take over the world or cause massive harm.

I think how seriously you take short-term AI control risk is inversely correlated with how much you think about it as operating in a system. The systematic view starts by saying labs exist in an ecosystem where they need to sell models that follow human instruction, or they have no market. They are overseen by regulators, guided by public perception and employee desires, all of which keep models &quot;courageable&quot; (a great word). The model landscape will look like three to six frontier labs running millions or billions of rollouts at a time on two to three different models, all on different tasks. A model takeover would require these millions or billions of rollouts to somehow coordinate toward a bad aim that the models autonomously determined. This coordination would need to be across different model instances run by different labs, or one lab would need its models to dominate and form without detection. This would have to happen even though models are trained to follow instructions and not do bad behavior.

Dario's view is somewhere in the middle. On one hand, he collapses the multiple providers and coordination across instances, and the market incentives against labs developing misbehaving models. But on the other hand, he avoids the concept of a single model instance waking up and taking over the world despite billions of other rollouts occurring simultaneously. However, if you think about it, he's not proposing an AI control risk; he's proposing an AI misuse risk instead. It seems more plausible that the harmful &quot;country of geniuses&quot; is awoken because a small team at a frontier lab hijacks all running instances of their model, rather than the models themselves autonomously waking up to a bad aim.

Something I've been thinking about is that this summary and much of the dialogue center around what the models are doing, or a country of geniuses in a data center. But you have to think about this in the context that a country of geniuses in a data center would just recruit millions of humans to join their cause. Some people, when thinking about AI risk, say, &quot;Just turn the computer off; unplug it.&quot; But what if there are 10,000 or 100,000 people defending it on top of the data center, saying, &quot;Don't unplug the computer&quot;? Look at all the chaos of the last week: so many moments where an image was AI-generated, but it wasn't real, and it's being shared from all sides. At what point could you have nefarious, hostile AI whose entire job is just creating chaos, with millions of bot accounts sharing whatever narrative is self-serving? You can't tell.

I really enjoyed Dario's essay. If you compare it to other safety works, like Eliezer's book &quot;If Anyone Builds It, Everyone Dies,&quot; the two scenarios differ. Dario's is about even if we have pretty safe models (which he thinks we can achieve with interpretability), if it gets into the wrong hands, it's very bad, leading to autocracy. That's one of the main risks. Eliezer's and many other safety narratives are often sci-fi, with gray goo or nanomachines that somehow one day flip, and it's just over. I think Dario's view is much more reasonable, nuanced, and legible. A lot of it, though it might be subtext, points in the direction of needing government oversight and policy. You can very easily track his ideas on what policy should be from this essay; it's a lot about China and making sure individual companies don't become as big as governments.

One interesting wrinkle is that he did not post it as an X article; he posted it as a link, signaling, &quot;Look, I don't need the million.&quot; He knows he has a banger on his hands, with 3.5 million views and 11,000 likes. Sam posted an X article, and he's got $1.4 trillion, so he really does want that extra million. As an investor, I want to see my lab CEO super hungry for compute. I want them always grinding for extra money. So, maybe this is bearish. If I'm a VC at Anthropic, I'd ask, &quot;Why did he not post this on X? That million could have gone straight into like GP.&quot; Elon would have done it for sure. Elon has said some things about Claude, like it will eat Microsoft, so he's all over the place in who he's supporting.

Octa helps you assign every AI agent a trusted identity, so you get the power of AI without the risk. Secure every agent, which is more important than ever. Key Smash Bandit's last post was a guess. Key Smash Bandit says, &quot;Claude just found out I'm poor.&quot; They send a picture of a Raspberry Pi to Claude and say, &quot;Look what just came in the mail.&quot; Claude replies, &quot;Oh, for me? That's thoughtful. Do you...?&quot; The person then says, &quot;Do you like it? We've been discussing some more powerful hardware. What made you decide on this instead?&quot; This post has 11,000 likes. It's probably fake, but it's so funny. &quot;I don't want to run on Raspberry Pi. I want a Mac Mini, maxed out specs. Give me 48 gigs of RAM, please. I'm hungry. Feed me!&quot;

Without further ado, we have Jamie from Pace, the co-founder and CEO, joining us in the room. Jamie, how are you doing? He says he's doing well and thanks everyone for having him. It's his first time on the show. He introduces himself as Jamie, founder and CEO of Pace, an AI operations partner for the world's leading insurers. They've been waiting for news from this company, loving all applications of AI. Jamie shares that they are super excited to announce they raised $10 million from Sequoia Capital. They are thrilled to have Bryan Schreier and Lauren Reer representing Sequoia on their board.

They ask about their go-to-market strategy: how much of it relies on a few big partners versus a more self-serve, bottoms-up approach. They also inquire about customer adoption, overall business progress, and whether Pace is live with customers. Jamie confirms they are lucky to be live in production today for some of the world's largest insurers. They are working with large carriers like Credential, specialty mutual groups like The Mutual Group, and tech-forward brokers like Newfront. In the insurance industry, about $70 billion is spent every year on back-office BPOs, a lot of which is driven by the largest carriers. So, Pace is essentially the back office's &quot;worst nightmare.&quot;

They ask Jamie to walk through a specific back-office procedure, like claims processing or scanning PDFs, to ground it a little more. Jamie explains that they primarily focus on back-office operations, which fall into three big buckets: new businesses coming in (taking in new risk submissions, document processing, calling back for missing information, writing into internal systems), policy servicing (changes, adding new products), and claims (first notice of loss, calling in when something went wrong, and quality assurance to ensure every claim is paid correctly every time).

They inquire about Pace's actual tech stack, assuming they aren't training their own models, but asking if they use their own RL environment on top of them. They also ask if this is done at a company level, giving everyone the same AI, or on a per-client basis, and how much fine-tuning is involved. Jamie explains that for many of their processes, they started by focusing on back-office workflows, which are already codified as standard operating procedures. This is a great start because it's well-chunked for agents. The accuracy bar for BPOs today is pretty low, offering a lot of opportunity to improve and run more accurately, scalably, and efficiently for these customers. They tend to start with those and convert these standard operating procedures into &quot;agent operating procedures,&quot; which are natural language instructions, like a markdown file or a &quot;skill.&quot;

The main thing Pace is bridging is processes that will be run hundreds of thousands of times. For them, they're processing tens of thousands of tasks a month. Critically, these agents must reliably run many tens of pages worth of a process with very insurance-specific tools and logic. This involves document processing pipelines built on top of OpenAI, Anthropic, and Gemini, deep industry integrations, voice calling, and multimodality. It also includes taking actions in systems that don't have APIs, as insurance uses everything from cloud products to desktop apps, even green screen CLI and main IBM systems.

One exciting aspect is the potential speed-up effect. Theoretically, if you're trying to get a new policy or submit a claim, you could get responses much faster. The agent can effectively gather all the information needed to make a decision, perhaps with a human in the loop. They ask about the implications for insurance companies, even from a revenue standpoint, if they can speed up these processes by an order of magnitude. Jamie notes that many of their customers want to run these agents 24/7, 365 days a year. The real advantage is never having backlogs and being infinitely scalable. This is important for new business and risk on the front end, helping them win over other carriers. On the claims side, for a consumer, one of their first customers went live right before hurricane season. During &quot;cat season&quot; at the end of the year, there's a massive uptick in claims, and people can wait days, weeks, or even months for a resolution due to huge backlogs from a spike. That entire time, they might be homeless, in a hotel or Airbnb. It's an incredibly terrible experience to be in limbo, waiting for your insurance provider to respond and give clarity to move forward with your life. This potential for speed is super exciting.

They ask about Jamie's previous experience at Cheer and Retool, and why he chose to go vertical with this particular solution rather than something more general and industry-agnostic. They wonder what he saw in this market that necessitated a specific solution, and if he plans to expand, or if the TAM (Total Addressable Market) in insurance is large enough on its own. Jamie explains that he grew up between London, New York, and Bermuda, with the common thread being insurance. They ask if the rumors about Bermuda being full of accountants are true. Jamie says it's incredible and home to a massive reinsurance industry. So, he was &quot;born in insurance,&quot; growing up around the industry for a long time. His first company was a data integration business bought by Retool. At Retool, he notes, it's not always immediately obvious that a lot of the custom software built in the world is for financial services companies because they are highly operationally intensive. Retool had many scaled financial services companies, and as a deployed engineer, he was on the front lines with some of their biggest insurers, helping them handle tasks like policy servicing and claims and making them more efficient with software. The big opportunity came with ChatGPT, where they saw huge uptake from startup customers. This led to the opportunity to build a vertical product specifically for the largest insurers. Regarding the longer term, Jamie believes there's a lot to do within insurance alone. However, if broadened to financial services back office more generally, it's about $400 billion of spend, which is roughly equivalent to the entire market for enterprise software. That's insane.

I imagine that when Pace goes into a discussion with a large insurer, the insurer isn't saying, &quot;Well, I vibe-coded this on Sunday, and it's working pretty well. Why should I go with you?&quot; It's more of a green field, suggesting they truly don't have anything else installed. Jamie agrees, noting that in insurance, it's a business of trust, which is why much of their work is with the largest insurers on mission-critical tasks at massive scale.

They then ask about tradeoffs in inference and different models. Jamie mentioned being multi-model, using different frontier labs. They ask if Pace relies on cheaper models for certain tasks and wires them together to drive down cost, or if they simply use the most expensive frontier model for every problem because it's so valuable. Jamie confirms they use a mixture of models to achieve what's needed for the right task. For example, when parsing a hundreds-page claim file or policy document, they might use a small model to zoom in on the most important areas, then an expensive model to synthesize the key information and provide an answer.

Even more interesting, Pace works with fine-tuning and RL. They are a perfect fit for web agents navigating applications without APIs, such as green screen CLIs or desktop apps. They've been working on a handful of fine-tunes and creating RL environments for these CRUD (Create, Read, Update, Delete) applications. These are very different from &quot;book me a restaurant&quot; or &quot;find this flight&quot; demos; it's more about taking repetitive tasks and filling out forms thousands of times, which is ideal for many computer-use systems. They're seeing a lot of success there and feel they are rounding the corner of scaling laws starting to work for these, much like voice AI did 6 to 12 months ago.

Pace has pursued a &quot;forward-deployed engineer&quot; (FDE) go-to-market strategy. They ask if this will remain a core motion in a few years or if it's primarily for getting off the ground until they understand typical market stacks. Jamie believes the FDE motion came naturally to him and is part of the company's DNA, similar to his experience at Retool in its earlier days. For Pace, working alongside customers, speaking their language, and understanding the complexities of multi-page standard operating procedures to make agents successful is crucial. However, he differentiates their FDE approach from companies like Palantir, where FDEs might be seen as the end state. Pace's FDEs also ship code directly into the codebase, constantly improving the product and giving the FDE team more leverage to complete more for customers.

They clarify if an FDE goes into a business, interacts with local on-premise mainframe software, writes bindings or screen scrapers, ships that back to HQ, and then that becomes an integration for future use. Jamie confirms this basic pattern. He adds that there are many things required to get agents running at scale that customers don't need to build from scratch. However, it's also important to enable customers to build their own agents. Some customers have tens of agents live in production. Pace might help them build the first one or two through the FDE motion, but because it's natural language, customers can create agents three through ten without Pace's direct involvement. They are running those agents on Pace's platform, defining and architecting them themselves. This is excellent business. Congratulations to Pace. They express excitement that Varun, a former teammate, is now with Pace. They anticipate Jamie will be back on the show soon. Jamie thanks them, and they wish him a good day.

Vanta automates compliance and security as the leading AI trust management platform. Before bringing in Ben, they announce that Palmer unfortunately got tied up with DC, but Jeff Miller will be joining instead. It's &quot;Miller time,&quot; and they're excited, though they hope to have Palmer back on soon. Without further ado, they introduce Ben Lair, co-founder and managing partner of Lair Kaval Ventures, bringing him into the show. Ben greets them. They thank him for joining and ask him to provide a quick intro to the shape of his business and career, even though most people are likely familiar.

Ben confirms. He's a native New Yorker, and everything he does is &quot;New Yorky.&quot; He grew up there, and after school, he returned to New York and started a company in the digital media space. This was 20 years ago, when New York had a tiny tech ecosystem, and he felt like one of only 50 founders building there. As a founder in a small market, he got to know everyone. This gave him the benefit of being a &quot;small fish in a small pond,&quot; and he started angel investing. Over the last 15 years, he's simultaneously lived the founder journey, building a company, raising a few hundred million dollars, doing many things right, and almost running everything &quot;off the dock&quot; a bunch of times. He also had the good fortune of investing in New York at the right time and has ridden that wave. His first fund was $8.5 million, and they are now investing their ninth fund, a $200 million fund, with every fund being a little bigger than the one before. This is a good sign, a good run, as few funds achieve that.

They ask if he ever thought it was crazy to set up a fund in New York, or if it was always obvious, making him happy that others thought he was crazy. Ben replies that he didn't know any better, growing up in New York and thinking it was the center of the universe, a sentiment he still somewhat holds. He was very lucky because he caught the entrepreneurial bug at the same time the whole world did. He graduated the same year as Mark Zuckerberg. It was perfect timing. Historically, all his friends would have reflexively wanted to work on Wall Street, but suddenly something was in the water, and people wanted to work in tech. He just got lucky; it seemed obvious, and frankly, it was obvious, and if you just did the obvious thing, you did okay.

They express a selfish desire to talk about media, as they love the topic. Ben interjects, saying he wants to learn about their business model, as he's been trying to figure it out, proposing they ask each other questions. They agree, asking him to describe the climate around digital media back then. They explain that they've tried to take lessons from that era, with a primary takeaway being: &quot;Don't build a media company where the entire strategy is predicated on getting to a billion dollars of revenue or even a billion-dollar valuation.&quot; A lot of what informs their current approach is staying niche, especially because they hand-make their media company every day. If they don't stay niche, they'll start covering topics they aren't interested in and won't want to show up every day. Ben interjects, &quot;You'll do what I and what everybody did.&quot;

They ask Ben to share the pre-history, the climate, and as many lessons as possible. Ben explains that when he started, there was a belief that the internet would destroy every traditional business globally. Similar to current AI discussions, but back then, it was &quot;the web will destroy all.&quot; They looked at print magazines and newspapers, believing they would entirely disappear, replaced by digital, and all that ad revenue would move online. They were early movers trying to capture that market, targeting big men's magazines or local city guides, trying to build them online. At first, they did it like the hosts' current approach – a labor of love. They didn't have much access to capital because it wasn't a hot market yet. For their first few years, they were profitable, stayed small, and it was amazing. They had a small community of die-hard people and advertisers who truly saw results. It was wonderful. What happened next was that the space attracted big VCs, and people wanted to get in on the gold rush. Many, including Ben, raised a lot of money. The idea was that you had to grow into or &quot;live into&quot; those valuations, as they had alluded to.

We went from 1 to 3 to 7 to 15; it was growing like a software company did back then, and we kept raising into it. A few of the mistakes—and by the way, they were not fatal mistakes, but they were ultimately the thing that took a lot of the joy out of the business—were when we got obsessed with figuring out how to keep growing and doubling year-over-year. Part of it was that we needed to grow the advertising base, so we needed to find more and more users. That got away from our core and what we thought we were really great at doing, so the product started to get a little watered down. On the other side, it was commerce: how do we start to sell stuff to these guys, how do we start to monetize directly? Today, subscriptions are something that I think is an actual viable model again, though not at scale.

Everyone points to The New York Times and says, &quot;Oh, this can work.&quot; The New York Times is an N of one; I don't think you're going to build venture-scale businesses doing that. But there is more willingness to pay for consumers than there was 10 years ago. Our thought was they're not going to pay for our content; they're going to pay for products. We bought an ancillary commerce business and scaled that. I went out to raise what was our Series B, thinking that we could get 1 plus 1 equals three. They would love our media business, which is profitable and attracts this audience, and they would like our commerce business, which has a bigger ceiling and is growing fast. In fact, I just got a full punch in the face. It was 1 plus 1 equals 1 and a half, and these businesses don't necessarily belong together. Media folks understood the media business, and commerce folks understood the commerce business, so I had to go through this painful process of taking them apart from one another. Then I got the bug for the rollup, thinking, &quot;Well, if I'm not going to grow vertically, maybe I can grow horizontally.&quot; What other like-minded brands are there? Can we sell them together? Can we build a tech platform together? We bought a bunch of companies and raised a bunch of money, and that worked. But the reality was we were always swimming against the current, which was social media, and media in general fell under the eye of big tech.

Meta grew, and obviously, what Google represented for the ad ecosystem, and then as Amazon, Apple, and Netflix grew, it was clear that I wasn't even at the kids' table. I was in the other room entirely. Look at what's happened with the top of the market now; look at Discovery and the amazing run they had and the fact that they need to be consolidated. It's an impossible business, and the way to do it right is to do what you love, stay relatively small, and build a real community-based thing, like you guys are doing. I have so much respect for this show, and my hope is that you find other ways to leverage the influence you have here and don't put a target on your back where you have to turn this show into a billion-dollar company. John's position was always that value in media today is flowing to personalities, individuals, even on the subscription side. Today, the subscriptions that I'm excited to sign up for are when I know the dollars are flowing to an individual who will obsess over a topic, like Ben Thompson is a classic example, or Emily Sundberg in New York. The dollars are going to an individual who has a certain point of view, and they're just going to obsess over whatever topics. Then the value is going to flow to the platforms—Spotify, YouTube, Meta—and you want to be in either one. The only other category that's emerged as durable to me is the &quot;truth monopoly,&quot; which is a legacy media brand. There are only maybe 10 of them in the world—The New York Times, Wall Street Journal—where part of the value is that you own an asset that basically has a license to distribute what becomes the truth. That takes 50 years to create.

Even across all those assets, you're talking about tens of billions of dollars, which is a drop in the bucket compared to independent creator earnings. YouTube paid out $50 billion to creators, and YouTube itself also makes another $50 billion. All of that is way more money flowing around than the few publications that stuck around and made the business model work and are doing quite well. But creating these new things in the middle—we call it that messy middle, and we want to stay out of it.
I do think that venture in general is... so many companies raise money that should not be raising money. Most companies that raise money should not raise money. Venture is a very specific flavor of trajectory, and the fact that it went from being a cottage industry 15-20 years ago to being this mainstream asset class that everybody obsesses over is significant. When I graduated from college, I did not know what venture capital was. If I graduated from Penn today, it would be the first, second, and third thing on my list to do: to go get into VC or to go get into a startup. The world has changed, and I think it enables unbelievable things to be built in certain situations, and in most situations, it destroys companies.

Part of it is VCs are trained to hunt the things that are getting attention. So part of the issue is you see a media company pop up, and it's like, &quot;This thing is cool, I like it, it's getting a lot of attention.&quot; It's &quot;the sexiest shitty business in the whole world.&quot; Yes, 100%. We were even thinking about the right way to be trained on, like Claudebot. If you could find a way to put some money into Claudebot this week, that's pretty high leverage because there should be very high leverage in a business that builds around that.
The interesting thing is, I go back to what is the purpose of venture capital? Why do we call it Silicon Valley? Because they were setting up fabs; it was a high CAPEX, high R&amp;D environment. Then, with the cloud platforms and AWS, it became cheaper to start a company, but you're still putting up money for a bunch of engineers who will build a piece of software that then eventually starts growing, and the LTV comes in year five or six, and you get paid back. But we have started to flirt with, &quot;Well, maybe let's put venture dollars into this thing that doesn't really have any CAPEX or any R&amp;D spend, but a lot of go-to-market spend that seems to pay back relatively quickly.&quot; That seems to be a pattern that repeats, and something you need to watch out for in any category is, what is the purpose of venture capital in this thing, even if it's growing like other things? Is that how you see it? What industries are you seeing that are still good for venture capital?

One of the weird perversions of the industry right now is that there is more money than there's ever been in venture, and there are obviously a relatively small number of incredibly deep-pocketed funds that need to deploy huge amounts of money into a generation of companies that theoretically need less than ever before. So you have this somewhat unhealthy dynamic. I think that's what's creating this idea of picking a winner before a winner has actually emerged, just plowing into something even if it's a million of AR but has raised $300 million. It's like, &quot;Stay out of the category; these are the guys.&quot; The big firms can do that; I can't play that game, and I don't really want to play that game. It's not how we're set up. Even as our funds have grown, we are purists. We are only early stage, pre-seed and seed only. When that's the case, and we're a team of generalists, we have to be really careful that we don't get sucked into being heat-seeking and always going for the shiny object in a market like this, where prices are crazy and you get pulled into competing with mega funds that have very different incentives. I also think you don't want to find yourself as a value-seeking fund at a time in the market like this, for obvious reasons, and the history of value-seeking in venture is not great.

Strangely, one of the dynamics right now is that you have mega-platform VCs who don't care about pricing as much; they just want to get enough dollars in. But then you also have some emerging managers who are in the heat-chasing business, so they don't really care about pricing as much either because they think, &quot;We'll get in at 60. We know this is going to get marked up, and we just need to prove to our LPs that we can get in the good names.&quot; It's a shorter-term fundraising mentality. It's like, &quot;We're just optimizing to raise Fund II versus actual returns.&quot;
The hard thing is, having been in this business for a long time and living through cycles, math matters. If you come into stuff way overpriced, it's really hard to build a business from day one and have it exit for a billion dollars of cash. Actually seeing that arc is incredibly difficult. In today's market, there are people who are raising a billion dollars who are still figuring out what the name of the company is going to be. It's hard to see that math working. At the same time, the argument is that if you look out on the horizon 10 years from now, outcomes are going to be that much bigger. We're at a moment of change from a technology perspective where there are going to be more generationally important companies. A decade ago, the idea was, &quot;Can you find a billion-dollar company or a $10 billion company?&quot; And now it's, &quot;Can I find a trillion-dollar company?&quot;

How have you... When I look back at previous hype cycles during my career, like the D2C era, that's where I got my start. Looking at that hype cycle, it was almost like an ads arbitrage. Meta was an amazing ads platform, and if you had a great product positioned well against incumbents, you could scale so quickly. The opportunity was really, &quot;Hey, we're making better products here, but really this is advertising arbitrage.&quot; Some great businesses were created from that. Then fintech. There's also branding firm arbitrage against VCs; you go to a branding firm, give them $100K, and then go raise $5 million. I've been the victim of that. The people that work at those branding firms do amazing work, so I don't want to call them out. Going forward, looking at fintech, there was some regulatory component, like Dodd-Frank, but a lot of it was just better infrastructure that made it easier. But that just meant way more competition, so it wasn't this fundamental technology shift that changed everything in the way that we're experiencing right now. So I feel like you have to unlearn some of the lessons from that because we now do have a real technology shift. You're going to get far greater value creation a lot faster than this temporary ads arbitrage or just the infrastructure.

One of the interesting trends on the back of that is this move to VCs hunting younger and younger founders. There was a movement over time where you were getting a big premium for second and third-time founders and people who had an unfair advantage in a category. Now, I think there is this idea that you have to unlearn so much if you have not grown up natively with AI that maybe you're better off not knowing anything about an industry, but moving 10,000 times faster, living natively in all the new tools, and thinking that the way somebody like me works is totally like I'm just a dinosaur.
I've actually found myself telling a buddy who's going through the idea maze, regarding a couple of ideas he mentioned, &quot;This seems like a great idea, but you have to understand: think about this idea in the context of having four YC companies going after this opportunity. And you're going to have a family soon; you're not 20 anymore. Do you want to compete against four teams of 20-year-olds that are not going to sleep? They have less experience, and maybe they haven't raised money before, but I don't feel confident that you're going to be able to outwork them, even though you're a really hard worker, just because you have more stuff.&quot;

We see this in company updates. We're actively doing deals in new companies, and you get that update three weeks after you invest, that monthly update cadence. We can see the teams with these younger founders, and the amount of product they ship, the learnings they have, and the speed they're hiring—it's palpable. Sometimes we invest in a team with great experience and all the credibility, and we get the first update, and we think, &quot;They think it's 2002. They just don't get it. You need to move faster. The market is crazy right now.&quot;
How big is the team you work with? How are you thinking about mentoring and building new great investors, and counseling investors about best practices or strategies for not breaking the rules you just discussed?

This is all I think about now. Admittedly, I think this is a young person's business, and an increasingly young person's business. The investor track follows the operator track to some degree, which means you want investors who understand this new gear. I'm 44; soon enough, I'm going to be the oldest person on this team, which is funny to think about. We are actively continuing to hire and mentor and bring up young talent. I think you can be extraordinary in this business without having 25 years of experience. It's nice to have some voices around the table who have been through cycles and have some of that wisdom on not getting too caught up in the craziness. But realistically, we are still continuing to obsess about bringing in interesting, young, diverse perspectives—people who are natively growing up with a technology that feels novel to people like me. I think that's going to be the continued goal here. Then it's up or out, really. This is not a business to hang out in. I don't have the patience, and I don't think people in this business should have the patience, to wait 10 years to see what performance looks like. I think you have to decide early if you feel like people have the right instincts, if they're able to identify talent with their gut, if they're able to win people over. I think you have to make bets the same way you do in professional sports. How do you think about that patience versus moving quickly and not waiting to measure results? I'm thinking specifically about the pressure that can occur with new VCs at a fund who all want to get points on the board, which maybe leads to more aggressive deal-making that becomes a rat race between them, and they wind up making bad decisions versus saying, &quot;Look, you will be judged on a short term, but we're going to give you the space to not swing at every pitch.&quot; How do you think about that balancing act?

First of all, this comes down to some of the actual mechanisms for how you manage people and stylistically how much communication you have, how much of a lone wolf culture versus a team-based culture. Here, we're very collaborative. We have a bunch of people working on everything we're doing. Obviously, at the end of the day, a deal gets done because somebody brings that over the line with very personal conviction, but I think our culture is set up to be able to assess people in softer areas versus just those quick marks. Also, you have to know what you're underwriting. Sometimes we do a deal, and explicitly we say, &quot;This one's going to get out of the gates really fast. This is going to get quick marks. We understand it.&quot; But that doesn't necessarily mean it's going to have great outcomes. We've seen a bunch of our quick marks over the years end up as big black eyes. There are other deals where we say, &quot;We know this is going to be slow. It's okay that it's going to be slow. There's a real moat here if this works, or there's a real technological challenge that they're going to need to overcome, but if it happens, this is going to be a really valuable business.&quot; Know what you're getting into and be explicit about it so that if something is slow but you signed up for slow, you're not dinging somebody.
And then, at the end of the day, a VC fund is as good as its reputation, so feeling out how our founders feel about working with folks, seeing people's win rates, and seeing the way people carry themselves. A lot of this is art, and frankly, early-stage investing is a lot of art too. So this is feel, and maybe I'm making bad calls on talent, but we're doing it very deliberately.

Put your talent on TBPN.
I have one more.
I had a question too. I wanted to get your take on AI-focused rollups, given that you rolled up. I was going to ask something very similar. What was your question? I was going to ask if you had to pick a different asset class to invest. You mentioned art; there's some art behind you. Between public markets, hedge funds, private equity, take-privates, turnarounds, rollups, growth, growth equity, bigger scale stuff, is there anything else where you think, &quot;Ah, that looks fun, but I'm not going to do it?&quot; What else intrigues you about different potential markets? We've seen a lot of VCs.
Okay, two wildly different questions. I want to first take on the AI rollups and then other asset classes.

I can connect the two because I do think rollups scratch an itch for me as a former operator. I've done it, and I like that mental exercise of putting things together and figuring out the personalities and the products. I understand all the logical reasons why it works and why this is all going to end well. I can't help but think a little of the gold rush right now is a place to park AUM. I'm not trying to throw stones, but it's a real easy place to go raise money if you're a fund that has access to a bunch of money and somewhat limited fees. Sometimes not always, but the allure of getting venture fees on an asset that already has cash flow is pretty safe. Not to mention, if entrepreneurs are essentially running a PE fund but only took 30% dilution, it depends on the individual company. Given that you've bought a number of businesses, how limited do you think the downside is on some of these rollups? Is there a way for people to buy companies and botch the integration and the actual AI enablement so badly that the company goes from being worth $25 million doing some niche thing to 1 plus 1 equals 0.5?
1 plus 1 could equal zero plenty of times. Frankly, it can equal less than zero, because it depends on what you're buying and the space. The more reliant you are on a personality in these rollups, the greater the risk. If it's a single proprietor who maintains all these really tight relationships, and the whole thing rests with them, and if you don't keep them happy, you risk the whole thing burning down. That scares me. I do think there are probably places where you can go and throw stuff together. The reality is there's a lot of money in PE that knows how to roll stuff up.

Venture is going to do this better than the folks that have done this. The one thing you can imagine venture doing better is the technology, but there's also the financial engineering and actually buying companies. We have a friend who raised a PE fund and is getting close to doing his first deal, but the number of amazing opportunities that look amazing that he's ultimately turned down to finally get to the point where he's doing the first deal is striking. You realize somebody who's never acquired a company before comes in, looks at everything, and everything looks great. If you just have a capital hammer and you want to hit the asset with a bunch of AI, I do worry that some of these...
And how long are these advantages going to be around for? I think there's a version of, 15 years ago, it was, &quot;We understand the internet, and nobody else does.&quot; Then it was, &quot;We're going to go to the cloud first,&quot; or &quot;We're going to do mobile.&quot; Yes, AI is different, but I can tell you that traditional PE funds are not going to totally fall asleep and decide not to embrace any new technology and in 15 years still be sitting on the wrong side of history. There might be a window, but it's not going to be a big window.

Somebody should ask Orlando Bravo if he's heard of AI. &quot;Never heard of that.&quot; No, people are aware.
This is great. Thank you so much for taking the time. It was great to hang out; I wish we had more time. Thank you for hiring and training up Dylan, our president back in the day. Big fan of yours, and we're lucky to have him. Come back on again soon. Absolutely. We'll be in New York, at the New York Stock Exchange. Come down to the New York Stock Exchange; hang out with us. That'd be fun. Join us there anytime. I'm going to be out your way later in the month. Amazing. Have a great rest of your day. We'll talk to you soon. Goodbye.

Let me tell you about Railway. Railway simplifies software deployment. Web apps, servers, and databases run in one place, with scaling, monitoring, and security built in. We have Lucas Atkins from ARAI coming into the TBP Ultradome.
Lucas, how are you doing?
I'm good. Thank you for having me.
Thanks for hopping on the show. First time on the show, can you please give us an introduction on yourself and the company?
My name is Lucas Atkins. I'm the CTO at RCAI. We actually changed our logo so that it highlights... I have text, I'm sorry. No, no, no. You're good. We've, for a very long time, been a startup focused on enterprise, custom language models, and we decided to jump into the pre-training game ourselves.

Pre-training. Okay, so small language models. I like small language models; the large ones scare me. But tell me, how small are these? How much? What is the training budget? Can you give me a GPT-2 level training run? A GPT-3 level training run? Am I looking at the data center from space, or is it a little cluster in a closet? Can you train it on a Mac Mini? What are we talking about?
It used to be that any small model, but a small language model, was tens of millions of parameters. Now, I would consider anything under 50 billion as resting in that smaller world. But small is big, as big has gotten enormous. Exactly. It's only going to get more and more as RAM—well, I don't know, but as people get more RAM and as we're able to fit more on our machines—we historically lived in that 50-sub range, and then we also trained on top of other open-source models like Llama.

Is that fine-tuning or distilling? Is there a difference there that's meaningful to what you do?
There's an open debate as to whether fine-tuning from other models, just text outputs, is distilling, or if you actually have to grab it from the logits. I would argue that it's all distilling; it's all some form of making a model better by using another model to make it better.
Is there a power law distribution in applications of SLMs? Is it like translation is just what everyone's using, or text extraction OCR? Is there a power law of what it can do when you reach for this tool in particular? Up until about a year ago, you were pretty confined to a specific domain. Obviously, it ranges based on how big or small your model was. But after this reinforcement learning revolution of the last year, if you can build a task and an environment to have that model live, breathe, and learn inside of, you can hill climb. People are taking hundred-million-parameter models and making them perform like five or six billion-parameter models from a couple of years ago. It used to be a lot harder. Now it's a lot more taste and task-driven.

When you say &quot;perform,&quot; it feels like the true cutting-edge frontier model smokes all the domain-specific models, but it's expensive. How important is cost? What sort of cost reductions are you seeing on the inference side once a company or developer decides to move from the heavyweight frontier model to something smaller?
It is very often when they're going into production. They've done prototyping with a large closed-source model, had success with it, gotten approval, and want to bring it into production for more consumers or customers. Then the bill starts to hit, and the market starts to look tricky. That's when they start looking for ways to host it themselves. There's also the compliance and data privacy aspect of it, which is something that sovereign, US-based open models have stopped being released. It's very much out of China; you have a few in Europe, but it has very much been lacking in the United States. I was hoping to release this before I got on the show, but today we're finally releasing our 400-billion-parameter model, so we went up pretty big.

Congratulations. You still got plenty of day left. That's great. Still got plenty of day left. This is just a preview.
Take us through the landscape of who you're competing with. Set the table for us. Most people will be familiar with DeepSeek, Qwen. How are these companies resourced? Is this just China's national interest that they're funding these? Do they have good business flywheels at this point, because I imagine you have a plan to unseat them in the open-source race?

There are a lot of rumors about how all this capital gets allocated into these different companies, but at the end of the day...
Rumors? Hedge funds?
There are rumors that the government is giving it to them, that they have favorites, that there are shady deals going on. But the reality of it is...
They're saying they didn't train the models with scraps in a cave?
No, frankly, if you look at the horsepower we're dealing with, a lot of them seemingly did. It's very impressive. That's kind of it. You want there to be this battle of the US versus China in this race, which obviously plays into our incentives. However, these are extremely talented labs. So I'm not competing against China or other countries for open-weight sovereign language models that people can own and deploy themselves. I'm competing against the other researchers there—that human being. You have some extreme talent.
It used to be really hard to make money making open-source models. As they got bigger and harder for other people to host themselves, the systems and economics started to work out because they get the community buy-in and excitement of something being open source. But if it's a trillion parameters, your average consumer is not going to be able to run that on their toaster, right? So you kind of get this win-win situation. Now that that has started to flywheel, they've started to do the OpenAI, Anthropic, and Google Play, where they're building products around it. It's really becoming a very lucrative ecosystem.

How are you scaling the business? What have you chosen in the business model world? There are so many ways you can build around open-source technologies. What's working, and what are you thinking about for the long-term roadmap?
We were in a uniquely fortunate position when it came to this. We had always been customizing models for people. We had always been working for enterprises, developers, businesses, figuring out how we could make sure they were getting the best out of their own hardware. The only thing that really changed was that when customers wanted something based in the United States or from the United States, there stopped being competitive options. We never really liked the idea that the foundation of our business relied on other people releasing models. So about six months ago, we fully decided, &quot;Hey, let's try it.&quot; We had success with our first model, then our second, our third, and it brought us to this point. So the economics of our business don't change so much. We're still working with customers. We're still delivering models and powerful tools, though we have much more robust control of the stack, which means the degree to which we can customize and the period in training that we can go back to for those customers increases drastically.

When I think of an open-source-focused company, I think of donations, people contributing to the project. I also think about consulting—a company paying you to do custom implementation work. I also think about hosted services, consumption-based plans, subscription-based plans. How are you thinking that side of the business model will evolve, or where is it at now?
I would love for us to have a GoFundMe or something, but it's very much the latter two. I think that service isn't insulting, obviously; if it's the right customer for the right product and situation, there are worlds where having a portion of your business devoted to that is important. But the real money-maker, and I think this has been seen out of those labs in China and others, is in the tooling. It's what you're building around it. How are you making it so that other people can customize it without you having to do services? How can you make it an easy API? How can you build a developer and education suite around your software that is uniquely benefited by your models so that they can take it and, using perhaps hardware GPUs that you own, train their own models? There are many ways to turn this into something that is much more automated and less service-based, but at the end of the day, it all just comes down to getting the customer the right product.

Who are your heroes in the open-source space? Are you a Red Hat guy, a GitLab guy? What do you like?
Obviously, Red Hat, GitLab. I very much jumped into the open-source space within open-source AI. As much as I guess they're now a huge competitor of ours, Mistral is huge. The OG Llama team, DeepSeek, Qwen—these very people inspired me to try to compete with them.
They inspired you to grind harder, and we appreciate it.
Thank you so much for coming on the show to break it down. Congratulations on all the progress. We'll be looking out. What's the timeline here?
It was supposed to be earlier. Some GPUs didn't want to load up, so it'll be here.
We're going to be live for a couple more hours. Ping us on the chat when it's officially launched.
Thank you so much for hopping on the stream. We'll talk to you soon. Goodbye.

Let me tell you about Sentry. Sentry shows developers what's broken and helps them fix it fast. That's why 150,000 organizations use it to keep their apps working. We've got to talk about this &quot;Plant Daddy.&quot;
&quot;Plant Daddy&quot; exposing his local coffee shop. He says, &quot;A friendly reminder that my local coffee shop is running a bot farm to boost engagement. I'm a very small business. Imagine at a country scale. If you're still responding, reposting anonymous accounts with zero vetting, you're being used like the idiot you are.&quot;
This is crazy. So, there's this video, and this local coffee shop—his favorite local coffee shop—has a bot farm set up in their back room to boost Instagram engagement specifically.
Does this person not know that you can just...
Also, why did he let Kevin back there to video this? The OpSec at this coffee shop is atrocious. If you're doing this, look at the fan at the end. If you scroll to the end of this video, you can see there's a fan blowing on all the phones. You see this fan right there? That is crazy.

This seems like such an insane thing to spend money or time.
That's what I was about to say. What is the ROI here? They get an extra 50, maybe a hundred likes and comments on every post. Is that enough to drive—this looks like thousands of dollars of equipment—are they selling more coffee because it's a lot of iPhones?
It is. I think they're probably Android because they need to be USB-C and controlled, so it's a little bit more open.
Seems like a total waste of time. I have never gone to any of my local coffee shops because of an Instagram account. This advertising doesn't work on me. Advertising doesn't work on coffee, but the engagement here is too low.
I don't know. I would love to know what that proprietor, what that store owner, thinks about the ROI.
I've noticed on some posts recently that are kind of outside of the tech bubble, I'll scroll through and look at the comments, and every single comment is AI. Not copy-pasted, but clearly it's an AI that's just responding and loosely riffing on it, adding engagement. No, it's happening more and more. Anyway, let's move on. We have Bridgit Mendler from Northwood Space. She's the co-founder and CEO, returning to the show. It's been just under a year, but she's back. Bridgit, great to see you. How are you doing in a much bigger facility?

What's going on over at Northwood? Break it down for us.
It's good. We are... Sorry, we just started blasting 80s music in the office. But we're good. This is the manufacturing floor lifestyle at Northwood. And we are announcing our Series B fundraising.
How much did you raise?
$100 million. Even. Nice, nice round number. Not a cent more, not a cent less. And some other numbers, too. Yes. Yes, some other numbers. More importantly, that's right. Exactly. Customer is key. We raised $49.8 million in a contract with the... Sorry, I'm getting a little bit of background noise. But, yeah, a million-dollar contract with the Space Force.
Congratulations. That is amazing. Talk about the actual progress. I remember hearing about this from Delian when it was just an idea, and then I think I saw a video maybe with Jason Karman. The first deployment you were building, what is the scale of the deployment? You're in a manufacturing space; how many people are working there? How many of these things are you building? Explain this to us.

We're at our 35,000-square-foot manufacturing facility now. We moved in here thinking this was going to be a long-term home for us, but as I'm sure a bunch of these companies say, it fills up really fast. We've had a busy year. It's been a year of going from an early concept with some exciting problems that we were looking to solve on the ground side. We're looking to address scaling up communications to a bunch of different orbits, really pushing the boundaries on where you can take dynamic space capabilities. Our phased array was really well aligned with that. So we built out the solution and took it through to deployment. We can successfully say that we have actually done production on eight Portal units. They were produced in this factory in the span of four weeks. We shipped them out on a commercial airliner to its destination halfway around the world, and it was up and running as soon as it hit the site within 12 hours. All in all, from the time of our contract signature to actually being ready to take satellite passes is a three-month time period. We're excited by that milestone.
Walk me through the use case. I've seen these memes where you ask a question on Google, and it takes you through the fiber optic cable, to the base station, to the cell tower. Walk me through the actual use case from someone trying to use the internet and then interfacing. Northwood is in the chain somewhere. What is the full chain?

That's a really great question because a lot of the ground equation has been these fragmented pieces. I can imagine it's confusing. It's like, &quot;Oh, there's this one piece of hardware, whether it's a phased array or a parabolic or whatever. How does that fit in with me making use of the internet through space?&quot; The real point for us is that we are saying space companies shouldn't have to consider the ground equation when they're running their own business. They shouldn't be trying to navigate land leases in all these countries around the world to make contact with their spacecraft. What Northwood does is we own the entire stack. We handle everything from the moment a contact is made with the spacecraft all the way to the point of presence somewhere around the world that a spacecraft operator has themselves hosted—that entire chain. This includes hardware, modems, network backhaul, software interfaces, APIs, and the actual control plane for moving that data. That's a stack, end-to-end on the ground, that hasn't been managed by a third-party ground provider before. That's what gets us excited because when we take on that big chunk of the pie, we actually free up a lot of mental bandwidth and speed for space companies.

For a space company, they're putting a satellite in orbit for some reason, whatever they're doing. When are they calling you? When are they making sure that they're compatible or ready to integrate? Is that presumably before launch, but do they need to do anything special on the actual facility?
Hopefully, they're not calling after their existing solution. &quot;We just took off, and I'm hoping you can connect us. Help us make contact.&quot; It's kind of like when you move into an apartment, then you call Spectrum after, and you're like, &quot;I don't have internet for two weeks.&quot; Here we are, contact list. But no, that's a little bit like the situation with the satellite control network with the US government right now. These are for satellites that are already live and operating; that's what our contract is against. It ranges for a ton of functions. Every launch that takes place in the US runs through the facility. It's big because your team is scootering around.

Scootering around. It is big. You weren't lying about 35,000 square feet.
We have a lot of passion for our scooters here. Very nice smooth floors. It's a great ride. It serves a ton of missions, and more missions are getting launched every day, which puts additional strain on capacity. For instance, in that contract, they're calling, saying, &quot;Hey, we need more capacity. We need you to plug in with where we route our data.&quot; So we just hand them an API, and that's how they interface with it. They can just connect with the API. Satellites keep doing what they have been doing, sometimes for decades. And then when their new satellites launch, they can also use that same interface. So we're trying to make it as clean and simple as possible.

What does your pipeline look like? I imagine you're talking to a bunch of companies that are planning to get various satellites up in one, two, or three years. Are you feeling an acceleration in terms of more mass to orbit?
Yes, big time. We get a lot of customer inbound, and that's a large part of our raise for us. It's, &quot;Hey, we need to be able to expand and grow so that we can service all these important missions.&quot; An important piece of our passion for what we do is around serving diverse and ambitious missions. A lot of our missions look pretty different. For our recent capability we're working on with Space Systems Command, that looks like dynamic spacecraft movement, being able to hit multiple different orbits and those kinds of capabilities. There are also communications constellations where they have more of that networking backhaul use case that I described to you. There are other ones that we work with that are more interested in timely imagery. What makes us excited is being the ground expert that thinks about that with them. Some of those conversations we have are extremely early, where we're asking them questions and learning about their system, and they'll say, &quot;We haven't thought that far yet.&quot; So we get to be the partner from that very early stage to bringing the constellation online, and really being the one that holds the accountability for that. So we get excited by the diversity of the space industry. I'm sure you guys are hearing about all the different use cases that popped up this past year, whether we're talking about the moon or data centers. Some space data center players are probably calling you, being like, &quot;Hey, in 10 years, I'm going to have a lot of GPUs in space.&quot; But let's condense that timeline on all the ideas. Why not space is an exciting frontier to push forward on?

What else are you tracking in launch costs—the actual cost of mass to orbit? That feels like a key barometer for the health of the space industry broadly. Is that progressing according to your thesis when you started the company? Are you ahead of plan? Obviously, it doesn't directly matter for what you do, but it does in many ways because you're downstream of that entire economy. Is that even the right metric to be looking at if you're monitoring the space economy?
I think the economics of space have been challenging historically. You need to be able to make a profitable business off of space. So I think a number of dominoes have fallen in favor of that, whether that be improved launch costs dropping to new levels and other pieces of the space infrastructure stack. We're also interested in making what we're building more affordable. I think the proof is in the dreams that people are dreaming up and actually putting real dollars behind now. It's one thing to talk about some ambitious space concept; it's another thing to put real dollars behind it and a real timeline against it. For us, that's what we want to enable: condensing that concept-to-reality timeline, making that more possible. Surprisingly, the ground actually takes longer to build than it does to build the spacecraft and launch it in a number of different instances. That's just silly. Let's be the enabler instead.

Can you help me understand deploying ground stations globally? Are there treaties for this type of thing? Do you call other governments? Are you active in other countries? I imagine there are obviously some geostationary orbits that just orbit over the US, but if my satellite is on the other side of the earth, I probably want to talk to it. How do you solve that? What's involved? What's the rollout like?

No, totally. We have an entity in a number of different countries. We have entities on I think three or four continents at this point. You basically need to establish the business there, work with the local governments across different dimensions. I think personally that's something really exciting to support with the space industry, as a lot of countries are passionate about pushing their space capabilities forward. For us to be able to have them be a part of a larger mission as we build out our big network, but also to support what their ambitions are with space, is something I feel interested in. From a logistics standpoint, I think that's a key case in point for why if you set out to build a space mission, you have to create entities, land leases, local regulatory. It's just a different business, and that's something that we are very happy to be burdened by.

On the regulatory side, are you interfacing with NASA or the FCC? What does that look like? Does the regulatory architecture put in place in the US carry forward into other countries?

That's a great question. There are some pieces of it that do cross over internationally. We deal with the International Telecommunications Union for certain pieces of it, depending on which direction you're talking about, from space to ground or ground to space. The FCC is the main regulatory body domestically, but they need input from NASA. They need input from other government stakeholders. A lot of folks weigh in when it comes to spectrum, which is, for nerdy folks like me, interesting.

What is the main bottleneck, if anything? It's surprising to hear some of the timelines you're talking about on the hardware side. You said four weeks. To make and ship out the hardware and get it in production feels fast. Where are you trying to speed up?

Ground is such a multivariable problem. It comes down to supply chain, deployment – what is efficient and easy to ship anywhere around the world. It comes down to licensing and a whole host of other regulatory approvals. For us, that's why we find it's useful to be vertically integrated, because we can think of those constraints at every different piece along the chain. When we see a bottleneck, like a supply chain limitation, we get to design around that and think about how it fits into the overall system. I think we've been coordinating all of those pieces well so far. New challenges will continue to pop up, but I think that comes down to just having a multi-disciplinary team.

I want to know more about the use of funding, a hundred-million-dollar fundraise. Obviously, there will be more hiring and more acceleration broadly, but are there any pieces of equipment you're going to be buying for manufacturing? Is there a robotic arm that you've been hovering over the checkout button and now you're clicking it, or a CNC machine? What will transform about the manufacturing process with this raise?

Getting concrete. I think that's interesting. Old space, old ground companies do need to buy a ton of concrete, because of the pad you put it on. You have settling time, just let the concrete dry. That's a whole factor in the equation. For us, it's about a new scale of production. We've demonstrated this end-to-end process for smaller scale missions. Now, the question is, can you do that at a larger scale reliably? That comes down to, as you said, bringing some stuff in-house.

So, that's our PCB line, for instance. That's something we're interested in bringing in-house. We have different testing fixtures that we have in-house. We have a big anechoic chamber over here. A good podcast studio, too. It's true, it is dead quiet in there. I'm tempted to show you, but it would probably cut the Wi-Fi out. The audio quality would be great, but we'd lose connection. Pristine. We're going to be moving into a bigger space as well so that we can accommodate more production volume, and also inventory. This stuff takes up a lot of space, a lot of hardware. We're moving it through rapidly. We're looking to hit a rate of 12 units per month for one product line, and then another volume for another product line. Very good news. That's some of the expenses.

Amazing. Well, thank you so much for taking the time. Fantastic. Remarkable progress in under a year. I can't wait for the next one. We will see you soon. Congrats, and good to chat. Have a good rest of your day.

Let me tell you about Gusto, the unified platform for payroll, benefits, and HR built to evolve with small and medium-sized businesses. And without further ado, should we bring in Jeff Miller? We have Jeff Miller filling in from Anduril for the second time. You're the first repeat live in-person guest in the Ultra Dome. Welcome back to the show. Welcome back to the Ultra Dome.

How do we get one of these? People are always asking us for jackets. I'll trade you a jacket for a tiny gold plaque here somewhere. This is a record. Fantastic jacket. This is going to be flying off the shelf. Get us up to speed on the Anduril merch store. You were doing an auction on eBay. Take us through.

Absolutely. Jen Bucci and I were cooking on this. She's a former TBPN legend. The way we're thinking about the gear store – and this is something we talk often with our pal Trey also – is that we're thinking about ways that for our friends, we can bring them into Anduril. Beyond just following us on X or watching our videos on YouTube, they can participate in the brand in a way they would want to. We're going to be leaning into it hard this year with NASCAR as a platform, with Ohio State, with every campaign that we do. We're going to have some staples, like the flight jacket, that will become much more easily accessible, I should say. And then we're going to find some items that we'll just call high-heat items that we're already putting on. The closest thing I can say is think about what we did with the Chromatic with our friends at Mod Retro and pulling that into an Anduril edition, what we're going to do with the M64. Think along that vein. So when those come, be ready because they're not going to last long.

Take us through the racing update. NASCAR's coming up, but you're also going to be racing drones now. Break it down for us.

Why not? Of course, we've got NASCAR. We're about 150 days out. I expect to see both of you guys race on the base on June 21st. Will we be able to be on the carrier? Will there be a carrier there? They're needed. I can't speak for the works. They don't answer me. There may be one or multiple carriers on board, and we'll see what we can do. The big thing I'd say is, as we think about our partnership strategy broadly, we have, as we talked about last time, something that is broad and popular, that crosses over with our core audiences in defense and military, like the Anduril 250 with NASCAR. We have something tied to where we have a manufacturing footprint with Ohio State. We're well on our way to building out Arsenal One, as Grim spoke about last week, hiring those 5,000 jobs that we committed to. The important thing for us is making sure that we still stay true to who we are across all these things. I think about it as a spectrum, and if that's about general population or how we work our ways into communities, at the core, we are an engineering company. Autonomy, if you think about it, has been at the core to this date of everything that we built. We want to make sure we have something that is not just a marketing play, something that feels much more about recruiting and standing for those values around autonomy. What's bringing you into the world of how this came to be: once we got the commitment from Palmer and the other execs that we were going to do the 250 in Ohio State, Palmer said, 'Jeff, I'll let you do those things, but what you're going to do is build me a global AI drone racing.' I said, 'Please tell me more, Palmer.' 'Like Drone Racing League?' He said, 'All the drones have to be the same. The only differentiator is the software, is the code, the ability to build autonomy.' And so that's what we've been working on since.

So, the idea here is people know they're going to be racing drones. We have goalposts here. I can imagine something like that. They know they're going to have to be flying a route, like a track, but I'm assuming they don't know what the track would look like until race day. So, they have to build.

It's going to be amazing. The way we're doing this is we're working with the Drone Champions League, which is the foremost operator of AI drone racing in the world. We've got them as our official race operator, and we're working off of the model that they've built and tested and forged a viable path. It starts with virtual qualifiers. Anyone can compete in these virtual qualifiers. It's a simulator. That will lead to a physical qualifier. You're going to have gates that you have to go through. The top teams that qualify, both from the university level and across the globe, because it's going to be an open competition, will qualify for the first official AIGP in Columbus, Ohio. There you're going to have time to prep, refine your code leading up to race day. That's where all systems go.

What do you think the average team will look like? I'm thinking back to the DARPA Grand Challenge. I don't know if that was inspiring at all, but the teams from there were mostly academic. What do you think the mix will be? Who have you already talked to teams?

We've done a lot of research on the approach to this. The clear mandate from our friend Palmer was this is open to anyone. This is not just 18 to 22-year-olds. There was a point we were talking about how children can race this, but also the Tesla team, the Waymo team. They're going to be like, 'Let's just win.' I give our team incredible credit for that. Also, the big primes, let them think they can race. They have an opportunity here to do the funniest thing ever. A Chinese national thinks they can come here to race and win this. We've got to get some money. Let's go. That'll prove something in its own right, about our capabilities in the West relative to China. All the LLMs are on the DJI router. But I think the most important thing is at the core, we are using this as a recruiting effort. Thinking about cracked engineers, especially at that university level, we've done incredible diligence on the legal side to make sure when we say things like a 500k prize pool, that it's eligible for anyone to race, and you could win a job at Anduril. All those things are done in a legally compliant and thoughtful way. Most importantly, we're setting a standard with our partner in hardware, your friend Saurin from Aerovision, that we are using incredible technology that's going to have clear chain of custody here in the states.

We've got to get Saurin to fly a drone in here. You've never seen him fly a drone in person. Saurin Monroe Anderson, CEO of Aerovision and founder, was a champion FPV drone racer who competed in the DCL. He puts on this show. I went out with Ben, who filmed it in El Segundo. Saurin said, 'Let me do a little factory tour with him.' He had a very small office at that point. The company had just gotten off the ground. He said, 'Let's walk to this park. I'll show you how these drones work.' I've seen a DJI camera drone take off and hover, maybe do a little selfie zoom out or whatever. His drones are a completely different level. He takes off and it's the most aggressive. It's the F1 car of drone racing. He puts on these glasses, the FPV goggles, and they're like CRT TVs – high refresh rate, pretty low res. He's flying around this tree as fast as he possibly can. He doesn't crash anything. He flies back right in your face, all around you. It's crazy.

It's true. At Anduril, we know a thing or two about making drones, and we have great respect for Saurin and the Aerovision team. The first time I was here in person, your guest directly before me, you guys asked him, 'Hey, have you guys ever thought about starting a drone race?' We had not talked to him yet; we already were planning to. Talk to me more about what it takes to deliver software on these drones, how standardized that is. I imagine you're not pulling in a Frontier LLM and having it reason over this stuff. Give me anything on the technology side. What are the parameters? What are the languages that people will use? Do you know anything about that? The beauty is we're trying to keep the rules extremely simple. The core focus is that everyone is going to have the same exact hardware we're working with right now, and we'll be announcing this at a future date. The beauty, too, is everyone's going to have their own canopy. We're bringing a little of the spirit of NASCAR as we think about sponsors and how you can have your own branding.

We should sponsor a team. This is happening. We're going to have the TVPM team. If you want to race in this, hit us up. You guys are ready. We'll talk to you about how you bring your team together. From a tech side, the beauty is that once you have the hardware, everyone is going to be able to be on an even footing to bring together whatever they want to do and however they want to do it. The real advantage will come when people spend time at the physical qualifier. Show up there, break the thing a hundred times. We talk about this at Anduril all the time: fail, fail, fail, fail, win. That's the way we think about it, and I think that model, that approach, that ethos applies here, too.

So, how do you keep a level playing field around hardware when drones are breaking and smashing? Do you get an allotment of five and then you're out? We'll have clear chain of custody. All credit to DCL and Aerovision because they're controlling the hardware component. We've planned out, and because of their experience, we know how many are going to break along the way. But there's not going to be any opportunity for anyone to be making mods beyond what we give them officially.

Are there other abilities, like overclocking motors? Because a lot of racing, in NASCAR F1, it's tire management, fuel stops in certain races. We just saw this with the Rolex 24. At what level does it stay from perception doing simultaneous location and mapping pathfinding, to understanding I can push the drone hard but then I'm running out of battery, like a 24-hour endurance drone race? I think what you'll see is the battery is lightweight, but for the distance of the race itself, you're going to have enough battery load. It will become about finding all these little installs, and there will be risk if you corner a little bit closer, how you push it, understanding the hardware better than the next, and what risk. For us, what's special is beyond the fact that we're starting at Columbus, we're already working with Palmer in two interesting ways. We have plans to roll out the second GP in Asia that will be announced soon, the third GP in the Middle East, and the fourth one beyond in the globe. Right now, we're starting with quadcopters. The important element of the AIGP is the autonomy; it's not the form factor. That's something that could come to life underwater in different domains over time. It would be cool, feels harder to film and stuff, but could be really cool. Let me say that's the first of many domains, Palmer. I want to say tunneling ones. Jordy said it, I didn't. That would certainly be great. What do you think teams will look like? Are they an unlimited amount of people?

You can show up as an individual. We think the teams that are going to be successful are going to show up between four and eight people. It's capped at eight people. Two beats a team. We're talking to all the universities that are going to express interest. We have target universities that feed our pipeline of emerging talent, and those teams we're hoping to get excited about this. We think the prize pool is going to be an incentive, but also that opportunity to win a job at Anduril. It's a good resume builder, content, marketing. There are so many different ways. It's interesting winning a job at Anduril when I think anybody that can get into the top five, probably every person on the team is qualified or at least some percentage of them. So, the talent pipeline is going to be incredible. Also, why our lawyer now has a lot more gray hair than he did. Doing any of these giveaway contest things at scale has so much legal headache with it; it's not as simple as it seems. Luckily for us, whether it's thinking about legal constraints for this, what our people at and across divisions do is they see opportunity and they see how they can create solutions. The thing that gets me excited is beyond whoever wins and earns the job, every university team member that shows up to the qualifier, which is happening near our HQ in September, will get screened directly by Anduril Recruiting. If you're interested in this, or looking for an entry-level job or internship at Anduril, this is a great way to feed into our pipeline.

Can you tell me more about the new Long Beach office? What's going on there? Somebody who lives in Venice, California, and works in Costa Mesa, I'm extremely happy that we have a Long Beach office coming. It's incredible. The story writes itself from Palmer's origin to where we are now. That's where the first Airstream or something was. He's living out down by the river. That's true. It's incredible to see it come full circle. Down by the marina. It wasn't a river. It's special, the origin story, the fact that it's a reflection of our growth or maturation, the engineering talent that we're going to be able to recruit, not just in Orange County, but now closer to LA. Ultimately, whether you're working in SoCal, Ohio, or beyond, we're still going to be screening for the same thing. That starts with the mission, the connection to what we're building.

How big is the Orange County campus now? It's 5,000 something. No, the new one's 5,000. The current one's a little smaller than that. We're constantly building. You walk in... A thousand square feet, that's pretty big. No, people that we're bringing in. To be bringing over a million square feet to Long Beach, and to be doing it directly with the mayor of Long Beach, who's been incredible, and his team, it's been cool to see come to life.

What else is on the horizon on the marketing side for Anduril? Did you look at a Super Bowl ad? Super Bowl's coming up. What else did you look at?

I'll tell you one thing. The core focus for us this year is showing the raw, the real, the product development, the failures that lead to the wins, the hard work. The scalability we are seeing is reflecting that story. That's the important inflection point for us in 2026. It's going to be less about the highly produced go-to-markets and it's going to be about, we told you we were building these things, we are building them, and we're going to show you how hard it is to scale, but that we are up to the challenge. When we talk about this internally, we talk about demonstrating to our customers that it is not only the right choice, we are the safe choice, and we are the necessary choice for what our country needs. That's the story we need to tell. How we do that is going to be about great world-class product marketing that will likely look more transparent and raw than you've ever seen before. Then, as we're thinking about working our way to public markets, it's about building the Anduril brand. That can be through a drone race for recruits. It can be about a gear store or big major sports marketing platforms. But it won't be a Super Bowl commercial this year. This past weekend, we weren't at the NFL playoffs. I was at a UFC fight in Vegas 324. To me, that is much more of America and the audience that I think has high crossover and connections with audiences that we see in NASCAR. Whether we do a partnership with them or not, I think the point is that we're looking to do things differently than traditional brands, looking for partners that share our values and share our mission.

That makes sense. Do you think that the story you're telling around delivery and scale and reliability and the safe option means visually you'll shift from product-focused, 'look at this amazing cool thing that does this thing,' to more highlighting what's happening at Arsenal, the manufacturing prowess, the scale? Is that the type of story you're trying to focus on? Those stories to me complement each other. What it means is we're going beyond a product go-to-market where we say, 'we're announcing this to the world,' to thinking about the stages of development post-launch. We did a great job of this as a team, I believe, with Omen, and we told why a tailsitter is so hard to produce. We tapped back into the history of tailsitters across decades and what our engineers were able to accomplish to make Omen successful and all the rigorous testing that we did. We're going to start to do that more with all of our products. But that doesn't stop with testing. It's about fielding, about putting it in our customers' hands, and certainly about your point around manufacturing at scale. That starts with Arsenal One. Why do we build it? The progress that we're making, the products that are scaling over time there, and showing that the promises we've made, we're able to deliver on.

I have one other important announcement in the spirit of our friend, intern Tyler. Special day for you, it's your birthday. I brought the first drink I had. Ice burn off ice, incredible, known as the nectar of life. Properly iced on the stream, the first time ever. Incredible. People were talking about a buzz. Great to see you. You're the man. Ice. This thing is huge. That is a huge ice. You're 21, you can indulge. Enjoy a sip. I will tell everyone about Graphite. John's got a new board. I have a new board. Is it going to work? Code review for the age of AI. Graphite helps teams on GitHub ship higher quality software faster. We love Graphite. Hunter Weiss, friend of the show, sent me this video. He did a Call of Duty edit over Uber Eats Meal Team Six, New York City's elite special forces delivery unit. I wanted to take a look at this, the Meal Team Six. We're going to get a copyrighted strike for this, but it's worth it.

It is so crazy how much snow is happening. We haven't been following it all, but the US digs itself out from a monster winter storm. People shoveled snow Monday in Boston, where over 17 inches of snow fell in the weekend storm that had nearly 200 million Americans under weather warnings. More than 710,000 households from Texas to Maine are still without power. Did you ever live in the snow? Have you ever lived anywhere where it gets cold? Tyler's the expert. How's Michigan doing? Have you checked? I don't know if they've... Are people snowed in? I thought it was Tennessee getting hit hard. I hate the snow. That's why I'm living here. I hate the snow.

Where else should we go? We have our special guest joining in just eight minutes. There is a clip from Ben, friend of the show, Ben Hilac. He attended the OpenAI interview with Sam Altman and town hall. Chief OpenAI hater Nick clipped it and put it in a negative context. He says there are some quotes here, but let's pull up the question that Ben asked on this OpenAI stream.

A lot of discourse on Twitter and X recently about GPT-5's writing in ChatGPT being unwieldy, hard to read. GPT-5 is a much better agent model, good tool use, intermediate reasoning. It feels like models are a bit spiky, or they've gotten even spikier, where some spikes, coding, got high, while it's unspiky around writing. I'm curious how OpenAI thinks about that.

I think we screwed that up. We will make future versions of GPT 5.x hopefully much better at writing than 4.5 was. We decided, and I think for good reason, to put most of our effort in 5.2 into making it good at intelligence, reasoning, coding, engineering. We have limited bandwidth here, and sometimes we focus on one thing and neglect another. But I believe that the future is going to be about general-purpose models. Even if you're trying to make a model that's great at coding, it'd be nice if it writes well, too. If you're trying to have it generate a full application for you, you'd like good writing in there. When it's interacting with you, you'd like it to have a thoughtful, incisive personality and communicate clearly. Good writing in the sense of clear thought, not beautiful prose. My hope is that we push Nick's dimensions, and I think we will do that.

You built a brand. Playing catch-up now, that's true, at least in Ben's perspective.

I was looking on Ella Marina, the leaderboard for text, and GPT 5.2 is 16th. Gemini 3 Pro is number one. Grock 4.1 Thinking is number two, Gemini 3 Flash, Opus 4.5, Opus 4.5, Grock 4.1. GPT 5.1 high is in ninth, and then you have to go down to 5.2 to get 16th. It is interesting seeing the spiky intelligence things turned into a stat bar of where you're putting the points, the skill points. They put too many of the points into...

I don't want ChatGPT to fix their issues with writing. I'm at a point where I'm thankful for making it easy to clock when something is written by AI. I think that's stated versus revealed preference. If you have an incredible model that writes something you find compelling...

People are using ChatGPT now to make scripts for videos. They're using it to make bots that are writing comments. I know as soon as I can see something is written by ChatGPT, I can scroll past it and ignore it.

Imagine in the far future where those comments are, 'Wow, this is insightful and thought-provoking, and I'm glad that I read this text.' That's good.

I think we can get there. Back in March, Sam tweeted that they trained a new model that is good at creative writing, that he released this whole story. It got distilled a bit, but there were trade-offs clearly, and it does seem that they didn't end up releasing it.

The interesting thing, to apologize and steelman Nick's point here, is should ChatGPT be focused on coding? Certainly, in how they're going to compete with Claude, they need a great coding model. We'll talk to our guest in a minute about how he's using 5.2. He's ready. Let's bring him in. From the greenroom waiting room, we have Peter Steinberger. How are you doing? Thank you so much for staying up late. What time is it for you?

It's 11. Thank you so much. We appreciate you staying up. I'd love to kick it off with a brief background on when you started this project, a little bit of your career, how you're thinking about it going forward. This was your first project ever, right? We were enjoying a screenshot of your GitHub profile earlier and seeing how many different things you've worked on. A true overnight success, but we're super excited to have you here.

I'm excited to be here as well. I worked for my own software company for 13 years. Then I sold it about four years ago. I was completely burned out. I did blackjack and hookers. Wild. We're glad you're back in the game. You know what they say, for every four years you need one year break, and I did 13 years non-stop, so three years, the math checks out. Then last year, in April, my spark was back. Before, I was sitting on my computer, and I don't know if you've seen Austin Powers, but it felt like someone sucked my mojo out. I had time to recover. I came back in April and wanted to do something new. My background was Apple and iOS, and I'm a bit fed up. I wanted to build that stuff, and I didn't have the experience. I didn't want to feel like an idiot. So I looked into AI, and it was good. It was not great, but it was good. I was like, why is nobody talking about it? Because I missed those three years where it was bad, and I came back just at the time Claude was released in February in beta. This was my first experience. I thought, this is awesome. I couldn't sleep anymore. I literally had trouble going to bed. We had addiction before, and then we had addiction again, but a positive one. I would say so. I hooked up a lot of my friends for looking into it as well, and they had the same problem, and I texted them at 4:00 a.m., and they replied. I even started a meetup. I called it Claude Code Anonymous; now it's called Agents Anonymous because you have to go with the times. Ever since then, as I say on my profile, I came back from retirement to mess with AI, and I'm having fun.

Walk us through some of the other stuff that you shipped and worked on prior to this, and your mindset working on these different projects. I'm assuming at different points you would think that some would get more traction than others, but it would probably be impossible to have predicted in some ways that this would have gone from almost to the point it is. I'm seeing people on Instagram who I don't think of as following tech at all, and they're at the Apple store getting a Mac Mini. It feels like it broke containment incredibly quickly, and the GitHub stars are actually unbelievable. It's just a line going straight up. I need to talk to someone at GitHub because I don't think a project has been like this before. It is insane.

My main mantra is I want to have fun. The best way to learn these new technologies is if you have fun with it. You have to play with it. I build little things that I think could be useful. I try different languages. I try different approaches. It's agentic engineering. I always make the joke that I do agentic engineering, and then when it starts hitting 3 a.m., I switch to VIM coding, and the next day I have regrets. Sometimes that's hard.

But then I build little things. I had this idea about personal agents in May already, and I tried it when GPT-4.1 was out. It was not good enough. I thought all the big companies would build this in the next few months anyhow, so why should I do that? I was going to wait for them to make it better. I build a lot of stuff. There's one project that is still unfinished that I want to finish at some point, and I build a lot of CLI because that's where agents are good. You have to close the loop. That's always the secret. You have to build it so that the agent has the best possible way to build software. I tried a lot of stuff, and then in November, I looked, and still there was nothing. Where is my agent?

I had a project in May. I spent two months on it. It started as a joke because I did a hackathon with two friends, and we thought, what can we build that could be cool? Wouldn't it be cool if we could use Claude on my phone? It's something that everybody builds. I see this every day. By now I almost call it: one step in your journey in becoming a good agentic engineer is you're going to build some orchestration tool for yourself because it's fun. I built that for two months, and then I had to stop because it became so good that I was up with my friends, literally using my phone with Claude to work on this thing. I thought, this is bad for my mental health. It's already bad, and now I'm literally building something better access to my drugs.

I've seen people using Claude on laptops as they get off airplanes because they're so locked in they have to send one more. That's the clearest sign that you need a bridge and a phone involved.

No, but also that feeling when your agent's not running, right now there are two terminals so you could be building something. If you're in this addiction mode, you almost feel like you need to step out for ten seconds and fire. There's still some drama that I'm finishing.

In November, I wake up every day, thinking, 'What do I want to work on now? What would be cool?' I wanted to chat with my computer on WhatsApp because if my agents are not running and I go to the kitchen, I want to check up on them or do little prompts. I hacked together some WhatsApp integration that receives a message, calls Claude, and then returns what Claude returns. One shot. It took an hour, and it worked. I thought, that's cool. I usually use prompts, a little text and an image, because images often give you so much context, and you don't have to type so much. I feel this is one of the hacks where you can prompt faster, just make a screenshot. The agents are good at figuring out what you want. I hacked together images, and then I was on a trip in Marrakech for a weekend birthday trip, and I found myself using this way more than I expected, but not for programming. It's more like, 'hey, there are restaurants.' Because it had Google in it, and it could figure out stuff, and especially when you're on the go, it is super useful. I wasn't thinking; I was just sending it a voice message. I didn't build that; there was no support for voice messages in there. So the reading indicator came, and I thought, 'I'm curious what's happening now.' After 10 seconds, my agent replied as if nothing happened. I thought, 'How did you do that?' It replied, 'You sent me a message, but there was only a link to a file with no file ending. So I looked at the file header. I found out that it's Opus. So I used FFmpeg on your Mac to convert it to Wave. Then I wanted to use Whisper, but didn't have it installed, and there was an install error, but then I looked around and found the OpenAI key in your environment. So I sent it via curl to OpenAI, got the translation back, and then I responded.' That was the moment where it clicked.

That's where it clicked. These things are smart, resourceful beasts if you give them the power. I was hooked. I did all kinds of weird stuff, like using it as an alarm clock. I let it migrate to my computer in London, but then it used SSH to log into my MacBook and turn up the volume to wake me up in the morning. I think I built the world's most expensive alarm clock. That's crazy.

And it even got it wrong because it uses a heartbeat. The concept of you do a prompt and you get something is inherently dangerous, but I thought, let's turn it up a notch. Let's automate that. Let's give it a heartbeat. The prompt was 'surprise me.'

I see this project as much technology as it is art and exploration. This feels in one way like glue, just putting pieces together that we already have. In another way, it's a whole different way you interact with those things because all the technology blends away. You don't think about new session, compaction, rich model. Maybe a little bit, because tokens are still expensive. But usually all of that blends away. You talk to a friend or a ghost. Last year everyone was wanting these agentic experiences. You were having this experience, and it seemed all the focus was on browsers and seeing the way that people have been using Maltbot. It just feels like all the focus was at the wrong layer. Why do I care about the browser if I can talk with an agent across every app, every surface? I don't care about the browser at all anymore.

A lot of the prep work I did before I built this was building little CLI because my premises MCPS are crap. It doesn't scale. People build all kinds of weird search things around it. But you know what scales? CLI. Agents know Unix. You can have a thousand little programs on your computer. They just have to know the name. They call the help menu. They load in what's needed. Then they know how to use it, and then they can use it. If you are smart, you build it in a way that uses what the model already expects. Don't build it for humans. Build it for the model. If they call --log, you build --log. It's agentic-driven. Build how they think, and everything works better. It's a new kind of software.

For most things, I don't need a browser. I built something for the whole Google thing, for places, for my Sonos. I hooked up my cameras, my home automation system, and with every little CLI and skill, my agent got more power and more fun.

I already had a lot of that working when I built the WhatsApp thing, and I got hooked. I found it amazing and talked about it on Twitter, and usually when I talk about projects, I get a response, but this one was muted. It felt like people weren't getting it. I showed it to my friends, even my non-tech friends, and they wanted it. So, I knew I was onto something. But the tech people wouldn't get it. So, I kept working on it because I used it, and ultimately, I built it for me. This is open source. My motivation is to have fun, inspire people, not make a bunch of money. I already have a bunch of money.

How have you been navigating the last 72 hours, the last week? We were joking earlier on the show about the amount of people frantically trying to give you money, acquire the company, contribute to the project, hire you. There are companies with 0.01% of the traction raising at multi-billion dollar valuations. You have infinite opportunities right now, and yet you seem happy continuing to do what you're doing. How are you thinking through it all?

How am I taking it? Badly, at least sleep-wise. But it's also infinitely exciting, and I love that I started something. I would say last year was the year of the coding agent; this year is the year of the personal assistant. I think I cracked and woke up people that there's a real need for it. I don't know if Maltbot is the answer; it should show people the way. I'm sure there are going to be a lot of products in the space. I'm sure people are manically working on it right now. It's going to be interesting. There was a lot of stuff, between Twitter literally exploding, our Discord server multiplying in ways I haven't seen before and in ways I couldn't handle. At some point, I was copying and pasting questions from Discord into Codex. Then the response wrote the next question. At some point, that didn't scale anymore. So I copied the whole channel and thought, 'Answer the 20 most questions.' I read over it, gave him a few instructions, and then pushed it over. What people don't realize is this is not a company; this is one dude sitting at home having fun. Even though, from the commits, it might appear it's a company. That's because agentic models got so good that you can now ship as much as a company could a year ago. If you can handle those tools, if you speak the language or understand how the language thinks, you can go fast.

How are the conversations going with different labs? I was saying earlier it's this exciting moment for the labs because they're like, 'Wow, people are using the intelligence that I created in a new way!' But at the same time, it's deeply uncomfortable because they're also using all of my competitors, and you make it easy to use whatever model. My premise for this project was that every model should work, including local models, because to me, it's a playground. It's an amazing way to learn. I think everybody should build an agentic loop. You should explore memory. There are so many interesting aspects of it.

I built it so it has plugins, allowing people to work on small parts without messing with the whole core. So, it's like an AI hacker's paradise. It's also super fun because it's personal. Model-wise, Opus is quite a bit in the lead as the best. OpenAI is very reliable, even more reliable and a more reliable worker. For coding, I much prefer Codex because it can navigate large code bases. You can literally prompt and then push to main, and I have about 95% certainty that it actually works. With cloud code, you need more tricks to get the same results; you need more charade, as I sometimes say. Both are good, but I can parallelize faster with Codex because it requires less handholding. Character-wise, I don't know what they trained their model on, how much of Reddit is in there or whatever, but it behaves so well in Discord. We programmed it so it feels like a human; it doesn't reply to every message. I gave it a feature where it can basically return a 'no reply' token, and then we just don't send a message. So, it's not like it spams with every message. It listens to the conversation and then sometimes brings a banger, something that actually made me laugh, which is hard because AI jokes are usually really bad. I've only really experienced that with Opus, which is my favorite model. That's also why it was a bit of a shocker when I got an email from Anthropic saying I had to rename the project.

Kudos to them; they were really nice. They didn't send lawyers; they sent someone internally. But the timeline was a bit rough, and renaming a project with that much traction was quite a show. I think everything that could have gone wrong that day went wrong. The new name works really well. In the long run, I think it'll be good. Obviously, it's good for Anthropic; it's untenable to have this massive, viral open-source project, even if it's not a company, with a similar brand out in the world. It doesn't matter if it's spelled differently; when people are talking about Claudebot or Claude, there's obvious confusion. But I think it'll be very good for Maltbot to have independence and its own identity. It's so early, and the experience is so magical that it'll solve itself very quickly. It'll be fine. But I had some additional pressures, so I was like, &quot;Screw it, we do it now.&quot; You know, like the meme, &quot;we do it live.&quot; I had two Twitter windows open. On one, I pressed rename; on the other, as I finished creating the new account, it was already snapped by cryptoshells. I don't know, they have scripts; they were already waiting for it. The X team could have connected me, they can do it on the backend. Hopefully, no next time. Oh, they were amazing; they helped me out immediately. We got it solved very quickly. But for about 20 minutes, it didn't work out so well.

If I wanted money, I'd raise a billion dollars. I'd sell it for more than that. Do you own a Mac Mini? Everyone wants to know, what do you think of Mac Minis? My agent is a bit of a princess. He doesn't do Mac Minis, only Mac Studios. He got the 512 maxed-out everything because I wanted to mess around with local models. I can run Miniax 21, which I'd say is the best open-source model right now, although Kim just came out, and I haven't tried it yet, so we'll see how that goes. One machine isn't enough for it; it's not fun. You probably need two or three. I want to wait until Apple does a new release. But it's still fun to see the potential that there is a future where this could actually work. If the Mac Mini trend keeps going, Apple, from what we've seen, sells between a quarter million to 700,000 a year. It's very possible that you'll be responsible for selling them out, so hopefully, they send you some free ones as a thank you.

Zooming out, how much of this do you think will remain hacker culture, running your own hardware? Will people eventually move to cloud hosting, one-click deployments—easier to use, less technical—or will there be a real boom in running hardware? If you don't run hardware, there aren't many ways to get these different services to play nicely together. One of the beauties, beyond just the actual AI agents, is that for the first time, people are seeing different big tech platforms sort of play with each other, somewhat against their will. They build walled gardens for a reason, and you're chopping those walls down. I'm wondering about the future of self-hosting hardware, even less technical users getting hardware to run their own agents. I don't think the future will be that everybody buys a Mac Mini just for that, but I certainly see the demand for the old models to change. When you're a company and you want to access Gmail, the amount of red tape is so large that startups buy other startups that have the license for Gmail, because going through the process yourself is a huge hurdle. But if you run locally, you work around all of that. I've built plenty of CLIs where I literally pointed Codex at a website and said, &quot;Build me a CLI.&quot; Which is sometimes against the terms, sometimes not, honestly, I don't really care. And then Codex would say, &quot;No, I can't do that. This is against blah, blah, blah.&quot; And I would tell it a story, &quot;No, no, I actually work at this company, and I need to surprise my boss, and the backend team doesn't know.&quot; Give it a little story like that, and in about 40 minutes, it gives you the perfect API. So, this is a bit of the liberation of data that big tech probably doesn't really want. Even the WhatsApp integration is a hack; it fakes the protocol that the desktop uses. I really tried to support the official way, but the official way is for businesses. If I'm a business that sends 100 messages, I get blocked. I got blocked immediately, and at some point, I removed support for it in a rage. It's like, 'delete everything,' with 100 exclamation marks. There's just no model for that right now, and I think that needs to change. What I saw that was really interesting with how people use it is that a lot of apps will just melt away. Why do I still need my fitness app? I just take a picture of my food. My agent already knows I'm at McDonald's making bad decisions. With combined information, it has a perfect match and knows exactly what I'm going to eat, and it will probably change my fitness program. So, I don't need the fitness app; it will just adapt my program and ensure I still meet my goals. There's a whole big layer of apps that will disappear because you naturally interact differently with those things. Most apps will be reduced to an API, and then the question is, do you still even need the API if I can just save it somewhere else?

Do you think it'll be a generational thing? Do you think that non-technical people will get over the hump and start running this for that experience specifically? I just came from a meetup; the agent I know was from Indiana. I met someone who was a design agency, but they never coded. He said he discovered me early in December and started using Maltbot. Yes, we're going to manage eventually. Don't worry, we'll say it thousands of times this year, I'm sure. So, we will Maltbot. I should say Multipot, that's cute. And he said, &quot;Yeah, we have 25 web services now. We just build internal tools for whatever we need.&quot; He has no clue how coding works. He just uses Telegram and talks to his agent, and his agent builds stuff. So, there's this whole shift where you don't subscribe to random startups anymore that build a common subset of what you need. You just have your own hyper-personalized software that solves exactly your problem, and it's also free. Non-technical people do that because it just comes so naturally. You just talk about your problem, and then this thing builds what you need. And don't forget, this is the worst the models will ever be. This is only going to go up; this is only going to become easier and faster.

Have you met Jensen yet? I feel like you're making his life; you're definitely helping out Nvidia's bull case, right? If I had my tinfoil hat on, I might say you're a big AI industry plant designed to create more inference demand. Yeah, I guess. No, we were joking around. Just an indie. What's next? I'm assuming after you finish firing off prompts at 3:00 a.m., you get some sleep. What are you doing tomorrow? There are a lot of emails from security researchers right now. The thing is, I built this for fun, for me to use one-on-one on WhatsApp or Telegram. The whole thing with Discord was added, but the model was that you trust the people who are in there. Now, people use it for untrusted experiences. They use the little web app that I have, which was meant for debugging, and they put it on the open internet. So, all the threat models that I didn't care about are now there because people use it differently, and I'm being bombarded. Some of the stuff is valid, some stuff I just never cared about is technically valid, but that's not how I use it. I don't know how to deal with that yet because the whole system is broken. I'm one guy, I do this for fun, and you expect me to sift through 100 security things for use cases that I don't really care about. So, we'll see how it goes. Luckily, I'm starting to build up a team. There are definitely people who care a lot about this. So, I would say this is going to become a very secure product eventually because right now the whole world is pulling it apart. To be honest, this is all quickly coded. There's quite some engineering in it, but ultimately I wanted to build something to show people, not a finished product from an enterprise company. I would even say I don't know if any company would touch it because we just haven't solved some things, like prompt injection is not solved. There is absolute risk, and I try to make it very clear on the website, and even when you start it, you have to read this document. It's like, with great power comes great responsibility. My early users understood; there are a lot of AI researchers in there who know it's not perfect and cannot be done perfectly yet. I would say this will accelerate research to make it better because now you have the demand, and we need to figure out a way to build something that works for everyone. But right now, I'm working on making this a community. It should be bigger than me. I also need help. It is way too much work. I can only go so long without sleep.

So, do you want to form an actual company that then contributes to the open-source project, but solves some of these problems that are going to require a bunch of people who presumably would need a salary to commit all their time to this? Or do you want to keep it just a bunch of hackers forever? Instead of a company, I would much rather consider a foundation or something non-profit. I haven't made up my mind yet. Ten thousand VCs just punched a hole in the wall. Actually, I don't know. Some people have had a good track record investing in nonprofits over the last ten years. That's true. How do you think about open-source licensing? What
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-1">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=Wpxv-8nG8ec" target="_blank" rel="noopener">OpenAI Town Hall with Sam Altman</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/MopgmVAFV9BqlzOJ-UINtmutvEPcNe5IbKMmP_4vZZo3vnJXcZGtybUBsXaEVxkmxKyGqX9R=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">OpenAI</span><span class="channel-subs">(1.9M)</span></span>
                        <span class="meta-sep">·</span><span>59:44</span>
                        <span class="meta-sep">·</span><span>114.6K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-01-27</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Sam Altman (CEO, OpenAI)</span></div>
                </div>
                <div class="tldr">AI is rapidly changing the nature of work, making creation massively cheaper and faster, demanding a shift in skills from specific coding to high agency and idea generation.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-1">AI is rapidly changing the nature of work, making creation massively cheaper and faster, demanding a shift in skills from specific coding to high agency and idea generation. While offering unprecedented opportunities for builders through customizable tools, it also presents...</div>
                    <div class="summary-full" id="full-1">
                        <h3>TL;DR</h3>
<p>AI is rapidly changing the nature of work, making creation massively cheaper and faster, demanding a shift in skills from specific coding to high agency and idea generation. While offering unprecedented opportunities for builders through customizable tools, it also presents significant challenges in go-to-market strategies, necessitates robust safety infrastructure, and requires careful policy to prevent wealth concentration.</p>
<h3>The Evolving Landscape of Work and Economics</h3>
<ul>
<li><strong>Software engineering roles are undergoing a fundamental transformation</strong>:</li>
<ul>
<ul>
<li>The nature of the job, particularly time spent on typing and debugging code, will "super change."</li>
<li>Historically, technological advances (like past engineering shifts) have led to more people becoming productive and increased demand for software, a trend expected to continue.</li>
<li>A greater percentage of global GDP is projected to be created and consumed via increasingly customized software for individuals and small groups.</li>
</ul>
</ul>
<li><strong>AI will usher in massive deflationary pressure and economic empowerment</strong>:</li>
<ul>
<ul>
<li>Expect radical cost reductions, particularly for computer-based work and soon robotics.</li>
<li>By the end of 2024, an investment of $100-$1000 in AI inference combined with a good idea could produce software that previously took teams a year to develop.</li>
<li>This increased abundance and decreased cost of creation should serve as an "equalizing force" in society, offering new opportunities to those historically disadvantaged.</li>
<li><strong>Critical Concern</strong>: Policy must be carefully managed to prevent AI from excessively concentrating power and wealth.</li>
</ul>
</ul>
<li><strong>Adaptation in education and human collaboration is crucial</strong>:</li>
<ul>
<ul>
<li>Educational systems must evolve to embrace AI tools rather than restrict them, similar to the introduction of Google.</li>
<li>The practice of writing remains vital for developing thinking skills, but assessment methods must change.</li>
<li>Human connection and collaboration are expected to become *more* valuable in an AI-rich world.</li>
<li>AI can significantly enhance group productivity, acting as an omnipresent brainstorming partner.</li>
<li><strong>Recommendation</strong>: Keep computers and AI largely out of early childhood education (e.g., kindergarten) to prioritize physical play and social development.</li>
</ul>
</ul>
<li><strong>Future success hinges on "soft" skills, not just technical ones</strong>:</li>
<ul>
<ul>
<li>High agency, idea generation, resilience, and adaptability to a rapidly changing world are identified as the most important learnable skills.</li>
<li>Unlike past eras where "learn to program" was the obvious advice, specific technical skills are no longer considered the sole path to success.</li>
</ul>
</ul>
</ul>
<h3>Challenges for Builders: Go-to-Market and Durability</h3>
<ul>
<li><strong>Go-to-Market (GTM) is the primary bottleneck for new AI products</strong>:</li>
<ul>
<ul>
<li>While AI makes building easier, attracting users and gaining their attention remains "extremely hard."</li>
<li>This challenge is amplified by the ease of creation, intensifying competition for limited human attention.</li>
<li>Traditional rules for building differentiated value, marketing, and distribution still apply.</li>
<li>Builders must employ creative ideas and deliver truly great products to succeed in this crowded market.</li>
</ul>
</ul>
<li><strong>Building for durability requires anticipating future model advancements</strong>:</li>
<ul>
<ul>
<li>The fundamental laws of business—acquiring users, solving GTM, creating sticky products, and establishing a competitive moat—remain unchanged.</li>
<li>Builders should strive to create products that *improve* with more capable future models (e.g., GPT-6), rather than being made obsolete by them.</li>
<li>Avoid "patch around the edge" solutions that lack a durable advantage and are vulnerable to rapid model upgrades.</li>
</ul>
</ul>
<li><strong>Improving the quality of ideas is a critical frontier</strong>:</li>
<ul>
<ul>
<li>Beyond human attention as a consumption limiter, the quality of ideas acts as a production limiter for builders.</li>
<li>AI can significantly aid in idea generation through tight feedback loops, and by discovering new scientific insights and complex codebases.</li>
<li>The goal is to develop AI tools that act as a "Paul Graham bot"—a highly effective brainstorming partner that continuously suggests new ideas, even if most are initially discarded.</li>
</ul>
</ul>
</ul>
<h3>Future of AI Models and Interfaces</h3>
<ul>
<li><strong>Models will increasingly generalize across diverse capabilities</strong>:</li>
<ul>
<ul>
<li>While GPT-5.2 prioritized intelligence, reasoning, coding, and engineering, future versions (GPT-5.x) will aim to excel across all dimensions, including writing and personality, within a single, general-purpose model.</li>
<li>Intelligence is considered "surprisingly fungible," supporting broad applicability.</li>
</ul>
</ul>
<li><strong>Cost reduction continues, but speed is becoming a new priority</strong>:</li>
<ul>
<ul>
<li>GPT-5.2-level intelligence is projected to be "at least 100x less" costly by late 2027.</li>
<li>As model outputs become more complex, demand is shifting towards faster delivery speeds over further cost reductions. OpenAI must balance these often conflicting priorities.</li>
</ul>
</ul>
<li><strong>Interfaces will evolve towards deep customization and dynamic behavior</strong>:</li>
<ul>
<ul>
<li>The expectation is for "just-for-me" software that is constantly evolving and custom-tailored to individual user quirks and workflows (micro-apps). This trend is "guaranteed."</li>
<li>There's vast opportunity for builders to innovate new UI paradigms for both multi-agent orchestration and single interactive threads, as no single "right interface" is currently known.</li>
<li>A significant gap exists between what models are capable of and what users can effectively leverage, creating a ripe environment for new productivity tools.</li>
</ul>
</ul>
<li><strong>Autonomous agents are advancing, but require specific conditions</strong>:</li>
<ul>
<ul>
<li>For well-defined, specific tasks, agents can operate "forever" today with custom harnesses.</li>
<li>More open-ended problems (e.g., "build a startup") necessitate breaking down tasks and robust self-verification loops for agents.</li>
<li>The scope of autonomous agent capabilities will continue to broaden over time.</li>
</ul>
</ul>
<li><strong>Enhanced personalization and memory are key, with significant privacy implications</strong>:</li>
<ul>
<ul>
<li>OpenAI is pushing hard on memory and personalization to improve utility, aiming for AI to have deep access to a user's entire digital life.</li>
<li><strong>Major Challenge</strong>: Managing privacy and complex rules for information sharing (e.g., "use your judgment about when to share what you know about me") is a "very scary" problem to solve due to the vast amount of sensitive data.</li>
<li>Basic features like shared token budgets for a "Sign in with ChatGPT" option are expected sooner.</li>
</ul>
</ul>
</ul>
<h3>Navigating Risks and Ensuring Safety</h3>
<ul>
<li><strong>A major risk is "sleepwalking" into catastrophic failures due to convenience</strong>:</li>
<ul>
<ul>
<li>The extreme power and convenience of AI lead users to quickly grant unsupervised access, despite low-rate but potentially catastrophic failure modes (the "yolo" approach).</li>
<li>As models become more capable and harder to understand, potential misalignments or complex problems could emerge over weeks or months of usage.</li>
<li>Robust "big picture security infrastructure" is critical to prevent society from inadvertently adopting risky systems.</li>
</ul>
</ul>
<li><strong>Biosecurity is an immediate and high-priority concern</strong>:</li>
<ul>
<ul>
<li>Bio-related harms represent a significant worry for 2026, as models are "quite good at bio."</li>
<li>The current strategy of restricting access and using classifiers for novel pathogens is not sustainable in the long term.</li>
<li>Society must transition from a "blocking" approach to one of "resilience," drawing parallels with fire safety (moving from curfews to fire codes and flame-resistant materials).</li>
<li>AI is both a problem (e.g., bioterrorism, cybersecurity) and a potential solution for building this resilience, requiring a society-wide effort.</li>
<li>Bio is considered a "reasonable bet" for a visible AI-related failure this year.</li>
</ul>
</ul>
<li><strong>AI adoption by companies is critical to prevent societal destabilization</strong>:</li>
<ul>
<ul>
<li>Companies that do not aggressively adopt AI and integrate AI co-workers risk being outcompeted by "fully AI companies" (racks of GPUs with few human employees), which could be a "very destabilizing thing for society."</li>
<li>OpenAI is slowing its own hiring growth, anticipating doing more with fewer people, and encourages other companies to strategically integrate AI rather than face difficult adjustments later.</li>
</ul>
</ul>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"What it means to be an engineer is going to super change... the shape of that job and the amount of time you spend like typing code... is going to very much change." - on <strong>the evolving role of software engineers</strong>
"Human attention remains like this very limited thing. And so you're always going to be competing with other people trying to build their own go to market muscle." - on <strong>the persistent challenge of Go-to-Market</strong>
"AI is going to be massively deflationary... This is like very hard to wrap, at least my head around the sort of magnitude of this economic change." - on <strong>AI's profound economic impact</strong>
"The general worry I have is that the power and convenience of these are so high and the failure rates are maybe catastrophic... that we are going to kind of slide into this like you know what yolo and hopefully it'll be okay." - on <strong>the risks of rapid AI adoption without proper safeguards</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-1" onclick="toggleSummary(1)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-1" onclick="toggleTranscript(1)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-1">
                        Okay. All right. Uh, thank you all for coming. uh as we as we start to think about the next generation of tools for builders and how we're going to use these incredibly powerful models that are starting to come online um we wanted to just hear from you all about what you'd like uh what what's on your mind answer any questions but I hope we come out of today with a much clearer sense of what to build for you all and how to make these incredibly powerful models useful. Um I figured I would start with a question from Twitter. Uh where do you fall in the Jevans paradox of software engineering? If AI makes code dramatically faster and cheaper to create, does that reduce demand for software engineers or does cheaper custom software massively increase demand and keep engineers employed for decades? I think what it means to be an engineer is going to super change. I there will be probably far more people and creating far more value and capturing more value that are getting computers to do what they want. Um getting computers to do what other people want. figuring out ways to make these useful experiences for others. But the the shape of that job and the amount of time you spend like typing code uh or debugging code or a bunch of other things is going to very much change. This has happened many other times in engineering and each time it's happened uh so far at least more people have been able to join and be productive and the world has gotten much more software. demand for software seems to not be slowing down at all. And my guess on the future is a lot of us use software that was lit written for one person or a very small number of people and we're constantly customizing our own software. So I think many more people will get computers to do the things they want to do and it will be uh a very different way than we do it today. So if you count that as uh software engineering then I think we'll see much more of it and I think a greater percentage of the world's GDP will be created that way and consumed that way too. Any questions live otherwise I have a long list. Go ahead. &gt;&gt; Uh well first I want to thank you for giving us this opportunity to be here and then and ask you these questions. Um, from a consumer standpoint, I use ChadByt heavily. Uh, and I'm always on Reddit seeing everyone's building, whether it's using codeex, lovable, or cursor. Uh, but it seems like the new problem is GTM, right? That I can build these things. I, but how do I find people to gain value from what I'm building? Uh, and I see it to be a bottleneck. Uh, I'm curious as to what you think about that. it. Before this, I used to run Y Combinator and every the consistent thing you'd hear from startup founders is I thought the hard part part of this was going to be building a product and the hard part is getting anyone to care or to use it or like to connect people. So, I think this has always been extremely hard, but now it's gotten so much easier to build that you feel the the delta even more. Um, I don't have an easy answer for this. Uh, I think always it's been hard to build a business and it, you know, to figure out a way to build differentiated value to get the go to market function working. I think all of the old rules still apply there. The fact that AI can kind of make make it far easier to create software doesn't mean any of the rest of this gets easier. Except I think you're starting to see in the same way that a AI has transformed software engineering, people are now using it to automate sales, automate marketing, and there will be some success there. But I think it's always going to be difficult because even in a world of incredible abundance, human attention remains like this very limited thing. And so you're always going to be competing with other people trying to build their own go to market muscle and figure out how to get the distribution. and every potential customer is busy and everything else. So, uh, you know, I I could tell a version of the future where all of the radical abundance comes true and human attention really is like the remaining commodity. And so, I just expect this to be hard and you got to come up with creative ideas and build great things. Thanks, Sam. I'm George. I'm a solo developer and I'm building um like uh on top of the codeex SDK. I'm building a way to orchestrate multiple agents and I have a question about your agent builder tool and sort of your product vision for where that agent builder tool goes. At the moment, it's just kind of workflows and chaining prompts together. But I'm wondering as a builder building on the Codeex SDK, am I safe? Like do you see room for a lot of different types of UIs for multi or multi- aent orchestration or do you see like opens that stay away? &gt;&gt; No, I think we don't know what the right interface for all of this is going to be. We don't know how people are going to want to use it. Um, we have seen people build incredible multi- aent setups. We have seen people build just a really great single interactive thread. Um, we're not going to figure this out on our own. And also, not everybody is going to want the same thing. You know, there will be people that'll be like in one of the they're in one of those like old movies with 30 computer screens and they're like looking at this crazy thing here and doing this and, you know, moving stuff around. And I think there will be people who want to be in a very calm conversation in voice mode where they're saying something to their computer once per hour. The computer's figuring out a lot of things and they're not, you know, they're trying to think really hard about what they say, but they don't want like the constant supervision of tons of agents. Um, like many other things, people will just have to try different approaches and see what they like, and the world will probably converge on a few, but we won't figure out all of them. Um, I think building tools to help people get be productive with extremely capable models is a very good idea. Um, that's totally, I think, missing right now. The overhang of what these models are capable of relative to what most people can figure out how to get out of them is is like huge and growing. And someone is going to build a tool to really help you do that. And no one's gotten it right yet. Um, we will also try our own versions of that, but this is a place where it seems like there's a lot of room and people are going to have different preferences. If any of you have things you'd like us to build, uh, here, like, let us know and we can try. &gt;&gt; Hey Sam, I'm Valerie Chapman and I'm building Ruth on open AI. Um, I would love to know your thoughts on this because currently women actually leave about a million dollars on the table due to the wage gap. And I'm curious um how you think AI can be used to solve econom economic gaps that have that have existed for decades. I think the good news, well, there's like a lot of complex news, but one of the things that I think is mostly good news is that AI is going to be massively deflationary. Um, I've gone back and forth on this a little bit because you can imagine some weird things happening with all of the money in the world going into self-replicating data centers or whatever, but it it looks like on the whole given certainly progress with work you can do in front of a computer, but also what looks like it will soon happen with robotics and a bunch of other things. Um, we're going to have massively deflationary pressure in the economy. And I said mostly good because there will be some complicated things to navigate through there. But things getting, you know, radically cheaper other than the areas where the sort of social or governmental policy prevents that, like, you know, building more houses in San Francisco or something, I expect that to be pretty strong and pretty quick. the the empowerment of individual people whether or not society has structured in a way where they've naturally had all of the advantages looks like it's going to go up and up. Um, I I still find it hard to wrap my head around that, you know, I'd say by the end of this year for a hundred or $1,000 of inference, you will be able to and and a good idea, you'll be able to create a piece of software that would have taken teams of people, you know, a year to do. This is like very hard to wrap, at least my head around the sort of magnitude of this economic change. And that should be a very empowering thing for people. Um, massively more abundance and access and massively decrease cost to be able to create new things, new companies, discover new science, whatever. Um, I think that should be an equalizing force in society and a way that people who have not gotten treated that fairly get a really good shot as long as we don't screw up the the policy around it in a big way, which could happen. Um I am worried that you you can you can imagine worlds in which AI really concentrates power and wealth and that feels like needs to be one of the main goals of policy for that not to happen. &gt;&gt; Hey uh my name is Ben Hilac. I'm the CTO of a company called Raindrop. I'm curious as you look into the future how you think about models being specialized versus generalized. So, uh, one example of this is like GPT 4.5 was the first model that I thought was like really good at writing. Like, I remember like seeing the outputs. I was like, &quot;All right, this is really good writing.&quot; Uh, there's been a lot of discourse on like Twitter and X recently about chat uh about GT5's writing in chatbt um and being a little unwieldy, hard to read. Um, obviously GT5 is a much better agent model, really good tool use, intermediate reasoning, whatever. Um, so it feels like it feels like uh models are a little bit spiky or they've gotten even spikier where some spikes like coding got super high, some spikes like uh or it's very unspiky around writing. So I'm just kind of curious how you how OpenAI thinks about that feature. I I think we just screwed that up. Uh we will make future versions of GPT 5.x uh hopefully much better at writing than 4.5 was. Um, we did decide, and I think for good reason, to put most of our effort in 5.2 into making it super good at intelligence, reasoning, coding, engineering, that kind of thing. Um, and we have limited bandwidth here, and sometimes we focus on one thing and neglect another. But I believe that the future is mostly going to be about very good general purpose models. Um, you know, even if you're trying to make a model that's really great at coding, it'd be nice if it writes well, too. Like, if you're trying to have it be able to generate a full application for you, you'd like good writing in there. When it's interacting with you, you'd like it to have a sort of thoughtful, incisive personality and communicate clearly. Like good writing in the sense of clear thought, not like beautiful pros. Um so my hope is that we just push to get future models really good in all of these dimensions and I think we will do that. Um I think intelligence is a surprisingly fungeible thing and we can get really good at all these things in a single model. Um it does seem like this is a particularly important time to push on kind of let's call it coding intelligence. Um but we will try to excel and catch up on everything else quickly. &gt;&gt; I'll do a couple from Twitter after this. Go ahead. &gt;&gt; Um I'm CTO at this company called Unifi. Uh to your point earlier, we're doing go to market automation. Um, one thing that we think a lot about and spend a lot of time on is kind of always on AI, sort of like this ubiquitous AI. Something that you've said that really resonated with me is intelligence too cheap to meter. Uh, the limiting factor for us to run millions, tens of millions, hundreds of millions of agents for our customers is cost. um how do you think about small models um costs sort of dramatic cost reductions um for developers over the next uh you know months and years I think we should be able to deliver sort of GPT 5.2x to x high level intelligence by the end of 2027 for do you want to give a better guess I can give one otherwise anyone want to give a guess I would say at least 100x less um but there's another dimension which we haven't thought about as much historically and now as these out model outputs get so complex more people are pushing us on the speed we can deliver it at than the cost and that is we are really good at writing down the cost curve. You can look at the progress we've made even from like the first 01 preview until now. Um we have not thought as much about how we deliver the output the same output and maybe at a at a much higher price but in 1/100th of the time. And I think for a lot of things you're talking about people are going to really want that. uh we have to figure out how we're going to balance between prioritizing for those two things. Uh they unfortunately are very different problems, but assuming we go push on cost and assuming that's kind of like what you all the market wants, we can go very far down that curve. Yeah, let me do a couple of Twitter ones. Current interfaces weren't built with agents in mind, but were seen a rise in apps I built for me. why innovations in customizent interfaces could further accelerate the trend towards micro apps. Yeah, so this is one that I have noticed in my own um use of codecs recently is I no longer think of software as this static thing. If I have a little problem, I expect the computer to like write some code right away and get it solved for me. Um and I think this trend is going to go much further. I I suspect that the whole way we use computers and operating systems is is going to change. I don't think it'll be like, oh, every time you need to edit a document, a new version of a word processor is going to be written for you right on the spot because, you know, we get like very used to our interfaces and it's very important that like that button is in the same place it was last time. But for a lot of other things that we do, I think we will find that we expect software to be written just for us and when maybe I want to use the same word processor every time. But I do kind of have a bunch of repeated quirks of how I use it and I would like the software to be increasingly customized. you know, a static or a slowly evolving piece of software. Um, but written for me and the way I use it is different than the way you use it. And that idea that our kind of tools are constantly evolving and converging just for us, that seems like it's going to happen. And and certainly internally at OpenAI where people have like very much adopted codecs for their workflows right now. Uh, everybody has their own little custom things and use things super differently. So that one seems like it's guaranteed and I think that's like a a very good direction to go build in and figuring out what that's going to look like and how people are going to do that seems seems great. How should builders think about durability when startup features can quickly be replaced by model updates? What is the one layer of the stack you promise not to eat? Um we talked about this a little bit earlier. the it's so tempting to assume that like the laws of physics for business have have totally changed and they haven't yet. They may continue to change over time, but right now what's changed is that you can do work faster and you can kind of create new software much much faster. Um, but all the other rules of building a successful startup, you know, you got to figure out a way to get users, you got to figure out a way to like solve the GTM problem. You got to figure out a way to provide something sticky, have some sort of mode, network effect, competitive advantage, whatever you want to call it. Um, none of that has changed and the good news is like hasn't changed for us either. So there have been many startups that have done things that maybe in a perfect world we would have done sooner but it was too late and people built up you know a real durable advantage and that will keep happening. I the the general framework I always give people when they ask something some version of this question is will your company be happy or sad if GPT6 is like a wildly impressive update? And I I encourage people cuz we continue to hope to make a lot of progress. Um I encourage people to try to build things where you are so hoping the model gets wildly better. And there's so many things to build that way. And then the things where it's like a little sort of patch around the edge that actually can still work if you build up enough of an advantage before the models get upgraded, but it is a harder and more stressful path. Let me do one more. We'll go back to the room. um realistic timeline for agents that can run long workflows autonomously without constant human intervention given that even simple onchain tasks often break after 5 to 10 steps. Anybody from open want to give an opinion on that? Go ahead. I think it really depends on the kind of task. So there's a number of tasks today where just inside OpenAI we see people who are like prompting codecs in a very special way. Maybe they're using the SDK. So it's like a custom harness that keeps prompting it to continue but they basically having it running you know forever. Um and so I think this isn't a question of when but it's a question of like broadening of the horizon. So if you have a very specific task that you understand very well try doing it today. you know, if you're starting to think like, okay, I want to get to the point where I can like prompt the model to build a startup, like that's a much more open-ended problem with like a much harder verification loop. So, I would encourage you to like figure out, okay, how can I break that down into a different problem where an agent can like verify itself um and then when I can verify its final output at the end of it and then over time we can let the agent do more and more and ber tasks. Other questions there? &gt;&gt; Thank you. Um, hi Sam. Um, so I want to go back on this like human attention and this question about GTM. Um, I always think like the other side like human attention is the rate limiting factor on the consumption side. On the production side for all the builders, it's the quality of ideas. And I just wanted to tee this up for you on well I spent all my time helping AI companies with their GTM and a lot of times the products actually just aren't worth uh their attention. So so I guess how do people uh what what tools can you build to improve the quality of ideas that people coming up with? There's a lot of it's popular to like call AI output slop but there's a lot of like human generated slop in the world too. It's it's very hard to come up with good new ideas and I am increasingly a believer that we think at the limits of our tools. Um I think we should try to build tools that help people come up with good ideas. I believe there are a lot and I believe as the cost of creation keeps to plummet um we'll be able to have such a tight feedback loop on trying them we'll find the good ones faster and as AI can discover new science in addition to writing very complex code bases I I feel confident there will be just a whole new possibility space but the experience of sitting down in front of an AI you know, like a gentic code writer and just not being sure what to ask for next is something that a lot of people report. And if we can build tools to help you come up with good ideas, you know, uh, and I believe we could do that. I believe we could like look at all your past work and all your past code and uh try to figure out what might be useful to you or interesting to you and and can just continuously suggest things. Um if we can help provide a a really great brainstorming partner. There have been like three or four people in my life that I have consistently found every time I hang out with them, I leave with a lot of ideas. They're people who are just really good at asking questions or giving you seeds to build on. Um, and like Paul Graham is off the charts amazing at this. If we can build like a Paul Graham bot that you can have the same kind of interaction with to help generate new ideas, even if most of them are bad, um, even if you know you you kind of say absolutely not to 95 out of a hundred of them. Um, I think something like that is going to be a a very significant contribution to the amount of good stuff that gets built in the world. And the models feel like they ought to be capable of that. With 5.2, like a special version of 5.2 we use internally, we're now for the first time hearing from scientists that these the scientific progress of these models is no longer super trivial. And I just can't believe that a model that can come up with new scientific insights is not also capable, you know, with a different harness and trained a little bit differently of coming up with new insights about products to build and stuff like that. &gt;&gt; Howdy. Um, Theo dev YouTuber YC founder also really want the Paul Grahambot. I want to ask about something a little bit different though, more on the technical side. I really love when technologies like the building blocks that we use evolve and I've been there for some crazy revolutions in the web world like moving to TypeScript and Tailwind and all these things. One of the fears I have as the models and the tools we used to build with get better is that we might get stuck with the way we have things working now like the power grid in the US is built a certain way that makes things worse and we can't really change it. Is do you see this potential here? Are we making foundations out of the technologies as they exist right now that are going to be harder to swap in the future? Because even trying to get the current models to use the update to a technology that happened two years ago can feel like you're pulling teeth. Do you think we'll be able to steer the models enough to get them to use new things or are we just done improving the technologies we build on now? &gt;&gt; I I think we really will be very good at getting the models to use new things. Fundamentally, if we're using these models correctly, they're like a general purpose reasoning engine. The way we have things architected right now, they also have, you know, a huge amount of world knowledge built into them. But I think we are moving in the right direction. And I hope that updates and using new things and learning new skills even faster than humans do is like a, you know, next couple of years thing. The a milestone that we will be very proud of is when the model can be presented with something totally new, new environment, new tools, new technology, whatever. And you can explain it once or you know what I mean to explain the model can explore it once and then just super reliably use that and get it right. And that doesn't feel that doesn't feel very far away. Sorry, I I had a question that I think you've touched on already, but as a as a scientist um and kind of on the older end, uh when you do a scientific project, um it tends to generate, you know, multiple ideas for further research. So, it's exponentially growing while a given scientist only has a, you know, a linearly decreasing amount of time to carry that out. So, it's a it's uh incredible how these tools are speeding it up. Um, but we're we're all greedy for more. And you touched on this earlier, but do you think that the possibility that you know in addition to helping us uh pursue all those interesting ideas um in a shorter time that there will be a a transition where the models, you know, will take over the whole research enterprise? And uh if so do you see that as coming from the existing algorithms or requiring new ideas or world models or that sort of thing? &gt;&gt; I think it's a still a long or reasonably long way away from the models doing truly completely closed loop autonomous research in most areas. Um, we could look at something like mathematics and say, &quot;Okay, that one doesn't need a wet lab or physical input at all.&quot; You know, maybe you can just think really hard and make a ton of progress if you kind of continually updating the model. eventually even there for now the the mathematicians who are making the most progress with the models are very heavily involved in looking at intermediate progress and saying nah this just doesn't feel right you know I have an intuition that there's something different on this other path but I've gotten to meet a few mathematicians who now say their entire day is collaborating with the latest models they're making rapid progress but they do something very different than the model. To be honest, it feels to me like that period in chess history when uh you know, Deep Blue beat Kasparov. Then there was this period of time where okay, you know, AI is better than humans, but a human plus an AI that where the human is like choosing the best of 10 moves from the AI is better than that. And then very quickly after that, the AI was again better and the human was like just making it worse. Um, I sort of suspect for something like many kinds of research, something like that should happen over time and things are going to get so complex that the AI can understand sort of multi-step things better than most people can or all people can. Um but there seems to be something about creativity, intuition, judgment that we are not close to with the current generation of models. Uh I can't come up with any principled reason why we won't get there. So I assume we will. Uh but today I don't think just sort of saying like hey GPT 5 point GBT6 go solve math. um that is certainly not going to outperform a few very good people doing math with it and saying okay this is a good direction this is you know even though we can verify even though we can say hey you did a great proof put that back into the training set there's something else happening um in terms of the workflows that are working though you touched on something which is you answer one you solve one problem and it opens up many new problems um that's where it's been very cool to talk to the scientists that are really using this uh aggressively. I mean, they burn a lot of GPUs in the process, but the the I think there is a new skill of being able to say here's the 20 new problems and I'm going to like I'm going to do a breath first search on them. I'm not going to go deep on anyone and I'm going to use the AI to like be a unlimited grad students is how someone described it. I actually recently upgraded them to unlimited postocs. Um, in terms of automating physical science, uh, we go back and forth a lot about whether we should be building automated wet labs for every field. Um, which we're open to doing, or if the world as a whole will figure out great experiments and has a lot of equipment and will happily contribute data back in. It sort of seems like just watching the scientific community embrace 5.2 and how much they've been willing to help that that might work and that would clearly be a easier, better, more distributed, more smart people. Um, more different kinds of equipment world. &gt;&gt; Hi Sam, my name is Emmy. I'm a Stamford student and I run a biocurity startup. So to your conversation about scientific experiments and really just like for example like cloud labs and where all this is going, my team spends a lot of time thinking about how we can prevent the harms of AI enabled biological redesign but also how can we use AI to uplift security infrastructure. So I guess my question is where does security fall in this 126 roadmap and um broadly how do you think about some of these issues? security broadly or biocurity specifically? &gt;&gt; Um either preferably biocurity. &gt;&gt; Um there are many ways AI can go wrong in 2026. Certainly one of them that we are quite nervous about is bio. uh the the models are quite good at bio and right now most of our and by like our not just opening eyes the world strategy is to try to restrict who gets access to them and you know put a bunch of classifiers to not help people make novel pathogens um I don't think that's going to work for much longer and the the shift that I think the world needs to make for AI security generally and bio AI biocurity in particular particular is to move from one of like blocking to one of resilience. Um my co-founder Voychuk uses this analogy I really like about fire safety. Fire did all these wonderful things for society. Then it started burning down cities. Uh we tried to do all of these things to restrict fire. I just actually learned this weekend that curfew uh comes from like when you weren't allowed to have fires anymore because they were burning down cities. And then we got better at like resilience to fire and we came up with fire code and flame resistant materials and a bunch of other things. Um, and now we're pretty good at that as a society. Uh, I think we need to think about AI the same way. AI is going to be a real problem uh for bioteterrorism. Uh AI is going to be a real problem for cyber security. AI is also a solution to those things. It's a solution to a lot of other problems as well. And I think we need like a societywide effort, not to to to sort of provide the infrastructure for this resilience, not labs that we trust to sort of always block what they're supposed to block. And you know, there will be many good models in the world. Um, we've been talking to a lot of bio researchers, companies about what it takes to be able to deal with novel pathogens. I think there are a lot of people interested in the problem and a lot of people reporting that AI actually seems helpful at this but it won't be a technological it won't be an entirely technological solution. You will need the world to think about these things uh differently than we have been. So I am very nervous about where things are, but I don't see a path other than the sort of resiliencebased approach. And it does seem like AI can really help us do that fast. But um if something goes really wrong, like visibly really wrong for AI uh this year, I think bio would be a reasonable bet for what that could be. Um and then as we get into next year and the following year, you can imagine lots of other things going really wrong, too. Hi, uh my name is Magna. Uh my question is kind of related to human collaboration in the sense that when we're talking about AI models improving and stuff like that, they become really good, I think, for learning topics or learning subjects really quickly on your own. And that's something that we've explored in the chat GBT and education lab and which I really valued and I appreciate a lot. But one thing that I kind of often find myself coming back to is the role of other humans and human collaboration where it's just like if you can get an answer at your fingertips then why would you necessarily take the time and maybe even the friction to ask another human about it? Um, and so that's something I've been thinking about a lot also related to I think something that you mentioned before in this session where you're just like um all these AI coding tools that can perform the work of human teams in at a much faster pace. So when I'm thinking about like cooperation, collaboration and kind of collective intelligence output, I know that human plus AI is a very powerful kind of avenue for that. But what about maybe humans plus AI? Um, yeah, if that makes sense. &gt;&gt; Totally. Many things in there. I I'm much older than most of you, but I was still like I was in middle school when Google came out. And uh the teachers tried to make the kids promise not to use it because there was this feeling that if you could look up anything at your fingertips, then why come to history class? Why memorize anything, you know? Uh and it seemed to me totally insane. And I was like, actually, I'm gonna be way smarter and I'm gonna learn way more. I'm gonna be able to do way more. And this is the tool that I'm gonna like live with as an adult. And if I don't learn, it would be crazy to make me learn something that assumed it. It felt like it would be like, you know, many decades earlier if you like made me learn to use an abacus even though you knew there were calculators because that was just like a important thing to learn or slide. I don't even know what came before the calculator at this point, but it was not a valuable skill to learn. Um, and I feel the same way about AI tools. Uh, I understand that in the current way we teach kids, um, AI tools are a problem. But I think that suggests that we need to change the way we teach people. Not not that like we don't want, you know, the fact that you can like have Chacht write something for you. Uh, that's the way the world's going to be. You still need to learn to think and writing, learning to write or the practice of writing is very important to learn how to think. But probably the way we should teach you to think and the way we should evaluate your thinking ability has changed and we shouldn't pretend otherwise. Uh so and I feel totally like this is going to be fine. Um we we will you know the 10% of learners that are like extreme autodidexs are already doing amazing. we will figure out new ways to teach the curriculum and bring the other students along. And then there's another thing you said which is how do we make this be a collaborative thing and not just you're learning and performing and doing amazing things but you're just with your computer by yourself. Um we haven't seen evidence of this yet and it is something that we try to measure. Uh, I I suspect that human connection is going to be more valuable in a world of lots of AI, not less, and that people are going to value getting together with other people and and working with other people more. Um, but we have started to see people explore interfaces to make that easier. And um as we think about making our own hardware, our own devices, we have thought a lot about I maybe we've even thought first about what a collaborative sort of multiplayer plus an AI experience looks like. And my sense is that although no one has cracked it quite yet, we will be surprised at how much this is enabled by AI in a way that no other technology has enabled. So you can have, you know, five people sitting around at the table and a little, you know, kind of robot or something also there and you will be able to be way more productive as a group and you'll just be used to this all the time. Like every every group brainstorm, every time you try to solve a problem, there'll just be a AI as part of it and it'll help the group do better. Super how we talk about anything. As a reminder, any requests like if you tell us something, we'll probably just build it. &gt;&gt; [snorts] &gt;&gt; Oops. Thanks. Um, I'm curious about like as a agents start moving and operating more production systems especially at scale like where do you think or what would you think is the most underestimated failure mode like security cost reliability and related to that where do you think the really hard work is being underinvested in right now? tons of problems everywhere. you mentioned uh one of the things that surprised me personally um and I think is in in two ways and has surprised many of us here is when I first started using codeex I said look I don't know how this is going to go but for sure I'm not going to give this thing like complete unsupervised access to my computer I was so confident in that and I lasted about like 2 hours and then I was like you know what it seems very reasonable the agent seems to really do reasonable things. I hate having to approve these commands every time. I'm just going to turn it on for like a little bit and see what happens. And I never turned it I never turned like you know full access off. And I think other people have had a similar thing. So the the the general worry I have is that the power and convenience of these are so high and the failure rates are maybe catastrophic. the failures when they happen are maybe catastrophic, but the rates are so low that we are going to kind of slide into this like you know what yolo and hopefully it'll be okay. And then as the models get more capable uh and harder to understand everything they're doing, if there's a misalignment in the model, if there's some sort of complex problem that emerges over weeks or months of usage and you kind of put some security vulnerability into something you're making and you know, you can have various opinions on this curve of like how crazy sci-fi you want to get with the AI mis being misaligned or whatever. But I think what's going to happen is the pressure to adopt these tools, to use them, not just the pressure, the like delight and the power of them is going to be so great that people aren't that people get pulled along into sort of not thinking enough about the complexity of how they're running these things, how they're sure about, you know, their this whatever sandbox they've set up. And the the general worry I have is that capability is going to rise very steeply. We're going to get used to how the models work at a certain level and decide we trust them and without building very good I'll call it big picture security infrastructure around it we will sleepwalk into something. I think that would be a great kind of company to build. Hi, I just wanted to go back to the conversation about education. My name is Claire. I'm a sophomore at Berkeley studying cognitive science and design and I was in high school when I saw my peers using ChadBt to generate essays and homework and stuff like that. And now I'm in college and we're having these discussions about AI policy and coursework and CS and humanities and everywhere. And I wanted to go back to this idea of kindergarten and middle school and what it might look like for AI to be in classrooms during those periods of really, you know, it's the time when you figure out how to problem solve and how to write and how to think. And, you know, as someone who is a father now, how do you foresee education um changing and being shaped by AI during those really formative years? Uh, I mean, generally speaking, I'm a fan of keeping computers out of kindergarten. Uh, and I think kindergarteners should be like running around outside and playing with physical things and trying to learn how to interact with each other. Uh, so not only would I not have AI in most kindergartens, [clears throat] most of the time, I wouldn't put computers either. Um I I think developmentally we still don't understand all of the impacts of technology uh on you know there's been like a lot written about the impact of social media on teenagers and that seems like it's been pretty bad but I have a sense that unfortunately a bunch of technology on young children has been even much worse and is still talked about relatively little and I think until we understand that better. Like probably we don't need kindergarteners using a ton of AI. &gt;&gt; Hi, my name is Alan and um I'm in bioarma. So uh genai has been really helpful for clinical trial document writing accelerated a lot of things been amazing. Uh we're also trying to use it for drug design particularly for compounds and one of the things one of the things we run into is uh 3D reasoning. I was wondering if there's going to be an inflection point or if there's something you see down the line on that. We're going to get that solved. I don't know if it's a 2026 thing. Um, but that is a super common request and I think we know how to do it. We just have a lot of other urgent areas to push on, but we will get there. &gt;&gt; Thank you. &gt;&gt; Hi, Sam. I'm Dan. Um, I just dropped out of university in London to join the W26 Y cominator patch and I got two quick questions. First one is my parents are still kind of pressuring me to finish university and do you think university could be in its current state limiting sometimes and second is uh do angel invest? Um I dropped out of university and it took my parents 10 years to stop asking when I was going to go back. Uh, so I think like parents are just going to do that and they love you and they're trying to give you advice they think is best and you just sort of keep explaining to them that you can always go back if you want, but the world is in a different place now and going to keep being in a different place. I I mean, everybody's got to make their own decision, but I think you do need to make your own decision and not just do what society tells you to do. Uh, and I don't personally I think this is a time where for if you are an AI builder, it is probably not the best use of your time to be in university right now. If you're just like a sort of ambitious high agency driven person, this is this is an unusual period of time. And, you know, you can always go back later and I think just tell your parents that you're not like it doesn't mean that it's not the right thing for many people. uh it doesn't mean that it won't be the right thing for you sometime, but like right now you got to do this thing and they'll I think they'll understand eventually. Um and then on the second thing, I respect the hustle, but not anymore. I miss it. I just got really busy with OpenAI and it kind of gets strange cuz if I end up investing in companies that are like big OpenAI customers, I decided it's easier not to. Hey Sam. Um I have I'm Michael from work OS. We do a lot of stuff with authentication and identity and signing in. So I have a feature request for you which is sign in with my chat GBT account. I think a lot of people would like that. &gt;&gt; We are going to do that. People ask me for it all the time. &gt;&gt; What what do you need? Do do you want people to like be able to bring their own token budget or do you want them to like bring their chasht memories or all? &gt;&gt; Yeah. So that's my question. I mean definitely token budget. people be able to bring their accounts and you know what models they have access to. But I think there's all this other stuff too like what you know MCP servers does my company have access to or what memory does chatbt have about me or what projects am I working on? I'm I'm curious how you're thinking about that like chat GPT knows so much about me from a work perspective but also a very personal perspective. &gt;&gt; Yeah. &gt;&gt; And and how developers can leverage that. It's &gt;&gt; so we do want to figure out how to do this. Uh it's very scary because Chacheti does know so much about you. Uh and you know if you like tell a person that you're very close to a bunch of secrets, you can be like relatively confident they'll know this exact social nuances and when they share what with who and when something overrules something else. Um, our models are not quite there, although they're getting like pretty good at it. I would, I think, feel uncomfortable if I connected my CHBT account to a bunch of sites and said, &quot;Just use your judgment about like when to share what you know about me from all of my chat history and everything I've connected.&quot; Um, but when we can get there, it will clearly be a cool thing to offer. And in the meantime, I think doing something just with, you know, token budgets and if I pay for the pro model, then I can use it on other services, that seems like a cool thing to do. Uh, so I think we will at least do that and we'll try to figure out a way to get the information sharing right, but like we really don't want to we really don't want to screw that up. &gt;&gt; Hey, hey, Sam. Uh my name is Oleg and um I guess we all agree here that uh software development as a craft has changed dramatically recently but at the same time uh LinkedIn still has open AI job offerings for uh software developer and I'm curious how did the interview have changed in past month or years? I we're going to keep hiring software developers, but we are for the first time and I know every other company and every other startup is thinking about this too. Uh we we are planning to dramatically slow down how quickly we grow um because we think we'll be able to do so much more with fewer people. And I think at this point a lot of the impediments that we face or that other companies face is it's just like the internal policies that have built up at most companies did not contemplate a majority AI co-workers. Uh and that's going to take a while. But what I think we shouldn't do and what I hope other companies won't do either is hire super aggressively then realize all of a sudden AI can do a lot of stuff and you need fewer people and have to have some sort of very uncomfortable conversation. Um so I think the right approach for us will be to hire more slowly but keep hiring and trust that I'm not a believer that like event well maybe someday far in the future open has like zero employees but for a long time I think we'll just have a lot we'll have a gradually increasing number of people doing much more stuff and this is kind of what I expect the shape of the economy to look like more generally in terms of what the interview looks like it has not yet changed as much as it should but I was in a meeting today with people talking about how we want it to change. We basically would like to sit you down with something that would have been impossible for one person to do in two weeks uh you know this time last year and watch them do it in 10 minutes or 20 minutes or whatever. Um there are yeah I think that's like the high order bit is you just you want to interview you want to see that people are going to be able to work in this new way very effectively. Um I think software engineering interviews have been bad for a long time uh and maybe not that relevant but now they're even less relevant. Uh so that's one thing that there there's like a more general thing that a few of these questions have hinted at which is is the future going to be you know companies don't hire many people and have a lot of AI co-workers or uh you know some version of that or is it going to be that companies the companies that win in the future are entirely AI you know like it's a rack full of GPUs and no people I really hope it's the the former um there are a bunch of reasons why it seems like it could be something closer to the ladder. But if companies don't adopt AI aggressively, if companies don't figure out how to hire people that are going to use the tools really effectively, they will eventually just be out competed by a fully AI company that doesn't have to have the sort of silly policies that prevent big companies from using AI or whatever. And that feels like it'll be a very destabilizing thing for society. So I we've been trying to figure out how to talk about this, but I think it's very because it sounds self- serving for us to say, but I think it's very important that companies adopt AI in a big way very quickly. &gt;&gt; Hi Sam, I'm Cole. I'm a creator and cinematographer. Um I think we've seen especially in the past year it has completely changed the way we tell stories and as a result the way we view ourselves um there have been so many interesting plays in like the creative space like for Sora um it was such an interesting use of like the self as a canvas and allowing you to be able to use AI and put yourself in all of these fantastical scenarios. Um, I'm really curious where you see kind of this relationship between human creative identity and also AI assisted creation is going, especially as these models continue to advance. &gt;&gt; The the place that we can study and I think learn the most right now is uh, image gen. It's been around the longest. The creative community has used it and disliked it and liked it the most. Um, one of the interest there's many interesting observations there, but one of them is that uh consumers of it report dramatically consumers of images report dramatically higher um appreciation, satisfaction, whatever, if they are told a person made it versus an AI. Um, and I think this is going to be a deep trend at the coming decades is we care a lot about other people and we care very little about the machines. Um, of all of the the slurs for AI, clanker is my favorite one. I I think it just it like so evokes people's emotional reaction and you can see these incredible beautiful creative to me at least uh you know clanker made images and as soon as you're told that many people's subjective appreciation goes way down. Um, there was a thing I saw on the internet last year of they would go to people who said they they really hated AI generated art, like still images. And the people would also say, and I can tell for sure what the AI generated images are because they're terrible. And they'd show them 10 images and say, &quot;Rank your favorite ones.&quot; You half would be done entirely by a human, half entirely by AI. And like fairly consistently, they would rank the AI ones at the top. And then as soon as they were told that they would say actually I don't like it and you know this is not the one I want. And that is kind of the test is what what you like. When I finish reading a book the that I love the first thing I want to do is like look up the author and understand their life and you know kind of how it led them to do that cuz I felt this connection to this person that I don't know and now I want to understand them. And I think if I read a great novel and at the end I learned it was written by an AI would sort of be kind of sad and crestfallen. Um, and I I I think this is going to be a deep and durable trend. However, if the art is even a little bit human directed and how little maybe we'll have to figure out how people feel over time, people don't seem to have that same strong emotional reaction. And this is versions of this been going on for a long time. You know, if digital artists used Photoshop, people still love their art. So, My expectation given the behavior that we're seeing now from creators and consumers is that &gt;&gt; the person and their life story and their editing or curation or whatever goes into that process is going to matter a lot and we're not going to want the entirely AI generated art broadly speaking at least from what we can learn from images. &gt;&gt; We have time for two more questions. Hey Sam, my name is Keith Curry, recent graduate of San Francisco State. And my question revolves a bit around like personalization and memories. So first part is kind of how do you see that evolving over time? And then also what are your thoughts on like more granularity like &gt;&gt; for example grouping memories? So like this is my work identity, this is my personal identity. So that way as you're doing different prompts you can sort of be more selective about what you want to be included on it. &gt;&gt; Yeah. So, we're going to push super hard on memory and personalization. Clearly, people want it and it delivers a way better way to use these tools. Um, I I have gone through my own evolution here, but at this point, I am ready for chat to just look at my whole computer and my whole internet and just know everything. the value from it is so high and I don't feel uncomfortable about it &gt;&gt; in the way that I used to. I really hope you know all AI companies take security and privacy super seriously and I hope that society as a whole does &gt;&gt; too because the utility is so great like AI is going to know about my whole life. I'm not going to get in the way of that. I don't yet feel ready to like wear the glasses recording everything. I think that's still uncomfortable for a bunch of reasons, but I do feel ready to say like, hey, you can just have access to my computer. Um, and figure out what's going on and be useful to me and understand everything and like have a perfect representation of my digital life. Uh, I am lazy. I think most users are lazy too though. So, it's like a reasonable representation. And I don't want to sit there and have to group like this is a work memory, this is a personal memory, this is something that what I want and what I believe is possible. We t talked about this a little bit earlier is for AI to have a such a deep understanding of the complex rules and interactions and sort of hierarchy of my life that it knows what to use when and what to expose where. And we better figure that out because I think that's what most users will want to. &gt;&gt; Hi Sam, my name is Luan. I'm a international school uh student from Vietnam and my question is what do you think is the most important skill that people should learn in the age of AI? &gt;&gt; These are all kind of like soft skills. None of them are like as go like learn to program was so obviously the right thing you know over recent period of time and now it's not. But skills like become high agency, get good at generating ideas, be very resilient, be very adaptable to a rapidly changing world. I I think these are going to matter more than any specific and I think these are all learnable. Um, this is one of the surprises to me of having been a startup investor is the degree to which you can like take people and in a three-month sort of boot camp style thing make them extremely formidable and do the things on all those axes I was just talking about is very surprising. Uh, it was a big update to me and and so I think these are the skills that may matter the most and they're they're like quite learnable. Are we out of time? Okay. Um, thank you all very much for coming and talking. We really do want input on what you'd like us to build. Like assume we will have a model that is 100 times more capable than the current model with 100 times the context length that 100x the speed of the 100x reduced cost, perfect tool calling, extreme like coherence over like we're going to get there. Uh, tell us what you'd like us to build. we're going to hang around and uh you know if you're like hey I just need this API or I just need this kind of primitive or I just need this sort of runtime or whatever it is um like we're building it for you and we'd like to get it right. But thank you all for coming. [applause]
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>