<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - February 04, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
            scroll-margin-top: 1rem;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-header-link {
            display: block;
            padding: 1.25rem 1.5rem 0.75rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header-link:hover .day-date {
            color: var(--accent);
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
            transition: color 0.15s ease;
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.3rem;
            padding: 0.6rem 0;
            border-bottom: 1px solid var(--border);
            text-decoration: none;
            color: inherit;
            border-radius: 4px;
            transition: background 0.12s ease;
        }

        .day-preview-item:hover {
            background: var(--bg-tertiary);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-title {
            font-size: 0.88rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.35;
        }

        .preview-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            background: var(--bg-tertiary);
            padding: 0.15rem 0.5rem 0.15rem 0.25rem;
            border-radius: 14px;
        }

        .preview-channel-icon {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-channel-name {
            font-weight: 500;
            color: var(--text-secondary);
            font-size: 0.72rem;
        }

        .preview-channel-subs {
            color: var(--text-tertiary);
            font-size: 0.68rem;
        }

        .preview-details {
            font-size: 0.72rem;
            color: var(--text-tertiary);
        }

        .preview-tags {
            display: inline-flex;
            gap: 0.3rem;
        }

        .tag-sm {
            padding: 0.1rem 0.45rem;
            font-size: 0.65rem;
        }

        .preview-tldr {
            font-size: 0.78rem;
            color: var(--text-tertiary);
            line-height: 1.45;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">February 04, 2026</p>
            <div class="stats">
                <span><span class="stat-value">2</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card" id="video-0">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=mIK5-yi7a-c" target="_blank" rel="noopener">Alphabet 2025 Q4 Earnings Call</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/ytc/AIdro_kjtQx9fT4338ZMPXI7KaDkOUt2D2YO9_0nrl5Q5DAQzag=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Alphabet Investor Relations</span><span class="channel-subs">(59.4K)</span></span>
                        <span class="meta-sep">·</span><span>60:47</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-04</span>
                    </div>
                    
                </div>
                <div class="tldr">Alphabet achieved a tremendous Q4 2025, exceeding $400 billion in annual revenue for the first time, with AI investments driving significant acceleration across Search, Cloud, and YouTube, alongside a projected $175-185 billion in capital expenditures for 2026 to meet surging AI demand.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">Alphabet achieved a tremendous Q4 2025, exceeding $400 billion in annual revenue for the first time, with AI investments driving significant acceleration across Search, Cloud, and YouTube, alongside a projected $175-185 billion in capital expenditures for 2026 to meet surging AI...</div>
                    <div class="summary-full" id="full-0">
                        <h3>TL;DR</h3>
<p>Alphabet achieved a tremendous Q4 2025, exceeding $400 billion in annual revenue for the first time, with AI investments driving significant acceleration across Search, Cloud, and YouTube, alongside a projected $175-185 billion in capital expenditures for 2026 to meet surging AI demand.</p>
<h3>Q4 2025 Financial &amp; AI Impact</h3>
<ul>
<li><strong>Record Revenue Achievement:</strong> Alphabet's annual revenues surpassed <strong>$400 billion</strong> for the first time.</li>
<ul>
<li>Q4 2025 consolidated revenues reached <strong>$113.8 billion</strong>, up <strong>18%</strong> year-over-year (<strong>13%</strong> in constant currency).</li>
</ul>
<li><strong>AI-Driven Growth Across Segments:</strong> Investments in AI are directly translating into strong financial performance.</li>
<ul>
<li><strong>Search Revenues:</strong> Accelerated to <strong>17%</strong> growth, reaching <strong>$63.1 billion</strong>, led by broad strength across all major verticals, particularly retail.</li>
<li><strong>Cloud Revenues:</strong> Significantly accelerated, growing <strong>48%</strong> to <strong>$17.7 billion</strong>, now on an annual run rate over <strong>$70 billion</strong>, driven by demand for AI products.</li>
<li><strong>YouTube Annual Revenues:</strong> Surpassed <strong>$60 billion</strong> across ads and subscriptions. Q4 ad revenues grew <strong>9%</strong> to <strong>$11.4 billion</strong>, with direct response being a key driver despite lapping strong prior-year election spend.</li>
</ul>
<li><strong>Strong Profitability &amp; Cash Flow:</strong></li>
<ul>
<li>Operating Income: Increased <strong>16%</strong> to <strong>$35.9 billion</strong>, with an operating margin of <strong>31.6%</strong>.</li>
<li>Net Income: Increased <strong>30%</strong> to <strong>$34.5 billion</strong>, with EPS up <strong>31%</strong> to <strong>$2.82</strong>.</li>
<li>Operating Cash Flow: Record <strong>$52.4 billion</strong> in Q4, and <strong>$164.7 billion</strong> for the full year.</li>
<li>Free Cash Flow: <strong>$24.6 billion</strong> in Q4, and <strong>$73.3 billion</strong> for the full year.</li>
</ul>
</ul>
<h3>Advanced AI Development &amp; Infrastructure</h3>
<ul>
<li><strong>Gemini 3 Milestone:</strong> The launch of Gemini 3 was a major milestone, driving significant momentum and rapid adoption.</li>
<ul>
<li>Gemini 3 Pro has consistently processed <strong>three times</strong> as many daily tokens on average as 2.5 Pro since its launch.</li>
</ul>
<li><strong>Unrivaled AI Infrastructure:</strong> Serves as the bedrock of Alphabet's AI stack.</li>
<ul>
<li><strong>Compute Options:</strong> Includes NVIDIA's latest Vera Rubin GPU platform (Alphabet among the first to offer it) and proprietary TPUs developed over a decade.</li>
<li><strong>Efficiency Gains:</strong> Gemini serving unit costs were lowered by <strong>78%</strong> over 2025 through model optimizations and utilization improvements.</li>
<li><strong>Strategic Acquisition:</strong> Intent to acquire Intersect, a data center and energy infrastructure solutions provider.</li>
</ul>
<li><strong>World-Class AI Research &amp; Product Integration:</strong></li>
<ul>
<li><strong>Extensive Model Portfolio:</strong> Leads across text, vision, and image-to-video LMARENA leaderboards.</li>
<li><strong>Google Antigravity:</strong> A new development platform empowering agents to autonomously plan and execute complex software tasks, already boasting over <strong>1.5 million</strong> weekly active users.</li>
<li><strong>API Growth:</strong> First-party models, like Gemini, now process over <strong>10 billion</strong> tokens per minute via direct API use by customers, up from <strong>7 billion</strong> last quarter.</li>
<li><strong>Widespread Product Integration:</strong> Launched personal intelligence in AI Mode in Search and the Gemini app, introduced new AI features to Gmail, reimagined Chrome as an AI-first browser, and announced Project Genie for real-time interactive world generation.</li>
</ul>
</ul>
<h3>Core Business Segment Performance</h3>
<ul>
<li><strong>Search Momentum:</strong> AI drives an expansionary moment, with over <strong>250 product launches</strong> in AI Mode and AI Overviews last quarter.</li>
<ul>
<li><strong>User Engagement:</strong> Daily AI Mode queries per user doubled in the US; queries in AI Mode are <strong>three times longer</strong> than traditional searches.</li>
<li><strong>Multimodal Search:</strong> Nearly <strong>one in six</strong> AI Mode queries are now non-text (voice or images); Circle to Search is available on over <strong>580 million</strong> Android devices.</li>
</ul>
<li><strong>Google Cloud Strength:</strong> Delivered outstanding results, benefiting from strong demand for enterprise AI products.</li>
<ul>
<li><strong>Customer Acquisition:</strong> Doubled new customer velocity compared to Q1.</li>
<li><strong>Large Commitments:</strong> Number of deals over <strong>$1 billion</strong> in 2025 surpassed the previous three years combined.</li>
<li><strong>Customer Expansion:</strong> Existing customers are outpacing initial commitments by over <strong>30%</strong>.</li>
<li><strong>AI Adoption:</strong> Nearly <strong>75%</strong> of Cloud customers use vertically optimized AI, utilizing <strong>1.8 times</strong> as many products as non-AI customers.</li>
<li><strong>Cloud Backlog:</strong> Increased <strong>55%</strong> sequentially and more than doubled year-over-year, reaching <strong>$240 billion</strong>.</li>
</ul>
<li><strong>YouTube Dominance:</strong> Continues as the number one streamer in the U.S. for nearly three years (Nielsen).</li>
<ul>
<li><strong>Subscription Growth:</strong> Strong growth across YouTube Music Premium and new YouTube TV plans, with NFL Sunday Ticket achieving its highest paid subscriber number ever.</li>
<li><strong>Podcast Engagement:</strong> Viewers watched over <strong>700 million hours</strong> of podcasts on living room devices in October 2025, up <strong>75%</strong> year-over-year.</li>
<li><strong>Shorts Performance:</strong> Averages over <strong>200 billion</strong> daily views and earns more revenue per watch hour than traditional in-stream in several countries, including the U.S.</li>
</ul>
<li><strong>Waymo Expansion:</strong></li>
<ul>
<li><strong>Significant Growth:</strong> Surpassed <strong>20 million</strong> fully autonomous trips and provides over <strong>400,000 rides</strong> every week.</li>
<li><strong>Market Expansion:</strong> Launched its sixth market in Miami, with planned expansion to multiple cities across the US, UK, and Japan.</li>
</ul>
</ul>
<h3>Monetization, Commerce, and Strategic Partnerships</h3>
<ul>
<li><strong>AI in Advertising:</strong> Gemini models are profoundly improving ads quality and advertiser tools.</li>
<ul>
<li><strong>Ads Quality:</strong> Gemini enhances query understanding, driving better query matching, ranking, and significantly reducing irrelevant ads served.</li>
<li><strong>Advertiser Tools:</strong> Businesses used Gemini to create nearly <strong>70 million</strong> creative assets in Q4 via text customization in AI Max and PMax.</li>
<li><strong>AI Mode Monetization:</strong> Early-stage experiments are underway, including testing ads below AI responses and "Direct Offers" for shoppers ready to buy.</li>
</ul>
<li><strong>Agentic Commerce &amp; Universal Commerce Protocol:</strong> Laying the groundwork for shopping in the AI era.</li>
<ul>
<li><strong>New Standard:</strong> Introduced the Universal Commerce Protocol, built with retail industry leaders, enabling seamless transactions directly within AI Mode and Gemini.</li>
</ul>
<li><strong>Key Partnerships:</strong></li>
<ul>
<li><strong>Apple Collaboration:</strong> Alphabet is Apple's preferred cloud provider and will develop the next generation of Apple Foundation Models based on Gemini technology.</li>
<li><strong>Reliance Jio:</strong> Partnership to provide over <strong>500 million</strong> consumers with an 18-month free trial of Gemini Suite and two terabytes of cloud storage, with enterprise access to Google Cloud's Gemini Enterprise and TPUs.</li>
</ul>
</ul>
<h3>Operational Outlook &amp; Focus Areas</h3>
<ul>
<li><strong>Aggressive Capital Expenditure (2026):</strong> Anticipates <strong>$175-185 billion</strong> in CAPEX, with investments ramping over the year.</li>
<ul>
<li><strong>Investment Breakdown:</strong> Approximately <strong>60%</strong> allocated to servers and <strong>40%</strong> to data centers and networking equipment. Just over half of ML compute is expected to go towards the Cloud business.</li>
<li><strong>Purpose:</strong> To support frontier model development, enhance user experience, drive advertiser ROI, meet significant Cloud customer demand, and fund strategic Other Bets.</li>
</ul>
<li><strong>Cost &amp; Expense Pressures:</strong></li>
<ul>
<li><strong>Depreciation:</strong> Expected to accelerate in Q1 and meaningfully increase for the full year 2026 due to higher CAPEX investments (2025 depreciation increased by nearly <strong>$6 billion</strong>, or <strong>38%</strong>, to <strong>$21.1 billion</strong>).</li>
<li><strong>Hiring:</strong> Continued hiring planned in key investment areas like AI and Cloud.</li>
</ul>
<li><strong>Ongoing Efficiency Drive:</strong> Efficiency and productivity are viewed as an ongoing operational approach, not a one-time effort.</li>
<ul>
<li><strong>Internal Optimization:</strong> Focus on optimizing technical infrastructure, coding productivity (approx. <strong>50%</strong> of code written by coding agents), and using AI to drive daily operations across various internal teams.</li>
</ul>
<li><strong>Compute Capacity Challenge:</strong> Managing extraordinary demand for compute capacity, addressing constraints related to power, land, and supply chain.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"Alphabet annual revenues exceeded $400 billion for the first time." - on <strong>overall financial performance</strong>
"Cloud significantly accelerated with revenues growing 48%, now on an annual run rate of over $70 billion. Backlog grew by 55% quarter-over-quarter to 240 billion, representing a wide breadth of customers, driven by demand for AI products." - on <strong>Cloud's exceptional growth</strong>
"Our 2026 CAPEX investments are anticipated to be in the range of $175-185 billion." - on <strong>future investment strategy</strong>
"We are collaborating with Apple as their preferred cloud provider and to develop the next generation of Apple Foundation Models, based on Gemini technology." - on <strong>strategic partnerships</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        Welcome, everyone. Thank you for standing by for the Alphabet Fourth Quarter 2025 Earnings Conference Call. At this time, all participants are in a listen-only mode. After the speaker presentations, there will be a question-and-answer session. To ask a question during the session, you will need to press *1 on your telephone. I would now like to hand the conference over to your speaker today, Jim Friedland, Head of Investor Relations. Please go ahead.

Thank you. Good afternoon, everyone, and welcome to Alphabet's Fourth Quarter 2025 Earnings Conference Call. With us today are Sundar Pichai, Philipp Schindler, and Anat Ashkenazi. Now, I will quickly cover the safe harbor. Some of the statements that we make today regarding our business, operations, and financial performance may be considered forward-looking. Such statements are based on current expectations and assumptions that are subject to a number of risks and uncertainties. Actual results could differ materially. Please refer to our Forms 10-K and 10-Q, including the risk factors. We undertake no obligation to update any forward-looking statement. During this call, we will present both GAAP and non-GAAP financial measures. A reconciliation of non-GAAP to GAAP measures is included in today's earnings press release, which is distributed and available to the public through our Investor Relations website located at ABC.XYZ/investor. Our comments will be on year-over-year comparisons unless we state otherwise. And now, I will turn the call over to Sundar.

Thanks, Jim. Hi, everyone. Thanks for joining us. It was a tremendous quarter for Alphabet. The launch of Gemini 3 was a major milestone and we have great momentum. Alphabet annual revenues exceeded $400 billion for the first time. This quarter: Search continued to accelerate with revenues growing 17%. YouTube's annual revenues surpassed $60 billion across ads and subscriptions. Cloud significantly accelerated with revenues growing 48%, now on an annual run rate of over $70 billion. Backlog grew by 55% quarter-over-quarter to $240 billion, representing a wide breadth of customers, driven by demand for AI products. We have over 325 million paid subscriptions across consumer services, with strong adoption for Google One and YouTube Premium. In addition, we have sold more than eight million paid seats of Gemini Enterprise, which we launched just four months ago. And our Gemini app now has over 750 million monthly active users. We are also seeing significantly higher engagement per user, especially since the launch of Gemini 3 in December. Overall, we are seeing our AI investments and infrastructure drive revenue and growth across the board. To meet customer demand and capitalize on the growing opportunities ahead of us, our 2026 CapEx investments are anticipated to be in the range of $175-185 billion. Today, I will provide an update on our AI progress and then share highlights from Search, Cloud, YouTube, and Waymo.

First, AI progress across the full stack. Our unrivaled infrastructure serves as the bedrock of our AI stack. We have the industry's widest variety of compute options. That includes GPUs from our partner NVIDIA, who announced at CES that we will be among the first to offer their latest Vera Rubin GPU platform. Plus, our own TPUs that we have been developing for a decade. In December, we announced our intent to acquire Intersect, which provides data center and energy infrastructure solutions. As we scale, we are getting dramatically more efficient. We were able to lower Gemini serving unit costs by 78% over 2025 through model optimizations, efficiency, and utilization improvements.

Next, world-class AI research, including models and tooling. We offer the most extensive model portfolio in the world and lead across text, vision, and image-to-video LM Arena leaderboards. Gemini 3 Pro drives the state of the art in reasoning and multimodal understanding. It has seen the fastest adoption of any model in our history. Since launch, Gemini 3 Pro has consistently processed three times as many daily tokens on average as 2.5 Pro. Our latest model powers Google Antigravity, our new development platform where agents can autonomously plan and execute complex software tasks. It already has more than 1.5 million weekly active users after launching just over two months ago. Our first-party models, like Gemini, now process over ten billion tokens per minute via direct API use by our customers, up from seven billion last quarter.

Third, bringing AI to our products and platforms. We are shipping innovation at scale to bring helpful AI features to people everywhere. In January alone, we have: launched Personal Intelligence in AI Mode in Search and the Gemini app; introduced new AI features to Gmail and updated Veo; reimagined Chrome as an AI-first, agentic browser through features like Chrome Auto Browse; announced Project Genie, which lets users create and explore interactive worlds generated in real-time using Genie 3, our general purpose world model; and we laid the groundwork for shopping in the AI era by introducing a new open standard for agentic commerce, the Universal Commerce Protocol, built alongside many retail industry leaders.

Finally, from Android to Pixel, we are getting our best AI capabilities into people's hands. At CES, a range of partners, including Samsung, showcased how they are bringing Gemini to more devices, from XR to the living room and beyond. And to confirm the rumors, we will be introducing our Pixel 10a to our best-ever rated Pixel 10 series very soon.

Turning now to key highlights from the quarter, starting with Search. Search saw more usage in Q4 than ever before, as AI continues to drive an expansionary moment. We have executed with incredible speed. We shipped over 250 product launches within AI Mode and AI Overviews just last quarter. We have integrated Gemini 3 directly into AI Mode in Search. Now, Search can better understand your query, dive deeper on the web, and generate interactive UI experiences. And last week, we upgraded AI Overviews to Gemini 3, giving users a best-in-class AI response at the top of the search results page. We have also made the Search experience more cohesive, ensuring the transition from an AI Overview to a conversation in AI Mode is completely seamless. These new experiences are proving to be more helpful and are driving greater usage. A few highlights: First, once people start using these new experiences, they use them more. In the US, we saw daily AI Mode queries per user double since launch and AI Overviews continue to perform very well. Second, people are engaging in longer, more complex sessions. Queries in AI Mode are three times longer than traditional searches. We are also seeing sessions become more conversational, with a significant portion of queries in AI Mode now leading to a follow-up question. Third, people are searching in new ways beyond text. Nearly one in six AI Mode queries are now non-text, using voice or images. And Circle to Search is now available on over 580 million Android devices.

Next, Google Cloud. Our growth in revenue, operating margin, and backlog highlights the strength of our entire portfolio: One, we are winning more new customers faster. We exited the year with double the new customer velocity compared to Q1. Two, we are also signing larger customer commitments. The number of deals in 2025 over a billion dollars surpassed the previous three years combined. And three, we continue to deepen our relationships with existing customers, who are outpacing their initial commitments by over 30%. Nearly 75% of Google Cloud customers have used our vertically optimized AI, from chips, to models, to AI platforms, and enterprise AI agents which offer superior performance, quality, security, and cost-efficiency. These AI customers use 1.8 times as many products as those who do not, enabling us to diversify our product portfolio, deepen customer relationships, and accelerate revenue growth. Our product line has multiple monetization levers, spanning infrastructure; platform; and high-margin, AI-powered products and services with 14 product lines each exceeding $1 billion in annual revenue.

We offer leading infrastructure for AI training and inference to our Cloud customers, with the industry's widest variety of compute options, from our own seventh-generation Ironwood TPU to the latest NVIDIA GPUs. Our ten-year track record in building our own accelerators, with expertise in chips, systems, networking, and software, translates to leading power and performance efficiency for large scale inference and training. Our Cloud AI accelerators serve the leading frontier AI labs, capital markets firms like Citadel Securities, enterprises like Mercedes-Benz, and governments for high performance computing applications. We also offer our leading generative AI models, including Gemini, Imagen, Veo, Chirp, and Lyria to Cloud customers. In December alone, nearly 350 customers each processed more than 100 billion tokens. In Q4, revenue from products built on our generative AI models grew nearly 400% year-over-year, significantly accelerating from the prior quarter. Today, more than 120,000 enterprises use Gemini, including AI unicorns like Lovable and OpenEvidence, and global enterprises like Airbus and Honeywell. 95% of the top 20, and over 80% of the top hundred SaaS companies use Gemini, including Salesforce and Shopify. Gemini is becoming the AI engine for the world's most successful software companies.

Leading enterprises are also driving strong demand for our enterprise AI agents. We have sold more than eight million paid seats of Gemini Enterprise, our enterprise AI platform, to more than 2,800 companies including BNY and Virgin Voyages, to streamline knowledge management and automate processes. Gemini Enterprise managed over five billion customer interactions in Q4 growing 65% year-over-year, for customers including Wendy's, Kroger, and Woolworths Group. Our integration of Gemini in Google Workspace is driving wins with global brands like Schwarz Group and public sector organizations like the US Department of Transportation. We are also seeing momentum with independent software vendors. Revenue from AI solutions built by our partners increased nearly 300% year-over-year, and commitments from our top 15 software partners grew more than 16X year-over-year. Before moving on, I am pleased that we are collaborating with Apple as their preferred Cloud provider and to develop the next generation of Apple Foundation Models, based on Gemini technology.

Up next, YouTube. I want to highlight four points. First, streaming. In the living room, YouTube continues to be the number one streamer in the U.S. for nearly three years, according to Nielsen. From the NFL to Coachella, YouTube is where people watch today's biggest popular culture moments unfold. Second, subscriptions. We continue to see strong subscription revenue growth across YouTube, particularly YouTube Music Premium. We will soon launch new YouTube TV plans, bringing more choice and flexibility to subscribers with over ten genre-specific packages. And the NFL has seen strong NFL Sunday Ticket subscriber growth with YouTube, with the highest paid subscriber number ever in the history of the product. Third, podcasts. To illustrate YouTube's popularity, in October 2025, viewers watched over 700 million hours of podcasts on living room devices, up 75% from just a year prior. And fourth, AI is transforming the YouTube experience for both creators and viewers. On average, every day in December, over one million channels used our new AI creation tools to supercharge their creativity. During that same month, more than 20 million viewers used our new Ask tool, powered by Gemini, to learn more about the content they watched.

And finally, Waymo. This week, Waymo raised its largest investment round to date, and is well positioned to continue its momentum, with safety at the core. In December, we surpassed 20 million fully autonomous trips and are now providing more than 400,000 rides every week. Waymo continues to expand its service territory. Its sixth market, Miami, launched two weeks ago, and Waymo will soon expand its service to multiple cities across the US, and in the UK and Japan. The team has made incredible progress on important capabilities, including opening up public service to airports and freeways. In closing, 2025 was a fantastic year for the company. A big thanks to our employees and partners worldwide. We are really well positioned going into 2026. Now, over to Philipp.

Thanks, Sundar, and hello, everyone. I will cover performance for Google Services for the quarter, then structure the rest of my remarks around the great progress we are delivering across Search, YouTube, and Partnerships. Google Services revenues were $96 billion for the quarter, up 14% year-on-year, primarily driven by accelerated growth in Search. Adding some further color to our results. The 17% increase in Search and other was led by broad strength across all major verticals, with retail particularly strong. On YouTube, the 9% growth in advertising revenues was driven by direct response. Network advertising revenues were down 2% year on year this quarter. Starting with Search and other revenues, which delivered over $63 billion in revenue for the quarter. Sundar mentioned the expansionary moment for Search. The same is true for ads. We are investing in AI to drive significant improvements across all areas of marketing. We are expanding the entire playing field that advertisers can compete on. AI gives businesses the ability to reach more customers in more places than ever before. Gemini uniquely positions us to bring the transformational benefits of AI to ads in three critical areas for our customers: ads quality, advertiser tools, and new AI user experiences.

First, ads quality. We have been deploying Gemini models to improve query understanding at a rate of almost a launch per month for the last two years. These improvements drive better query matching, ranking, and quality, making Search ads even more effective. With Gemini across our ads quality stack, we evaluate relevance with greater accuracy than with previous generations of models. This has significantly improved our ability to systematically deliver more helpful, high-quality ads, contributing to a meaningful reduction in irrelevant ads served. Gemini's understanding of intent has increased our ability to deliver ads on longer, more complex searches that were previously challenging to monetize. Gemini models also have a significant impact on query understanding in non-English languages, expanding opportunities for businesses to scale globally.

Second, we are building more agentic actions into our advertiser tools. Businesses can now leverage Gemini in conversational experiences within Ads and Analytics Advisor to identify and run recommended actions, such as generating new campaigns. Advertisers use Gemini as a real-time partner to assemble creatives. In Q4 alone, they used Gemini to create nearly 70 million creative assets via text customization in AI Max and PMax. For instance, Aritzia, Canada's premier fashion house, used AI Max to find new high-value customers that traditional strategies miss, delivering an 80% incremental uplift in conversion value for Q4. L'Oréal, one of the first alpha testers, used AI Max in 2025 across 800 unique campaigns in 23 countries and 30 brands. AI Max enabled the L'Oréal Group to maximize its presence across the full consumer journey, fuel its consumer growth, and increase revenue for DTC brands like NYX by 23%.

The third area is how we monetize new AI user experiences in Search. We have significantly increased our focus on AI Mode and are in the early stages of experimenting with AI Mode monetization, like testing ads below the AI response, with more underway. For example, we announced Direct Offers, a new Google Ads pilot, which will allow advertisers to show exclusive offers for shoppers who are ready to buy, directly in AI Mode. This new type of sponsored content uses AI to match the right offer provided by the retailer to the right user. As Sundar mentioned, we are building the era of agentic commerce and working with our partners to introduce the Universal Commerce Protocol in our consumer products and across the web. We have received tremendous feedback from the industry. Soon, people can use a new checkout experience to buy directly in AI Mode and Gemini from select merchants.

Turning now to YouTube, which remains the number one streamer in the U.S. for nearly three years, according to Nielsen. YouTube creators are providing an unmatched breadth of content. Our investment in AI innovation across creativity, viewing experience, and monetization continues to pay off. We are seeing strong traction in our subscriptions business, and are innovating to meet consumers where they are. We added a new sports tier for YouTube TV at a lower price point. YouTube Premium Lite is proving to be a popular choice. And we continue to deliver strong year-on-year growth across YouTube subscriptions, particularly YouTube Music and Premium.

Looking at monetization across YouTube, momentum continues in Shorts and the living room. Shorts now averages over 200 billion daily views and, as we have shared before, in a number of countries Shorts earns more revenue per watch hour than traditional in-stream on YouTube, including the U.S. The retail vertical continues to grow, fueled by smaller advertisers increasingly adopting Demand Gen. Likewise, direct response continues to benefit from the momentum we are seeing with small and medium sized advertisers. Viewers trust product and brand recommendations from YouTube creators, and we are focused on making YouTube a premier shopping destination. Innovations, like shoppable ad formats, are improving advertiser return on investment. During Cyber 5, advertisers piloted shoppable mastheads, a new interactive ad format where viewers browse products and send links to their phones for an easy shopping experience. On brands, our Creator Partnership Hub makes it easier for brands to find creators and develop campaigns. This holiday season, brands like JCPenney, Old Navy, and Target worked with creators for their holiday campaigns. Mattel partnered with eight top YouTube creators to reach families during the peak holiday shopping season in a campaign that helped drive a 25% increase in Search volume for UNO.

As always, I will wrap with the progress we are seeing across partnerships where our customers tap into the strength and breadth of Google's products to accelerate their transformation. I would start by joining Sundar in how pleased I am that we are collaborating with Apple as their preferred Cloud provider and to develop the next generation of Apple Foundation Models, based on Gemini technology. We partnered with Reliance Jio to provide over 500 million consumers with an 18-month free trial of our Gemini suite of products and two terabytes of Cloud storage. Reliance's enterprise customers will also get access to Google Cloud's Gemini Enterprise and TPUs, bringing the best of Google AI to every employee and workflow. The Home Depot is applying Google AI across the board, from Cloud tools to AI-powered ads and YouTube creator partnerships that connect with the next generation of doers. Their investments in PMax and YouTube creator partnerships have resulted in double-digit increase in ad clicks and visits. In closing, I would like to thank Googlers everywhere for their contributions to our success and, as always, to our customers and partners for their continued trust. Anat, over to you.

Thank you, Philipp. My comments will focus on year-over-year comparisons for the fourth quarter, unless I state otherwise. I will start with results at the Alphabet level, and will then cover segment results. I will end with some commentary on our outlook for the first quarter and full year 2026. 2025 was a strong year of innovation and execution for Alphabet. These efforts, combined with our investments in AI, drove meaningful results across the business. For the full year 2025, Alphabet consolidated revenues were $403 billion, up 15% on a reported and constant currency basis.

Moving to Q4 performance, we delivered strong growth in the fourth quarter. Consolidated revenues reached $113.8 billion, up 18%, or 13% in constant currency, and were driven by an acceleration in Search and Cloud revenues. Turning to costs and expenses, we reported a $2.1 billion stock-based compensation charge due to an increase in Waymo's valuation related to the investment round that was announced on Monday. The vast majority of the charge was reflected in R&amp;D expenses. Total cost of revenue was $45.8 billion, up 13%. TAC was $16.6 billion, up 12%. Other costs of revenues were $29.2 billion, with the increase primarily driven by appreciation, content acquisition costs largely for YouTube, and other technical infrastructure operations costs. Total operating expenses were up 29% to $32.1 billion. R&amp;D expense increased by 42%, driven by compensation and appreciation. The increase in compensation was due to the Waymo charge and investment in AI talent. Sales and marketing expenses were up 12%, primarily driven by marketing investments to support the Gemini app and Search. G&amp;A expenses increased 21%, primarily due to a shift in timing of our charitable contributions. Operating income increased 16% to $35.9 billion, and operating margin was 31.6%. Both operating income and operating margin were negatively impacted by the $2.1 billion Waymo charge in the quarter. Other income and expenses was $3.2 billion, primarily due to unrealized gains in our nonmarketable equity securities portfolio. Net income increased 30% to $34.5 billion, and earnings per share increased 31% to $2.82. We generated record operating cash flow of $52.4 billion in the fourth quarter, and $164.7 billion for the full year. This translated into $24.6 billion of free cashflow in the fourth quarter and $73.3 billion for the full year. We ended the quarter with $126.8 billion in cash and marketable securities, and $46.5 billion in long-term debts.

Turning to segment results, Google Services revenues increased 14% to $95.5 billion, reflecting strong growth in Search and subscriptions. Google Search and other advertising revenues increased by 17% to $63.1 billion, representing another strong quarter with continued growth across all major verticals with the largest contribution from retail. YouTube advertising revenues increased 9% to $11.4 billion, driven by direct response advertising. Results were negatively affected from the lapping of the strong spend on U.S. election in the fourth quarter of 2024 that we have mentioned on previous earnings calls. Network advertising revenues of $7.8 billion were down 2%. Subscriptions, platforms and devices revenues increased 17% this quarter to $13.6 billion, due to strong growth in YouTube subscriptions, and growth in Google One, which benefited from increased demand for AI plans. Google Services operating income increased 22% to $40.1 billion, and operating margins was 41.9%.

The Google Cloud segment delivered outstanding results in the fourth quarter as the business continued to benefit from strong demand for our enterprise AI products. Cloud revenue accelerated meaningfully and were up 48% to $17.7 billion. Revenues were driven by strong performance in GCP, which continued to grow at a rate that was much higher than Cloud's overall revenue growth rate. As Sundar noted, we are driving performance through strong growth and a win rate of new customers, larger customer commitments, and increasing spend with existing customers, which were generating billions in quarterly revenues. We had strong growth in both enterprise AI infrastructure driven by deployment of TPUs and GPUs, and enterprise AI solutions, which benefited from demand for our industry-leading models, including Gemini 3. Core GCP was also a meaningful contributor to growth due to strong demand for infrastructure and other services, such as cybersecurity and data analytics. We also had double-digit growth in Workspace, driven by an increase in average revenue per seat and the number of seats. Cloud operating income was $5.3 billion, more than doubling year-over-year. And operating margin increased from 17.5% in the fourth quarter of last year to 30.1%. Google Cloud's backlog increased 55% sequentially and more than doubled year-over-year, reaching $240 billion at the end of the fourth quarter. The increase in backlog was driven by strong demand for our Cloud products, led by our enterprise AI offerings from multiple customers. In Other Bets, revenues were $370 million and operating loss was $3.6 billion, reflecting the $2.1 billion Waymo charge I mentioned earlier. We allocate resources in Other Bets to businesses like Waymo, where we see meaningful opportunities to create value. Alphabet funded a significant portion of the $16 billion investment round that Waymo announced, which will allow the business to accelerate its global expansion. CapEx was $27.9 billion for the fourth quarter, and $91.4 billion for the full year, in line with our expectation. The vast majority of our CapEx was invested in technical infrastructure, with approximately 60% of that investment in servers and 40% in data centers and networking equipment. In Q4, we returned capital to shareholders through $5.5 billion of share repurchase and $2.5 billion of dividend payments.

Turning to our outlook, I would like to provide some commentary on factors that will impact our business performance in the first quarter and full year 2026. First, in terms of revenues, we are pleased with the overall momentum of the business. At current spot rates, we would expect to see an FX tailwind toward consolidated revenues in Q1. However, the volatility in exchange rates could affect the impact. In Google Services, we expect growth to be driven by ongoing innovation in the user experience, as well as improved ROI for advertisers, keeping in mind the normal seasonal pattern for advertising revenue. In Google Cloud, we are seeing significant demand for our products and services, which we expect to continue to drive strong growth, despite the tight supply environment we are operating in.

Moving to investments, the investments we have been making in AI are already translating to strong performance across the business, as you have seen in our financial results. Our successful execution, coupled with strong performance, reinforces our conviction to make the investments required to further capitalize on the AI opportunity. For the full year 2026, we expect CapEx to be in the range of $175 billion to $185 billion, with investments ramping over the course of the year. We are investing in AI compute capacity to support frontier model development by Google DeepMind, ongoing efforts to improve the user experience, and drive higher advertiser ROI in Google Services, significant Cloud customer demand, as well as strategic investments in Other Bets. Keep in mind that the availability of supply, price of components, and timing of cash payments can cause some variability in the reported CapEx number.

In terms of expenses, as we have discussed on previous calls, the significant increase in our investments of technical infrastructure will continue to put pressure on the P&amp;L in the form of higher depreciation expense and related data centers' operations costs such as energy. In 2025, depreciation increased by nearly $6 billion, or 38%, from $15.3 billion in 2024, to $21.1 billion in 2025. Given the increase in our CapEx investments in recent years, we expect the growth rate in 2026 depreciation to accelerate in Q1, and meaningfully increase for the full year. We are also planning to continue hiring in key investment areas, such as AI and Cloud. In 2025, our teams delivered amazing innovation, executing with a high level of discipline and velocity. These efforts provided great experiences for consumers and outstanding performance for creators, partners, and enterprise customers driving strong revenue growth. I am going to take this opportunity to thank our employees for their contribution to this impressive performance. Now, Sundar, Philipp, and I will take your questions.

Thank you. As a reminder, to ask a question, you will need to press *1 on your telephone. To prevent any background noise, we ask that you please mute your line once your question has been stated. Your first question comes from Brian Nowak with Morgan Stanley. Your line is now open.

I will take the agentic part first. I definitely think 2025 was more about laying the foundation, getting the models to start being more robust in agentic use cases. Obviously, coding is the area where progress was the most felt. In the areas like commerce, I think we spent the year working with the ecosystem to develop the underlying protocol that is going to be needed for this agentic world, so I think the launch of Universal Commerce Protocol at NRF in January with a bunch of founding partners, I think has been super well-received. So, I am excited now that we have laid the foundation of interoperability on which agentic commerce can work, and now we are integrating those experiences into Gemini, AI Mode, and so on. So I think this is the year where you will see consumers actually being able to use all of this, and I am excited about the opportunity ahead. On YouTube, I am super excited by Genie. I am blown away by – I have spent a lot of time creating these incredible worlds. I think it is going to have a wide level of applicability. An area where we shine in general is multimodality and representing the real world, and I think Genie is a further step in that direction in terms of building world models. All the innovation we are doing, be it Imagen, Veo, Lyria, Genie, all that work we bring into our products and to our Cloud customers, and YouTube is going to be a natural place for creators. We are going to keep incorporating these tools. Already creators are responding by adopting these, but we do want to put creators at the center of the experience, and that is very, very important to us, and so it is, for us, making sure YouTube is a voice for creator expression as the foundation by which we will approach this.

Thanks for taking my question. Over the last couple of earnings calls, we have talked a lot about imbalances between demand and capacity for AI, both internally and externally. With the staffing changes and absolute capital dollars you are projecting now in 2026, can you talk about the pathway of closing the gaps for the need for compute, both internally and externally? And how to think about some of the outputs of closing that gap as the year progresses. And again, the second part would be against that level of spend that you are now projecting toward 2026, how do you think about continuing to find operating efficiencies inside the business to fund those growth investments as well? Thank you.

Thanks, Eric. You are right, and we have been supply constrained, even as we have been ramping up our capacity. Obviously, our CapEx spend this year is an eye towards the future, and you have to keep in mind some of the time horizons are increasing in the supply chain. So, we are constantly planning for the long-term and working towards that. And, obviously, how we close the gap this year is a function of what we have done in the prior years. And so there is that time delay to keep in mind. I expect the demand we are seeing across the board, across our services, what we need to invest for future work for Google DeepMind, as well as for Cloud, I think is exceptionally strong. And so I do expect to go through the year in a supply constrained way. Maybe Anat can touch on the second part.

Thanks, Eric, for the question. I have mentioned on one of the previous earnings calls our approach to how we look at efficiency and productivity, and we do not view this as an episodic one-time project or effort, but rather how we run the business on a regular basis, and always seek additional opportunities to drive efficiency across the business. And certainly, with the demand we are seeing, whether it is from external customers or across the organization, the more capital we can free up within the organization to invest, the better we can turn this flywheel of making investments to drive future growth, and we are doing this across the organization, whether it is within our technical infrastructure, certainly when we invest at these amounts, we look at how we can ensure that we are the most efficient with every dollar that goes towards our technical infrastructure. There are scientific innovations that are part of that process, technical innovation, as you know, and we have mentioned before. We primarily focus on construction of our own data centers. We do partner with some external parties on lease on occasion, but most of our data centers we can start ourselves, and we ensure we do it in the most efficient way, in a way that matches our workloads and our needs. We look at coding productivity that Sundar mentioned. About 50% of our codes are written by coding agents, which are then reviewed by our own engineers. But certainly, it helps our engineers do more, move faster with the current footprint. We look at how we run the business across the organization. So, using AI within the business to drive daily operations. It can be all the way from the engineering team to small teams within our back office, even within my finance team, for example, we deployed the agents within our Treasury organization. We are deploying agents within how we pay and reconcile invoices. So, there are opportunities across the business that we evaluate on a regular basis to ensure we can free up more of that capacity to invest in our future.

And yeah, maybe I can answer on what keeps us up at night. I think overall, we have been on this AI-first trajectory for over a decade now, and it is what we have been methodically thinking our way through. It is the reason why we have been working on TPUs for over a decade, as an example. But I think specifically at this moment, maybe the top question is definitely around compute capacity, all the constraints, be it power, land, supply chain constraints, how you ramp up to meet this extraordinary demand for this moment. Getting our investments right for the long-term and doing it in a way that we are driving efficiencies and doing it in a world class way. And so that is where I think we are meeting the moment well, but it is definitely an area where we are spending a lot of time.

Thanks for taking questions. I have two. Over the last couple of years, we have seen considerable large language model leapfrogging, and many expect that to continue. What are the ways that Google can build and maintain its Gemini position around data and distribution and product integration? And then, as we think about the potential for TPUs to move outside of Google Cloud and into external data centers and develop as an incremental revenue stream? Thank you.

I think the LLM frontier, it has been an exciting trajectory, and I think 2026 will continue to show that progress. We are obviously improving these models across many paradigms, on pre-training, post-training, test time compute, and so on. And we are bringing multimodal models into the picture. We are bringing agentic capabilities, coding areas showing a lot of progress. And obviously, integrating all of this together and offering a great customer experience to our products, as well as through our APIs, to our Cloud customers. It feels to me like there is a lot of headroom ahead. And as you have seen our trajectory over the past two years, in terms of how we have been making progress, I think we have a very, very relentless innovation cadence, and I think we are confident about maintaining that momentum as we go through 2026. In terms of TPUs, I would think about it as it is reflected in our overall part of what makes Google Cloud an attractive choice is the wide choice of accelerators we bring to bear here, and we meet customers in terms of what their needs are, and the choice, as well as other things we bring as part of Google Cloud, efficiencies in our data centers, and all of that comes to bear and that is what you see in the strong momentum of Google Cloud, and given the overall investment we are making, we expect to be able to drive that momentum there, so that is how I would think about it.

Thank you, Sundar.

Thanks. Two questions. One, could you just comment a little bit on the YouTube ad revenue that 9% year-over-year growth? It sounded like direct response was good, and it sounded like from Search that retail came in relatively strong. So it is a little surprising that did not kind of come through in a YouTube ads revenue growth. And then, Sundar, could I ask you to try to get ahead of a debate in the market, which is kind of maybe at a Deepseek moment again. You talked earlier about Gemini being the AI engine for some of the most successful software SaaS companies out there in the world, and it just seems like there is a market belief that these software companies are kind of losing seat, power, losing pricing power, and it looks like it would be a really terrible customer base. I cannot imagine that that is actually going to happen, but could you just talk about it? You are at the forefront of AI and the impact that that is having on software companies. Why would not that be – or why would it be – undermining the economics of your large software SaaS company base? Thanks.

Mark, first of all, thank you for the question. For the full year 2025, YouTube's annual revenue surpassed $60 billion across ads and subscriptions. In Q4, YouTube ads was driven indeed by strong growth and response. On the brand side, the largest factor negatively impacting the year-over-year growth rate was lapping the strong spend on U.S. elections. We also saw a slight impact in some other brand related verticals. But taking a step back, I think it is important to think about YouTube ads and subscriptions holistically, because when a user shifts from being an ads-supported user to a YouTube Music and Premium customer, it has a slightly negative impact on YouTube ads revenues, but a positive impact on our business. And we had strong revenue growth in YouTube subscriptions this quarter, particularly in the YouTube Music and Premium category. Maybe the interesting part is what we are actually excited about, our growth momentum in brand, the opportunity on connected TVs, more innovative ad formats. For example, the shoppable mastheads I spoke about earlier that we piloted during Cyber 5. We are working really, really hard to further connect brands and creators, scaling sponsorships, and enabling advertisers to showcase their products, their services during higher visibility spotlight moments. We continue to expand the functionality of the Creator Partnership Hub, making it a lot easier for brands to find creators and develop campaigns. We are heavily focusing on brand deals, on measurement efforts. So, there is a lot of interesting work in the pipeline. And on top of that, we actually see opportunity also for upside with performance advertising. There is a lot of momentum with Demand Gen advertising. We are also excited about the opportunity for continued ads innovation and direct response. For example, shoppable formats, including in the living room, which is helping drive strength. And in retail, the continued momentum in Shorts. We are quite excited.

And, Mark, in terms of Gemini adoption and what this moment means for SaaS. At least from my vantage point, I definitely see we are very, very good SaaS customers who are leaders in their respective categories. And what I see the successful companies doing is they are definitely incorporating Gemini deeply in critical workflows, improving their product experience and driving growth, or using it to drive efficiency within their organizations. And I think it is an enabling tool, just like it has been an enabling tool for us across our products and services, be it Search, YouTube. I think the companies who are seizing the moment, I think have the same opportunity ahead, and at least we are excited about the partnerships we have there and the momentum, if I look at it in terms of their tokens usage, the growth has been very robust in Q4.

Yes, thanks for taking my questions. Two, if I may. The first for Anat. Can you talk about the relationship between investment levels and how you expect core performance to trend? Is there an operating income or free cash flow objective that you solve towards? How do you think about greenlighting resources and projects? And the second question is for all of you. A year ago, you probably could have guessed the answer to this question, but given where we are today, for each of you, what keeps you up at night here as you think about the Google story and what is next? Thanks.

Thanks, Mark. Let me start with the question on the investment framework, and it is an important one. You can imagine an important one for us as well. We have a highly rigorous framework that we use internally where we look at all the needs for investment, whether it is from our own organization, or from external customers, and have an estimate of what that investment could potentially yield. Obviously, not just near-term, but long-term as well. So, we take that into consideration when we make the following decision. The first one is the total investment that we make across the company. This was, for example, in 2025, the $91 billion we invested in CapEx, and our estimate for CapEx investment this year. So, what is the total envelope that we want to invest to ensure that we can drive both near-term and long-term growth for the company. And then the second way we use that framework is to allocate those funds across the organization, determine where we should make these investments. And throughout the year, as you can imagine, we always look to understand where things are moving, whether it is external dynamics or internal dynamics, and I have mentioned some of the supply chain pressures we are seeing externally. So we look at this with a highly rigorous framework to make sure that we are making the right decision. It was exciting to see the fact that we are already monetizing, and you saw it in the results that we just issued this quarter, the investments that we have made in AI. It is already delivering results across the business. I know in Cloud, it is very obvious external, but you have heard the comments on the success we are seeing in Search, the comments from Sundar and from Philipp, and then the frontier model development that really serves as the foundation for the organization. We will also look at the cash flow, the cash flow generation, the health of our financials and the balance sheet, that is important as well. So we take that into consideration when we make the decision about the overall level of investment. We want to make sure that we do it in a fiscally responsible way, and that we invest appropriately, but we do it in a way that maintains a very healthy financial position for the organization.

And maybe I can answer on what keeps us up at night. I think overall, we have been on this AI-first trajectory for over a decade now, and it is what we have been methodically thinking our way through. It is the reason why we have been working on TPUs for over a decade, as an example. But I think specifically at this moment, maybe the top question is definitely around compute capacity, all the constraints, be it power, land, supply chain constraints, how you ramp up to meet this extraordinary demand for this moment. Getting our investments right for the long-term and doing it in a way that we are driving efficiencies and doing it in a world class way. And so that is where I think we are meeting the moment well, but it is definitely an area where we are spending a lot of time.

Thanks. I have one for Sundar and one for Anat. Sundar, you mentioned Universal Commerce Protocol a bunch of times. I wanted to spend some time talking about the rationale for developing it, the opportunity that you see, and what it means for the discovery funnel for consumers. And Anat, any color you can provide on longer duration assets, like buildings and infrastructure, cycle assets. That would be helpful. Thanks.

Thanks, Michael. Obviously, people go through a lot of commercial journeys through our surfaces. Search, YouTube, Gemini app, and so on. So I think as well as we support through Cloud and ads, our entire retail partners as well. And the opportunity to improve the experience, I think can be a huge foundational uplift here. But it is important that we are approaching it keeping in mind that our users, as well as merchants here, and figuring out that value, part of what is been good in designing the Universal Commerce Protocol is it makes it much easier for users to complete transactions, but at the same time, it allows merchants to help showcase the range of their offerings, if they want to make promotions. So all of that is built into the protocol. And I think you have to get that value proposition for the ecosystem right to make the experience better. And so, it is foundational, and more importantly, we are now implementing the protocols, and our Gemini models are making progress in those agentic capabilities. So, I am excited about a future where, as people are going through discovery, searching, finding new things, if they are interested in acting upon it, all of that is seamless, and so it overall creates an expansionary moment.

And the question with regard to the CapEx and what makes up the total that we have announced for this year and last year. Approximately 60% of our investment in 2025, and it is going to be fairly similar in 2026, went towards machines, so the servers. And then 40% is what you refer to as long duration assets, which is our data centers and networking equipment. I think you are probably referring to the depreciation delta between them, those long-term duration assets depreciate over – the building could be 40 years or longer. Other components may be less than that. Another important component is how we allocate this CapEx, and we have commented in the past about the allocation of our ML compute across the business, and for 2026, just over half of our ML compute is expected to go towards the Cloud business.

Thank you so much.

Just a question on the native Gemini 750 million. So we added 100 million MAUs in the fourth quarter. Could you just talk high level about usage and retention of native Gemini? And is this 750 the right way to measure your progress against companies like ChatGPT, or is there another cohort of users that are not in that 750 that maybe we should also consider? Thanks a lot.

Of course, I think we definitely saw, I would say, extraordinary creative growth in Q4 for Gemini app. It is not just a growth in monthly active users, but there is definitely – there was a sharp increase in engagement per user on the app. So, all the metrics, be it active usage, the intensity of usage, retention, all showed distinct progress across iOS, web, Android, and geographically globally. So definitely, all the product experience improvements, the work we did with Nano, the progress with the Gemini models, all translated into strong momentum, and the momentum is continuing. So, we are excited about that and will continue to invest. Obviously, there are many people who are getting a deeply AI-native experience in the context of AI Mode and Search as well, and we are definitely seeing strong growth and progress, and the introduction of Gemini 3 in AI Mode was a very positive driver as well. And, obviously, we will continue to evolve these experiences, and I am excited about the opportunities there.

Thank you.

Thank you very much. Two, if I may. Both on Search. First, could you walk us through how you are evolving your views on the monetization of AI Search activity? Given the more conversational nature and longer periods of GAI engagement per session, consumer utility increasingly is driven by the on-platform results, not specifically referrals.

How do you think about increasing the revenue opportunity to match consumer utility, and is this increasingly where premium subscriptions play? The second, related question is, as you think about partnerships such as the new Apple partnership on Siri, how do you align for success with those partners? Previously, as disclosed in the DOJ documents, et cetera, it was a revenue share relationship. But now, if you think about the utility that you're driving through AI search and Gemini on those platforms, it may be less related to the actual &quot;search revenue.&quot; Could you talk a little bit about how you align with partners for success there?

First, the acceleration we saw in search was not due to a single driver, but was the result of many different parts of our business showing strength and working well together. I'll quickly add that from a vertical perspective, retail, finance, and health drove the greatest contribution to search revenue. Nearly every major vertical accelerated in Q4. More specifically to your question, the ongoing innovation, which is core to what we do, and the enhancements to the user and advertiser experience continue to drive our performance. We make hundreds of these changes every quarter. We see AI Overviews and AI Mode continue to drive greater search usage and growth in overall queries, including important commercial queries. Gemini-based improvements and search ads help us better match queries and craft creatives for advertisers. The understanding of intent has significantly expanded our ability to deliver ads on longer and more complex searches that were previously difficult to monetize. AI Max, for example, has already supported hundreds of thousands of advertisers and continues to unlock billions of net new queries. We see strength with SMB advertisers expanding their budgets and adopting automation tools, leading to better ROI. On the creative side, we're using Gemini to generate millions of creative assets via text customization in AI Max and P Max. We are very pleased with what we're seeing here.

Our last question comes from Justin Post with Bank of America. He wanted to follow up on the Gemini app, noting its great growth. Are you seeing any cannibalization of search activity as people start using that app more? Secondly, on monetization, where are you on that? And with Agentic and other ads coming, could that be incremental to your growth over the next few years?

Right now, overall, we are giving people choice. People are using search, experiencing AI Overviews and AI Mode as part of it, and the Gemini app as well. The combination of all of that creates an expansionary moment. It's expanding the type of queries people do with Google overall. Some of it is what we see as a growth opportunity, and we haven't seen any evidence of cannibalization there. Philipp can comment on the monetization.

Sundar previously commented on Agentic and how we think about it. As with all of our products, we focus first and foremost on creating a great user experience. We are excited about where we are with the ads and AI Overviews and early speerm experiments in AI. In terms of the Gemini app, we are focused on the free tier and subscriptions and seeing growth, as Sundar discussed. As part of scaling products to reach billions of people, if done well, ads can be valuable, helpful commercial information. We are not rushing anything here.

That concludes the question-and-answer session. Jim Friedland offered closing remarks, thanking everyone for joining and looking forward to speaking again on their first quarter 2026 call. He wished everyone a good evening.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-1">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=6fbyiPRhMSs" target="_blank" rel="noopener">Cisco AI Summit | Special live event with Jensen Huang</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>52:05</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-04</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Chuck Robbins</span> <span class="tag tag-person">Jensen Huang</span></div>
                </div>
                <div class="tldr">AI fundamentally reinvents computing by shifting from explicit to implicit programming, driving the need for enterprises to adopt an &quot;AI factory&quot; mindset, strategically experimenting with the technology, and transforming into &quot;technology-first&quot; compa...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-1">TL;DR AI fundamentally reinvents computing by shifting from explicit to implicit programming, driving the need for enterprises to adopt an &quot;AI factory&quot; mindset, strategically experimenting with the technology, and transforming into &quot;technology-first&quot; companies to leverage AI's...</div>
                    <div class="summary-full" id="full-1">
                        <p><strong>TL;DR</strong></p>
<p>AI fundamentally reinvents computing by shifting from explicit to implicit programming, driving the need for enterprises to adopt an "AI factory" mindset, strategically experimenting with the technology, and transforming into "technology-first" companies to leverage AI's exponential capabilities and avoid being left behind.</p>
<h3>AI as a Fundamental Computing Transformation</h3>
<ul>
<li><strong>Reinventing Computing:</strong> Jensen Huang, Founder, President &amp; CEO of NVIDIA, states that AI represents the first reinvention of computing in 60 years, moving from explicit programming (where developers write instructions) to implicit programming (where intent is given, and the computer figures out solutions).</li>
<ul>
<ul>
<li>This shift affects the entire computing stack: processing, storage, networking, and security, all of which are being reinvented.</li>
</ul>
</ul>
<li><strong>The "AI Factory" Concept:</strong> An AI factory is an infrastructure designed to develop AI to a useful level, moving beyond basic chatbots to "agentic AI" that can solve problems, reason, plan, use tools, perform research, and grounded retrieval augmented generation.</li>
<ul>
<ul>
<li>This evolution requires foundational changes to the computing stack, which NVIDIA and Cisco are partnering on.</li>
<li><strong>Cisco's Role:</strong> Cisco is integrating NVIDIA's AI networking technology into its Nexus control plane to provide AI performance with Cisco's manageability and security, and will also address the security pillar of the reinvented computing stack.</li>
</ul>
</ul>
</ul>
<h3>Strategic Enterprise Adoption of AI</h3>
<ul>
<li><strong>Urgency to Engage:</strong> Enterprises must get engaged with AI quickly to avoid falling behind; while not needing to be first, being last is not an option.</li>
<li><strong>Beyond ROI:</strong> Jensen Huang advises against focusing on immediate ROI in early AI deployments, as the value of new technology is hard to quantify initially.</li>
<ul>
<ul>
<li><strong>"Let a Thousand Flowers Bloom":</strong> Companies should encourage widespread experimentation safely across the organization, rather than seeking explicit, specific, or demonstrable ROI from the outset.</li>
<li><strong>Focus on Core Work:</strong> Identify the most impactful, "essence" work of the company and dedicate significant expertise and capability to revolutionize that work with AI (e.g., NVIDIA's focus on chip design, software, and system engineering).</li>
</ul>
</ul>
<li><strong>Innovation Mindset:</strong> Innovation is inherently "out of control" and requires a "yes, then why" approach to experimentation, mirroring how one encourages exploration in children.</li>
</ul>
<h3>The Abundance Mindset and AI's Impact</h3>
<ul>
<li><strong>Abundance of Intelligence:</strong> AI dramatically reduces the cost of intelligence, creating an abundance where tasks that once took years can now take days or even real-time.</li>
<ul>
<ul>
<li>This is a much faster acceleration than Moore's Law, representing a "million times every 10 years" improvement in AI capabilities.</li>
</ul>
</ul>
<li><strong>"Infinity" Sensibility:</strong> Leaders should approach problems as if technology is infinitely fast, has zero mass, or can handle immense scale without effort (e.g., processing an entire graph database rather than small pieces).</li>
<ul>
<ul>
<li>Applying this "infinity" or "zero" sensibility to the hardest, most impactful problems will move the needle for a company.</li>
</ul>
</ul>
<li><strong>Competitive Imperative:</strong> If a company isn't thinking with this "AI sensibility," competitors or new startups will, fundamentally changing the competitive landscape.</li>
</ul>
<h3>Beyond Digital: Physical AI and the "Technology-First" Imperative</h3>
<ul>
<li><strong>Agentic AI &amp; Tool Use:</strong> The latest breakthroughs involve "tool use" because AI, like humans, will leverage existing explicit tools (e.g., SAP, ServiceNow, design software) rather than reinventing fundamental algorithms (like F=MA or V=IR).</li>
<li><strong>Physical AI and Causality:</strong> A new type of physical AI is needed to understand the physical world and causality (e.g., a domino effect), a concept large language models currently struggle with but is critical for robotics and real-world application.</li>
<li><strong>Augmented Labor &amp; TAM Expansion:</strong> For the first time, the IT industry is creating "augmented labor" (e.g., a digital chauffeur), unlocking a Total Addressable Market (TAM) potentially 100 times larger than the traditional IT market (trillion vs. hundred trillion dollars of the global economy).</li>
<li><strong>Become a "Technology Company":</strong> Every company has the opportunity to become "technology-first," operating with the mindset of dealing with "electrons" (software, data) rather than being limited by "atoms" (physical products/services).</li>
<ul>
<ul>
<li><strong>Domain Expertise as Superpower:</strong> With implicit programming, domain expertise and understanding customer needs become the ultimate value, as AI can handle the "commodity" of coding/typing.</li>
</ul>
</ul>
</ul>
<h3>Building and Integrating AI Capabilities</h3>
<ul>
<li><strong>Build Your Own Computer:</strong> Jensen Huang advises enterprises to "lift the hood" and build some of their own AI infrastructure, even if it's small, to gain tactile understanding and potentially discover new skills.</li>
<ul>
<ul>
<li>This balances renting cloud services with owning on-prem capabilities for sovereignty and privacy.</li>
<li><strong>Protecting Proprietary Questions:</strong> Companies should maintain private AI infrastructure because proprietary *questions* (what a company is thinking about, what problems it's trying to solve) are often more valuable IP than the answers themselves.</li>
</ul>
</ul>
<li><strong>AI in the Loop:</strong> The future lies in having "AI in the loop" rather than "human in the loop."</li>
<ul>
<ul>
<li>This ensures that AI continuously captures life experience and contributes to the company's intellectual property, preventing backward steps and fostering continuous learning and growth.</li>
</ul>
</ul>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"We're reinventing computing for the first time in 60 years. What used to be explicit programming... to implicit programming. You now tell the computer what your intent is and it goes off and and it figures out um how to solve your problem."
— Jensen Huang, Founder, President &amp; CEO of NVIDIA
"Don't don't fall behind. I think there's you don't have to be the first company to take advantage of AI but don't be the last."
— Jensen Huang, Founder, President &amp; CEO of NVIDIA
"If you're not thinking that way, just all you have to do just imagine your competitors thinking that way. If you're not thinking that way, just imagine a company who is about to get founded is thinking that way. It changes everything."
— Jensen Huang, Founder, President &amp; CEO of NVIDIA
"You're not going to lose your job to AI. You're going to lose your job to someone who uses AI."
— Jensen Huang, Founder, President &amp; CEO of NVIDIA
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-1" onclick="toggleSummary(1)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-1" onclick="toggleTranscript(1)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-1">
                        First of all, thanks everybody for being here for an incredibly long day. We started this thing early this morning, and we had speaker after speaker after speaker, and then we had about a two-and-a-half-hour break and they came back to see you. I’ve been up since 1:00.

This guy is on the tail end of a two-week trip, covering four or five different cities in Asia. One day ago I was in Taiwan. Last night I was in Houston. Here I am. He's been gone two weeks, and we're standing between him and his personal bed versus a hotel. So, we're going to have fun and then we're going to get him out of here. You don't need much of an introduction, but thank you for being here, man. We really appreciate it.

Thanks for our partnership, and I’m really proud of you guys.

Let's start with that. We have had a partnership, and you introduced this whole concept of AI factories, and we're working on this together. It's probably not going as fast as either one of us would like in the enterprise space, but can we start by talking about what an AI factory is to you?

First of all, remember we're reinventing computing for the first time in 60 years. What used to be explicit programming—we wrote the programs and the variables that are passed through APIs and are very explicit—is now implicit programming. You now tell the computer what your intent is, and it goes off and it figures out how to solve your problem. So, from explicit to implicit, from general purpose computing (basically calculation) to artificial intelligence, the entire computing stack has been reinvented.

People talk about computing where the processing layer is, which is where we are, but remember what computing is: there's computing, there's the processing, but there's storage, networking, and security. All that is being reinvented as we speak. So, the first part is we need to develop AI to a level—and we'll talk about that—we need to develop AI to a level that is useful to people. Until now, chatbots, where you give it a prompt and it figures out what to tell you, is interesting and curious but not useful.

It helps me finish crossword puzzles sometimes.

Yes. But only on things that it had memorized and generalized. If you go back to the beginning—literally only three years ago when ChatGPT emerged—we thought, &quot;Oh my gosh, it's able to generate all these words, it's able to create Shakespeare.&quot; But it's all based on things that it memorized and generalized. We know that intelligence is about solving problems, and solving problems is partly about knowing what you don't know, partly about reasoning how to solve a problem you've never seen before, breaking it down into elements that you know how to solve very easily so that in its composition you're able to solve problems you've never seen before, and to come up with a strategy, what we call a plan, to perform a task. Ask for help, use tools, do research, and so on.

These are all fundamental things that now, in the phraseology of agentic AI, you're starting to hear: tool use, research, retrieval augmented generation (which is grounded on facts), memory. These are all things that all of you, in the context of talking about agentic AI, are starting to hear.

But the important thing is, in order to evolve from general purpose computing, which is explicit programming—we wrote in Fortran, we wrote in C, we wrote in C++...

Cobol.

That's right, that's good stuff, Chuck, that's good stuff.

It's my fallback job.

That's good stuff, that's good stuff.

Yeah, that's one of those skills that remains valuable.

I know that it remains valuable.

I've got a lot of offers.

Dinosaurs are valuable forever.

We just established that you're older than me.

I know. And I'm the prehistoric. It doesn't appear so, but it's true.

All right, that was pretty good. I'm probably the oldest person in this room. Let's talk a little bit about how you think about it.

So here we are. I went to Chuck and I said, &quot;Hey listen, we need to reinvent computing and Cisco's got to be a big part of it.&quot; So we have a new computing stack coming out, Vera Rubin, and Cisco is going to go-to-market with us on that. So there's the computing layer, but there's also the networking layer. Cisco is going to integrate AI networking technology from us but put it into the Cisco Nexus control plane, so that from your perspective, you're going to get all the performance of AI but with the controllability, security, and manageability of Cisco. We're going to do the same thing with security. Each one of these pillars has to be reinvented so that enterprise computing can take advantage of it. But ultimately, and we'll come back to this hopefully, why is it that enterprise AI wasn't ready three years ago, and why is it that you have no choice but to get engaged as quickly as you can? Don't fall behind. You don't have to be the first company to take advantage of AI, but don't be the last.

So if you're an enterprise today, what's your recommendation on the first, second, third step they should take to begin to get ready?

I get questions like ROI, and I wouldn't go there. The reason for that is because with all technology deployments in the beginning, it's hard to put into a spreadsheet the ROI of a new tool, a new technology. What I would do is I would go find out what is the essence of my company? What's the most impactful work that we do in our company? Don't mess around with peripheral stuff. In our company, we just let a thousand flowers bloom. The number of different AI projects in our company is out of control, and it's great. It's out of control, and it's great. Innovation is not always in control. If you want to be in control, first of all, you've got to seek therapy. But second, it's an illusion. You're not in control. If you want your company to succeed, you can't control it. You want to influence it, you can't control it.

Too many companies I hear want it explicit. They want it specific. They want demonstrable ROI. Showing the value of something worth doing in the beginning is hard. What I would say is, let a thousand flowers bloom. Let people experiment. Let people experiment safely. We're experimenting with all kinds of stuff in the company. We use Anthropic, we use Codex, we use Gemini, we use everything. When one of our groups says, &quot;I'm interested in using this AI,&quot; my first answer is yes. I ask why instead of why then yes. I say yes, then why. The reason for that is because I want the same thing for my company that I want for my kids: go explore life. They say they want to try something. The answer is yes. You don't go prove it to me. Prove to me that doing this very thing is going to lead to financial success or some happiness someday. Prove to me. And until you prove it to me, I'm not going to let you do it. We never do that at home, but we do it at work. Do you know what I'm saying? It makes no sense to me.

The way that we treat AI—and whether it's AI or the internet before, or cloud before—just let a thousand flowers bloom. Then at some point, you have to use your own judgment to figure out when to start curating the garden, because a thousand flowers blooming makes for a messy garden. But at some point, you have to start curating to find what's the best approach, or what's the best platform, so that you can put all your wood behind one arrow. You don't want to put all your wood behind one arrow too soon. You might pick the wrong arrow. So, let a thousand flowers bloom. At some point, you curate. I haven't started curating yet. I've got a thousand flowers blooming everywhere. But I encourage everybody to try.

However, I know exactly what is most important to our company. Of course, I do. What is the essence of our company? What is the most important work of our company? And I make sure that I've got a lot of expertise and a lot of capability focused on using AI to revolutionize that work. In our case, chip design, software engineering, system engineering. You might have noticed that we partnered with Synopsis and Cadence and Siemens and Dassault so that we could insert our technology and infuse as much technology as they want. Whatever they want, whatever they need, I will provide so that I can revolutionize the tools by which we use to design what we do. We use Synopsis everywhere. We use Cadence everywhere. We use Siemens everywhere. Use Dassault everywhere. I will make sure that they have 1000% of whatever they want so that I have the tools necessary to create the next generation. That tells you something about my attitude about what's most important to me and what I would do to revolutionize my own work.

Think about what AI does. AI reduces the cost of intelligence or creates the abundance of intelligence by orders of magnitude. That's another way of saying what used to take one unit of time. What used to take a year could take a day now. What used to take a year could take an hour. It could be done in real time. The reason for that is because we are in the world of abundance. Moore's Law, goodness gracious, that was slow. That's like snails. Moore's Law was two times every 18 months, 10 times every five years, 100 times every 10. But where are we now? A million times every 10 years. In the last 10 years, we advanced AI so far that engineers said, &quot;Why don't we just train an AI model on all of the world's data?&quot; They didn't mean, &quot;Let's just collect all the data from my disc drive.&quot; They meant, &quot;Let's pull down all of the world's data and let's train an AI model.&quot; That's the definition of abundance.

The definition of abundance is you look at a problem so big and you say, &quot;I'll do it all. I'm going to cure every field of disease. I'm not going to just do cancer.&quot; We'll just do all of human suffering. That's abundance. When I think about engineering, when I think about a problem these days, I just assume my technology, my tool, my instrument, my spaceship is infinitely fast. How long is it going to take for me to go to New York? I'll be there in a second. So, what would I do differently if I can get to New York in a second? What would I do differently if something used to take a year and now takes real time? What would I do differently if something used to weigh a lot and now it's anti-gravity?

You approach everything with that attitude. When you approach everything with that attitude, you are applying AI sensibility. For example, there are many companies that we're working with where graph analytics, the dependency, the relationships and dependencies, these graphs, they have so many edges, so many nodes and edges, trillions of them. Back in the old days, you would process a graph, small pieces of it. These days, just give me the whole graph. How big is it? I don't care. That sensibility is being applied everywhere. If you're not applying that sensibility, you're doing it wrong.

If speed matters, imagine it doesn't matter at all. You're at the speed of light. If mass is a factor, you're at zero weight, zero gravity. If you're not applying that logic, if something that was insanely hard to you in the past you now go, &quot;Doesn't matter.&quot; If you're not applying that logic, you're not doing it right. Imagine you apply that logic, that sensibility, to the hardest problems in your company. That's how you're going to move the needle. And that's how they all think. If you're not thinking that way, just imagine your competitors thinking that way. If you're not thinking that way, just imagine a company who is about to get founded is thinking that way. It changes everything. So I would go find where are the most impactful works in your company. Apply infinity to it. Apply zero to it. Apply the speed of light to it. And then ask Chuck how to make that happen.

Just call me. I'll…

We'll call you. We'll do it together.

You have this analogy, this five-layer cake, because everybody's talking about infrastructure, models, apps. How do I go about it? Talk about that a little bit.

The first thing successful people do is they reason about what's happening. Almost 15 years ago, an algorithm, with two engineers, was able to solve a computer vision problem. Computer vision is basically the first part of intelligence: perception. Intelligence is perception, reasoning, planning. Perception: What am I? What's going on? What's my context? Reasoning: How do I compare this to my goals? And then three: come up with a plan to solve that, to achieve that. For example, the jet fighter problem: perception, localization, and then action.

Intelligence is about those three things. You can't have the second and third part without perception. You can't figure out what to do without understanding context. And context is highly multimodal. Sometimes it's a PDF, sometimes it's a spreadsheet. Sometimes it's information. Sometimes it's senses and smells. Where are we? What are we doing here? Who's the audience? Reading the room, and so on. That's about perception.

About 13 or 14 years ago, we made a huge, gigantic leap in computer vision, which is the first layer of the perception problem. It was super hard. And AlexNet was the first breakthrough that we saw. It was like our first contact to AI. We said, &quot;What does that mean? How is it possible that two engineers were able to overcome the algorithms that all of us worked on for some 30 years?&quot; Ilya Sutskever, I talked to him yesterday, and Alex Krizhevsky—how is it possible two kids with a couple of GPUs solved this problem? What does it mean? We broke it all down, and I reasoned about it a decade ago, and I came to the conclusion that in fact, most of the hard problems in the world that seemed unsolvable could now be solved this way.

The reason for that is most of the hard problems in the world, most of the valuable problems, have no principled algorithms. There's no F=MA. There's no Maxwell's equation. There's no Schrödinger's equation. There's no Ohm's law. It just doesn't exist. There's no law of thermodynamics. It's not that specific. Most of the valuable things that we call intuition and wisdom—the problems that you and I get—the answer is, &quot;It depends.&quot; If it was 3 it'd be great, if it was 3.14 it'd be fantastic. Those are the great ones. But most of the hard problems in life, most of the valuable problems in life, are &quot;it depends,&quot; because it depends on the context, it depends on a circumstance.

So, 12 or 13 years ago, computer vision was solved. We reasoned that in fact, this could be scalable because of deep learning, and you can make the models larger and larger. There was only one problem we had to solve: how do we train that model? The big breakthrough was self-supervised learning or unsupervised learning. Self-AI is that goal, and it learns by itself. Today, we're not limited by labeling anymore, not even close. That breakthrough opened up the floodgates for us to scale these models from a few hundred million parameters to billions to trillions. The amount of knowledge we can codify, the number of skills we can learn algorithmically, really largely exploded. But the basic approach was the same.

We reasoned that, in fact, we're going to reinvent computing altogether, from explicit programming to a new way of doing computing where the models—the software—will be learned. If you take another step back, what does that mean to the computing stack? What does it mean to how you develop software? What happens to the engineering organization in your company? What happens to the product marketing team that specifies the product? What happens to the engineering team that codifies the product? What happens to the QA team that evaluates the product? What do these products even become someday? How do we deploy the product? How do we keep it up to date? If it's based on machine learning, how do you keep it refreshed forever? How do you patch software? The number of &quot;hows&quot; I asked about the future computing must have been a thousand questions, and our company came to the conclusion that this is going to change everything. We pivoted the whole company based on that core belief.

Simplistically, what Chuck is saying is that we came from a world where everything was pre-recorded. The software that Chuck worked on...

It ran a very long time. Just for the record, it was indeed described in the Hebrew.

That is true. That was another skill. The only person in the room that knows Hebrew Cobol. Anyway, that was pre-recorded. We engineers described our algorithms, described our thoughts, and then we put data that goes along with it. Everything is pre-recorded. Software in the past was pre-recorded because it came in a CD-ROM. It was pre-recorded.

What is software now? Because it's contextual, dynamic, and every context is different, and every time everybody who uses the software is different, and every prompt is different, and the precursor, the priors, the context you give it is different. Every single instance of the software is different, which is the reason why the amount of computation necessary in the past was retrieval-based. Check yourself. When you use your phone, you touch something, it went and retrieved some software, some files, some images, and brought it to you. In the future, everything is going to be generative, just like what is happening right now. This conversation has never happened before. The concepts existed before. The priors existed before, but every single word in this sequence has never happened before. The reason for that is obviously we're four wines in.

Cobol and Hebrew have never come out of the...

Cold brew. Yes. Cobol, Hebrew. No. Thank goodness this is not on campus or being streamed.

Do you understand what I'm saying? As a result, do you understand what you're saying? The only thing that Chuck has fed me today so far is four glasses of wine.

To be fair, I only fed you one of them. You took the other three off the buffet.

I was eyeing the food. I was so hungry, eyeing the food. It was forever about 40 feet away from me.

Because you were taking photos.

It was so close. It was so close. I actually leaned towards the food one time, but I was pushed back again.

Your team actually told us ahead of time, &quot;If you get three glasses of wine in, he's optimal. If you get the fourth one in, it's going to be incredible.&quot; This is suboptimal. So, listen, what is AI? We have to leave some wisdom behind. Can we get another glass of wine, please? This is not just Dave Chappelle stuff. Let's talk about one other thing: energy. That, chips, infrastructure, both hardware and software. Then the AI model. But the most important part of AI is applications. Every single country, every single company, all that layer underneath is just infrastructural stuff. What you need to do is apply the technology. For God's sakes, apply the technology.

A company that uses AI will not be in peril. You're not going to lose your job to AI. You're going to lose your job to someone who uses AI. So, get to it. That's the most important thing. Call Chuck as soon as possible.

You call me, I'll call him. Got it.

We don't have a lot of time.

We've got all the time in the world.

Do we? How much? Look, Chuck, he bills on the clock. I don't even wear a watch. Look at that. Chuck, I've got you right here. Yeah, we're doing great. You bill people on the clock. Not me. I'm not leaving until value's delivered. If it takes all night, I'm not... Until you could say that you learned something, you are going to be trapped in here.

We're going to torture everybody until value is delivered.

I did check, there is more wine. Can you just give us your top of mind on physical AI?

Remember what software is? Software is a tool. There's this notion that the tool industry is in decline and will be replaced by AI. You could tell because there's a lot of software companies whose stock prices are under a lot of pressure because somehow AI is going to replace them. It is the most illogical thing in the world, and time will prove itself.

Let's give ourselves the ultimate thought experiment. Suppose we are the ultimate AI, artificial general robotics, the physical version of us. You could of course solve any problem because you're humanoid. You could do things. If you were a humanoid robot, would you use a screwdriver or invent a new screwdriver? I would just use one. Would you use a hammer or invent a new hammer? Would you use a chainsaw or invent a new chainsaw? Do you understand what I'm saying? If you were a humanoid robot, artificial general robotics, would you use tools or reinvent tools? The answer obviously is to use tools.

Now do the digital version of that. If you were an artificial general intelligence, would you use the tools like ServiceNow and SAP and Cadence and Synopsis, or would you reinvent a calculator? Of course, you would just use a calculator. That's the reason why the latest breakthroughs in AI is tool use. Because the tools are designed to be explicit. There are many problems in our world where F=MA. F is not kind of MA. It's just MA. V=IR. It's not kind of IR. It is IR. Do you understand what I'm saying? So I think we want artificial general robotics, artificial general intelligence to use tools.

That's the big idea. I think that in the next generation of physical AI, we're going to have AIs that understand the physical world, understand causality. If I tip this over, it's going to tip all of that over. They understand the concept of a domino. The concept of a domino—a child understands if you tip that over—it's deeply profound. Causality, contact, gravity, mass—all of that is integrated into a domino. The idea that you could have a little tiny domino tip a larger domino, tip a larger domino, tip a larger domino to the point where there's a ton on the other side, a child has no trouble with that concept. A large language model will have no idea.

So we have to teach, we have to create a new type of physical AI. So far, the industry that Chuck and I have been part of is about creating tools. We have been in the screwdriver and hammer business. Our entire life has been about creating screwdrivers and hammers. For the first time in history, we are going to create what people call labor, but augmented labor. What is a self-driving car? What's a digital chauffeur? What's a digital chauffeur valued at? A lot. A lot more than the car. The reason for that is because in the lifetime of the digital chauffeur, the economics of the digital chauffeur is a lot more than the car. For the very first time, we are exposed to a Total Addressable Market (TAM) that is 100 times larger. Literally, mathematically true. The IT industry is about a trillion dollars, or so. And yet the economy of the world is about 100 trillion dollars. For the very first time, we're going to be exposed to all of that.

It is the case that everyone in this room today has the opportunity to apply this technology to become a technology company. Let me give you some examples. I love Disney and working with them. I'm pretty sure they'd rather be Netflix. I love Mercedes. I came in a Mercedes. I am certain they'd rather be Tesla. I love Walmart. I am certain they'd rather be Amazon. Do you agree so far? Am I three for three? All of you are that way. I believe that we have an opportunity to help transform every single company into a technology company. Technology first. Technology is your superpower, and the domain is your application, versus the other way, which is the domain is who you are, and you're seeking for technology. The reason that's so is because companies who are technology first are dealing with electrons, not atoms. And there are a lot more electrons. Atoms, you're limited by mass, which is the reason why the moment they went from CD-ROMs to electrons, the value of the company exploded by a thousand times. You need to be like us, an electron company, which is another way of saying a technology company.

So I think the opportunity for you is here. Another way to think about that is AI. Even Chuck, who only knows how to program in Hebrew... It's a gift. His instrument choice is a right-to-left, because as you know, it smears otherwise. It is pretty smart, actually. Smart people do smart things.

The beautiful thing is that the programming language of the world, for all of your companies—you feel like software is not our strength, but knowledge, intuition, domain expertise is your strength. You now, for the first time, can explain exactly what you want to a computer in your language. Remember where we started, from explicit programming to implicit programming? For the first time in history, you could program a computer implicitly. Just tell it what you want. Tell it what you mean, and the computer will write the code, because coding, as it turns out, is just typing. And typing, as it turns out, is a commodity. That's the great opportunity for you. All of you could be levitated above the atomic limitations that you were limited by before. All of you could escape from this limitation: &quot;We don't have enough software engineers,&quot; because, as it turns out, typing is a commodity. All of you have something of great value, which is domain expertise to understand the customer, understand the problem. That is the ultimate value, to understand the intent. When you graduate from college, you could be a super programmer, but you have no idea what customers want. You have no idea what problems to solve. You know what customers want. You know what problems to solve. The coding part of it is easy. Just tell the AI to do it. That's your superpower. Chuck and I are here to enable you to do that. That closing was done with five glasses of wine in me.

As it's a miracle indeed, this is somebody who works off a table, a true representation of artificial intelligence, maybe that's enhanced. I just want to tell you that it's a great pleasure working with all of you. Cisco, as you know, has extreme expertise in two very important pillars of the invention of computing. Without Cisco, there is no modern computing. One of them supports networking, and the other is security. Both of those pillars have been reinvented in the world of AI. The part that we know very well, which is the computing part of it, is in a lot of ways a commodity, and the stuff that Cisco knows is deeply valuable. Between the two of us, we'll be delighted to help all of you engage the world of AI.

Somebody asked me earlier, and I think it's worth repeating, should you just rent the cloud, or should you even make the effort to build your own computer? Here's what I would tell you. I would advise you to do exactly the same thing I advise my children: build a computer. Even though the PC is everywhere, even though it's mature, even though technology is developed, build one. Understand why all the components exist. If you were to be in the world of automotive, the transportation industry, don't just use Uber. Lift the hood, change the oil, understand all the components. Understand how it works. It is vital. This technology is so important to the future. You must have some tactile understanding of it. Lift the hood, change the oil, build something. It doesn't have to be large. Build something. You might discover you're actually insanely good at it. You might discover that you need that skill. You might discover that the world is not about all rent versus all own, that you want to rent some and own some, because some part of your company should be built on-prem.

For example, sovereignty and proprietary information. You're not comfortable sharing your questions with everybody. When you go see a therapist, you don't want the questions to be online. You know what I'm saying? Hypothetically, a lot of questions you have, a lot of conversations you have, a lot of dialogue, a lot of uncertainties you have ought to be kept private. Companies are the same way. I am not confident. I am not secure about putting all of Nvidia's conversations in the cloud, which is the reason why we built it locally. We've built a super AI system locally because I'm just not confident to share that conversation, because, as it turns out, the most valuable IP to me is not my answers; it's my questions. My questions are the most valuable IP to me. What I'm thinking about are my questions. The answers are a commodity. If I simply knew what to ask. I'm identifying what's important. I don't want people to know what I think is important. I want that to be in a small room. I want that to be on-prem. I want that to be by myself. And I want to create my own AI.

One last thought. There was an idea that AI should always have human in the loop. It's exactly the wrong idea. It's backwards. Every company should have AI in the loop. The reason for that is because we want our company to be better and more valuable and more knowledgeable every single day. We never want to go backwards. We never want to go flat. We never want to start from the beginning. If we have AI in the loop, it will capture our life experience. Every single employee in the future will have AI, lots of AIs in the loop. Those AIs will become the company's intellectual property. That's the future company. I think it sensible for all of you to call Chuck immediately.

Two weeks on the road. Jensen flew here, spent his last evening with us before he gets to sleep in his bed for the first time in a long time. We're forever grateful. Appreciate you being here. Thank you. Thank you, man. From the corner of my eye, there were all these skewers. Somebody was still there. Where's the bag of Fritos? All right, let's go. Thank you. Thank you, everybody.
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>