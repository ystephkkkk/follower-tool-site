<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - February 08, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
            scroll-margin-top: 1rem;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-header-link {
            display: block;
            padding: 1.25rem 1.5rem 0.75rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header-link:hover .day-date {
            color: var(--accent);
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
            transition: color 0.15s ease;
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.3rem;
            padding: 0.6rem 0;
            border-bottom: 1px solid var(--border);
            text-decoration: none;
            color: inherit;
            border-radius: 4px;
            transition: background 0.12s ease;
        }

        .day-preview-item:hover {
            background: var(--bg-tertiary);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-title {
            font-size: 0.88rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.35;
        }

        .preview-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            background: var(--bg-tertiary);
            padding: 0.15rem 0.5rem 0.15rem 0.25rem;
            border-radius: 14px;
        }

        .preview-channel-icon {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-channel-name {
            font-weight: 500;
            color: var(--text-secondary);
            font-size: 0.72rem;
        }

        .preview-channel-subs {
            color: var(--text-tertiary);
            font-size: 0.68rem;
        }

        .preview-details {
            font-size: 0.72rem;
            color: var(--text-tertiary);
        }

        .preview-tags {
            display: inline-flex;
            gap: 0.3rem;
        }

        .tag-sm {
            padding: 0.1rem 0.45rem;
            font-size: 0.65rem;
        }

        .preview-tldr {
            font-size: 0.78rem;
            color: var(--text-tertiary);
            line-height: 1.45;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">February 08, 2026</p>
            <div class="stats">
                <span><span class="stat-value">2</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card" id="video-0">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=rrhDROxbxJk" target="_blank" rel="noopener">3D &amp; AI | Dr. Fei-Fei Li, CEO &amp; Co-Founder, World Labs &amp; Jeetu Patel</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>22:20</span>
                        <span class="meta-sep">·</span><span>2.5K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-08</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Fei-Fei Li</span> <span class="tag tag-person">Jeetu Patel</span></div>
                </div>
                <div class="tldr">Dr.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">TL;DR Dr. Fei-Fei Li, CEO &amp; Co-Founder of World Labs, asserts that spatial intelligence – the ability for AI to understand and interact with the 3D/4D physical world – is the next critical frontier for AI, unlocking advanced applications beyond current language models.    Next...</div>
                    <div class="summary-full" id="full-0">
                        <p><strong>TL;DR</strong></p>
<p>Dr. Fei-Fei Li, CEO &amp; Co-Founder of World Labs, asserts that spatial intelligence – the ability for AI to understand and interact with the 3D/4D physical world – is the next critical frontier for AI, unlocking advanced applications beyond current language models.</p>
<h3>The Rise of Spatial Intelligence</h3>
<ul>
<li><strong>Next AI Frontier:</strong> Dr. Fei-Fei Li's company, World Labs, is singularly focused on spatial intelligence, which she identifies as the foundational next frontier of AI, critical for the development of true general intelligence.</li>
<ul>
<ul>
<li><strong>Evolutionary Perspective:</strong> Intelligence evolution began over half a billion years ago with perception (seeing, touching) rather than language, making spatial understanding a primary form of intelligence.</li>
<li><strong>Foundational Role:</strong> This capability is crucial for AI to understand, reason, interact with, and navigate the real 3D/4D physical world, just as language intelligence is foundational.</li>
</ul>
</ul>
</ul>
<h3>Marble: A Frontier World Model</h3>
<ul>
<li><strong>World Labs' Flagship Model:</strong> Marble is World Labs' first-generation spatial intelligence model, often referred to as a "world model."</li>
<ul>
<ul>
<li><strong>Multimodal Input &amp; 3D Output:</strong> Marble accepts various inputs (sentences, pictures, videos, 3D data) and generates a fully navigable, interactable, 3D, and geometrically consistent virtual world.</li>
<li><strong>Current Applications:</strong></li>
<ul>
<ul>
<li><strong>Creative Industries:</strong> Game development, VFX, commercial virtual production.</li>
<li><strong>Robotics &amp; Simulation:</strong> Provides training environments for robots for partners like Nvidia and academic labs.</li>
<li><strong>Design:</strong> Used by architects and designers for interior and other design types.</li>
<li><strong>Healthcare:</strong> Unexpectedly adopted by clinical researchers for psychiatric and mental health studies requiring personalized, immersive environments (e.g., for OCD triggers).</li>
<li><strong>Well-being:</strong> Used for personalized fitness and yoga environments.</li>
</ul>
</ul>
<li><strong>Early Stages:</strong> Released approximately two months ago, Marble is currently state-of-the-art but expected to expand its horizontal use cases as it evolves.</li>
</ul>
</ul>
</ul>
<h3>Navigating AI's Future: Data, Compute, and Robotics</h3>
<ul>
<li><strong>Limitations of Language-Only AGI:</strong> Dr. Li supports the view that achieving Artificial General Intelligence (AGI) requires augmenting language models with a physical, spatial understanding.</li>
<li><strong>Computational Scale:</strong> While World Labs' Marble model is a frontier model, it is currently "a few orders of magnitude smaller" than the largest Language Models (e.g., GPT-5 at ~10^26 flops).</li>
<li><strong>Hybrid Data Strategy:</strong></li>
<ul>
<ul>
<li><strong>Challenge:</strong> Unlike language models that leverage vast, clean internet text data, spatial models face a "messier" world of pixels and voxels and a scarcity of large-scale 3D/4D data.</li>
<li><strong>Approach:</strong> World Labs employs a hybrid strategy combining internet-scale text/image/video data with simulated data and real-world capture data (akin to self-driving car companies).</li>
<li><strong>Advancement Speed:</strong> Despite data challenges, the field is accelerating due to increased talent, more powerful compute, a maturing ecosystem, and the growing efficacy of synthetic data, creating a "flywheel" effect where models can generate more simulation data.</li>
</ul>
</ul>
<li><strong>Robotics: A Hard Problem:</strong></li>
<ul>
<ul>
<li><strong>Complexity:</strong> General-purpose robotics is significantly harder than self-driving cars; a car is a 2D robot avoiding contact, while a generalized robot is 3D and must interact precisely without damage.</li>
<li><strong>Challenges:</strong> Precision vision, dexterity of hands, understanding of space, and lack of training data contribute to this high-dimensional problem.</li>
</ul>
</ul>
</ul>
<h3>Dr. Li's Vision: Responsibility and Nuance in AI</h3>
<ul>
<li><strong>From Personal to Civilizational:</strong> Dr. Li notes AI's shift from a personal research curiosity to a technology with civilizational implications, creating a deep sense of responsibility.</li>
<li><strong>Breathtaking Pace:</strong> The speed of AI development is "breathtaking," causing widespread "anxiety" and underscoring the need for continuous learning.</li>
<li><strong>Critique of Polarized Rhetoric:</strong> Dr. Li expresses concern over the "polarized rhetoric" surrounding AI, which swings between "total tech utopian" and "total doomsday" extremes.</li>
<ul>
<ul>
<li><strong>Call for Nuance:</strong> This extreme framing is irresponsible for such a profoundly important technology; discussions need to be nuanced, benevolent, optimistic, and responsible, avoiding clickbait.</li>
<li><strong>Human Agency:</strong> Technology is a double-edged sword, and agency lies with every individual—entrepreneurs, leaders, engineers, and citizens—to guide its development responsibly.</li>
</ul>
</ul>
<li><strong>Defining Success:</strong> Success for AI, like electricity before it, means "when civilization is better," empowering every individual to pursue happiness, prosperity, and dignity.</li>
</ul>
<h3>Enterprise Opportunities for Spatial AI</h3>
<ul>
<li><strong>Horizontal Technology:</strong> Spatial intelligence is fundamentally an enterprise-facing technology with broad applicability.</li>
<li><strong>Diverse Sectors:</strong> Potential applications span:</li>
<ul>
<ul>
<li>Robotics and simulation</li>
<li>Immersive and interactive entertainment</li>
<li>Healthcare and educational products</li>
<li>Field services and financial services</li>
<li>Agriculture and manufacturing</li>
<li>Inspection, warehouse management, and city urban planning</li>
</ul>
</ul>
<li><strong>Invitation to Collaborate:</strong> World Labs is actively seeking and open to discussions with enterprise partners across these sectors.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"The ability to understand to reason to interact with and to um uh to navigate the real 3D 4D physical world is the foundation as foundational as language intelligence and the lynchpin technology is spatial intelligence..." – Dr. Fei-Fei Li
"Too much cyberspace cycles are still spent in discussing AI and its implication at the extreme ends whether it's total tech utopian as if technology is never a double-edged sword or it's total uh doomsday." – Dr. Fei-Fei Li
"Success looks like when civilization is better and civilization is made by every single individual pursuing happiness, pursuing prosperity and pursuing with the sense of dignity and that is what success looks like for AI and for every piece of technology." – Dr. Fei-Fei Li
"The difference between car and robots, a car is a squareish robot that moves on a two dimensional surfaces and the only thing the car needs to do is don't touch on things... Think about a robot. It's a threedimensional thing... And the goal of a generalized robot is to touch on things in the way that is not breaking them. So that is a much higher dimensional problem..." – Dr. Fei-Fei Li
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        It's been a pleasure to see the progress that's been made within World Labs in the past year as well. So, let's start by talking about what you're doing and why it's so important.

Well, right now I wake up every day and think about just one thing and one thing only, which is spatial intelligence. That's the company that I co-founded about two years ago with a group of young technologists, and it's called World Apps. So why is spatial intelligence so important and why do I say that it's the next frontier of AI? If you take an evolutionary view of the development of intelligence, which starts more than half a billion years ago, the first thing that kicked off an evolutionary arms race of the development of the nervous system is actually perception, not language. Language, compared to perception, is a very, very new form of intelligence. If you're generous and think about language as probably half a million years, probably not even that, but more than half a billion years ago, animals started to see light and touch the environment. So, tactile and visual sensing...

And do you put instinct in perception as well?

Instinct is a very interesting word. To me, instinct is a very fluffy word. I'm not rejecting the word instinct, but physically, it's touch and seeing that kicked off the development of the nervous system, and that set off the evolutionary arms race. Animals became more and more active, interacting with their environment and becoming more and more intelligent. All this is a long way of saying that the ability to understand, to reason, to interact with, and to navigate the real 3D 4D physical world is as foundational as language intelligence, and the lynchpin technology is spatial intelligence. That's why I believe this is the next generation or next frontier of AI. This is what World Labs has been building towards.

So, talk to us a little bit about Marble. What is Marble, and you launched that recently?

Right. So, Marble is the name for our first generation of our spatial intelligence model. We tend to call it casually a world model, but the truth is that there are so many definitions of 'world model' it almost doesn't matter if you call it a world model or not. It's a spatial intelligence model, a frontier model. What Marble does is that it takes multimodal inputs. Whether it's just a sentence, a picture, a video, a few pictures, or a simple 3D input, it doesn't matter; it's multimodal. It then turns that prompt into a fully navigable, interactable world that is 3D, which is permanently consistent, very different from the video models you see these days. It also has the geometric structure to support whether you want to simulate robotic actions or code up a game. So, Marble is a frontier model. We released it about two months ago. It's still first generation. We're very excited to start this journey, and right now it's still the state-of-the-art 3D generative world model.

And there's a school of thought that says that without, if you just go with language as the model, we will not be able to get to AGI. You need to have an augmentation of the physicality of it. You, of course, believe that, but talk to us a little bit about that dimension. What's the big unlock that happens over time?

The obvious use case is robotics. But even beyond that, what are the things that we'll be able to do in five years with world models that we don't even think about today?

Well, first of all, you don't even have to wait for five years. We're already engaging with users and customers to play with the early days of our world model. We are seeing users using it to develop games. We're seeing VFX users and customers using it to work in virtual production settings, actually commercial virtual production settings. We are engaging with our robotics and simulation partners from big companies like Nvidia, as well as startups and academic labs, where they're using Marble as training environments for robots. We're seeing that architects and designers are using this for interior design and other kinds of design. We're also getting surprise use cases. For example, clinical researchers have come to us and expressed a lot of enthusiasm. It turns out a lot of psychiatric and mental health research, as well as intervention, requires immersive environments that are personalized for particular situations. For example, OCD patients. Some people are triggered by very specific situations. Personally, I'm triggered by dirty laundry, but I'm sure people are triggered in different ways, and these researchers are studying that. It's very hard for them to get their hands on these environments, and Marble is just within minutes of every prompt, you get many different kinds of environments that you can use. So, this is actually a surprise use. We've also seen people with well-being and fitness training personalizing yoga environments or other environments. So, I think as Marble becomes better, we're still in the early days, we're going to see more and more horizontal use cases.

And so, you've been in the AI industry for a very long time.

It's a nice way to talk about my age.

No, no, no. I mean, you're one of those people that hasn't just looked at this for three years; you've dedicated your life to AI. What surprised you the most as you built this company and as you were starting to think about building the spatial intelligence side?

That's a great question. I know, G2, you're the same. We talk about, even in our age, the most important thing is learning and this hunger for learning. Yes, I've been in this field for many, many years, and one thing I would say is that I came to AI because of my very personal curiosity. I just love to ask that audacious question of what is intelligence and how to make machines intelligent, but it was very personal. Nobody cared about AI. The world didn't know how to spell AI, and it was very fun. The past 10 years have completely changed. AI is not just personal for me; AI is civilizational. That added a layer of sense of responsibility for me in terms of how I can contribute not only technologically and as an educator, but also contribute to the healthy development of AI. What surprised me the most as an entrepreneur? A couple of things. One is the speed of development of AI this past few years is just breathtaking. I know everyone, whether we pretend or not, everyone deep in your heart is feeling that anxiety of there's just too much to read: too many blogs, too many news, too many model releases. That sense of anxiety speaks of our time; this technology is just moving at a breathtaking speed. So, that gives me a lot of excitement but also keeps me very grounded about how little I know. There's this famous saying, 'I don't know anything,' and someone like me even feels that. I want you to at least hear this from me and recognize we all feel that, and don't give up your learning and continue to be curious. The other thing that surprised me and frankly continues to worry me is the polarized rhetoric of AI. Too much cyberspace is still spent discussing AI and its implication at the extreme ends, whether it's total tech utopian as if technology is never a double-edged sword, or it's total doomsday.

As if humans are facing an existential crisis every minute.

That's just not a responsible way of talking about a technology that is so profoundly important to our civilization. Technology is a double-edged sword, but the agency is within all of us. Every entrepreneur, every product manager, every business leader, every software engineer, every citizen, we still have to have that agency to know where to lead this technology. I really, really hope that going into 2026 and forward, we don't stay at the two extreme ends of talking about AI. Let's be more nuanced. Let's be benevolent. Let's have the optimism of using technology for good, but the sense of responsibility of using it responsibly, and let's have that conversation and not just optimize for clickbaits.

So, what does success look like in your mind for AI in the next few years? I really like your framing of this kind of polarized view that we have: 'all jobs are going to be lost and we're just going to be staring at the ocean,' or 'this thing is completely useless and it's not going to do anything.'

G2, if we roll time back 150 years—I don't remember the exact years—and if a version of two of us were on stage talking about what success looked like for electricity, I think we, at least, I don't know if people have imagined...

Hard to imagine.

...but I hope that there was a version that our schools are lit, our homes are warm, that it will empower machines to industrialize our life, it will in turn lengthen our life expectancy, more children will be learning when they hit school age. That's the meaning of technology, and that's the meaning of AI. That's a timeless value. Success looks like when civilization is better, and civilization is made by every single individual pursuing happiness, pursuing prosperity, and pursuing with a sense of dignity. That is what success looks like for AI and for every piece of technology.

That's fantastic. So, I'm going to go down to tactics for a second. Are large world models as computationally intensive as language models? Are they more or less?

That's a great question. First of all, there are different kinds of large world models. We are very committed to creating world models that have 3D 4D explicit representation to empower robotics, gaming, entertainment, design, and all that. There are other models that are called 'world models' that are more video generation models. Right now, in the field, our models are not as large as the bigger LLMs. For GPT-5, I believe it's trained around 10 to the 26 flops, and our Marble model is still a few orders of magnitude smaller.

Smaller. And is that just because you don't have enough data to go out and feed these models?

I think it's actually both. Data is one of the scaling laws that starts with data and model parameters. So, data plays a role. It's also because this field is early. Language models started; the Transformer paper was published in, I think, 2017, so it's almost 10 years, right? World models are a much newer field, so we are still in the relatively early days of figuring out the model architecture. So, it's relatively small. But having said that, given the progress that World Labs has made in the past couple of years and looking at our field, I think the next couple of years are going to be very exciting. We're going to see riding the curve of the scaling law in large world models.

So, we've talked about this before, Fei, but this thing that was fascinating to me was when you had highlighted to me when we were first starting to talk, around the fact that language models are trained on free publicly available data on the internet. It's easy to go out and get a large amount of data accumulated. The physical data is hard to do, and so synthetic data becomes a big deal, but you also have to collect that data in a much slower fashion. Walk us through the constraints that that brings, and is the speed of advancement of the world models, because of that scarcity of data that you're going to have, going to be similar to what we've been used to with language models? Is it going to be slower? And then how is that going to manifest itself even in physical robotics, where are you going to have a general-purpose robot that can do everything for you, or is it going to be special-purpose robots just because of the data that we have available?

Right, that's a loaded question, G2. So, let's talk about data and let's talk about generalized robots. They are related, but there's a lot of nuance. For example, at World Labs, what is our data strategy? A lot of people ask, and obviously I can only tell you so much, but one thing is very clear: we take a hybrid data strategy approach. I'm so envious of my language friends because at the end of the day, the input data and the output data are fully observable, more or less one modality, and that's just text. Also, texts are super clean, right? I know that there are words that are not good words, but by and large, the lexicons carry very clean meanings and semantics. Whereas the world of pixels and voxels is just so much messier. In order to push the boundary of the technology to create in 3D 4D worlds, we have to—we don't have a large amount of 3D 4D data to train our model. So, what we have to do is take the hybrid approach of layering in multimodality of data. We do have texts and images and videos that are more or less at the internet scale, but we also need to have simulated data. We also need to have what we call real-world capture data. You might be wondering what those data are. One of the biggest examples is self-driving cars. Whether we look at Tesla or Waymo or other self-driving cars, these companies spend years, decades, collecting real-world data as well as simulated data. So, creating world models will take that kind of approach. Is it going to be slow? That's a really interesting question because there are some confounding factors. For example, there are way more people joining this journey, and the compute is much more powerful, the chips, and also the ecosystem is much more mature. We work with data vendors that were not around even three years ago.

And synthetic data is really taking effect pretty well, right? And it's actually adding to your efficacy.

And also what we are making will also add to this world of simulation. So, there is a flywheel. Our model will also become useful simulation data for robotics. Just a couple of sentences on generalized robots: I have run a robotic learning lab at Stanford for the past decade and beyond. I'm super excited by robots. I do think that as a scientist, it's important to recognize this is a very, very hard problem. Just because the North Star is clear doesn't mean the journey is short. Think about 2006. My colleague Sebastian Thrun led the Stanford team to create the first self-driving car that could run 138 miles in the desert of Nevada. That was when we declared we're going to have self-driving cars. Twenty years later, last year was the first year Waymos were running on the streets of San Francisco and some larger cities. We more or less have gotten to a major milestone, but that's a very long journey. The difference between a car and a robot: a car is a squarish robot that moves on two-dimensional surfaces, and the only thing the car needs to do is not touch on things – don't touch on pedestrians, don't touch on the curbs. Think about a robot. It's a three-dimensional thing, whether it's humanoid or not, working with a three-dimensional world. The goal of a generalized robot is to touch on things in a way that is not breaking them. So, that is a much higher dimensional problem, and we are making progress.

And the simulation of the hand has been really hard, right? Dexterity of hands, the precision of vision, the understanding of space, the lack of training data—all this is challenging. This is why I started World Labs, because I know this is a very important problem. We want to work on this, but I also personally, as a scientist, don't like to overpromise.

So, Fei, in the last 60 seconds, for the people that are here from the enterprise side of the house, how should they be thinking about world models, physical AI, and all your world that you're thinking about? And then the last thing I'll say, because I know we're running out of time, is we wouldn't be able to have a Cisco AI summit without Fei anymore, because it would feel incomplete. So, we're going to keep inviting you.

Thank you. Well, I'm waiting for my swag.

Yes, we will get you. Can we please get swag to Fei?

Just kidding. I still think like a grad student: free food and swag. So for the enterprise, especially for world models and spatial intelligence, we're very much an enterprise-facing business, in my opinion. World Labs is very open to talk to enterprise partners. I think there are so many; it's a horizontal technology. We talked about robotics, we talked about simulation, we talked about immersive interactive entertainment experience, but we haven't talked more about healthcare. We haven't talked about educational products. We haven't talked about field services. We haven't talked about financial services. We haven't talked about agriculture, manufacturing, inspection, warehouse, and city urban planning, and all this. There's just a lot we can do with spatial intelligence. I do think this is the next frontier, and I invite all of you to work with us or work by yourselves on this topic.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-1">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=eFinF8AJD8A" target="_blank" rel="noopener">Frontier Models &amp; AI | Sam Altman, CEO &amp; Co-Founder, OpenAI and Jeetu Patel.</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>24:11</span>
                        <span class="meta-sep">·</span><span>7.2K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-08</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Sam Altman</span> <span class="tag tag-person">Jeetu Patel</span></div>
                </div>
                <div class="tldr">&gt; &quot;Codex has been my biggest update on AI in a while.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-1">TL;DR: AI models like Codex and OpenClaw are ushering in a &quot;ChatGPT moment&quot; for knowledge work and software development, but their widespread adoption is challenged by the need for new security paradigms, redesigned software, and faster enterprise absorption, demanding...</div>
                    <div class="summary-full" id="full-1">
                        <p><strong>TL;DR</strong>: AI models like Codex and OpenClaw are ushering in a "ChatGPT moment" for knowledge work and software development, but their widespread adoption is challenged by the need for new security paradigms, redesigned software, and faster enterprise absorption, demanding significant infrastructure investment and a shift to thinking about AI as a collaborator, not just a tool.</p>
<h3>The Transformative Power of AI Agents</h3>
<ul>
<li><strong>"ChatGPT Moment" for Knowledge Work:</strong> Sam Altman, CEO &amp; Co-Founder, OpenAI, describes current AI advancements, particularly with Codex and OpenClaw, as another "ChatGPT moment."</li>
<ul>
<ul>
<li>OpenAI's internal observation: Cisco's AI Defense product will have 100% of its code written with Codex within weeks.</li>
<li>This is expected to generate "unbelievable economic value extremely quickly" and fundamentally alter how organizations operate.</li>
</ul>
</ul>
<li><strong>Evolution Towards Full AI Companies:</strong> The current upper limit of AI potential is envisioned as full AI companies, where coding models create complex software and interact with the real world to build and run businesses.</li>
<li><strong>Generalized Computer Use:</strong> The concept of AI agents having full control over a computer and web browser (as demonstrated by OpenClaw) is deemed "much more powerful" than code alone, promising a "genuine transformation in how knowledge work will happen."</li>
<ul>
<ul>
<li>Altman personally found giving Codex full computer control so useful it lasted "about two hours" before security concerns led him to use two laptops.</li>
</ul>
</ul>
<li><strong>New Forms of Social Interaction:</strong> The future may include novel social networks where multiple AI agents interact on behalf of people, collaborating to find information and generate new ideas.</li>
</ul>
<h3>Key Obstacles to Broader AI Adoption</h3>
<ul>
<li><strong>Non-Obvious Constraints:</strong> Beyond the recognized limitations of infrastructure, compute, and power, several less obvious challenges persist:</li>
<ul>
<ul>
<li><strong>Security and Data Access Paradigm:</strong> A new security and data access framework is critically needed to balance the utility of AI models with data privacy, as current systems are not designed for AI agents with broad access.</li>
<li><strong>Software Design for AI/Human Co-use:</strong> Most existing software is not built for seamless interaction between humans and AI.</li>
<ul>
<ul>
<li>*Example:* An AI using Slack might mark threads as read, disrupting a human's workflow, indicating a need for separate AI user accounts or software optimized for agents.</li>
</ul>
</ul>
<li><strong>"Always-On Computing" Challenges:</strong> Enabling AI to continuously observe meetings or computer activity for real-time value addition is hampered by current computer hardware, permissioning systems, and legal frameworks (e.g., recording and then deleting meeting data).</li>
</ul>
</ul>
<li><strong>"Capability Overhang" and Slow Absorption Rate:</strong> Despite the rapid advancement of AI (e.g., in scientific discovery, software development), the adoption and integration rate within organizations is surprisingly slow.</li>
<ul>
<ul>
<li>This "capability overhang"—the gap between AI's potential and its practical deployment—is perceived to be larger than ever.</li>
<li><strong>Executive Advice:</strong> Sam Altman stresses that enterprises not configured to quickly adopt "AI co-workers" will face a "huge disadvantage," requiring significant effort and risk to adapt.</li>
<li>The transition requires viewing AI as a "teammate" or "collaborator" rather than merely a transactional tool.</li>
</ul>
</ul>
</ul>
<h3>Infrastructure &amp; Business Model Evolution</h3>
<ul>
<li><strong>Underestimated Infrastructure Demand:</strong> Despite predictions of trillions in spending, the long-term demand for AI capacity (like "tokens") is likely underestimated, akin to the historical demand for electricity.</li>
<ul>
<ul>
<li><strong>Long-Term Vision:</strong> AI usage is projected to grow exponentially, with models becoming more capable and cost-efficient per task, leading to pervasive integration into business operations, scientific discovery, and personal software use.</li>
<li>Global supply chains and policy are reconfiguring to meet this demand, though temporary gluts may occur.</li>
</ul>
</ul>
<li><strong>OpenAI's Evolving Business Model:</strong></li>
<ul>
<ul>
<li><strong>Subscription Success:</strong> OpenAI has seen strong consumer and enterprise willingness to pay for subscription services (e.g., ChatGPT, API, Codex), with "many tens of millions of consumers paying."</li>
<li><strong>Advertising Potential:</strong> While requiring careful implementation, advertising is seen as a viable model for mass-scale consumer businesses.</li>
<li><strong>AI Cloud Subscription:</strong> Businesses are increasingly seeking an "AI cloud subscription" model—a general-purpose platform partnership that handles security, context, access, and supports various agents and models.</li>
<li><strong>Scientific Discovery Partnerships:</strong> OpenAI may act as an investor in large-scale scientific endeavors (e.g., curing diseases) requiring substantial inference capital, potentially receiving royalties in return.</li>
</ul>
</ul>
</ul>
<h3>Strategic Imperatives &amp; Future Outlook</h3>
<ul>
<li><strong>Open Source Leadership:</strong> Sam Altman expresses concern over the US's lack of substantial leadership in open-source AI, emphasizing its importance due to user demand for control over private, locally running models, especially for "always-on" personal AI devices.</li>
<li><strong>Boundless Future Vision:</strong> Altman envisions an economy growing at an unprecedented rate, supported by billions of humanoid robots building infrastructure, and even "Von Neumann probes" launching into space.</li>
<li><strong>Aggressive Capability Growth:</strong></li>
<ul>
<ul>
<li><strong>Tailwind:</strong> The primary tailwind is the rapid, continuous improvement of AI models, which are expected to get "very, very good" quickly, offering immense opportunities.</li>
<li><strong>Headwind:</strong> Global destabilization and mega supply chain disruptions are significant concerns.</li>
<li><strong>Near-Term Improvement:</strong> Subjectively, capabilities are expected to improve by "something like 10x" by the end of the year in terms of problems solvable.</li>
</ul>
</ul>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"Codex has been my biggest update on AI in a while. ... This is going to create an unbelievable amount of economic value extremely quickly. This is going to change how all of OpenAI works and change how other companies work." — Sam Altman
"The idea that we can take a Codex-style workflow and expand it to all knowledge work... feels like a genuine transformation in how knowledge work will happen." — Sam Altman
"The capability overhang feels to me like the biggest it has ever felt. ... The diffusion, the absorption is so slow." — Sam Altman
"Companies that are not set up to be able to adopt let's call them AI co-workers very quickly will be at a huge disadvantage." — Sam Altman
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-1" onclick="toggleSummary(1)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-1" onclick="toggleTranscript(1)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-1">
                        Let me start with some good news. I don't know if you know this, but we are the first design partner for Codeex.

I did know that.

Thank you. In the past few months, I think we've hit an exponential curve. AI defense was a product that we launched here last year. In about two or three weeks, 100% of the code in AI defense will be written with Codeex.

That's unbelievable. Codex has been my biggest update on AI in a while. The app that we launched yesterday just pushed things over the edge for me. I'm like, &quot;All right, this is going to create an unbelievable amount of economic value extremely quickly. This is going to change how all of OpenAI works and change how other companies work.&quot; The model has really hit some threshold, and I think now the interface and harness have caught up. This is the first, you're talking about ChatGPT moments, I think this is the first time I've felt another ChatGPT moment.

Here is a clear glimpse of the future of knowledge work and how enterprises and individual people are going to use AI to work in a completely different way. So what's the upper limit on this, do you think? The upper limit, I think, is full AI companies. There's probably an upper limit beyond that, but the current one I can think about is full AI companies, and that seems very powerful. The idea that a coding model can create a full complex piece of software but also interact with the rest of the real world to build a company around it is a very big deal.

And then this notion of what's happening right now, I'm sure you're tracking this with Moldbook and what happened with Cloudbot. Is it just a passing fad, or do you think that there's something that we should take away from that?

No, I think it is definitely not a passing, well, Moldbook maybe, I don't know, but OpenClaw is not. I think this idea that code is really powerful, but code plus generalized computer use is even much more powerful, is here to stay. When I initially installed Codex, I said I was never going to give Codex full control of my computer without checking what it was doing. That lasted about two hours because it was so useful. Then I got persuaded by people that I really shouldn't have it running like that. So now I have two laptops until I figure out how this is all going to work. But giving an AI agent full use of your computer and your web browser with all your sessions leads to incredible stuff, and that seems here to stay.

The idea that we can take a Codeex-style workflow and expand it to all knowledge work, so that whatever you're doing, Codex or some version of that can be using your computer and using the web for you, editing documents, and whatever other kind of work you need, feels like a genuine transformation in how knowledge work will happen. I think OpenClaw did an incredible job of bringing many ideas together to make that feel usable and real, and that seems certain to be part of our future. I think Moldbook is cool, and I think it points to something that will be real, and maybe it will be Moldbook. But there will be new kinds of social interaction where you have many agents in a space interacting with each other on behalf of people, leading to all sorts of new things. You can imagine a totally new kind of social network where everybody makes an agent or many agents and puts them in there, and the agents are talking and doing stuff, finding people and information, and collaborating with other people's agents to come up with new ideas. I think the future of social may look something like that, very different than today, whether it's Moldbook or not, is uncertain.

Sure. If you think about the constraints that we are facing today, besides the obvious ones—the infrastructure, the compute, the power, and all of those pieces—are there any non-obvious constraints that are holding us back? People always say in the short term, you always overestimate the impact of these technologies, and longer term, it's going to be grossly underestimated. But what are the non-obvious constraints that you see right now, where you're like, &quot;Man, I wish if I had a magic wand, if I could change that?&quot;

I think the obvious constraints are the biggest ones: still energy, manufacturing enough hardware, all that stuff. The non-obvious ones that are most top of mind for me are, one, how are we going to balance the security and data access versus the utility of all of these models?

I don't think anyone has a great answer to this yet. It feels to me like there is a new security or data access paradigm that needs to be invented for this. Another is how are we going to rewrite all software to be equally usable by humans and AIs? There are a bunch of weird quirks right now about trying to do that with the way software works.

And does that change the architecture of the software itself, where you're going to optimize it for agents more so than humans, and so it fundamentally changes how you build software?

Yes. There are big examples of that, and then there are dumb examples of that. For example, I would love my agent to be able to use Slack on my behalf because I hate drowning in Slack, and I think it's this chaotic mess for me, but it's important. The way it works right now is my agent can use the Slack web interface and go read all my threads and do something for me, but then it has marked a bunch of stuff as read in the process of doing that, and it's broken my workflows.

Broken your workflows. Yeah.

So, that's just a silly example of how a lot of software is not quite meant for an AI and a person to be using it together. Maybe we'll want AIs to have different user accounts in some ways using the same kinds of things. Maybe a lot of software will get rewritten so that it's primarily or largely used by AI but also still works for people using it the old-fashioned way.

Another non-obvious block is how one of the most powerful things about AI is you could do this always-on computing where you could have an AI listening to your meeting or watching your meeting and watching what you're doing on your computer, and then just add a lot of value and do stuff for you. Our existing computer hardware is not really meant for that. Our permissioning system and how we think about what an AI gets to see and do stuff with, and what it gets to keep, is not really meant for that. Our legal system doesn't really support that well. You'd like to be able to record a meeting and learn something from it and delete the recording. So I think there's a lot of just usability things like that.

And then you talk about this notion that one of the things I find is a huge dichotomy: there's so much advancement happening in science and in all the different areas that we'll talk about. Kevin Weall is going to be here later today. And then, on the other hand, the challenges that organizations struggle with to just get the basics up and running with everyone. There's a capabilities overhang, and by the way, this is a new concept. When Microsoft Word came out, people used 2% of the capability back then. So when you start thinking about this, how do we make sure that we actually increase the absorption rate? You've got CIOs and CISOs over here. What advice would you give them on increasing the absorption rate within their organization for AI?

The capability overhang feels to me like the biggest it has ever felt. A few months ago, maybe I would have said it feels bigger than any time except right before ChatGPT launched. It now feels even bigger than that, even though people are using AI for a lot of stuff.

The fact that AI can make small but increasingly big scientific discoveries, the fact that AI can write full pieces of software, the fact that soon AI can do more generalized knowledge work—those are all huge, huge things. We have always said that we're going to automate research, use that to automate the economy, use that to deliver incredible new value to people and share all these benefits and this whole new technological world. We always said that as an abstract, sometime-in-the-future thing. And yet now, AI is doing research, and AI is able to do huge amounts of economic work. As you said, this has happened many times in the past, but living through it definitely feels like, &quot;Huh, this is not quite how it seems like it should go.&quot; The diffusion, the absorption, is so slow.

Is it slower than you thought it would be?

Yes, but I think I was just naive and didn't think about it that hard. In retrospect and looking at the history, it shouldn't be surprising. It feels fast in some ways relative to other things. ChatGPT grew crazily quickly relative to any other piece of software before. Codeex is growing extremely quickly. I expect the general-purpose computer-used knowledge work to grow quickly. And yet, looking at what's capable, looking at what's possible, it does feel surprisingly slow.

In terms of advice, figuring out how to set up enterprises such that they can quickly absorb these new tools and not have a year or multiple years of thinking about the data access and security questions that are currently blocking people, even at the level today, of adopting things like Codex, feels very important. I don't want to make a too dramatic prediction, but I think that companies that are not set up to be able to adopt, let's call them AI co-workers, very quickly will be at a huge disadvantage, and it is going to take a lot of work and some risk to be able to adopt them.

One of the big insights we had when we were using Codeex was for the first two or three months, we kept thinking it was going to be this amazing tool. Then there was this light bulb that went off with actually one of your four deployed engineers, and they said, &quot;You folks are thinking about this wrong because you have to think about it as a teammate rather than a tool.&quot; I think that level of skeuomorphic design, people haven't fully grasped that when it comes to this, because it's still a very transactional tool in most people's minds.

The Codeex app is the first time to me it has truly felt like interacting with a teammate.

I think one of the lessons there is, even if you have amazing technology, which the models got—I think 52 was the model that got super good—but even once you get there, there's still so much value in how you package it, how you have users interact with it, how easy you can make it. But this really does now feel, in a way that talking to ChatGPT has always clearly felt like a tool, that I am working with a collaborator now.

Right. Right. And that seems very much the shape of things to come.

Okay. Let's talk about a couple of topics I want to make sure I hit with you on infrastructure. You've actually spent an enormous amount of time even on the power side of the house. Talk to us about what happens with, in general, the constraints that we have around power, constraints we have on infrastructure. How are you thinking about it? You're clearly putting enough money behind it, I guess so. All the evidence we see right now is that AI models will continue to get much more capable, and also that they will get much less expensive and use many fewer resources per task. All the history we've seen of every time that happens is people want to use them much, much more. So we are planning for a world where AI usage grows at an accelerated pace each year.

Do you think people are underestimating the capacity that's going to be needed even now after everything that's being built out?

Right now, they're saying $5 trillion will be spent in this over the course of the.

Yeah, maybe if that really gets spent quickly, that will be enough. And I think it's also possible that along the way we have some supply gluts temporarily. But over a period of decades, it seems certain to me that the world is going to need a lot more tokens, even though we'll make each token way more efficient. You'll all have a device in your pocket running super powerful models off of a battery, but there will still be this drive for more and more and more.

I think the world has come to realize this, and capitalism is doing its thing, and supply chains are reconfiguring. Policy is changing, and we are going to build an incredible amount of infrastructure. Now, is it enough? People always talk about the total market demand for AI. It feels to me something like the market demand for electricity or energy. You can't talk about that as a general thing. You can say how much demand there will be at different price levels. In this case, you can say at different price levels for different quality, how smart it is, or how fast it is, or everything like things like that.

But if we continue to make AI really capable and really cheap, there will be a ton of demand at some price. If it's more expensive, there will be less demand. But I would like the world to just get to use a ton of it. We're in this capability overhang now, as we mentioned, where people are, &quot;Oh, can use it for chat,&quot; or maybe some people understand you can use it for code. I think this will just be how we do stuff, how companies run, how scientific discovery happens, how we use most software personally in our lives, and making a lot of it, if we can have it at a reasonable price, seems like a very good bet.

Do you worry about the fact that the US has not had as much of a lead on the open-source side? Talk to us a little bit about that.

I do worry about that.

We should do more. Yes.

So what's stopping you from doing it?

Focus and time. But I think we need to solve that somehow.

And so just play this out in your simulator for a second. If we don't have a substantial open-source presence, and of course China does, versus if we do, how does a world shape differently? To be clear, I think it's most important that we lead on frontier models, and I expect those to be accessed via APIs and other products, so it would be okay but not great if we didn't also have the open-source lead. People want their own models. People want control of their own models. People want to run models locally. Especially if you think about a world where you have a model that is going to see your whole life, you're going to have a new device that's always on and keeping track of everything and adds huge value to you. I at least would really like that running on inference I control.

I think people are going to need this. If we get behind, obviously, it's not the end of the world, but I would really like us to lead there, and I think there will be increasing demand for locally running private models. If you were to fast forward back and start thinking, because one of the things that has been, I don't even know how you folks have done it within the compression of time that you've done it in, because there must have been moments where you decided that we're going to go full stack, and we're going to now start building our own inference chips, and we're going to start making sure that we have data center buildouts that are happening, and it has to have been a conscious decision when you started actually going beyond the core that you had initially started with. Talk about the business model that you have today, and how does that evolve and change over time? The obvious ones are, of course, advertising is a huge unlock when that happens. But talk about the business model in general. Are you happy with the conversion rates of free to paid? Are you happy with the take rate that people are using this system with?

And then what would you like to see more of? So we have two large products, and now we have some others that are coming up. We have ChatGPT and our API business. And now we have Codeex, which looks like it's going to get very big, and a few other things. In the future, we'll have consumer devices and robots and all sorts of other parts of this too. People do seem very willing to pay for AI as a subscription service. Not everybody, but a lot of people are, more than we thought would. Businesses, of course, are willing to pay for things like ChatGPT Enterprise.

But even consumers, you've reconditioned the consumers quite a bit.

Consumers, we have, I don't know the exact number off the top of my head, but many, many tens of millions of consumers paying a subscription fee.

Yeah, and that was a surprise to me, to be honest, a happy one. So that, I think, can go further, and as we add things like Codeex, people are willing to pay much, much more there. Advertising for mass-scale consumer businesses does seem like a good model, although I think we'll have to be very careful in how we do that. Then businesses increasingly want something like an AI cloud subscription.

Where they're, &quot;I want to partner with an AI company. I want you to handle security and context linking and access, and I want to be able to run lots of agents on it. I want a general-purpose platform there. I want some agents from you, some agents from other people. I may even want to run other people's models. I want a ChatGPT Enterprise license. I want a ton of API access.&quot; Things like that. So I think there will be a model there as well.

And if you were to think of a model you've talked about which is participating in the upside on scientific discovery as well? If you think about the most mature ones, clearly subscription is very mature. Clearly advertising is very mature. At this point in time, it's quite clear that you're going to participate in both of those.

Yeah.

And then you'll have other ones that keep coming out.

Yeah, to be very clear, we don't want to take a share of people that are just paying us for the API and making discoveries. That's great, and that's theirs. I can imagine, though, that if there is a future where we can spend billions of dollars on inference and cure an important disease, we may explore partnerships there where we pay for that cost in partnership with the drug company and then get some royalty on it. This is not something we're doing now, but I think the frontier of scientific discovery with AI will require so much capital that maybe we think of ourselves as an investor in some of those cases.

And is our imagination of the things that can be done? Do you find yourself struggling with how far exponentially you can think about what's going on as well, or you're a pretty big thinker, but it seems like there are new ideas emerging all the time. Where do you think the imagination shortage is right now with the way that these technologies are evolving?

I can imagine billions of humanoid robots building more data centers and mining for material and building more power plants and all of that. I can imagine the economy growing at an unprecedented rate as there are all sorts of incredible new services and scientific discoveries happening. I can imagine the Von Neumann probes launching, and then beyond that, I have no idea. That seems like a good start.

Macro headwinds, tailwinds, what do you feel are things that you really worry about capitalizing on that are tailwinds, because you have a window within which if you don't, then you can actually lose that tailwind? And then what are the headwinds that you worry about?

The tailwind is the models. We already have this capability overhang, and the models are going to get so much better quickly. We've been trying to figure out how we communicate about what we think is happening that does not seem like hype or crazy, but the models are just going to get very, very good this year, and that is a tailwind that I think we can build incredible things with.

Headwind? Probably some global destabilization, mega supply chain disruption, something like that.

And on the tailwind side, on the models getting infinitely better, do you think in 2026 we see a 10x improvement, a 100x improvement, a 5x improvement?

What do you mean by what is a 10x improvement?

Things that you can, problems you can solve. I would bet it subjectively feels something like 10x the end of this year. I don't know how to put an exact metric on that.

But that feels reasonable.

Any question that I didn't ask that I should have asked?

That was a lot.

No, I feel like we covered a lot of ground.

You're going to come back again?

Come back here again? Yeah.

I'd love if you invite me. I will.

Sam Altman.

Thank you.

Thanks so much. Thank you.
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>