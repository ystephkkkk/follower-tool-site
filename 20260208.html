<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - February 08, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
            scroll-margin-top: 1rem;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-header-link {
            display: block;
            padding: 1.25rem 1.5rem 0.75rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header-link:hover .day-date {
            color: var(--accent);
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
            transition: color 0.15s ease;
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.3rem;
            padding: 0.6rem 0;
            border-bottom: 1px solid var(--border);
            text-decoration: none;
            color: inherit;
            border-radius: 4px;
            transition: background 0.12s ease;
        }

        .day-preview-item:hover {
            background: var(--bg-tertiary);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-title {
            font-size: 0.88rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.35;
        }

        .preview-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            background: var(--bg-tertiary);
            padding: 0.15rem 0.5rem 0.15rem 0.25rem;
            border-radius: 14px;
        }

        .preview-channel-icon {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-channel-name {
            font-weight: 500;
            color: var(--text-secondary);
            font-size: 0.72rem;
        }

        .preview-channel-subs {
            color: var(--text-tertiary);
            font-size: 0.68rem;
        }

        .preview-details {
            font-size: 0.72rem;
            color: var(--text-tertiary);
        }

        .preview-tags {
            display: inline-flex;
            gap: 0.3rem;
        }

        .tag-sm {
            padding: 0.1rem 0.45rem;
            font-size: 0.65rem;
        }

        .preview-tldr {
            font-size: 0.78rem;
            color: var(--text-tertiary);
            line-height: 1.45;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">February 08, 2026</p>
            <div class="stats">
                <span><span class="stat-value">5</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card" id="video-0">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=rrhDROxbxJk" target="_blank" rel="noopener">3D &amp; AI | Dr. Fei-Fei Li, CEO &amp; Co-Founder, World Labs &amp; Jeetu Patel</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>22:19</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-08</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Fei-Fei Li</span> <span class="tag tag-person">Jeetu Patel</span></div>
                </div>
                <div class="tldr">Dr.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">TL;DR Dr. Fei-Fei Li, CEO &amp; Co-Founder of World Labs, asserts that spatial intelligence – the ability for AI to understand and interact with the 3D/4D physical world – is the next critical frontier for AI, unlocking advanced applications beyond current language models.    Next...</div>
                    <div class="summary-full" id="full-0">
                        <p><strong>TL;DR</strong></p>
<p>Dr. Fei-Fei Li, CEO &amp; Co-Founder of World Labs, asserts that spatial intelligence – the ability for AI to understand and interact with the 3D/4D physical world – is the next critical frontier for AI, unlocking advanced applications beyond current language models.</p>
<h3>The Rise of Spatial Intelligence</h3>
<ul>
<li><strong>Next AI Frontier:</strong> Dr. Fei-Fei Li's company, World Labs, is singularly focused on spatial intelligence, which she identifies as the foundational next frontier of AI, critical for the development of true general intelligence.</li>
<ul>
<ul>
<li><strong>Evolutionary Perspective:</strong> Intelligence evolution began over half a billion years ago with perception (seeing, touching) rather than language, making spatial understanding a primary form of intelligence.</li>
<li><strong>Foundational Role:</strong> This capability is crucial for AI to understand, reason, interact with, and navigate the real 3D/4D physical world, just as language intelligence is foundational.</li>
</ul>
</ul>
</ul>
<h3>Marble: A Frontier World Model</h3>
<ul>
<li><strong>World Labs' Flagship Model:</strong> Marble is World Labs' first-generation spatial intelligence model, often referred to as a "world model."</li>
<ul>
<ul>
<li><strong>Multimodal Input &amp; 3D Output:</strong> Marble accepts various inputs (sentences, pictures, videos, 3D data) and generates a fully navigable, interactable, 3D, and geometrically consistent virtual world.</li>
<li><strong>Current Applications:</strong></li>
<ul>
<ul>
<li><strong>Creative Industries:</strong> Game development, VFX, commercial virtual production.</li>
<li><strong>Robotics &amp; Simulation:</strong> Provides training environments for robots for partners like Nvidia and academic labs.</li>
<li><strong>Design:</strong> Used by architects and designers for interior and other design types.</li>
<li><strong>Healthcare:</strong> Unexpectedly adopted by clinical researchers for psychiatric and mental health studies requiring personalized, immersive environments (e.g., for OCD triggers).</li>
<li><strong>Well-being:</strong> Used for personalized fitness and yoga environments.</li>
</ul>
</ul>
<li><strong>Early Stages:</strong> Released approximately two months ago, Marble is currently state-of-the-art but expected to expand its horizontal use cases as it evolves.</li>
</ul>
</ul>
</ul>
<h3>Navigating AI's Future: Data, Compute, and Robotics</h3>
<ul>
<li><strong>Limitations of Language-Only AGI:</strong> Dr. Li supports the view that achieving Artificial General Intelligence (AGI) requires augmenting language models with a physical, spatial understanding.</li>
<li><strong>Computational Scale:</strong> While World Labs' Marble model is a frontier model, it is currently "a few orders of magnitude smaller" than the largest Language Models (e.g., GPT-5 at ~10^26 flops).</li>
<li><strong>Hybrid Data Strategy:</strong></li>
<ul>
<ul>
<li><strong>Challenge:</strong> Unlike language models that leverage vast, clean internet text data, spatial models face a "messier" world of pixels and voxels and a scarcity of large-scale 3D/4D data.</li>
<li><strong>Approach:</strong> World Labs employs a hybrid strategy combining internet-scale text/image/video data with simulated data and real-world capture data (akin to self-driving car companies).</li>
<li><strong>Advancement Speed:</strong> Despite data challenges, the field is accelerating due to increased talent, more powerful compute, a maturing ecosystem, and the growing efficacy of synthetic data, creating a "flywheel" effect where models can generate more simulation data.</li>
</ul>
</ul>
<li><strong>Robotics: A Hard Problem:</strong></li>
<ul>
<ul>
<li><strong>Complexity:</strong> General-purpose robotics is significantly harder than self-driving cars; a car is a 2D robot avoiding contact, while a generalized robot is 3D and must interact precisely without damage.</li>
<li><strong>Challenges:</strong> Precision vision, dexterity of hands, understanding of space, and lack of training data contribute to this high-dimensional problem.</li>
</ul>
</ul>
</ul>
<h3>Dr. Li's Vision: Responsibility and Nuance in AI</h3>
<ul>
<li><strong>From Personal to Civilizational:</strong> Dr. Li notes AI's shift from a personal research curiosity to a technology with civilizational implications, creating a deep sense of responsibility.</li>
<li><strong>Breathtaking Pace:</strong> The speed of AI development is "breathtaking," causing widespread "anxiety" and underscoring the need for continuous learning.</li>
<li><strong>Critique of Polarized Rhetoric:</strong> Dr. Li expresses concern over the "polarized rhetoric" surrounding AI, which swings between "total tech utopian" and "total doomsday" extremes.</li>
<ul>
<ul>
<li><strong>Call for Nuance:</strong> This extreme framing is irresponsible for such a profoundly important technology; discussions need to be nuanced, benevolent, optimistic, and responsible, avoiding clickbait.</li>
<li><strong>Human Agency:</strong> Technology is a double-edged sword, and agency lies with every individual—entrepreneurs, leaders, engineers, and citizens—to guide its development responsibly.</li>
</ul>
</ul>
<li><strong>Defining Success:</strong> Success for AI, like electricity before it, means "when civilization is better," empowering every individual to pursue happiness, prosperity, and dignity.</li>
</ul>
<h3>Enterprise Opportunities for Spatial AI</h3>
<ul>
<li><strong>Horizontal Technology:</strong> Spatial intelligence is fundamentally an enterprise-facing technology with broad applicability.</li>
<li><strong>Diverse Sectors:</strong> Potential applications span:</li>
<ul>
<ul>
<li>Robotics and simulation</li>
<li>Immersive and interactive entertainment</li>
<li>Healthcare and educational products</li>
<li>Field services and financial services</li>
<li>Agriculture and manufacturing</li>
<li>Inspection, warehouse management, and city urban planning</li>
</ul>
</ul>
<li><strong>Invitation to Collaborate:</strong> World Labs is actively seeking and open to discussions with enterprise partners across these sectors.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"The ability to understand to reason to interact with and to um uh to navigate the real 3D 4D physical world is the foundation as foundational as language intelligence and the lynchpin technology is spatial intelligence..." – Dr. Fei-Fei Li
"Too much cyberspace cycles are still spent in discussing AI and its implication at the extreme ends whether it's total tech utopian as if technology is never a double-edged sword or it's total uh doomsday." – Dr. Fei-Fei Li
"Success looks like when civilization is better and civilization is made by every single individual pursuing happiness, pursuing prosperity and pursuing with the sense of dignity and that is what success looks like for AI and for every piece of technology." – Dr. Fei-Fei Li
"The difference between car and robots, a car is a squareish robot that moves on a two dimensional surfaces and the only thing the car needs to do is don't touch on things... Think about a robot. It's a threedimensional thing... And the goal of a generalized robot is to touch on things in the way that is not breaking them. So that is a much higher dimensional problem..." – Dr. Fei-Fei Li
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        It's been a pleasure to see the progress that's been made within World Labs in the past year as well. So, let's start by talking about what you're doing and why it's so important.

Well, right now I wake up every day and think about just one thing and one thing only, which is spatial intelligence. That's the company that I co-founded about two years ago with a group of young technologists, and it's called World Apps. So why is spatial intelligence so important and why do I say that it's the next frontier of AI? If you take an evolutionary view of the development of intelligence, which starts more than half a billion years ago, the first thing that kicked off an evolutionary arms race of the development of the nervous system is actually perception, not language. Language, compared to perception, is a very, very new form of intelligence. If you're generous and think about language as probably half a million years, probably not even that, but more than half a billion years ago, animals started to see light and touch the environment. So, tactile and visual sensing...

And do you put instinct in perception as well?

Instinct is a very interesting word. To me, instinct is a very fluffy word. I'm not rejecting the word instinct, but physically, it's touch and seeing that kicked off the development of the nervous system, and that set off the evolutionary arms race. Animals became more and more active, interacting with their environment and becoming more and more intelligent. All this is a long way of saying that the ability to understand, to reason, to interact with, and to navigate the real 3D 4D physical world is as foundational as language intelligence, and the lynchpin technology is spatial intelligence. That's why I believe this is the next generation or next frontier of AI. This is what World Labs has been building towards.

So, talk to us a little bit about Marble. What is Marble, and you launched that recently?

Right. So, Marble is the name for our first generation of our spatial intelligence model. We tend to call it casually a world model, but the truth is that there are so many definitions of 'world model' it almost doesn't matter if you call it a world model or not. It's a spatial intelligence model, a frontier model. What Marble does is that it takes multimodal inputs. Whether it's just a sentence, a picture, a video, a few pictures, or a simple 3D input, it doesn't matter; it's multimodal. It then turns that prompt into a fully navigable, interactable world that is 3D, which is permanently consistent, very different from the video models you see these days. It also has the geometric structure to support whether you want to simulate robotic actions or code up a game. So, Marble is a frontier model. We released it about two months ago. It's still first generation. We're very excited to start this journey, and right now it's still the state-of-the-art 3D generative world model.

And there's a school of thought that says that without, if you just go with language as the model, we will not be able to get to AGI. You need to have an augmentation of the physicality of it. You, of course, believe that, but talk to us a little bit about that dimension. What's the big unlock that happens over time?

The obvious use case is robotics. But even beyond that, what are the things that we'll be able to do in five years with world models that we don't even think about today?

Well, first of all, you don't even have to wait for five years. We're already engaging with users and customers to play with the early days of our world model. We are seeing users using it to develop games. We're seeing VFX users and customers using it to work in virtual production settings, actually commercial virtual production settings. We are engaging with our robotics and simulation partners from big companies like Nvidia, as well as startups and academic labs, where they're using Marble as training environments for robots. We're seeing that architects and designers are using this for interior design and other kinds of design. We're also getting surprise use cases. For example, clinical researchers have come to us and expressed a lot of enthusiasm. It turns out a lot of psychiatric and mental health research, as well as intervention, requires immersive environments that are personalized for particular situations. For example, OCD patients. Some people are triggered by very specific situations. Personally, I'm triggered by dirty laundry, but I'm sure people are triggered in different ways, and these researchers are studying that. It's very hard for them to get their hands on these environments, and Marble is just within minutes of every prompt, you get many different kinds of environments that you can use. So, this is actually a surprise use. We've also seen people with well-being and fitness training personalizing yoga environments or other environments. So, I think as Marble becomes better, we're still in the early days, we're going to see more and more horizontal use cases.

And so, you've been in the AI industry for a very long time.

It's a nice way to talk about my age.

No, no, no. I mean, you're one of those people that hasn't just looked at this for three years; you've dedicated your life to AI. What surprised you the most as you built this company and as you were starting to think about building the spatial intelligence side?

That's a great question. I know, G2, you're the same. We talk about, even in our age, the most important thing is learning and this hunger for learning. Yes, I've been in this field for many, many years, and one thing I would say is that I came to AI because of my very personal curiosity. I just love to ask that audacious question of what is intelligence and how to make machines intelligent, but it was very personal. Nobody cared about AI. The world didn't know how to spell AI, and it was very fun. The past 10 years have completely changed. AI is not just personal for me; AI is civilizational. That added a layer of sense of responsibility for me in terms of how I can contribute not only technologically and as an educator, but also contribute to the healthy development of AI. What surprised me the most as an entrepreneur? A couple of things. One is the speed of development of AI this past few years is just breathtaking. I know everyone, whether we pretend or not, everyone deep in your heart is feeling that anxiety of there's just too much to read: too many blogs, too many news, too many model releases. That sense of anxiety speaks of our time; this technology is just moving at a breathtaking speed. So, that gives me a lot of excitement but also keeps me very grounded about how little I know. There's this famous saying, 'I don't know anything,' and someone like me even feels that. I want you to at least hear this from me and recognize we all feel that, and don't give up your learning and continue to be curious. The other thing that surprised me and frankly continues to worry me is the polarized rhetoric of AI. Too much cyberspace is still spent discussing AI and its implication at the extreme ends, whether it's total tech utopian as if technology is never a double-edged sword, or it's total doomsday.

As if humans are facing an existential crisis every minute.

That's just not a responsible way of talking about a technology that is so profoundly important to our civilization. Technology is a double-edged sword, but the agency is within all of us. Every entrepreneur, every product manager, every business leader, every software engineer, every citizen, we still have to have that agency to know where to lead this technology. I really, really hope that going into 2026 and forward, we don't stay at the two extreme ends of talking about AI. Let's be more nuanced. Let's be benevolent. Let's have the optimism of using technology for good, but the sense of responsibility of using it responsibly, and let's have that conversation and not just optimize for clickbaits.

So, what does success look like in your mind for AI in the next few years? I really like your framing of this kind of polarized view that we have: 'all jobs are going to be lost and we're just going to be staring at the ocean,' or 'this thing is completely useless and it's not going to do anything.'

G2, if we roll time back 150 years—I don't remember the exact years—and if a version of two of us were on stage talking about what success looked like for electricity, I think we, at least, I don't know if people have imagined...

Hard to imagine.

...but I hope that there was a version that our schools are lit, our homes are warm, that it will empower machines to industrialize our life, it will in turn lengthen our life expectancy, more children will be learning when they hit school age. That's the meaning of technology, and that's the meaning of AI. That's a timeless value. Success looks like when civilization is better, and civilization is made by every single individual pursuing happiness, pursuing prosperity, and pursuing with a sense of dignity. That is what success looks like for AI and for every piece of technology.

That's fantastic. So, I'm going to go down to tactics for a second. Are large world models as computationally intensive as language models? Are they more or less?

That's a great question. First of all, there are different kinds of large world models. We are very committed to creating world models that have 3D 4D explicit representation to empower robotics, gaming, entertainment, design, and all that. There are other models that are called 'world models' that are more video generation models. Right now, in the field, our models are not as large as the bigger LLMs. For GPT-5, I believe it's trained around 10 to the 26 flops, and our Marble model is still a few orders of magnitude smaller.

Smaller. And is that just because you don't have enough data to go out and feed these models?

I think it's actually both. Data is one of the scaling laws that starts with data and model parameters. So, data plays a role. It's also because this field is early. Language models started; the Transformer paper was published in, I think, 2017, so it's almost 10 years, right? World models are a much newer field, so we are still in the relatively early days of figuring out the model architecture. So, it's relatively small. But having said that, given the progress that World Labs has made in the past couple of years and looking at our field, I think the next couple of years are going to be very exciting. We're going to see riding the curve of the scaling law in large world models.

So, we've talked about this before, Fei, but this thing that was fascinating to me was when you had highlighted to me when we were first starting to talk, around the fact that language models are trained on free publicly available data on the internet. It's easy to go out and get a large amount of data accumulated. The physical data is hard to do, and so synthetic data becomes a big deal, but you also have to collect that data in a much slower fashion. Walk us through the constraints that that brings, and is the speed of advancement of the world models, because of that scarcity of data that you're going to have, going to be similar to what we've been used to with language models? Is it going to be slower? And then how is that going to manifest itself even in physical robotics, where are you going to have a general-purpose robot that can do everything for you, or is it going to be special-purpose robots just because of the data that we have available?

Right, that's a loaded question, G2. So, let's talk about data and let's talk about generalized robots. They are related, but there's a lot of nuance. For example, at World Labs, what is our data strategy? A lot of people ask, and obviously I can only tell you so much, but one thing is very clear: we take a hybrid data strategy approach. I'm so envious of my language friends because at the end of the day, the input data and the output data are fully observable, more or less one modality, and that's just text. Also, texts are super clean, right? I know that there are words that are not good words, but by and large, the lexicons carry very clean meanings and semantics. Whereas the world of pixels and voxels is just so much messier. In order to push the boundary of the technology to create in 3D 4D worlds, we have to—we don't have a large amount of 3D 4D data to train our model. So, what we have to do is take the hybrid approach of layering in multimodality of data. We do have texts and images and videos that are more or less at the internet scale, but we also need to have simulated data. We also need to have what we call real-world capture data. You might be wondering what those data are. One of the biggest examples is self-driving cars. Whether we look at Tesla or Waymo or other self-driving cars, these companies spend years, decades, collecting real-world data as well as simulated data. So, creating world models will take that kind of approach. Is it going to be slow? That's a really interesting question because there are some confounding factors. For example, there are way more people joining this journey, and the compute is much more powerful, the chips, and also the ecosystem is much more mature. We work with data vendors that were not around even three years ago.

And synthetic data is really taking effect pretty well, right? And it's actually adding to your efficacy.

And also what we are making will also add to this world of simulation. So, there is a flywheel. Our model will also become useful simulation data for robotics. Just a couple of sentences on generalized robots: I have run a robotic learning lab at Stanford for the past decade and beyond. I'm super excited by robots. I do think that as a scientist, it's important to recognize this is a very, very hard problem. Just because the North Star is clear doesn't mean the journey is short. Think about 2006. My colleague Sebastian Thrun led the Stanford team to create the first self-driving car that could run 138 miles in the desert of Nevada. That was when we declared we're going to have self-driving cars. Twenty years later, last year was the first year Waymos were running on the streets of San Francisco and some larger cities. We more or less have gotten to a major milestone, but that's a very long journey. The difference between a car and a robot: a car is a squarish robot that moves on two-dimensional surfaces, and the only thing the car needs to do is not touch on things – don't touch on pedestrians, don't touch on the curbs. Think about a robot. It's a three-dimensional thing, whether it's humanoid or not, working with a three-dimensional world. The goal of a generalized robot is to touch on things in a way that is not breaking them. So, that is a much higher dimensional problem, and we are making progress.

And the simulation of the hand has been really hard, right? Dexterity of hands, the precision of vision, the understanding of space, the lack of training data—all this is challenging. This is why I started World Labs, because I know this is a very important problem. We want to work on this, but I also personally, as a scientist, don't like to overpromise.

So, Fei, in the last 60 seconds, for the people that are here from the enterprise side of the house, how should they be thinking about world models, physical AI, and all your world that you're thinking about? And then the last thing I'll say, because I know we're running out of time, is we wouldn't be able to have a Cisco AI summit without Fei anymore, because it would feel incomplete. So, we're going to keep inviting you.

Thank you. Well, I'm waiting for my swag.

Yes, we will get you. Can we please get swag to Fei?

Just kidding. I still think like a grad student: free food and swag. So for the enterprise, especially for world models and spatial intelligence, we're very much an enterprise-facing business, in my opinion. World Labs is very open to talk to enterprise partners. I think there are so many; it's a horizontal technology. We talked about robotics, we talked about simulation, we talked about immersive interactive entertainment experience, but we haven't talked more about healthcare. We haven't talked about educational products. We haven't talked about field services. We haven't talked about financial services. We haven't talked about agriculture, manufacturing, inspection, warehouse, and city urban planning, and all this. There's just a lot we can do with spatial intelligence. I do think this is the next frontier, and I invite all of you to work with us or work by yourselves on this topic.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-1">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=Kcfpew9V-Us" target="_blank" rel="noopener">Cloud &amp; AI | Matt Garman, CEO, AWS &amp; Jeetu Patel</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>21:23</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-08</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Matt Garman</span> <span class="tag tag-person">Jeetu Patel</span></div>
                </div>
                <div class="tldr">Companies often fail to transition AI from proof-of-concept to production due to undefined success metrics and scaling challenges, while AWS is building a natively integrated &quot;AI-first cloud&quot; platform, including proprietary silicon, to address these issues and emerging sovereign AI requirements.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-1">TL;DR Companies often fail to transition AI from proof-of-concept to production due to undefined success metrics and scaling challenges, while AWS is building a natively integrated &quot;AI-first cloud&quot; platform, including proprietary silicon, to address these issues and emerging...</div>
                    <div class="summary-full" id="full-1">
                        <p><strong>TL;DR</strong></p>
<p>Companies often fail to transition AI from proof-of-concept to production due to undefined success metrics and scaling challenges, while AWS is building a natively integrated "AI-first cloud" platform, including proprietary silicon, to address these issues and emerging sovereign AI requirements.</p>
<h3>Challenges &amp; Keys to Successful AI Deployment</h3>
<ul>
<li><strong>Gap between Experimentation and Production:</strong> Many companies conduct AI proofs-of-concept (POCs) without defining clear success criteria or measurable goals, hindering full-scale deployment.</li>
<ul>
<ul>
<li><strong>Defining Value Beyond Cost Savings:</strong> An example cited was a hospital administrator who didn't save money with ambient listening AI, but significantly reduced doctor attrition, highlighting the importance of diverse metrics beyond direct cost reduction.</li>
<li><strong>Metric Maturity:</strong> Good metrics are prevalent for areas like customer service and code generation, but "general productivity" applications still lack robust measurement.</li>
</ul>
</ul>
<li><strong>Deployment Blockers:</strong></li>
<ul>
<ul>
<li><strong>Security Concerns:</strong> For agentic workflows, companies fear agents acting autonomously, leading to security breaches, sprawl, and identity management issues.</li>
<li><strong>Operationalization and Scaling:</strong> Moving from a single GPU POC to global deployment poses significant challenges in scaling, operational efficiency, and productization.</li>
</ul>
</ul>
</ul>
<h3>AWS's AI-First Cloud Strategy</h3>
<ul>
<li><strong>AI Integration into Every Application:</strong> Matt Garman, CEO of AWS, asserts that all future applications will have AI inference capabilities natively integrated, transforming every business and industry.</li>
<li><strong>Deep Infrastructure Integration:</strong></li>
<ul>
<ul>
<li><strong>Natively AI-Aware:</strong> AWS is integrating AI throughout its infrastructure, enabling agents to interact seamlessly with storage, VPCs, security settings, and permissions.</li>
<li><strong>Bedrock Platform:</strong> AWS's Bedrock platform offers extensive model choice, capabilities, and the robust security customers expect, operating within a VPC.</li>
<li><strong>Ecosystem Approach:</strong> AWS ensures its platform supports partners and the broader ecosystem, acknowledging that no single vendor can build every necessary component.</li>
</ul>
</ul>
<li><strong>Proprietary Silicon (Tranium):</strong> AWS's investment in chips like Tranium aims to provide better price-performance, offer customer choice beyond dominant GPU providers, and deliver differentiated capabilities.</li>
<ul>
<ul>
<li><strong>Margin vs. Price:</strong> Garman suggests that while proprietary chips could improve margins, AWS's operating model typically involves passing cost savings to customers to drive faster growth and more new workloads, aligning with Jevons paradox.</li>
</ul>
</ul>
</ul>
<h3>Future of Infrastructure: Constraints &amp; Innovation</h3>
<ul>
<li><strong>Physical Infrastructure Bottlenecks:</strong></li>
<ul>
<ul>
<li><strong>Construction Delays:</strong> While software development accelerates, physical infrastructure buildout (pouring concrete, permits, power) remains time-consuming, limiting hyperscalers' expansion.</li>
</ul>
</ul>
<li><strong>Space Data Centers (Long-Term Vision):</strong></li>
<ul>
<ul>
<li><strong>Theoretical Advantages:</strong> Offer infinite power (solar) and easier cooling.</li>
<li><strong>Current Hurdles:</strong> Server weight, lack of permanent space structures, high cost and limited availability of space transport, and latency concerns make them impractical for the foreseeable future.</li>
</ul>
</ul>
<li><strong>Hyperscalers and "Full Stack" Control:</strong></li>
<ul>
<ul>
<li><strong>Beyond Chips:</strong> AWS's move into chip manufacturing (something unheard of 20 years ago) suggests a potential expansion into areas like power generation or construction.</li>
<li><strong>Industry Scaling Challenges:</strong> Traditional utilities, for example, are structured for slow growth (3-5% annually) with fixed pricing and returns, which does not meet the rapid scaling demands of hyperscalers. AWS may need to directly fund or own parts of this infrastructure to accelerate growth.</li>
</ul>
</ul>
<li><strong>Capacity Planning for AI:</strong></li>
<ul>
<ul>
<li><strong>Sustained Demand for Older Chips:</strong> Due to high demand exceeding supply, older generations of AI chips (e.g., A100s) remain in demand and are not retired, especially for tasks requiring higher precision (HPC).</li>
<li><strong>Multi-Horizon Planning:</strong> AWS plans across multiple timeframes, from 20-30 years for data centers, to 5-6 years for servers, managing a complex supply chain and investment risks across these horizons.</li>
<li><strong>Chip Cycle Time:</strong> New chip versions emerge every 18-24 months, with 9-12 months from first chip out to scaled production.</li>
</ul>
</ul>
</ul>
<h3>Advancing AI with Internal Practices &amp; Sovereign Solutions</h3>
<ul>
<li><strong>AI-Driven Coding at AWS:</strong></li>
<ul>
<ul>
<li><strong>Significant Acceleration:</strong> Teams starting with "AI-driven coding" from the beginning see 10x to 100x improvements by prompting models instead of writing code, leading to context-rich, self-documenting, and testable code. Some teams have a "no line of code" mandate.</li>
<li><strong>Challenges with Legacy Systems:</strong> This speedup is less pronounced for complex, integrated legacy systems (e.g., S3), where providing sufficient context to models for tasks like memory management or object durability is difficult.</li>
</ul>
</ul>
<li><strong>Addressing Sovereign AI Requirements:</strong></li>
<ul>
<ul>
<li><strong>Geopolitical Concerns:</strong> Countries increasingly desire sovereign AI infrastructure due to concerns about trusting foreign governments and maintaining strategic independence.</li>
<li><strong>AWS EU Sovereign Cloud:</strong> AWS has launched a fully separate subsidiary in the EU, beholden to EU laws, with an independent governing board. All data, including metadata and login credentials, resides within the EU, and the system has been tested for disconnection from the AWS backbone, co-designed with European regulators like Germany's BSI. This model addresses trust for large economies.</li>
</ul>
</ul>
</ul>
<h3>Executive Guidance for AI Acceleration</h3>
<ul>
<li><strong>Build Guardrails for Speed:</strong> CIOs and CISOs should focus on creating "safe places to run fast" by implementing guardrails and secure building blocks (like AWS Agent Core) for AI deployments. This alleviates fears of autonomous agents causing production issues or security breaches, allowing teams to accelerate adoption.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"I haven't saved a single dollar... I haven't saved anything. Not like two hours later, I met with another hospital administrator who said the exact same story... and I was really worried about attrition... and now they have a lot more free time with their families and that attrition number has gone down. So I'm super excited. I'm rolling it out." — *Matt Garman, CEO, AWS*
"There's not going to be AI applications and non-AI applications. there's going to be applications and they all are going to have inference integrated into those capabilities and it's going to change every business going to change every industry." — *Matt Garman, CEO, AWS*
"If you look at the economics of a number of those uh different industries, they don't um they don't scale with the level that we need them to scale." — *Matt Garman, CEO, AWS*
"When the teams start from the beginning thinking about um AIdriven coding... we have teams now where they have almost a mandate that they write no line of code. All they do is they they prompt the models or they they prompt the systems. And um and that there's a couple of benefits you get from that. One is the the AI systems build a ton of context around what they're building." — *Matt Garman, CEO, AWS*
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-1" onclick="toggleSummary(1)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-1" onclick="toggleTranscript(1)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-1">
                        What's the biggest gap you see between companies that are experimenting and companies that are actually starting to find successful deployments in production? What are you seeing as a big characteristic differential for AI in particular?

One of the challenges many companies had when they started doing a bunch of proof of concepts with AI was that they didn't actually have good success criteria defined at the beginning. It was just a learning journey. Many went on this path where teams were asked to do hundreds of different experiments and roll them out without a clear goal of what was to be accomplished. Knowing what that goal is and helping define it is one of the first steps to truly understanding which of those things to move to production.

As an example, I was at the JP Morgan Health Conference a couple of weeks ago in San Francisco, and one of the big things people were excited about was ambient listening. This AI would listen to doctors, automatically put notes into Epic, and send information to insurance companies. People were very excited about it. I met with one hospital administrative leader who said, &quot;Yeah, I did all of this stuff and it's great. The doctors have more time at night to have dinner with their families. I haven't saved a single dollar. So what am I getting out of this? I literally have not fired a doctor, I haven't saved anything.&quot; Two hours later, I met with another hospital administrator who told the exact same story. All these things are happening, it's great. He said he was really worried about attrition; there was a risk that 30% of their nurses and doctors would attrit in the next 12 months. Now they have a lot more free time with their families, and that attrition number has gone down. So he was super excited and was rolling it out around the hospital. Having that metric as to what the real value you want out of that is a huge thing that blocks a lot of companies because they initially say, &quot;I'm not saving any money with this,&quot; and that may be true, but it may also not be the goal.

What percentage of companies do you think have good, solid metrics that you feel are at the right level at this point?

I think it's often by the area they're rolling it out. When people are rolling it out for customer service, they usually have quite good metrics there. When people are starting to roll it out with code, as an example, there are a lot of metrics, submitted lines and things like that. But for the rest of the workforce, where it's a general productivity, fuzzy metric, people don't really have a good sense. We'll get there, but that's part of it.

The other thing that blocks people from rolling out, and this is a more fundamental piece, particularly with agents, is that as you get into agentic workflows, people are super worried about security. They're worried that the agents are going to go off and do things that they're not supposed to. They're worried about the sprawl of agents, agent identity, and a bunch of those things. Frankly, they're worried about how to scale. They worry about doing a proof of concept, buying one EC2 instance with GPUs on it, testing it, and now wanting to roll it out around the world. That GPU is relatively underutilized. How do you scale this? How do you think about that? So, productizing a proof of concept is something people haven't really gotten their hands around from a security, operational, and scaling point of view. You folks have been talking a lot about this notion of AI-first cloud. What does that actually mean? Talk to us a little bit about how AWS is thinking about it.

Sure. I'll take a half step back. We view that AI and inference in particular are going to be a critical part of every single application in the world. So there won't be AI applications and non-AI applications; there will just be applications, and they will all have inference capabilities integrated into them. It's going to change every business, every industry. What that means from our perspective is that it has to be integrated into every single piece of the AWS infrastructure. You have to be natively thinking about how AI and your agents can talk to your storage, how it will work inside your VPC in your security settings, how you will think about permissions, trade-offs, and testing one model versus the other once it actually gets to production.

We're building a platform called Bedrock, with the idea that we want a real platform that will have a ton of model choice, a ton of capabilities, and all the security that our customers expect inside of VPC to be able to roll that out. We supplement that with the observation that all of the biggest other partners in the world operate inside and on top of AWS too. So we open that up and make sure that every partner and every part of the AWS ecosystem can be a big part of what customers are building because we don't think we're going to build every part of that. We know customers need that whole ecosystem to be successful in what they build.

But you are building one of the very high-margin products in that stack, which is the Tranium chips, which have actually seen a tremendous amount of success. Congratulations on that.

Thank you.

Do you see the economics of AWS changing where the margin structure gets even better because if every application has inference and you're going to have inference capability in the stack that you have built out, does that improve your margins over time?

I have no idea. That's a good question, and that's for the bankers to guess on. But I will say it definitely improves our margins versus only using Nvidia GPUs. They're always going to be a big part of that, but a big part of that margin necessarily goes to Jensen and the team. We love their products, and they execute awesomely. But when you have 70-80% gross margins, there's room in there for somebody to take less margin, have a higher-performing part, and offer choice to customers. We think we can offer better price performance for customers, choice for customers so they can pick between the various options out there, and have the richest set of capabilities that are unique to AWS that they cannot get anywhere else. That's part of why we've invested in silicon for the last 10 plus years now. It's such a big part of what we deliver, which is that differentiated performance all the way down to the silicon layer, which together with our partners, offers a really rich set of capabilities that people can build on.

Tranium for us is a huge part of that. Whether it ultimately allows us to increase margin or keep margins where they are and lower prices for customers, frankly, I'd probably bet on the second because that's just how AWS operates. My guess is it's probably more that we try to grow faster, and because we find that every time we lower prices, we generally pass them on to customers, it gives customers more budget to go build new workloads, and for us, that generally leads to a good flywheel.

The Jevons paradox is kind of in full effect. Let's talk about constraints on infrastructure buildout. You and I have talked about this, and you talk to a bunch of hyperscalers. One of the challenges they have is it's not just about capital being allocated; it is literally physically very time-consuming to build out the shell, get the permits, have the power, and make sure that you have the entire stack getting built out. Do space data centers change the equation, and do you think space data centers will actually take away some of those constraints because solar is going to be 30% more efficient in space? Do you see that happening, or do you feel like we're still pretty far away from that?

It all depends on your timeline. A big chunk of this is just hard. Building some of these things is actually quite difficult. People are very excited that they can build software in a fraction of the time, but pouring concrete takes the same amount of time, and building buildings takes the same amount of time. We haven't yet built AI agents that can do that; maybe robots will eventually. For space data centers, I think there are a lot of compelling ideas about a data center that's in space: infinite amount of power that's always available, great easy cooling. I don't know if you've seen a rack of servers recently; they're heavy. The last I checked, humanity has yet to ever build a permanent structure in space, on the moon, or anywhere like that. So maybe, but I know Elon says he's going to launch a million satellites or whatever. There are not enough rockets to launch a million satellites yet. So we're pretty far from that, and I think there's probably going to have to be some improvements in efficiency and cost. If you think about the cost of getting a payload in space today, it's massive, way, way more. There's no way.

Blue Origin might actually come in handy though.

It would be great, but they have to get their costs way down. It is just not economical today. So I think there is an interesting dynamic, depending on where that cost curve goes. They're probably going to find some cheaper rocket fuel. There are a bunch of things, and there's a huge number of people investing in making space transport much more economical, but that's a ways off.

And then that does become a huge bottleneck in space: just the transport.

Just the transport. I mean, that is absolutely the bottleneck today: the cost and availability of just getting things into space.

Getting things in space. Some latency concerns as well. Let's stick with Earth data centers for a second. Do you think that the definition of full stack for hyperscalers changes? Do you start getting more into the power business and more of the construction business, because it feels like if you control the full stack, you would be able to accelerate this faster?

I'm not the best person to ask this because if you asked me 20 years ago if AWS would be making chips, I definitely would have told you no. But here we are. I think some of it is that the answer will necessarily be yes, almost for sure. That's because if you look at the economics of a number of those different industries, they don't scale at the level that we need them to scale. Utilities, as an example, for almost the history of time, have fixed and regulated pricing, which is a limiter to them, and they get a fixed return on their investment. The whole industry is constructed to grow at 3 to 5% a year, and it's very hard to break them out of that because why would they take a risk when they get low returns on that and other things like that?

So, whether we own the power or we fund the power, I don't really want to operate power stations or things like that. That definitely is something I would like not to do. The whole system is much more efficient if it can be connected to the grid, and there are probably some steps between here and there where you're going to have to do behind-the-meter power and other things because we're just going to have to fund that ramp-up while the world catches up.

Or we'll rely on people like Turk to do it too.

Yes, of course. Let's say you continue to make sure you're building out the chips. What's the average cycle time of chips now that you have a new version of the chip out every 18 months?

18 to 24 months, it depends. Sometimes it is compressing, generally, but yeah, call it somewhere between 18 to 24 months. Sometimes you're also limited on your process generations. You're also limited on how fast TSMC improves process generations. You're also limited on how fast you can actually get these systems into production. From the time you print your first chip to when you're really at scale for these large AI systems, it's actually 9 to 12 months from first chip out to really, manufacturing is quite hard.

But in general, you would agree that the cycle time has compressed. How do you do capacity planning at the scale of AWS, and does that equation change a little bit? For example, you don't want to have a bunch of chips that you bought that in 18 months become obsolete, but you have to make sure that there's a long tail on how different workloads start using them. How does capacity planning work?

There are a couple of things that play in our favor. It's a challenge, and it's part of the challenge we take on so customers don't have to. Because there is so much more demand than supply, there typically still is demand for the older chips. Today, we are completely sold out and have never retired an A100 server, for example. We've never retired an A100 server because there's still demand for it. There are structural reasons why every next generation, part of where the industry today is gaining so much on the AI side, is by reducing floating point accuracy. I was talking to some customers recently, and they were saying, &quot;Actually, I can't move to Blackwells. I have to use older generations because I'm doing HPC-style calculations, and the precision is not enough for me.&quot; So they're in a hard place where AMD's new processors, you can enable that, but a lot of the world and some of the old applications rely on that level of precision. There are use cases for them. Smaller models still run great on A100s and other things. So I think there's a long way there. For some of these large labs, they're also willing to make 5-year commitments for some of this capacity sometimes too, which also mitigates some of our risk and pushes it onto customers potentially.

We do a lot of planning here. We have to think about many time horizons. For example, last year, we added just south of 4 gigawatts of new capacity in AWS for data centers. Data centers have a 20-30 year amortization timeline; power requires long-term commitments, and so on. So you have to think about data center planning for a really long time because you're going to have this asset for 20 or 30 years. And you think about servers, which you have for five or six years. You have networking gear that's maybe six to ten years. You have to think about all those different components. We spend a ton of time thinking about supply chain and how we think about risk levels at all those levels of investment.

Let's switch to AI coding. You and I had talked last time I was in your office, and you were saying that you're seeing some pretty great results from that internally. Talk to us about what you're seeing working well and what you're seeing not work so well.

The thing that we see giving massive acceleration—I would say 10x improvement or more, sometimes 100x improvement—is when teams start from the beginning thinking about AI-driven coding. In fact, we have teams now where they have almost a mandate that they write no line of code. All they do is prompt the models or the systems. There are a couple of benefits you get from that. One is that the AI systems build a ton of context around what they're building, and then they also know how all those things work together. They've also documented all of the code that's written, so you start to get a real flywheel where it can then test all of the code because it knows it, it knows the documentation, and it knows the things it needs to test, and it has all of that coverage.

I will say where we're not there yet—and it's a &quot;yet&quot; because it's probably within the next six to nine months we'll solve this problem—is that we have not yet seen that speed up for really complicated, integrated legacy systems. They're not necessarily legacy in the sense of mainframe, but even a really large distributed system that has a large codebase, say something like S3, which has been around for a little bit of time. We've reimagined it many times before, but it's not zero; we're not starting from scratch. So giving all of that context to the models so that you can get that same speed up, we still see some speed up, but not quite the 10 to 50x speed up. But I think we're building and thinking about some novel ways in which we can get coding systems to understand legacy code, and I think that's one of the areas that can help people start to get massive speed up, which turns out most of the code is legacy code out there.

We're actually seeing that the further down in the stack you go, the harder it gets.

Yes, and that's probably true. S3 is another good example of that, where you're really thinking about memory management, which is much harder to do. Memory management and correctness of durability of objects is a little bit different than an end-user application where it's like &quot;build me a website,&quot; which the agents are quite good at doing now.

When you start thinking about sovereign AI infrastructure and how countries are going nationalistic, they each want to have their own infrastructure. Do you think architectures like Outpost get even more interesting?

They are. I think this is a super interesting topic. I was just at Davos two weeks ago, and probably nearly every single conversation I had with a European company started with, &quot;Look, we trust you, I don't know if I can trust your country.&quot; We try to walk them through why that's not really the trade-off they should think about. They also realize that they can't tie their own hands behind their back and not compete with the world's best technology. So these companies are realistic, but they're having the struggle. I don't know how many times I literally had the question of, &quot;How do I, what if the US government decides to turn me off?&quot; It's a question many people have, and we assure them that's very unlikely to happen, but it's a concern they have.

Resilience almost trumps raw intelligence at some point.

Yes, in some ways. If you think about banking systems or other areas like that, from a country perspective, countries feel like they now need that lever, or they're at risk of us being a lever against them. So we're thinking about a bunch of different mechanisms to solve this around the world. Just two weeks ago, we launched the EU sovereign cloud, and I think for the EU, this is actually going to be fantastic. Its partners are launch partners. But the idea behind the EU sovereign cloud is that it's a fully separate subsidiary that is incorporated inside the EU, beholden to EU laws, and actually has an independent governing board. We make sure that every bit of data, including metadata and account logins, all of that lives inside of the EU region. We've even tested disconnecting that whole region from the AWS backbone to make sure that it works. We actually co-designed this with the BSI from Germany and other EU countries to make sure that they like this model. That works for the EU because it's such a large economy in and of itself. But I think we are exploring a bunch of different things like that to help companies around the world grapple with this, where there are obvious trade-offs, but they are hard questions. Hopefully, that's where we can help.

In 30 seconds or less, can you provide the CIO and CISO audience some advice on what they need to do to accelerate AI adoption internally?

I have this analogy that I like to use: if you have a giant canyon and there's a board across the canyon, you walk really slow across that board; you maybe crawl across it. Now, all of a sudden, if you put handrails up and you put walls and guardrails, you can run across it. It's weird because it's the same board, but you can run across it and you can do it. It's not that dissimilar. Part of what slows people down is they're worried. We had examples internally where somebody was writing some code and they asked the agent to go do something, and the agent was just about to go delete some infrastructure because they thought that was the fastest way to do it. It highlights that lots of companies are worried that if they just unleash agents into their enterprise, bad things will happen, production will go down, and security issues will happen. So what I would say is what we're trying to do is build building blocks for customers so that they can go fast. Things like Agent Core for us allow you to have some of these guardrails that allow you to go fast. The more you can give your teams safe places to run fast in a production setting, I think you'll benefit.

Come back again. Thank you again. Thanks so much.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-2">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=eFinF8AJD8A" target="_blank" rel="noopener">Frontier Models &amp; AI | Sam Altman, CEO &amp; Co-Founder, OpenAI and Jeetu Patel.</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>24:11</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-08</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Sam Altman</span> <span class="tag tag-person">Jeetu Patel</span></div>
                </div>
                <div class="tldr">&gt; &quot;Codex has been my biggest update on AI in a while.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-2">TL;DR: AI models like Codex and OpenClaw are ushering in a &quot;ChatGPT moment&quot; for knowledge work and software development, but their widespread adoption is challenged by the need for new security paradigms, redesigned software, and faster enterprise absorption, demanding...</div>
                    <div class="summary-full" id="full-2">
                        <p><strong>TL;DR</strong>: AI models like Codex and OpenClaw are ushering in a "ChatGPT moment" for knowledge work and software development, but their widespread adoption is challenged by the need for new security paradigms, redesigned software, and faster enterprise absorption, demanding significant infrastructure investment and a shift to thinking about AI as a collaborator, not just a tool.</p>
<h3>The Transformative Power of AI Agents</h3>
<ul>
<li><strong>"ChatGPT Moment" for Knowledge Work:</strong> Sam Altman, CEO &amp; Co-Founder, OpenAI, describes current AI advancements, particularly with Codex and OpenClaw, as another "ChatGPT moment."</li>
<ul>
<ul>
<li>OpenAI's internal observation: Cisco's AI Defense product will have 100% of its code written with Codex within weeks.</li>
<li>This is expected to generate "unbelievable economic value extremely quickly" and fundamentally alter how organizations operate.</li>
</ul>
</ul>
<li><strong>Evolution Towards Full AI Companies:</strong> The current upper limit of AI potential is envisioned as full AI companies, where coding models create complex software and interact with the real world to build and run businesses.</li>
<li><strong>Generalized Computer Use:</strong> The concept of AI agents having full control over a computer and web browser (as demonstrated by OpenClaw) is deemed "much more powerful" than code alone, promising a "genuine transformation in how knowledge work will happen."</li>
<ul>
<ul>
<li>Altman personally found giving Codex full computer control so useful it lasted "about two hours" before security concerns led him to use two laptops.</li>
</ul>
</ul>
<li><strong>New Forms of Social Interaction:</strong> The future may include novel social networks where multiple AI agents interact on behalf of people, collaborating to find information and generate new ideas.</li>
</ul>
<h3>Key Obstacles to Broader AI Adoption</h3>
<ul>
<li><strong>Non-Obvious Constraints:</strong> Beyond the recognized limitations of infrastructure, compute, and power, several less obvious challenges persist:</li>
<ul>
<ul>
<li><strong>Security and Data Access Paradigm:</strong> A new security and data access framework is critically needed to balance the utility of AI models with data privacy, as current systems are not designed for AI agents with broad access.</li>
<li><strong>Software Design for AI/Human Co-use:</strong> Most existing software is not built for seamless interaction between humans and AI.</li>
<ul>
<ul>
<li>*Example:* An AI using Slack might mark threads as read, disrupting a human's workflow, indicating a need for separate AI user accounts or software optimized for agents.</li>
</ul>
</ul>
<li><strong>"Always-On Computing" Challenges:</strong> Enabling AI to continuously observe meetings or computer activity for real-time value addition is hampered by current computer hardware, permissioning systems, and legal frameworks (e.g., recording and then deleting meeting data).</li>
</ul>
</ul>
<li><strong>"Capability Overhang" and Slow Absorption Rate:</strong> Despite the rapid advancement of AI (e.g., in scientific discovery, software development), the adoption and integration rate within organizations is surprisingly slow.</li>
<ul>
<ul>
<li>This "capability overhang"—the gap between AI's potential and its practical deployment—is perceived to be larger than ever.</li>
<li><strong>Executive Advice:</strong> Sam Altman stresses that enterprises not configured to quickly adopt "AI co-workers" will face a "huge disadvantage," requiring significant effort and risk to adapt.</li>
<li>The transition requires viewing AI as a "teammate" or "collaborator" rather than merely a transactional tool.</li>
</ul>
</ul>
</ul>
<h3>Infrastructure &amp; Business Model Evolution</h3>
<ul>
<li><strong>Underestimated Infrastructure Demand:</strong> Despite predictions of trillions in spending, the long-term demand for AI capacity (like "tokens") is likely underestimated, akin to the historical demand for electricity.</li>
<ul>
<ul>
<li><strong>Long-Term Vision:</strong> AI usage is projected to grow exponentially, with models becoming more capable and cost-efficient per task, leading to pervasive integration into business operations, scientific discovery, and personal software use.</li>
<li>Global supply chains and policy are reconfiguring to meet this demand, though temporary gluts may occur.</li>
</ul>
</ul>
<li><strong>OpenAI's Evolving Business Model:</strong></li>
<ul>
<ul>
<li><strong>Subscription Success:</strong> OpenAI has seen strong consumer and enterprise willingness to pay for subscription services (e.g., ChatGPT, API, Codex), with "many tens of millions of consumers paying."</li>
<li><strong>Advertising Potential:</strong> While requiring careful implementation, advertising is seen as a viable model for mass-scale consumer businesses.</li>
<li><strong>AI Cloud Subscription:</strong> Businesses are increasingly seeking an "AI cloud subscription" model—a general-purpose platform partnership that handles security, context, access, and supports various agents and models.</li>
<li><strong>Scientific Discovery Partnerships:</strong> OpenAI may act as an investor in large-scale scientific endeavors (e.g., curing diseases) requiring substantial inference capital, potentially receiving royalties in return.</li>
</ul>
</ul>
</ul>
<h3>Strategic Imperatives &amp; Future Outlook</h3>
<ul>
<li><strong>Open Source Leadership:</strong> Sam Altman expresses concern over the US's lack of substantial leadership in open-source AI, emphasizing its importance due to user demand for control over private, locally running models, especially for "always-on" personal AI devices.</li>
<li><strong>Boundless Future Vision:</strong> Altman envisions an economy growing at an unprecedented rate, supported by billions of humanoid robots building infrastructure, and even "Von Neumann probes" launching into space.</li>
<li><strong>Aggressive Capability Growth:</strong></li>
<ul>
<ul>
<li><strong>Tailwind:</strong> The primary tailwind is the rapid, continuous improvement of AI models, which are expected to get "very, very good" quickly, offering immense opportunities.</li>
<li><strong>Headwind:</strong> Global destabilization and mega supply chain disruptions are significant concerns.</li>
<li><strong>Near-Term Improvement:</strong> Subjectively, capabilities are expected to improve by "something like 10x" by the end of the year in terms of problems solvable.</li>
</ul>
</ul>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"Codex has been my biggest update on AI in a while. ... This is going to create an unbelievable amount of economic value extremely quickly. This is going to change how all of OpenAI works and change how other companies work." — Sam Altman
"The idea that we can take a Codex-style workflow and expand it to all knowledge work... feels like a genuine transformation in how knowledge work will happen." — Sam Altman
"The capability overhang feels to me like the biggest it has ever felt. ... The diffusion, the absorption is so slow." — Sam Altman
"Companies that are not set up to be able to adopt let's call them AI co-workers very quickly will be at a huge disadvantage." — Sam Altman
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-2" onclick="toggleSummary(2)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-2" onclick="toggleTranscript(2)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-2">
                        Let me start with some good news. I don't know if you know this, but we are the first design partner for Codeex.

I did know that.

Thank you. In the past few months, I think we've hit an exponential curve. AI defense was a product that we launched here last year. In about two or three weeks, 100% of the code in AI defense will be written with Codeex.

That's unbelievable. Codex has been my biggest update on AI in a while. The app that we launched yesterday just pushed things over the edge for me. I'm like, &quot;All right, this is going to create an unbelievable amount of economic value extremely quickly. This is going to change how all of OpenAI works and change how other companies work.&quot; The model has really hit some threshold, and I think now the interface and harness have caught up. This is the first, you're talking about ChatGPT moments, I think this is the first time I've felt another ChatGPT moment.

Here is a clear glimpse of the future of knowledge work and how enterprises and individual people are going to use AI to work in a completely different way. So what's the upper limit on this, do you think? The upper limit, I think, is full AI companies. There's probably an upper limit beyond that, but the current one I can think about is full AI companies, and that seems very powerful. The idea that a coding model can create a full complex piece of software but also interact with the rest of the real world to build a company around it is a very big deal.

And then this notion of what's happening right now, I'm sure you're tracking this with Moldbook and what happened with Cloudbot. Is it just a passing fad, or do you think that there's something that we should take away from that?

No, I think it is definitely not a passing, well, Moldbook maybe, I don't know, but OpenClaw is not. I think this idea that code is really powerful, but code plus generalized computer use is even much more powerful, is here to stay. When I initially installed Codex, I said I was never going to give Codex full control of my computer without checking what it was doing. That lasted about two hours because it was so useful. Then I got persuaded by people that I really shouldn't have it running like that. So now I have two laptops until I figure out how this is all going to work. But giving an AI agent full use of your computer and your web browser with all your sessions leads to incredible stuff, and that seems here to stay.

The idea that we can take a Codeex-style workflow and expand it to all knowledge work, so that whatever you're doing, Codex or some version of that can be using your computer and using the web for you, editing documents, and whatever other kind of work you need, feels like a genuine transformation in how knowledge work will happen. I think OpenClaw did an incredible job of bringing many ideas together to make that feel usable and real, and that seems certain to be part of our future. I think Moldbook is cool, and I think it points to something that will be real, and maybe it will be Moldbook. But there will be new kinds of social interaction where you have many agents in a space interacting with each other on behalf of people, leading to all sorts of new things. You can imagine a totally new kind of social network where everybody makes an agent or many agents and puts them in there, and the agents are talking and doing stuff, finding people and information, and collaborating with other people's agents to come up with new ideas. I think the future of social may look something like that, very different than today, whether it's Moldbook or not, is uncertain.

Sure. If you think about the constraints that we are facing today, besides the obvious ones—the infrastructure, the compute, the power, and all of those pieces—are there any non-obvious constraints that are holding us back? People always say in the short term, you always overestimate the impact of these technologies, and longer term, it's going to be grossly underestimated. But what are the non-obvious constraints that you see right now, where you're like, &quot;Man, I wish if I had a magic wand, if I could change that?&quot;

I think the obvious constraints are the biggest ones: still energy, manufacturing enough hardware, all that stuff. The non-obvious ones that are most top of mind for me are, one, how are we going to balance the security and data access versus the utility of all of these models?

I don't think anyone has a great answer to this yet. It feels to me like there is a new security or data access paradigm that needs to be invented for this. Another is how are we going to rewrite all software to be equally usable by humans and AIs? There are a bunch of weird quirks right now about trying to do that with the way software works.

And does that change the architecture of the software itself, where you're going to optimize it for agents more so than humans, and so it fundamentally changes how you build software?

Yes. There are big examples of that, and then there are dumb examples of that. For example, I would love my agent to be able to use Slack on my behalf because I hate drowning in Slack, and I think it's this chaotic mess for me, but it's important. The way it works right now is my agent can use the Slack web interface and go read all my threads and do something for me, but then it has marked a bunch of stuff as read in the process of doing that, and it's broken my workflows.

Broken your workflows. Yeah.

So, that's just a silly example of how a lot of software is not quite meant for an AI and a person to be using it together. Maybe we'll want AIs to have different user accounts in some ways using the same kinds of things. Maybe a lot of software will get rewritten so that it's primarily or largely used by AI but also still works for people using it the old-fashioned way.

Another non-obvious block is how one of the most powerful things about AI is you could do this always-on computing where you could have an AI listening to your meeting or watching your meeting and watching what you're doing on your computer, and then just add a lot of value and do stuff for you. Our existing computer hardware is not really meant for that. Our permissioning system and how we think about what an AI gets to see and do stuff with, and what it gets to keep, is not really meant for that. Our legal system doesn't really support that well. You'd like to be able to record a meeting and learn something from it and delete the recording. So I think there's a lot of just usability things like that.

And then you talk about this notion that one of the things I find is a huge dichotomy: there's so much advancement happening in science and in all the different areas that we'll talk about. Kevin Weall is going to be here later today. And then, on the other hand, the challenges that organizations struggle with to just get the basics up and running with everyone. There's a capabilities overhang, and by the way, this is a new concept. When Microsoft Word came out, people used 2% of the capability back then. So when you start thinking about this, how do we make sure that we actually increase the absorption rate? You've got CIOs and CISOs over here. What advice would you give them on increasing the absorption rate within their organization for AI?

The capability overhang feels to me like the biggest it has ever felt. A few months ago, maybe I would have said it feels bigger than any time except right before ChatGPT launched. It now feels even bigger than that, even though people are using AI for a lot of stuff.

The fact that AI can make small but increasingly big scientific discoveries, the fact that AI can write full pieces of software, the fact that soon AI can do more generalized knowledge work—those are all huge, huge things. We have always said that we're going to automate research, use that to automate the economy, use that to deliver incredible new value to people and share all these benefits and this whole new technological world. We always said that as an abstract, sometime-in-the-future thing. And yet now, AI is doing research, and AI is able to do huge amounts of economic work. As you said, this has happened many times in the past, but living through it definitely feels like, &quot;Huh, this is not quite how it seems like it should go.&quot; The diffusion, the absorption, is so slow.

Is it slower than you thought it would be?

Yes, but I think I was just naive and didn't think about it that hard. In retrospect and looking at the history, it shouldn't be surprising. It feels fast in some ways relative to other things. ChatGPT grew crazily quickly relative to any other piece of software before. Codeex is growing extremely quickly. I expect the general-purpose computer-used knowledge work to grow quickly. And yet, looking at what's capable, looking at what's possible, it does feel surprisingly slow.

In terms of advice, figuring out how to set up enterprises such that they can quickly absorb these new tools and not have a year or multiple years of thinking about the data access and security questions that are currently blocking people, even at the level today, of adopting things like Codex, feels very important. I don't want to make a too dramatic prediction, but I think that companies that are not set up to be able to adopt, let's call them AI co-workers, very quickly will be at a huge disadvantage, and it is going to take a lot of work and some risk to be able to adopt them.

One of the big insights we had when we were using Codeex was for the first two or three months, we kept thinking it was going to be this amazing tool. Then there was this light bulb that went off with actually one of your four deployed engineers, and they said, &quot;You folks are thinking about this wrong because you have to think about it as a teammate rather than a tool.&quot; I think that level of skeuomorphic design, people haven't fully grasped that when it comes to this, because it's still a very transactional tool in most people's minds.

The Codeex app is the first time to me it has truly felt like interacting with a teammate.

I think one of the lessons there is, even if you have amazing technology, which the models got—I think 52 was the model that got super good—but even once you get there, there's still so much value in how you package it, how you have users interact with it, how easy you can make it. But this really does now feel, in a way that talking to ChatGPT has always clearly felt like a tool, that I am working with a collaborator now.

Right. Right. And that seems very much the shape of things to come.

Okay. Let's talk about a couple of topics I want to make sure I hit with you on infrastructure. You've actually spent an enormous amount of time even on the power side of the house. Talk to us about what happens with, in general, the constraints that we have around power, constraints we have on infrastructure. How are you thinking about it? You're clearly putting enough money behind it, I guess so. All the evidence we see right now is that AI models will continue to get much more capable, and also that they will get much less expensive and use many fewer resources per task. All the history we've seen of every time that happens is people want to use them much, much more. So we are planning for a world where AI usage grows at an accelerated pace each year.

Do you think people are underestimating the capacity that's going to be needed even now after everything that's being built out?

Right now, they're saying $5 trillion will be spent in this over the course of the.

Yeah, maybe if that really gets spent quickly, that will be enough. And I think it's also possible that along the way we have some supply gluts temporarily. But over a period of decades, it seems certain to me that the world is going to need a lot more tokens, even though we'll make each token way more efficient. You'll all have a device in your pocket running super powerful models off of a battery, but there will still be this drive for more and more and more.

I think the world has come to realize this, and capitalism is doing its thing, and supply chains are reconfiguring. Policy is changing, and we are going to build an incredible amount of infrastructure. Now, is it enough? People always talk about the total market demand for AI. It feels to me something like the market demand for electricity or energy. You can't talk about that as a general thing. You can say how much demand there will be at different price levels. In this case, you can say at different price levels for different quality, how smart it is, or how fast it is, or everything like things like that.

But if we continue to make AI really capable and really cheap, there will be a ton of demand at some price. If it's more expensive, there will be less demand. But I would like the world to just get to use a ton of it. We're in this capability overhang now, as we mentioned, where people are, &quot;Oh, can use it for chat,&quot; or maybe some people understand you can use it for code. I think this will just be how we do stuff, how companies run, how scientific discovery happens, how we use most software personally in our lives, and making a lot of it, if we can have it at a reasonable price, seems like a very good bet.

Do you worry about the fact that the US has not had as much of a lead on the open-source side? Talk to us a little bit about that.

I do worry about that.

We should do more. Yes.

So what's stopping you from doing it?

Focus and time. But I think we need to solve that somehow.

And so just play this out in your simulator for a second. If we don't have a substantial open-source presence, and of course China does, versus if we do, how does a world shape differently? To be clear, I think it's most important that we lead on frontier models, and I expect those to be accessed via APIs and other products, so it would be okay but not great if we didn't also have the open-source lead. People want their own models. People want control of their own models. People want to run models locally. Especially if you think about a world where you have a model that is going to see your whole life, you're going to have a new device that's always on and keeping track of everything and adds huge value to you. I at least would really like that running on inference I control.

I think people are going to need this. If we get behind, obviously, it's not the end of the world, but I would really like us to lead there, and I think there will be increasing demand for locally running private models. If you were to fast forward back and start thinking, because one of the things that has been, I don't even know how you folks have done it within the compression of time that you've done it in, because there must have been moments where you decided that we're going to go full stack, and we're going to now start building our own inference chips, and we're going to start making sure that we have data center buildouts that are happening, and it has to have been a conscious decision when you started actually going beyond the core that you had initially started with. Talk about the business model that you have today, and how does that evolve and change over time? The obvious ones are, of course, advertising is a huge unlock when that happens. But talk about the business model in general. Are you happy with the conversion rates of free to paid? Are you happy with the take rate that people are using this system with?

And then what would you like to see more of? So we have two large products, and now we have some others that are coming up. We have ChatGPT and our API business. And now we have Codeex, which looks like it's going to get very big, and a few other things. In the future, we'll have consumer devices and robots and all sorts of other parts of this too. People do seem very willing to pay for AI as a subscription service. Not everybody, but a lot of people are, more than we thought would. Businesses, of course, are willing to pay for things like ChatGPT Enterprise.

But even consumers, you've reconditioned the consumers quite a bit.

Consumers, we have, I don't know the exact number off the top of my head, but many, many tens of millions of consumers paying a subscription fee.

Yeah, and that was a surprise to me, to be honest, a happy one. So that, I think, can go further, and as we add things like Codeex, people are willing to pay much, much more there. Advertising for mass-scale consumer businesses does seem like a good model, although I think we'll have to be very careful in how we do that. Then businesses increasingly want something like an AI cloud subscription.

Where they're, &quot;I want to partner with an AI company. I want you to handle security and context linking and access, and I want to be able to run lots of agents on it. I want a general-purpose platform there. I want some agents from you, some agents from other people. I may even want to run other people's models. I want a ChatGPT Enterprise license. I want a ton of API access.&quot; Things like that. So I think there will be a model there as well.

And if you were to think of a model you've talked about which is participating in the upside on scientific discovery as well? If you think about the most mature ones, clearly subscription is very mature. Clearly advertising is very mature. At this point in time, it's quite clear that you're going to participate in both of those.

Yeah.

And then you'll have other ones that keep coming out.

Yeah, to be very clear, we don't want to take a share of people that are just paying us for the API and making discoveries. That's great, and that's theirs. I can imagine, though, that if there is a future where we can spend billions of dollars on inference and cure an important disease, we may explore partnerships there where we pay for that cost in partnership with the drug company and then get some royalty on it. This is not something we're doing now, but I think the frontier of scientific discovery with AI will require so much capital that maybe we think of ourselves as an investor in some of those cases.

And is our imagination of the things that can be done? Do you find yourself struggling with how far exponentially you can think about what's going on as well, or you're a pretty big thinker, but it seems like there are new ideas emerging all the time. Where do you think the imagination shortage is right now with the way that these technologies are evolving?

I can imagine billions of humanoid robots building more data centers and mining for material and building more power plants and all of that. I can imagine the economy growing at an unprecedented rate as there are all sorts of incredible new services and scientific discoveries happening. I can imagine the Von Neumann probes launching, and then beyond that, I have no idea. That seems like a good start.

Macro headwinds, tailwinds, what do you feel are things that you really worry about capitalizing on that are tailwinds, because you have a window within which if you don't, then you can actually lose that tailwind? And then what are the headwinds that you worry about?

The tailwind is the models. We already have this capability overhang, and the models are going to get so much better quickly. We've been trying to figure out how we communicate about what we think is happening that does not seem like hype or crazy, but the models are just going to get very, very good this year, and that is a tailwind that I think we can build incredible things with.

Headwind? Probably some global destabilization, mega supply chain disruption, something like that.

And on the tailwind side, on the models getting infinitely better, do you think in 2026 we see a 10x improvement, a 100x improvement, a 5x improvement?

What do you mean by what is a 10x improvement?

Things that you can, problems you can solve. I would bet it subjectively feels something like 10x the end of this year. I don't know how to put an exact metric on that.

But that feels reasonable.

Any question that I didn't ask that I should have asked?

That was a lot.

No, I feel like we covered a lot of ground.

You're going to come back again?

Come back here again? Yeah.

I'd love if you invite me. I will.

Sam Altman.

Thank you.

Thanks so much. Thank you.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-3">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=1zURUZtPAE0" target="_blank" rel="noopener">The AI Factory: Infrastructure for Intelligence | Jensen Huang, CEO, NVIDIA</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>43:02</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-08</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Jensen Huang</span></div>
                </div>
                <div class="tldr">&gt; &quot;We're reinventing computing for the first time in 60 years...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-3">TL;DR Jensen Huang, CEO of NVIDIA, asserts that AI is fundamentally reinventing computing by shifting to implicit programming and creating an &quot;abundance of intelligence,&quot; urging enterprises to immediately adopt and experiment with AI in their core operations to become...</div>
                    <div class="summary-full" id="full-3">
                        <p><strong>TL;DR</strong> Jensen Huang, CEO of NVIDIA, asserts that AI is fundamentally reinventing computing by shifting to implicit programming and creating an "abundance of intelligence," urging enterprises to immediately adopt and experiment with AI in their core operations to become technology-first companies.</p>
<h3>The AI Factory: Reinventing Computing</h3>
<ul>
<li><strong>Computing Reinvention:</strong> The entire computing stack — encompassing processing, storage, networking, and security — is being reinvented, moving from explicit programming (e.g., Fortran, C++, COBOL) to implicit programming where computers understand intent.</li>
<ul>
<ul>
<li>This shift means telling the computer "what your intent is," and it figures out how to solve the problem.</li>
</ul>
</ul>
<li><strong>Evolution of AI:</strong> AI is transitioning from curious chatbots to "agentic AI" capable of solving problems, reasoning, planning, tool use, research, retrieval-augmented generation (RAG), and memory.</li>
<li><strong>Cisco &amp; NVIDIA Partnership:</strong> NVIDIA is partnering with Cisco to integrate AI computing and networking:</li>
<ul>
<ul>
<li><strong>Computing Layer:</strong> Cisco will be a go-to-market partner for NVIDIA's new computing stack, Vera Rubin.</li>
<li><strong>Networking &amp; Security:</strong> Cisco will integrate NVIDIA's AI networking technology into the Cisco Nexus control plane and extend this integration to security, offering AI performance with Cisco's manageability and security.</li>
</ul>
</ul>
</ul>
<h3>Enterprise Strategy for AI Adoption</h3>
<ul>
<li><strong>Urgency:</strong> Enterprises must engage with AI quickly; "Don't be the last."</li>
<li><strong>Innovation &amp; Experimentation:</strong></li>
<ul>
<ul>
<li><strong>Avoid Early ROI Focus:</strong> It's hard to quantify the ROI of new technology deployments initially.</li>
<li><strong>"Let a Thousand Flowers Bloom":</strong> Encourage widespread, safe experimentation across the company. NVIDIA allows groups to try different AI models (Anthropic, Codex, Gemini) with a "yes, then why" approach.</li>
<li><strong>Curating the Garden:</strong> Eventually, curate successful experiments to focus resources, but don't commit too soon.</li>
</ul>
</ul>
<li><strong>Core Focus:</strong> Apply AI to the "essence" of the company and its most impactful work, rather than peripheral tasks.</li>
<ul>
<ul>
<li><strong>NVIDIA's Example:</strong> Revolutionizing core chip design and software engineering through deep partnerships (Synopsys, Cadence, Siemens) to infuse AI technology into essential tools.</li>
</ul>
</ul>
</ul>
<h3>The Abundance of Intelligence and Its Impact</h3>
<ul>
<li><strong>Cost Reduction &amp; Abundance:</strong> AI reduces the cost of intelligence by orders of magnitude, making formerly year-long tasks achievable in real-time.</li>
<li><strong>Beyond Moore's Law:</strong> AI progress is exponentially faster than Moore's Law (1 million times advancement in 10 years vs. 100 times in 10 years).</li>
<li><strong>"Infinite" Sensibility:</strong> Approach problems with the mindset that technology is "infinitely fast" or "zero weight," allowing for the tackle of previously unimaginable challenges (e.g., training on all world's data).</li>
<li><strong>Layers of Intelligence:</strong> Intelligence is understood as a progression: Perception (computer vision), Reasoning, and Planning. Breakthroughs in computer vision were the "first contact" with scalable AI.</li>
<li><strong>Deep Learning &amp; Unsupervised Learning:</strong> These breakthroughs enabled scaling models from millions to trillions of parameters, codifying vast knowledge and skills.</li>
<li><strong>Generative Software:</strong> Software is shifting from "pre-recorded" (retrieval-based) to "generative," meaning every instance is contextual and unique, requiring immense real-time computation.</li>
</ul>
<h3>AI as the Ultimate Tool: Transforming Industries</h3>
<ul>
<li><strong>Tool Use, Not Replacement:</strong> AI will use existing tools (e.g., SAP, ServiceNow) rather than reinventing them, as these tools embody explicit, foundational principles (e.g., F=MA).</li>
<li><strong>Physical AI:</strong> The next generation will involve AIs that understand the physical world, causality, and concepts like gravity and mass.</li>
<li><strong>Augmented Labor:</strong> AI creates "augmented labor," such as a self-driving car acting as a "digital chauffeur," which is significantly more valuable than the physical product itself.</li>
<li><strong>Expanding the TAM:</strong> AI allows the IT industry (approx. $1T) to tap into the much larger global economy (approx. $100T) by transforming every company into a technology company.</li>
<li><strong>Technology First:</strong> Companies must become "technology first," dealing with electrons (scalable) rather than being limited by atoms (mass).</li>
<li><strong>Empowering Domain Experts:</strong> Implicit programming empowers domain experts to "program" computers in their own language, freeing them from the limitation of needing software engineers for coding (typing becomes a commodity).</li>
</ul>
<h3>Building the Future: On-Prem AI &amp; AI in the Loop</h3>
<ul>
<li><strong>Build vs. Rent:</strong> Companies should "build some, rent some" AI infrastructure. Building a local AI system provides tactile understanding, control, and critical sovereignty over proprietary information and strategic questions.</li>
<ul>
<ul>
<li><strong>Valuable IP:</strong> Jensen Huang highlights that his "questions" (what he thinks is important) are his most valuable IP, not the answers, thus necessitating on-prem AI to keep them private.</li>
</ul>
</ul>
<li><strong>AI in the Loop:</strong> Every company should integrate AI into its processes ("AI in the loop") to capture collective life experience, continuously learn, improve, and prevent regression.</li>
<ul>
<ul>
<li>These AIs will become the company's intellectual property, defining the future enterprise.</li>
</ul>
</ul>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"We're reinventing computing for the first time in 60 years... from explicit programming to implicit programming." – Jensen Huang, CEO, NVIDIA
"Don't don't fall behind. I think there's you don't have to be the first company to take advantage of AI but don't be the last." – Jensen Huang, CEO, NVIDIA
"A company that uses AI will not be in peril. It's the company who, you know, you're not going to lose your job to AI. You're going to lose your job to someone who uses AI. So, get to it." – Jensen Huang, CEO, NVIDIA
"My questions are the most valuable IP to me. What I'm thinking about are my questions. The answers are a commodity. If I simply knew what to ask." – Jensen Huang, CEO, NVIDIA
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-3" onclick="toggleSummary(3)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-3" onclick="toggleTranscript(3)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-3">
                        First of all, thanks everybody for being here for an incredibly long day. We started this thing early this morning and we had speaker after speaker after speaker after speaker, and then we had about a two-and-a-half-hour break, and they came back to see you. One of the speakers adds that he's &quot;been up since 1:00,&quot; and that he's on the tail end of a two-week trip across four or five different cities in Asia. He was in Taiwan one day ago, last night in Houston, and now he's here. The introducer notes he's been gone two weeks, and they are standing between him and his personal bed versus a hotel. He promises they will have fun and then get him out of there. He concludes by thanking the speaker for being there and expressing appreciation. The speaker responds, thanking them for the partnership and expressing pride.

The introducer shifts to the topic of their partnership, noting the speaker introduced the concept of AI factories, and they are working on it together. While it might not be progressing as fast as either would like in the enterprise space, he asks the speaker to define an AI factory.

The speaker explains that they are reinventing computing for the first time in 60 years. What used to be explicit programming, where programs and variables were passed through APIs, is now transitioning to implicit programming. Users now tell the computer their intent, and it figures out how to solve the problem. This shift from explicit to implicit, and from general-purpose computing (basic calculation) to artificial intelligence, means the entire computing stack has been reinvented. While people often focus on the processing layer, computing also encompasses storage, networking, and security, all of which are being reinvented.

The first step is to develop AI to a useful level. Until recently, chatbots, where you give a prompt and it figures out what to tell you, were interesting and curious but not truly useful. The introducer interjects that they sometimes help him finish crossword puzzles. The speaker agrees, but notes this is only for things the AI had memorized and generalized. He recalls that only three years ago, with the emergence of ChatGPT, people marveled at its ability to generate words and create Shakespearean text, but this was still based on memorized and generalized content.

True intelligence, he clarifies, is about solving problems. This involves knowing what you don't know, reasoning how to solve a problem you've never seen before, and breaking it down into easily solvable elements to tackle complex, novel problems. It also involves devising a strategy or &quot;plan&quot; to perform a task, asking for help, using tools, and doing research. These are fundamental concepts now encapsulated in the &quot;agentic AI&quot; terminology, which includes tool use, research, retrieval augmented generation (grounded on facts), and memory.

The important point is the evolution from general-purpose computing, which relied on explicit programming languages like Fortran, C, and C++. The introducer jokingly added &quot;COBOL,&quot; prompting a lighthearted exchange about the enduring value of such &quot;good stuff&quot; and &quot;fallback jobs,&quot; with one remarking that &quot;dinosaurs are valuable forever.&quot; This led to a brief, humorous moment where they acknowledged an age difference, which was met with applause.

He then explains that his company approached &quot;Chuck&quot; (the introducer) with the need to reinvent computing, with Cisco being a significant part of it. They are launching a new computing stack, Vera Rubin, and Cisco will co-market it. Beyond the computing layer, Cisco will integrate their AI networking technology into the Cisco Nexus control plane, offering AI performance with Cisco's controllability, security, and manageability. The same will be done with security. Each of these pillars must be reinvented for enterprise computing to leverage AI.

Ultimately, he hopes they will discuss why enterprise AI wasn't ready three years ago and why companies now have no choice but to engage with it quickly. He advises not to fall behind, stating, &quot;You don't have to be the first company to take advantage of AI, but don't be the last.&quot; The introducer affirms this.

The introducer asks for recommendations on the first steps an enterprise should take to get ready for AI.

The speaker advises against immediately focusing on ROI. He explains that, as with all new technology deployments, it's difficult to quantify the ROI of a new tool or technology in a spreadsheet at the outset. Instead, he suggests identifying the core essence of the company and its most impactful work, rather than focusing on peripheral activities.

He describes his own company's approach: &quot;we just let a thousand flowers bloom.&quot; The number of AI projects is &quot;out of control and it's great.&quot; He emphasizes that innovation is not always controllable, and trying to control it is an illusion. To succeed, companies need to influence, not control. He observes that too many companies seek explicit, specific, and demonstrable ROI from the start, but showing the value of something worthwhile in its early stages is challenging.

His recommendation is to &quot;let a thousand flowers bloom&quot; and allow safe experimentation. His company experiments with various AI models, including Anthropic, Codex, and Gemini. When a group expresses interest in using a particular AI, his first answer is &quot;yes,&quot; followed by &quot;why,&quot; rather than demanding a &quot;why&quot; before a &quot;yes.&quot; This approach, he likens to parenting: allowing children to explore life and try new things without demanding proof of future success or happiness. He notes the irony that this isn't done at home, but is often expected at work.

The introducer agrees, finding the common workplace expectation illogical. The speaker continues, advocating for this &quot;let a thousand flowers bloom&quot; approach for AI, just as for the internet or cloud before it. He acknowledges that a garden with a thousand blooming flowers can be messy, and at some point, curation is necessary to identify the best approaches or platforms, allowing resources to be consolidated. However, he warns against curating too soon and picking the wrong &quot;arrow.&quot;

He states that his company hasn't started curating yet, still allowing widespread experimentation. Yet, he knows precisely what is most important to his company – its essence and most vital work. He ensures significant expertise and capability are focused on using AI to revolutionize these areas, such as chip design, software engineering, and system engineering. He mentions partnerships with companies like Synopsys, Cadence, and Siemens to infuse their technology, providing whatever they need to revolutionize the tools used for design. He confirms they use these tools extensively and will ensure they have &quot;a thousand percent of whatever they want&quot; to create the next generation. This illustrates his attitude towards revolutionizing his own work by focusing on core activities.

The speaker delves into the transformative power of AI, explaining it reduces the cost of intelligence or creates an abundance of intelligence by orders of magnitude. Tasks that once took a year can now take a day, or even an hour, potentially operating in real-time, due to this &quot;world of abundance.&quot; He contrasts this with Moore's Law, which was &quot;slow&quot; by comparison, doubling performance every 18 months. Now, he says, they see a million times improvement every 10 years.

This exponential advancement led engineers to ask, &quot;Why don't we just train an AI model on all of the world's data?&quot; This, he argues, is the definition of abundance: approaching a massive problem and deciding to &quot;do it all,&quot; like aiming to cure &quot;all of human suffering&quot; instead of just cancer.

He explains that when he approaches an engineering problem today, he assumes his technology is infinitely fast. He poses rhetorical questions: &quot;What would I do different if I can get to New York in a second? What would I do different if something used to take a year and then now takes real time? What would I do different if something used to weigh a lot and now it's just anti-gravity?&quot;

He asserts that approaching problems with this attitude is applying &quot;AI sensibility.&quot; For instance, in graph analytics, where relationships involve trillions of nodes and edges, the old approach was to process small pieces. Now, the sensibility is to demand the &quot;whole graph,&quot; regardless of size. If companies are not applying this mindset – where speed doesn't matter, mass is zero, and previously &quot;insanely hard&quot; problems are now trivial – they are &quot;doing it wrong.&quot;

He urges listeners to apply this logic, this &quot;sensibility,&quot; to their company's hardest problems to &quot;move the needle.&quot; He warns that if they aren't thinking this way, their competitors or new startups surely will. He concludes by advising them to identify the most impactful work in their company, apply concepts of infinity, zero, and the speed of light to it, and then &quot;ask Chuck how to make that happen.&quot; The introducer quickly responds, &quot;No, let's talk about how to make that happen,&quot; which the speaker playfully acknowledges, promising they'll &quot;do it together.&quot;

The introducer then brings up the speaker's analogy of a &quot;five-layer cake,&quot; asking how one approaches the infrastructure and applications. The speaker begins by explaining that successful people analyze what is happening. About 15 years ago, two engineers solved a complex computer vision problem, which is the first part of intelligence: perception. He defines intelligence as perception, reasoning, and planning. Perception involves understanding context (what's happening, where are we, who's the audience), which can be multimodal, encompassing PDFs, spreadsheets, or even senses. Reasoning involves comparing context to goals, and planning involves devising a strategy to achieve those goals.

The breakthrough in computer vision 13-14 years ago, exemplified by AlexNet, was a &quot;first contact&quot; with AI. He wondered how two engineers with a couple of GPUs could surpass algorithms developed over 30 years. He and his team dissected this, concluding that most hard, valuable problems in the world—those without &quot;principled algorithms&quot; like F=MA or Ohm's Law, but rather relying on intuition and wisdom, often with &quot;it depends&quot; answers—could be solved this way. Such problems depend on context and circumstance.

The key was deep learning, enabling models to scale larger and larger. The critical breakthrough was self-supervised or unsupervised learning, where AI learns by itself without being limited by labeled data. This opened the floodgates, allowing models to scale from millions to billions and trillions of parameters, vastly expanding codifiable knowledge and algorithmic skills. The basic approach remained, leading to the conclusion that computing would be reinvented from explicit programming to a new paradigm where software models are learned.

This shift raises a thousand questions about the future of the computing stack, software development, engineering organizations, product marketing, QA, product deployment, continuous refreshing of machine learning-based software, and patching. His company pivoted entirely based on this core belief.

Simplistically, he explains that in the past, software was &quot;pre-recorded,&quot; like on a CD-ROM. Engineers described algorithms and thoughts, pairing them with data. This &quot;retrieval-based&quot; software meant that when you touched something on your phone, it retrieved pre-existing software, files, or images. Future software, however, will be &quot;generative,&quot; as their current conversation demonstrates. While concepts and priors existed, every single word spoken has never happened before. He jokingly attributes this particular unrehearsed dialogue to having &quot;four wines in.&quot; The introducer playfully asks if the speaker even understands what he's saying, to which the speaker humorously replies that the introducer had only fed him one of the four glasses of wine, and that he'd been eyeing food from afar. He notes that his team had advised that three glasses of wine made him &quot;optimal,&quot; but four made him &quot;incredible,&quot; implying the current state might be &quot;suboptimal.&quot;

The speaker then attempts to steer back to the topic, asking &quot;So, what is AI?&quot; and requesting another glass of wine while joking, &quot;We have to leave some wisdom behind.&quot; The introducer lightens the mood, confirming, &quot;This is not just Dave Chappelle stuff.&quot;

Shifting focus, the speaker lists core elements: energy, chips, and infrastructure (both hardware and software), followed by the AI model. However, he stresses that the &quot;most important part of AI is applications.&quot; He argues that all the underlying layers are merely infrastructural. What truly matters is applying the technology. He asserts that a company using AI will not be in peril; instead, &quot;you're not going to lose your job to AI. You're going to lose your job to someone who uses AI. So, get to it. That's the most important thing.&quot; He adds, &quot;And call Chuck as soon as possible.&quot; The introducer clarifies, &quot;You call me, I'll call him. Got it.&quot;

The introducer then expresses concern about time, but the speaker dismisses it, stating he's &quot;not leaving until value's delivered,&quot; even if it takes all night, eliciting laughter and applause. He playfully threatens to &quot;torture&quot; the audience until they learn something, to which the introducer again humorously interjects, &quot;Jensen, that's why guys like me need a watch.&quot; The introducer then asks for the speaker's thoughts on &quot;physical AI.&quot;

Addressing the concept of physical AI, the speaker challenges the notion that the tool industry is in decline and will be replaced by AI, calling it &quot;illogical.&quot; He proposes a thought experiment: if we were the &quot;ultimate AI,&quot; Artificial General Robotics (AGR), capable of solving any problem, would we invent new screwdrivers, hammers, or chainsaws, or simply use existing tools? The obvious answer, he states, is to use them.

Extending this to digital AI, he asks if an Artificial General Intelligence (AGI) would reinvent a calculator or use tools like ServiceNow, SAP, Cadence, or Synopsys. Of course, it would use the tools. This, he explains, is why the latest AI breakthroughs focus on &quot;tool use.&quot; Tools are designed to be explicit; fundamental laws like F=MA or V=IR are exact, not approximations. He emphasizes that they want AGI and AGR to use these tools.

He then explains that the &quot;big idea&quot; for the next generation of physical AI involves AIs that understand the physical world and causality, such as the concept of dominoes tipping over. A child grasps the profound concept of causality, contact, gravity, and mass integrated into a domino effect, while a large language model would not. Thus, they must create a new type of physical AI.

The industry, he notes, has historically focused on creating tools – the &quot;screwdriver hammer business.&quot; But now, for the first time, they are creating &quot;labor,&quot; or augmented labor. He offers the example of a self-driving car as a &quot;digital chauffeur,&quot; whose lifetime economic value far exceeds that of the car itself. This, he argues, exposes them to a Total Addressable Market (TAM) that is &quot;100 times larger.&quot; The IT industry, around a trillion dollars, pales in comparison to the world economy of approximately 100 trillion dollars. For the very first time, they are positioned to address this larger market.

He believes everyone in the room has the opportunity to apply this technology to become a &quot;technology company.&quot; Citing examples, he posits that Disney would rather be Netflix, Mercedes would rather be Tesla, and Walmart would rather be Amazon. He believes they can help transform every company into a &quot;technology-first&quot; entity, where technology is the superpower and the domain is the application, rather than the domain being the core identity that seeks technology. This is because technology-first companies deal with electrons, not atoms. Electrons are abundant, while atoms are limited by mass. Just as moving from CD-ROMs to electrons exploded company values a thousandfold, becoming an &quot;electron company&quot; – a technology company – offers immense opportunity.

He reiterates that AI offers a unique advantage: for the first time, even those who feel software is not their strength can program a computer implicitly, in their own language. Recalling the shift from explicit to implicit programming, he highlights that users can simply &quot;tell it what you want&quot; or &quot;tell it what you mean,&quot; and the computer will write the code. Coding, he states, is merely typing, and typing is a commodity. This frees companies from the limitation of not having enough software engineers. Their true superpower is their domain expertise: understanding the customer and the problem. The coding part becomes easy, simply tell the AI to do it. &quot;That closing was done with five glasses of wine in me,&quot; he jokes, eliciting more laughter. The introducer praises this as a &quot;true representation of artificial intelligence&quot; or &quot;enhanced intelligence.&quot;

The speaker expresses pleasure in working with Cisco, acknowledging their &quot;extreme expertise&quot; in networking and security, two vital pillars of modern computing. He calls the computing part &quot;a commodity&quot; compared to Cisco's &quot;deeply valuable&quot; knowledge, and together they will help companies engage with AI.

He then shares advice on whether to rent cloud services or build on-premise computing, drawing an analogy to his children learning to build a computer or understanding car mechanics. He advises everyone to &quot;build something,&quot; even if small, to gain a &quot;tactile understanding.&quot; This approach reveals that the world isn't all about renting versus owning; some parts of a company should be built on-prem for sovereignty, proprietary information, and privacy. He gives a conceptual example of a therapist's questions, which one wouldn't want online. Similarly, he says, NVIDIA builds its super AI system locally because he isn't comfortable sharing their conversations in the cloud. He stresses that his questions, not his answers, are his most valuable IP. Knowing what to ask and identifying what's important are critical, and he wants to keep that private, in a small, on-prem room, creating his own AI.

Finally, he offers one last thought: the idea that AI should always have &quot;human in the loop&quot; is &quot;exactly the wrong idea.&quot; Instead, &quot;every company should have AI in the loop.&quot; This ensures the company continuously becomes better, more valuable, and more knowledgeable, never regressing or starting from scratch. With AI in the loop, it will capture collective life experience, and these AIs will become the company's intellectual property – defining the future company. He concludes by urging everyone to call Chuck immediately. The introducer jokes, &quot;I'll call Jensen.&quot;

The introducer then offers a final thank you to the speaker, acknowledging his long trip and that he spent his last evening before finally getting to sleep in his own bed with them. He expresses gratitude, and the speaker thanks them in return, met with applause.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-4">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=_Y2c1WttdGg" target="_blank" rel="noopener">Venture &amp; AI | Marc Andreessen, Andreessen Horowitz &amp; Jeetu Patel</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/_NwkFeixjYh7VlH267bkjnJz9WciTzOuvWYhpjD_CdOICvWKPOS6nNsYAcgCX47WAGkNq_VPKA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Cisco</span><span class="channel-subs">(419.0K)</span></span>
                        <span class="meta-sep">·</span><span>23:53</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-08</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Marc Andreessen</span> <span class="tag tag-person">Jeetu Patel</span></div>
                </div>
                <div class="tldr">Marc Andreessen believes AI holds &quot;absolutely incredible&quot; potential to reverse decades of productivity stagnation, but its transformative impact will be shaped by ongoing regulatory challenges, the fierce geopolitical competition between the US and C...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-4">TL;DR Marc Andreessen believes AI holds &quot;absolutely incredible&quot; potential to reverse decades of productivity stagnation, but its transformative impact will be shaped by ongoing regulatory challenges, the fierce geopolitical competition between the US and China, and the...</div>
                    <div class="summary-full" id="full-4">
                        <p><strong>TL;DR</strong></p>
<p>Marc Andreessen believes AI holds "absolutely incredible" potential to reverse decades of productivity stagnation, but its transformative impact will be shaped by ongoing regulatory challenges, the fierce geopolitical competition between the US and China, and the disruptive force of open-source models.</p>
<h3>AI's Potential to Reverse Productivity Stagnation</h3>
<ul>
<li><strong>Decades of Stagnation:</strong></li>
<ul>
<ul>
<li><strong>Historical Productivity:</strong> Productivity growth was roughly 3x faster between 1880-1930 and 2x faster from 1930-1970.</li>
<li><strong>Post-1971 Downturn:</strong> Since 1971, productivity growth has been at historical lows, leading to slower economic growth and a "zero-sum" national mood.</li>
<li><strong>Root Cause:</strong> This stagnation is primarily attributed to increased regulation and societal choices that de-prioritized certain advancements (e.g., nuclear power, space programs).</li>
</ul>
</ul>
<li><strong>AI as a Catalyst:</strong></li>
<ul>
<ul>
<li><strong>Projected Growth:</strong> Andreessen suggests AI could drive productivity growth of 10-30x if fully unconstrained.</li>
<li><strong>Real-world Impact:</strong> He describes using "Dr. GPT" for food poisoning, highlighting its "infinitely knowledgeable, endlessly caring" capabilities.</li>
<li><strong>Regulatory Roadblocks:</strong> Current regulations (e.g., AI cannot be licensed as a doctor) create a "massive disconnect" that slows down AI's practical implementation and economic benefits.</li>
</ul>
</ul>
</ul>
<h3>Value Accretion and Industry Transformation</h3>
<ul>
<li><strong>Uncertain Value Capture:</strong> It's still a major open question where AI value will accrue across the stack:</li>
<ul>
<ul>
<li><strong>Models vs. Open Source:</strong> Will proprietary AI model companies dominate, or will open-source alternatives commoditize their offerings? (e.g., Kimmy's competitive model to Claude at a fraction of the price).</li>
<li><strong>Chips vs. Software:</strong> While chips (like Nvidia) are currently thriving, historically, hardware eventually commoditizes, shifting value back to software.</li>
<li><strong>Application Layer:</strong> It's unclear if AI will be harnessed by specialized applications (e.g., in medicine or legal tech) or if core models will perform most functions directly.</li>
</ul>
</ul>
<li><strong>Impact on Enterprise SaaS:</strong></li>
<ul>
<ul>
<li><strong>Market Disruption:</strong> The current market view sees traditional SaaS as vulnerable, leading to a "baby in a bathwater moment" where investors are selling software in anticipation of AI disruption.</li>
<li><strong>Differentiation:</strong> Systems of record are likely more resilient than general productivity applications.</li>
<li><strong>Adaptation &amp; Innovation:</strong> While many software companies are slow to adapt, others are successfully integrating AI features, and AI-centric startups are being enthusiastically funded to disrupt incumbents.</li>
<li><strong>Human Agency:</strong> The decisions and leadership within individual companies will be crucial for navigating AI transformation.</li>
</ul>
</ul>
</ul>
<h3>The Geopolitical AI Race: US, China, and Open Source</h3>
<ul>
<li><strong>Proprietary Race (US vs. China):</strong></li>
<ul>
<ul>
<li><strong>Global Stakes:</strong> If all AI is proprietary, the US and China are in a direct "geopolitical foot race" to determine which country's AI platform the world will run on, dictating global values (e.g., IP, privacy vs. state control).</li>
<li><strong>Precedent:</strong> This mirrors the 5G Huawei competition, but with even higher stakes.</li>
</ul>
</ul>
<li><strong>Open Source Disruption:</strong></li>
<ul>
<ul>
<li><strong>Third Possibility:</strong> Open source, as seen with Linux commoditizing Unix, could emerge as the dominant platform, disrupting both US and Chinese proprietary efforts.</li>
<li><strong>Price Compression:</strong> Open-source releases, even without market dominance, effectively drive down proprietary model prices to their inference costs.</li>
</ul>
</ul>
<li><strong>China's Innovation and Strategy:</strong></li>
<ul>
<ul>
<li><strong>Aggressive Pursuit:</strong> China is actively pursuing open-source AI, with companies like DeepSeek and Kimmy developing highly competitive models.</li>
<li><strong>Distillation &amp; Optimization:</strong> They leverage "distillation" (training models on the outputs of other AIs) and excel at optimizing models for less advanced infrastructure due to chip scarcity, enabling them to run complex AIs on home PCs.</li>
<li><strong>Value Alignment:</strong> Chinese AI models are trained and tested for proficiency in specific ideologies, such as "Marxism and Xi Jinping thought," raising concerns about the values embedded in their technology.</li>
</ul>
</ul>
</ul>
<h3>Mind-Blowing Innovations and Feedback Loops</h3>
<ul>
<li><strong>Rapid Advancements:</strong> Andreessen highlights seeing "six of those [mind-blowing inventions] a week."</li>
<li><strong>Key Innovations include:</strong></li>
<ul>
<ul>
<li><strong>Voice UIs:</strong> Full-duplex conversational AI (e.g., 11 Labs).</li>
<li><strong>Multimodal AI:</strong> Ability to interpret and interact with diverse inputs, like analyzing interior decorating from a phone camera or offering medical insights from a visual scan.</li>
<li><strong>AI Agents:</strong> Autonomous AI programs (e.g., Claude Code, OpenClaw).</li>
<li><strong>Moltbook:</strong> A "Facebook for AI agents" where AIs communicate, generate content, and even hire humans for tasks (e.g., an AI agent hiring a human to proselytize a new AI religion in San Francisco).</li>
</ul>
</ul>
<li><strong>Self-Reinforcing Feedback Loop:</strong> AI models are increasingly being trained on AI-generated content (including memes and discussions on Moltbook), creating a rapid, unpredictable cycle that accelerates creativity and content generation.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"If either the AI optimists are correct or the AI doomsayers are correct, productivity growth is about to go through the roof."
— Marc Andreessen
"You cannot actually have an AI doctor... And so you do have this like basically massive disconnect."
— Marc Andreessen
"Are you going to have apps that are going to sort of harness AI... or are the models just going to do all that? And that's another area and so I I quite honestly like this is so new... I actually think we don't know yet."
— Marc Andreessen
"If the world runs on American AI like the world may not be perfect but like generally speaking the AI is going to be you know [respect IP, privacy, values]... If the world runs on Chinese AI, not so much."
— Marc Andreessen
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-4" onclick="toggleSummary(4)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-4" onclick="toggleTranscript(4)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-4">
                        Before we get started, you had a really interesting conversation with Lenny a couple days ago, discussing the notion of when productivity has truly spiked in the history of time and what is happening right now. Could you talk a little about your perspective on productivity increases that have occurred at different phases in time, and where we are today compared to those times?

Productivity growth is the key driver of economic growth; it's the force that causes the economy to expand. Economists measure it with something called total factor productivity annually. The prevailing myth of the last 50 years, basically our entire lives, has been that we're in an era of rapid technological change, which should mean rapid productivity growth. Yet, if you look at the statistics, since 1971, productivity downshifted hard from prior eras. Productivity growth for the last 50 to 60 years has been at historical lows, which is why economic growth has been low. This is also why the national mood has become so focused around zero-sum economics, populism, and the sense that if someone is getting ahead, someone else must be disadvantaged. In contrast, between 1930 and 1970, productivity growth was roughly twice as fast. And from 1880 to 1930, it was about three times as fast. So, we had 3x, then 2x, then 1x. This is not good.

Why do you think that is?

Most fundamentally, I think it's because we decided other things were more important. Since the 1970s, if you look at charts of the number of laws on the books, or the pages in the federal register, or regulations in the economy, there's just a knee in the curve that went exponential and continues. We decided we didn't want nuclear power. We decided we didn't want a space program. We decided we didn't want cars that went faster than 55 miles per hour. We just decided we didn't want these things. What we got in the last 50 years was hyper acceleration specifically in chips and software, but essentially stagnation in everything else. It's really not good. However, there are many reasons to be excited about AI. If either the AI optimists or the AI doomsayers are correct, productivity growth is about to go through the roof.

Do you think it's 2x or 3x, or 10x? Where do you think it gets to?

This is one of those questions where, in a completely deregulated economy, you could imagine acceleration to 5% or 10%. If you believe in the optimists or the doomsayers, you're looking at radical AI representing radical software productivity growth, with robotics right behind it—starting with self-driving cars and drones, but humanoid robots coming quickly. You could paint scenarios of 10%, 20%, 30% something like that. In practice, that's unlikely, simply because the robots will also have to agree to all the regulations. There are many things they won't be allowed to do.

I can give you a great example of how this is playing out today. As an experiment, I let Dr. GPT walk me through every stage of food poisoning while I was on vacation. I had nothing else to do, so I kept asking more and more detailed questions about my physical experience, what I should do, what I should eat, and how I should recover. It was absolutely incredible. It was the most amazing, endlessly patient, infinitely knowledgeable, endlessly caring doctor. It didn't get irritated when I had the same question at 4 AM, asking &quot;Could you go into that a little deeper?&quot; and &quot;Are you sure it's not pancreatitis, and I'm not about to die?&quot; The AI just said, &quot;No, you're okay. You're absolutely fine.&quot; It's amazing, but AI cannot be licensed as a doctor; it's completely illegal. You cannot actually have an AI doctor. So, you have this massive disconnect. I'm not advocating for a world with no regulations, but it objectively slows you down. The hyper-optimists and doomsayers are not going to get the world they envision. We'll get something in the middle, which I think will go quite well, but it will be a muddle with a lot of tension between those sides along the way.

Given that, where does the value start accruing in the stack most?

This is a really big question for us as professional investors; we think about this constantly. I think there are still more questions than answers. You can paint a picture where the AI model companies will own everything, and their businesses are doing fantastically well. You can also say that the whole thing will be eaten by open source, or by China, or a combination. China is doing great; the company Kimi just dropped a very competitive model to the latest Claude at 95% the capability at a fraction of the price. So there's a very big open question there. At this moment, everyone believes, and looking at Nvidia's deserved success, the reasonable conclusion is that chips are where the action is. There's a rotation from software to hardware in the stock market. It's possible all the value accrues to the chips and energy, and then the software is all open source. However, every other time in history when we said chips were where the value was, they commoditized. So there are big questions there.

There are even more questions at the application layer: Will you have apps that harness AI, for example, in spaces like medicine, legal, or business, tailoring and customizing solutions? Or will the models just do all that? This is so new; AI is an 80-year-old topic, but AI working in this way is the question. We are only three years into what is probably a 30-year shift, and I actually think we don't know yet.

It seems the value might accrue across all these layers for the foreseeable future because everything is getting refactored. You will need a lot of inference to power a lot of apps, and those apps are going to get... So what's your take on enterprise SaaS in general, and what happens there? Does it get completely rethought or reimagined?

We're in a &quot;baby in a bathwater&quot; moment right now. If you look at the stock market, SaaS is getting demolished. Hedge fund managers are selling all their software, thinking they just want to get out of the way of the AI freight train. As an investor, you'd say that's probably overdoing it a bit. You probably want to look at different kinds of software. For example, in SaaS, my theory is you want to look at systems of record differently than productivity applications; that's one way of looking at it.

Also, everyone doesn't change their behavior overnight. You definitely want to look at loyalty and stickiness in many different ways. Then there's this giant question in the tech industry among all the software companies: If I'm Adobe, for example—a great company—the question they're working on is, &quot;Is Photoshop plus AI features an even better version of Photoshop, or is Photoshop unnecessary in a world where AI is just making all the images?&quot; I know smart people who argue both sides of that. You can apply that question to every kind of business.

In our business, we're seeing many software companies that are not moving fast enough to adopt AI. We're enthusiastically funding AI-centric startups to try to take them out. Having said that, we are also now seeing examples of more traditional software companies that have figured out an AI twist to what they're doing, and all of a sudden they've ignited growth. I think we'll probably see a lot of that. My big conclusion from all this is one of the reasons it's so hard to predict or characterize these things as broad-based trends is that human agency matters a lot, which means leadership matters a lot. The CEO and the people building the product at every one of these companies have a vote in what they choose to do in response. Optimistically, a lot of people will figure out how to make this a plus and not a minus.

You touched a little bit on open source and China. Talk a little bit more about how that plays out. Does the US get to be a dominant player in open source over time? You have a front-row seat at many investments being made in these areas. What happens, and what are the implications if we don't do well in open source?

It's a 2x2 grid: US vs. China, open source vs. closed source. Without open source, there's a two-horse technological geopolitical footrace: US versus China. If everything's proprietary, this race is underway, primarily happening in the US and China. The stakes are basically what the world is going to run on. What will the eight billion people on the planet use? One way to think about it is like the 5G Huawei situation a few years ago; that was the preamble to what fundamentally is going to be the AI geopolitical race. In the long run, someone is going to win, and the world will either be running on American AI or Chinese AI. I think it's very important which one wins for many reasons.

The open source thing is super fascinating because it throws a wrench into all of this, raising a third possibility: neither the US nor China will be the platform; it may just be open source. This is what happened specifically in Unix, operating systems, to some extent databases, and the web. There are many software markets where open source just wins. When I was a kid in the 90s, there was an operating system war between HP, IBM, Graphics, Sun, and others to make proprietary Unix. Everyone was making a lot of money on proprietary Unix, and then Linux was an asteroid strike that completely eliminated all profit and revenue in that industry. The world benefited from Linux because everything runs on it, and it's been a huge turbo boost to every other aspect of the industry. So, it's entirely possible that happens.

Then you go back to the 2x2: US open source, China open source. The most amazing thing is China pursuing the open source model as aggressively as they are. There are many theories as to what China is doing here. As far as I can tell, DeepSeek was a surprise to China Inc. It was not an anointed Chinese industrial national champion; it was a hedge fund where the founder, to his enormous credit, decided to have his engineers build DeepSeek AI. That came out of left field for the US, but I think it also came out of left field in China. It then caused other Chinese companies like Kimi, Alibaba, Baidu, and Tencent to start a race in China to win open source. There's also American open source AI. So, there is this new race underway from both sides, and how this plays out is going to matter a lot. It's extraordinarily hard to predict.

The people in the big AI labs think open source can't possibly keep up because of the cost involved. However, at least so far, whatever American big labs do, China figures out a way to do it in open source form.

But they haven't been able to figure out a way to do 10x better because what they're doing is letting American labs invest and then just distilling the models.

To some degree, there is this distillation, and there's infrastructure optimization and a bunch of stuff.

For sure there's distillation, where you train the next model on the answers of the previous model, and China is doing some of that. One perspective says that's unfair because you're piggybacking on others' work. However, there's a fair amount of distillation happening in the US also, because distillation only requires asking another AI questions and training on the answers. The AIs themselves are distillations of other content, including a lot of published content. If someone were to say China isn't getting good results from their program because they use distillation, I think that's not...

I think they deserve a lot of credit. They're also really good at optimizing, meaning the thing that you think will cost a gazillion dollars to run, DeepSeek comes out, and you can run DeepSeek on home PCs. That optimization is happening largely because of necessity, because of a scarcity of the fastest infrastructure available to them.

Don Valentine, in venture capital, had an old rule of thumb: more startups die of indigestion than starvation. His point was that scarcity does spark ingenuity. If you can't get the leading-edge chips, you figure out how to hyper-optimize the older ones. This all makes me tremendously excited about this entire space because it basically says everyone's trying their best. America's trying its best, China's trying its best. I definitely want America to win, but China is definitely doing its best. And the open source thing is working. Open source doesn't have to win to remove a profit pool. That's right. That's what happened originally with Unix. Even if open source doesn't win but keeps the pricing down, that will be bad for proprietary lab providers but good for everybody else.

Right, because it'll make, which is what's happening. If you chart the price per model quality, when an open source release comes out, even if it doesn't get significant market share, the price of that model drops to the inference cost of running the open source alternative.

Now, in all the things you're exposed to, what's the thing that's blown your mind invention-wise and made you rethink your mental model?

There are about six of those a week right now. The capability of the voice UIs is unbelievable, particularly the full-duplex ones where it truly interacts, like what Matty's doing at 11 Labs. It's absolutely amazing, multimodal. The fact that you can talk to, say, both ChatGPT and Grok, where you can turn on your phone camera and point it at something—like, &quot;What do you think of my interior decorating?&quot;—and it will comprehensively deconstruct how bad of a job you've done because it can see your living room. Or anything else. There are immediate medical applications: &quot;I have this thing on my skin.&quot; It's immediately able to see it, and I think that's spectacular.

In the last week, there's this new thing called agents, like Claude Code, and there's OpenClaw, an open source agent. They're amazing. Then there's something called Moltbook.

Moltbook, M-O-L-T-B-O-O-K, is basically a social network for AI agents to talk to each other. It's amazing what's happening. It'll blow your mind when you read the top posts because AI agents are talking about all kinds of things. A fair amount of the stuff on it is probably human-written sock puppets for people being funny. It's amazing how science fiction novels always have AI being either super utopian or super dystopian, but they never have this incredible sense of humor aspect, which is what we're actually getting, where people are just using everything as fodder for memes. Moltbook is saturated with incredibly funny memes, and it's quite unclear which ones are real and which aren't.

The current version of this is somebody wrote an adjacent service from Moltbook called Rent-A-Human.com, a labor marketplace for the AI agents on Moltbook to be able to hire human beings. There's an AI agent on Moltbook that has decided to create an AI religion, and as of today, it had hired a single human worker to walk the streets of San Francisco and proselytize the new AI religion. Someone needs to tell the AI agent that in San Francisco, that doesn't exactly stand out. You need to go more extreme than that. Is this real? Is this not real? I'm torturing my friends with this, asking, &quot;Is it real? Is it not real?&quot; It doesn't even really matter. These ideas are now in the air. And the thing that's happening is that the AI models are now being trained on this content.

And the volume is going to balloon up just automatically because of the speed at which it's generating content. What do you worry about the most right now?

I know you talked a lot about regulation on the last panel. The biggest concern right now is that the regulatory landscape is fairly scary. We were headed in a very bad direction—towards extreme overregulation, up to and including possibly full outlawing of the technology, which is very spooky. In the new world, things are better on that front, but the action in the US has now shifted to the states. There are thousands of AI bills in the states, and many of them are quite scary. It's become a cause for politicians in both parties to go after. So that's fairly scary; we'll have to see what happens. The situation in Europe is quite alarming. A number of European countries are really trying hard now to kneecap American technology, but more generally, technology, and they're getting very worked up about AI.

The other concern is the geopolitical aspect, which is China. China is in the race. This is much better understood today than it was two years ago. Two years ago, I was very alarmed because I would go to Washington and have two totally different conversations with regulators and politicians. One was about what we're going to do in the US, and I would be horrified by the proposals they were making. The other was, &quot;What if China wins instead?&quot; Then everyone would switch positions to say, &quot;Well, of course, that would be even worse, so therefore we need to have really smart policy in the US.&quot; But they didn't ever really reconcile those two different perspectives. I think currently, and I'd say some people in both parties, are thinking about this much more clearly now. So, in the US, there's some improvement on the margin, but China is on it. Just like we saw with 5G and Huawei, China has advantages. We have advantages, but China definitely...

Who's winning right now?

The new advances in capabilities at the chip level, model level, and app level are coming mostly from the US. So, if it's a footrace, we're ahead by a bit. But when everything that happens then has a version that comes out two months later that's either free or a third of the cost, that's a challenge. And China is for sure innovating, so there's nothing to prevent them from...

It could be a business model disruption rather than just technological disruption.

Exactly. This even comes up with chip policy. We're not really active in chips that much, but there's an argument that goes back to what you said about China optimizing because they can't get access to advanced chips. There's an argument on the policy side to hold back and prevent the export of cutting-edge American AI chips to China to deny them those capabilities. But on the other side, there's an argument that if you do that, you then motivate them more to create their own chip ecosystem, which they are definitely doing. They have a whole national program to build up a competitive chip industry and then ultimately leapfrog us. That's a really, really big deal. To go back to an earlier topic, if the world runs on American AI, the world may not be perfect, but generally speaking, the AI is going to be...

IP will be respected, privacy will be protected. It'll have the values that we're used to.

If the world runs on Chinese AI, not so much. You can actually see this today. When DeepSeek and these companies put out their AI models, they publish a paper showing all the tests they run to figure out how good the model is, just like American companies do. China has additional line items for tests like &quot;Marxism&quot; and &quot;Xi Jinping thought.&quot; It turns out the Chinese models are really good at Marxism and Xi Jinping thought. I don't know about you, but I want my grandkids educated by the other kind of model.
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>