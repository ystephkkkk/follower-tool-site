<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - February 12, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
            scroll-margin-top: 1rem;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-header-link {
            display: block;
            padding: 1.25rem 1.5rem 0.75rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header-link:hover .day-date {
            color: var(--accent);
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
            transition: color 0.15s ease;
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.3rem;
            padding: 0.6rem 0;
            border-bottom: 1px solid var(--border);
            text-decoration: none;
            color: inherit;
            border-radius: 4px;
            transition: background 0.12s ease;
        }

        .day-preview-item:hover {
            background: var(--bg-tertiary);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-title {
            font-size: 0.88rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.35;
        }

        .preview-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            background: var(--bg-tertiary);
            padding: 0.15rem 0.5rem 0.15rem 0.25rem;
            border-radius: 14px;
        }

        .preview-channel-icon {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-channel-name {
            font-weight: 500;
            color: var(--text-secondary);
            font-size: 0.72rem;
        }

        .preview-channel-subs {
            color: var(--text-tertiary);
            font-size: 0.68rem;
        }

        .preview-details {
            font-size: 0.72rem;
            color: var(--text-tertiary);
        }

        .preview-tags {
            display: inline-flex;
            gap: 0.3rem;
        }

        .tag-sm {
            padding: 0.1rem 0.45rem;
            font-size: 0.65rem;
        }

        .preview-tldr {
            font-size: 0.78rem;
            color: var(--text-tertiary);
            line-height: 1.45;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">February 12, 2026</p>
            <div class="stats">
                <span><span class="stat-value">8</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card" id="video-0">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=oUSWtLu2RCE" target="_blank" rel="noopener">Ben Thompson from Stratechery on AI ads, the end of SaaS, and the future of media</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/kUa_ydk-cYKrVa3F2Xbrs54qzmIXl6ZCuSgrJR6lIMWj-VqZLtycN7M4DvxyeewPY3ldF3vL=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Stripe</span><span class="channel-subs">(87.2K)</span></span>
                        <span class="meta-sep">·</span><span>90:25</span>
                        <span class="meta-sep">·</span><span>12.5K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Ben Thompson</span> <span class="tag tag-person">John Collison</span></div>
                </div>
                <div class="tldr">Error generating summary: 429 RESOURCE_EXHAUSTED.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">Error generating summary: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your...</div>
                    <div class="summary-full" id="full-0">
                        <p>Error generating summary: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_paid_tier_input_token_count, limit: 1000000, model: gemini-3-flash\nPlease retry in 18.138523302s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_paid_tier_input_token_count', 'quotaId': 'GenerateContentPaidTierInputTokensPerModelPerMinute', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '1000000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '18s'}]}}</p>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        Ben Thompson is the founder and author of Stratechery, the newsletter that everyone in tech reads to make sense of what's happening. He was also early to the premium newsletter model that's become very popular in media nowadays. For many years, he ran Stratechery as a solo founder in Taiwan. Cheers, good to see you. Cheers. It feels like people in San Francisco have not properly discovered Taiwan as a tourist destination. Like, do you agree with that characterization? And what's your recommendation? Oh, it's funny because people always ask me about Asia. And the way I always characterize Taiwan is there's lots of great places to visit in Asia, and I would also put Japan on the list. But I like to think I went to Japan before it was cool. Yeah, nothing against Japan. It's just... Well, the whole thing with Japan is going to Japan pre-smartphone was a completely different experience than going there post-smartphone. Like, you think, &quot;Oh, the subway system's amazing, the trains.&quot; Try navigating that with no smartphone and nothing's in English. Like, Japan used to be very low on English. It's still lower than places like Taiwan. It's surprisingly low. Yeah. And Japan just has the... the way to visit Japan is you just walk. Like, don't go to like set destinations. Whereas... but the way I would talk about this is places to visit, but the best place to live is undoubtedly Taiwan. The one word everyone says for Taiwan sounds not that impressive, but the word is convenient. Like, it is the most convenient place to live. 7-Eleven has really good food. Well, it's actually downstream from the Japanese. Because Taiwan was a Japanese colony for the first 50 years of the 20th century. And it's laid out a lot like... why is it great to walk in Tokyo? Because Tokyo is all mixed-use, right? That's how Taipei is as well. You have these big blocks where the exterior will be commercial and the interior of these big blocks is all residential and the first floor is all like small shops or restaurants, things like that. So wherever you live, you basically have access to everything all around you. But the... I think the downside as a tourist is it's kind of an ugly city. Like, Taiwan's kind of notorious for just these dumpy dilapidated buildings and then you go inside and they're like palatial on the inside. Like Taiwan... Taipei is very, very rich. Like it has... it's in the top 10 I think as far as number of billionaires in the world or something like that. All downstream from building out China, things like that. It's a very beautiful country from Taipei. 30 minutes to the ocean, 30 minutes to the mountains. East coast is amazing. But if people listening to this are visiting, I feel like one thing they should do is... it's a mistake to try and use Yelp or anything like that too much because like, you should maybe just try and go to a night market and follow your belly and see what looks good. And there's like a lot of excellent street food. And so that would be one thing is to don't try to over-plan. Well, here's the problem though where tech has made it worse, I would argue, as a tourist. Which is... Taiwan is arguably the greatest Uber Eats market ever. Because there's just amazing options. It's all delivered by scooter so it's always like 10 minutes to get dinner and things along those lines. I think you were going to ask me about difficulties moving to the States. Not having access to that is definitely one of them. But the problem is that it's such a huge market now that I think there are fewer and fewer restaurants. In that a lot of these places actually just straight up closed their storefronts or just ghost kitchens basically, and all they do is just make Uber Eats orders all day. I see. So I mean, famously, yeah, the restaurant economy in places like Taipei would have been really good, but it's gotten worse because people are eating in more with Uber Eats and stuff like that. I think so. I think so. As far as the like walking around and just stuff on the... no, there's still plenty of places. It's still great. But there are like... there's a number of restaurants that I used to always take people to. Like holes in the wall that I knew were super good beef noodles or something. And I remember a couple of times, like, &quot;Oh, they... you can't actually go eat there anymore, but they're still on Uber Eats.&quot; That's a bummer. It's like a separate problem than the San Francisco problem at restaurants is that nobody drinks anymore and so the restaurants can't, you know... they've lost their major profit... It's so bad you had to get a pub in your own office. Exactly. We're trying just first-hand to fix it. Be the change you want to see in the world. Should people visit places beyond Taipei, or where should they go? Oh, for sure. Yeah. I mean, Taipei is great. It's great to walk around. Taipei 101, which is obviously very much in the news these days with the scaling... But you can go up the elevator... You go up there because there's a massive ball at the top. The mass damper, yeah. Yes, which is amazing. It's like... if you're into like engineering, that's actually a very underrated thing. National Palace Museum is amazing. But the whole... the East Coast in particular is incredible. You drive... there is a train, but the driving... you can drive like... you're driving on the coast like... It's like a lost coast of Hawaii kind of thing. Exactly. The problem... there's an incredible gorge called Taroko Gorge that was really, yeah, messed up by an earthquake a couple of years ago. So I don't know if it's even reopened yet. But I used to take people to that all the time because it's world-class. Yeah, yeah. It is impressive that they said, &quot;We're going to build the tallest skyscraper in the world in like a very frequent earthquake region.&quot; Yeah. It's been a great skyscraper. It's worked out well for the Netflix. So, you've talked a lot over the years about aggregation theory and really popularized this idea where pre-internet, often power would live with the supply, whereas on the internet, because of the different, you know, marginal cost dynamics and things like that, power will rest with the demand aggregators. And so Booking.com is a much bigger company than any hotel chain, you know, things like that. And Booking.com is the particularly interesting one because they aggregate all the hotels, but they are also aggregated by Google. So they're like Google's biggest customer even as they're also on the other side. I feel like Booking.com is a very underappreciated success story in tech. You know, they're a European company, kind of much quieter in a lot of ways. But like, if you invested a dollar in Booking.com and a dollar in Google 20 years ago, you made much more money as a Booking.com shareholder. And I think people don't appreciate that fact. It's a very well-run business. But where I was going with this is how does aggregation theory apply to AI? How does one need to update the framework? TBD to a certain extent. I mean, this is part of the huge, probably one of the most angst-y debates that I have internally generally, which is OpenAI's sort of welfare going forward. I put forward a few years ago that actually OpenAI could stop making models and be one of the most valuable companies in the world just because of ChatGPT. That's their most valuable asset. And part of the problem issue that they have is that was definitely the case in 2023, 2024. But they never... you have to actually build the business model around that. And I've, you know, I think fairly famously, at least based on all the tweets that I got when they announced that they were going to launch ads, have been losing my mind about this fact for a long time. And I think this is interesting. I'd actually be curious your view of this. Which is... there's this mindset in the Valley of this skepticism of advertising. And people have sort of like internalized that it's bad and evil. Do you sense that? Do you feel that? I agree there's kind of a knee-jerk skepticism of ads. And like, look, you know, I'm a YouTube Premium subscriber. When I see someone watch a video without premium, I'm aghast. Yeah, it's like, &quot;What are you doing with your life?&quot; And so like, I get the knee-jerk reaction. And at some level, as kind of the anti-advertising company, we're the opposite form of monetization. But I don't know, I've no particular issue. I think it's a very efficient form of monetization. It makes a lot of sense for certain products. And so I think it's just different strokes for different folks. Yeah, I think... you're on the skepticism side. I think ads are amazing. And, you know, I talk in my book a little bit, Stratechery has gotten tremendous traction just by not hating ads, even though I'm not an ad model myself. Exactly. But you're a paid model. Well, it's actually... it's funny. I actually think I got a lot of traction over the years by talking about ads when no one else was despite it's the most important business model in tech. And I look back and all my early writing about ads was terrible. I had no idea what I was... but just by virtue of talking about it, it was helpful. The reality of advertising is, number one, people... if you're making a product in the world, like Stratechery is very fortunate. Like, it is definitely a new model or a new internet-native model in that I have subscribers in like 200 countries, right? Like, I am literally the whole world is my market. And Stripe obviously helps make that possible. You've a few in the Vatican, you know, they're following along with... I could go check. I would put the odds very high that I do have at least one subscriber in the Vatican. And but where I benefited from is I was a massive beneficiary of social media, particularly Twitter. And that back in the early days, good days of Twitter, whatever it was, there was currency in sharing smart links. And so if I was a regular provider of links that people thought made them smart, so they would share them and talk about them and be sort of back and forth. And so that solved my customer acquisition issue. The reality though is most... and because the other thing about content, actually this is a point I'm interested to come back to, is it's something to talk about. It's something that's commonality between us that we can both read the same thing, we can both have opinions on it, sort of react to it. The sort of product that I buy on Instagram is not what I'm going to like post about it or talk about it, but it can be tremendously beneficial. And they in theory have... these small businesses or whatever they might be or trying to get suppliers or whatever, they have the same opportunity, which is to sell to everyone in the world. They just need a way to tell people about it. As someone who buys way too many products off of Instagram... and by the way, one of the great things about moving back to the US is the Instagram ads are unbelievable. Like, I thought they were pretty good in Taiwan, they're so much better in the US. Like, oh, this is the best part of living in the richest country in the world. It's the NBA of advertising. It's amazing. Like, I'm like, &quot;What's this native content? Give me more ads.&quot; Which, by the way, Facebook is very happy to do over the last six months. Lots of ads these days. But I get stuff that I never would have thought of, I didn't even know about, and it's great. It's amazing and it's a real benefit to me as a consumer who subscribes to YouTube Premium and looks down on people who don't, but finding things that I didn't know about that make my life better. So as a user, I'm benefiting. As a rich user, I'm benefiting. As the world is six billion people, most of whom do not have disposable income that I have, much less you have, much less anyone else in San Francisco has, they get the same experience I do. And something for AI, like when you think about... particularly when it's so costly to provide and the free product is so much worse than the paid product, of course it's a win for them to be able to get access... like so to have a mission of believing that AI makes the world better and to not embrace ads... Yeah, no, I agree with ads being an efficient form of monetization. What do you think is the right way for consumer AI apps to do ads? Like you know, ChatGPT just announced they're doing ads and they're doing them terribly. Well no, they're doing them as a very separate experience to the answer, or you can have the... No, this is why it's so bad. This is why I'm so frustrated with them. So what they're doing is the bare minimum easiest solution. Like banner ads basically. It's banner ads but it's based on the context of the conversation. And the problem is that like they released their ad principles, right? Which is &quot;our ads do not influence your answer.&quot; If you're using the easiest possible way to target ads, which is based on the context of the conversation, we're going to show you a roughly relevant ad. Number one, your market's way smaller because you have to hope someone starts a conversation that matches the inventory you have. Number two, you're getting into a &quot;my T-shirt answers questions that my T-shirt is raising&quot; sort of situation where if the ad is clearly connected to the answer, you're going to raise suspicion in users' minds about what sort of the connection is. So I would prefer if the ads had nothing to do with the answer. The way you get there is you build a Meta-style understanding of the user and show them stuff that's relevant to them. Like in Instagram, the best Instagram ads don't have anything to do with the stuff I'm surfing, it's from Meta's understanding of me broadly. So are you saying that the AI ads should be more like Facebook ads than Google ads? And you know, right now the focus is on doing targeted ads that are related to the prompt, whereas instead it should all be profiling the user and who this person is and what their interests are. Yes. I think that would be better. It would present less conflict of interest, less uncertainty amongst the user. And it's a model that I think... I'm not the world's biggest fan of search ads precisely for the reason why they work so well. I think there's a lot of search ads that are... Because the confusion between organic... No, they're cannibalization. Like, why is it that I have to buy my own name in search ads, right? Because someone else will go in there and you're getting... harvesting a click on the ad that would have been there sort of organically. Which is fine, it works, the search is providing a lot of value. But the challenge obviously is they only have one space for inventory, which is in ChatGPT. Well sorry, in defense of Google ads that everyone complains about the branded search and yeah you're paying for cannibalization, but Google pays so much attention to search quality that the sponsored listings themselves have a ranking of them, a relevance ranking of them. And so it's really just like the Yellow Pages where you know you need to pay to be listed in the Yellow Pages. Oh, it's fine. I'm not... again, I'm the ad lover here. I just think that Meta ads are more broadly valuable because they're showing me stuff I didn't know that I wanted. But if the AI apps are to generate a profile of you, does that profile include the content of all your conversation? And isn't that the same thing? Well so this is the thing. So Demis is out there saying, &quot;Well, I can't believe they're adding ads, we're not going to do that.&quot; Which is hilarious because the entire Gemini-DeepMind apparatus... what is it funded by? Sure, yeah it's the Google ad machine. It's funded by ads. And that actually is probably the ideal model. So it's actually very funny. I was actually in New York City last year, and I was meeting with someone in the office... actually in the shared office across the hallway was like a hedge fund or someone. And they came over and he's like, &quot;Oh, longtime reader. You're responsible for our worst decision ever.&quot; And I'm like, &quot;What?&quot; He's like, &quot;Putting money in Twitter.&quot; I'm like, &quot;I've never said to put money in Twitter. Like that's always been a terrible company. I've stopped covering them because it was such a bad business.&quot; And I was like, &quot;Oh no, I remember what it was.&quot; It was when they bought MoPub. And my theory, my problem with Twitter advertising has always been that, especially with very textual, I think text doesn't work as well... this is a problem for the all this applies to the chat clients. Text isn't the best interface for ads. Obviously visuals are generally better. And there's also a posture. If I'm on Twitter, I'm like I'm ready to do battle, I'm locked in, or I'm searching for information. If I'm on Instagram, the whole point of seeing an ad is I don't really care what I'm seeing right now, I'm wasting time. You're actually in a much better posture I think to absorb, just like TV. Like you're sort of... can absorb the ad. And Twitter is like bad for that. But Twitter, because it's an interest-based network, at least in theory, it should be able to understand a lot about you above and beyond theoretically having pixels and SDKs sort of all over the web. And so my theory with the MoPub acquisition, I thought it was a great acquisition because like oh, they can harness signal from Twitter and manifest it in other apps through this sort of MoPub network. Now Twitter was incompetent so they did nothing with MoPub, gave it to AppLovin who has now ridden MoPub to like the top of the world. But that was sort of my thesis. And I think that could apply to AI as well. I think the ideal outcome for Google is they never put ads in Gemini, but they understand so much about you because of what you do in Gemini that they can then manifest that through ads on YouTube, through ads on Google, through ads on their other properties. And the challenge for OpenAI is they only have one place to put inventory, which is in ChatGPT. Okay, so you're saying that Google could use Gemini to just improve the targeting of the ads across the Google properties, and then maybe if you want to have ads in Gemini... I don't think you need ever put ads in Gemini. But just if you did, you would also have the profile that Google has of you from across the web and you could use that. For sure. Yeah. And you don't need to have ads that are like making the user feel weird because why are you showing me ads about what I'm asking about? Okay. But in the scenario you're just describing for Google, wouldn't that have the same just like the you know Meta is listening to your microphone conspiracy theories where when the targeting is too good, people get concerned. Wouldn't you have similar issues? I think that's a made-up concern. No, it's but people have it. And wouldn't you have a similar issue where if you're using the Gemini data to make better ads, wouldn't ultimately the targeting be too good and people find it weird? I mean, I think that's a bridge that every tech company would be happy to cross if they came to it. I see. It's a thing that people say when you have very good targeting. I think there's a lot of... like honestly I think a lot of... there's a real stated versus revealed preference about a lot of this stuff. The reality is people like... you know even in the EU they think, &quot;Oh you could pay for Facebook or you could show...&quot; People would rather see the ads. People I think most people don't care. And this... a lot of tech... and this sort of ties into the skepticism of ads... it's sort of elite town. There's elite regulators. Everyone's thinking about these very theoretical things. Isn't a bit of the challenge banner blindness? Where Instagram advertising works so well because it's a picture feed and it's showing you pictures and then some of the pictures are like commercial. No, the amazing... so this is where Facebook... Whereas with an AI app, you're like looking for an answer and you don't want to look at the banner. No, it's a huge concern. And this is one of the great ironies of Meta/Facebook is the extent to which they... I mean of course Mark and everyone hates Apple for lots of I think very justifiable reasons. But Apple saved Facebook from itself. Like back in the day, remember Facebook platform, and there's like Facebook payments and all this sort of thing, and Mark has always wanted to build a platform. And if you're just an app on a phone, you can't build a platform. And the problem is that I think being an advertising-based model is generally incompatible with being a platform. The whole point of a platform is you're letting something else shine, something else bring to the surface. You're the support structure for something to take over. So an operating system is not about the... ideally it's the application on top of it that you're using. When Facebook was forced to not be a platform but just be an app, suddenly they could be fully leaned into being an advertising thing. And think about a Facebook ad, even back in the day when it was a feed ad or a story ad. Literally your entire device is all an ad. And somehow it's not a banner that's a little thing on the edge, they literally have achieved permission from users to take over your entire device to show you a full-screen ad every five seconds. It's amazing! And they were forced into it by Apple. Do you... okay this reminds me, and I want to come back to the AI dynamics, but this reminds me of a view I've had that I'm curious your thoughts on, which is... often when tech companies become really big, they become really big just because the core idea works better than even the founders could have realized. And so Meta is a really big company because they have a feed and the feed got really big, and they like were very smart along the way where they bought Instagram and they're like incredibly targeted good monetization. But just it turns out people spend a lot of time and many people, you know, the P times Q of that with the feed and they monetized it very well and that's what got really big. And same with Nvidia, it just turns out that the GPU market got really big and they sell a lot of GPUs. And so maybe founders because they're often like high-powered individuals who want to have lots of new ideas, they're often thinking about the next thing or like what the second act or the third act is and everyone wants to invent an AWS. But I'm curious what you would say to the idea that just generally it's making the core thing really big and there's more orders of magnitude at the top than you thought. Yes. I think that's always the case. And I think that sometimes people end up making something that they didn't want to make and they continually push back. I think Meta is the perfect example. My impression is Mark's not very interested in ads. He's had very good people along the way that have helped him build these ad products. I think Meta has suffered from that because he has not been front and center fighting for actually ads are good. They're a societal good. They're the driver of all the consumer surplus that tech throws off. Like the president uses the same search engine as the guy on the street or the same AI or whatever it might be. That's because of ads. Probably not. The president probably uses like a Palantir search engine or something. It's probably worse. Google's slipped a lot to be fair. There's so much junk online. But the... and you know I don't know Donald Trump ever searched I don't know. That's a good question. But he has not been fund... he has not made that case. And I think Meta has suffered because of the failure to make that case. And then you get things like, &quot;We're going to do the Metaverse, we're going to do XYZ.&quot; It's always coming back, &quot;We'll be a platform, be a platform.&quot; And Meta is an entertainment company. I wrote this like years ago about the... I think this was actually... it was simultaneously a good call and a bad call. Do you remember that Paul Krugman quote? &quot;The internet's not going to be very big or than the fax machine because people don't have much interesting to say.&quot; I actually defend that quote. And because it's actually true. Most people actually don't have that much interesting to say. And I brought up that quote around 2015 by saying this is a fundamental limiter on Meta's long-term potential. As long as they think of themselves as a social media company, they're going to run into a problem with their feeds becoming insufficiently interesting over time. Now the move from kind of peer content to... Well so that was... that was if I might say so myself a very brilliant insight. The bad insight was my prescription, which was they needed to do more with professional content makers, like more funding of like the BuzzFeeds of the world and share revenue all that. That was wrong. The actual answer was what TikTok did, which is... TikTok's not a social network at all. It is a harvesting... and YouTube you know same sort of idea. It's like personalized TV. What actually matters... and this is a key thing, people get hung up on relative numbers and what matters is absolute numbers. So it is better to have 0.1% of your content is good if your content is like in the billions or trillions. As opposed to, &quot;Oh 10% of our content is good, but you only have 100 pieces of content.&quot; That's actually worse even if it has a better hit rate. And so spurring lots of creation, writing the algorithms to capture the good stuff, put it up there, that actually solves the Paul Krugman fax machine problem. And Facebook was blindsided by that. They were so stuck on their identity of being a social network that they let TikTok take this huge chunk. It was their blind spot. Speaking of TikTok, I feel like you don't write about ByteDance that much and I'm curious just what your thoughts are on ByteDance from here and the TikTok sale and everything. What a mess. I had to make a decision a long time ago. I wrote about Chinese companies more previously. And I think there is... number one I have to decide what I'm going to be able to cover and what I'm not. I'm not in China. I was in Taiwan. It is a different internet. And there was too much sort of uncertainty and unknowns just in general about a lot of Chinese companies. I would write about them occasionally in the context of US tech companies. So I think I wrote about like WeChat and what it meant for the iPhone's relative competitive position in China, how it's different than sort of other countries. I think that sort of held up pretty well. Wrote about TikTok in the context... I mean more about TikTok I think in the context particularly as it comes to Meta. TikTok came up around the same time as the... what was the... Quibi. Which Quibi was the example of that. Quibi was like... it was actually right that there was room for a mobile entertainment product. It was totally wrong about the content acquisition strategy. So even if they had a hit rate was higher, their total volume was way too small. I follow them but not super closely. It's just a hard market to understand. But like TikTok's very relevant to the US market. So TikTok... I wrote the TikTok War, basically making the case that the problem with TikTok... and back then everyone was talking about user data. Who cares? Like the whole user data thing... people have this view of like the East German Stasi and like folders of like going through people's data. Like these are like vector databases with like numbers that no human can parse. Like it's really quite anodyne. It's just really to target ads. And I was very skeptical about that being a forcing function in terms of forcing divestiture or whatever it might be. The issue I had was the algorithm. And I noticed, I think it was when the Hong Kong protest happened and Daryl Morey, the then-GM of the Houston Rockets, tweeted like &quot;Free Hong Kong&quot; or something like that. And there's a huge meltdown, the NBA games got cancelled. And I noticed that on TikTok... and this was from... I tested it from Taiwan and via VPN from the US. If you searched for every single NBA team, you got NBA clips. Except for Rockets you got nothing. Oh that's funny. They got demonetized! The Houston Rockets. There is a thumb on the scale here. And I started talking about it then and my... I did support the ban of TikTok or the forced sort of divestiture from China because it seems fairly insane to have a primary information source controlled by your chief geopolitical adversary. Yeah, same like there's rules over TV station ownership and it's not wildly different. And so I... you know in the... everything is a tradeoff. Of course I'm pretty well known for being a pretty stark defender of free speech and against censorship. And my issue wasn't TikTok per se, it was the reality of China is the founder of ByteDance is long gone because he got called to the carpet for ByteDance showing a little too much of what people like, which is mostly like hot girls dancing, and being insufficiently like showing the right things that the Party wanted. It's in China's... the reality is China has... the price of doing business is they get you know they're on somewhere on the control structure, they can tell you what to do. And this just seemed like a very foolish thing to tolerate. Unfortunately, the US political process, or fortunately... maybe the reality is the US process and system is such a mess. Can anyone really truly impact it over time? The way that shows up messily is we somehow do pass the law banning TikTok and it didn't get banned and now it is sold but China still controls the algorithm. So I think it's a big disaster. It's also like what can I say about it? I said my piece. We ended up in the worst possible case which is we violated property rights and we did all this stuff that's ridiculous and we probably bartered XYZ for ABC and we didn't get the most important thing which was control of the algorithm. Has that not happened as part of the sale? No, ByteDance still controls the algorithm. I didn't know that. Yeah. Good job by us. That does seem like it was the point of the spin-out. Well the data was always the... was always the most salient political point. And so when I wrote about it that was my point. It's like I don't care about the data, the issue is the algorithm. And unfortunately that did not... maybe I should have written about it more. But the anything like all the politics stuff... there was a period... I mean thank God for AI. There was a period... I wrote like when I wrote aggregation theory, a couple of weeks later wrote like &quot;aggregation... something about regulation.&quot; I'm like this is going to drive a bunch of regulatory issues and antitrust things or and all these bits and pieces. When that actually happened the late end of the last decade, of course I was writing about it, I was watching the congressional hearings, all this sort of thing. And that is the close I came to quitting and burning out. I think burnout's not a function of how much work you're doing, it's doing work you don't enjoy. And at one point I'm like okay either I quit or I stop watching congressional hearings. So I decided to stop watching congressional hearings. I only wrote about antitrust stuff if it was super prominent. And I've been much happier ever since. And maybe that's part of the price of just not writing about that is maybe I should have pushed on the TikTok thing more. I said my piece. So... Is Stratechery very widely read in DC? It is. Sometimes it's gratifying. It's great when you get called and ask for your opinion about or you know you get certain responses or you see impact. It's less gratifying when you get yelled at and people are mad at you. But fortunately the key thing to succeeding on the internet is something I have in spades which is a very high level of disagreeableness. So you can be all as you want, I'm not going to change my mind. Okay. But getting back to aggregation theory as it pertains to AI. Like a simplistic view you could have is that the AI apps are the new aggregators and so a huge amount of economic value will accrue to them and that's it. You could also say that that's too simplistic in a bunch of ways because one of like we're saying the... you know Booking.com you expect it to return you hotels that you should book, but you expect a little less of a commercial incentive from the AI apps. And this is like a little more of an abstract technology where it's actually not trivial to insert all of the you know commercial incentives in the right way. Anyway, you come up with various objections. Well I think the ad model is probably the way to start. Which is I just talked about before sort of the lean-in versus lean-back. Ads are very tied into human psychology and like what you're sort of tapping into and people's response to that and how do you make something creative. And in the short term, you know technology often makes old business models even more powerful before it kills them, right? So you have something like you know suddenly you're a newspaper I used to be limited to my geographic area. Now I can reach the whole world. Oh wait a few years later everyone can reach the whole world. I mean pure competition, I'm screwed. And that is certainly a concern about this model. If you get to a world of say agentic commerce and the agents are just buying the right thing. Like and this is I think this is also something that has driven a lot of tech skepticism of ads. People in tech tend to be fairly nerdy, fairly obsessed. They're doing a ton of research to find sort of the exactly right thing. Why would anyone tell me what to buy when I've, you know, researched it for two hours? That's right. But so like ads have no effect on me. Well what if that sort of obsessive deep dive approach is now trivially available to everyone because AI is the one actually doing it? Now where do ads sort of function? And I think this is definitely a bit of a &quot;be careful what you wish for&quot; scenario. Because what this entails is of course more transparency, more details, more understanding sounds good. What it actually entails is sort of perfect competition, which is a very sort of brutal game that can just wipe out entire categories. That's you know that's basically what happened in newspapers in many respects. So that's that's number one. Number two, in a world of this sort of world, you're sort of by definition anchoring on whatever specifications or whatever can be measured can be put down. And you had the old sort of Steve Jobs adage about feeds and speeds versus like the feel of something, &quot;where the intersection of liberal arts and tech...&quot; What the f*** does that mean? It's just like well what it actually means is there's things that can't be measured and that don't go on an Excel spreadsheet. And everyone you talk to acknowledges this. They say, &quot;Yes there's things that can't be measured.&quot; And the way it actually plays out in practice is only the things that get measured sort of matter. I think this has happened to a this has been a huge problem for sports analytics is a great example of this. Where there... I think basketball is my favorite sport. There's a lot that goes into basketball in winning that is somewhat hard to wrap your hands around. It's not like baseball which is very measurable. Baseball's very measurable. I do think there's aspects about clutchness and stuff that I'm that I don't know that are properly measured. But around basketball for sure there's the interaction and the way teams play together and how your effort on or your involvement on offense can affect defense or sort of back and forth. And you see again and again like to take my you know I like Daryl Morey. I think there's a reason his teams have won. They've over-optimized at the expense of some of these these other issues. And if you can't measure them, they tend to get devalued. And in a world of AI-mediated everything, how many things that can't be measured fall by the wayside because we end up with it's very utilitarian sort of goods that have no soul to them. Sort of a silly sort of thing to worry about in some respects, it's like or it sounds silly, but I'm a human and I anticipate liking and preferring the humanity of things of all sorts in the long run. But you could say that like e-commerce aggregators like Amazon and lots of others have led to you know fairly anonymous manufacturers of lots of everyday goods, the kind of Amazon Basics type stuff on a much lower price point than they you know were at previously and still perfectly good quality. Isn't this fine? Like isn't that fine? There's no soul in an Amazon Basics power adapter and that's fine. No this is where you throw my ad argument in my face. Which is like actually it brings up the base level for everyone. Like your basic consumer, the access of items they have to in the... like everyone thinks back to like &quot;Oh my washing machine was so much better in the 1960s.&quot; And it's like yes that's true and also far fewer people had washing machines. And so I'm now like making the opposite argument sort of against myself. We'll switch back and forth. You can have a one-person debate. Exactly. You can change sides in the booth. You mentioned agentic commerce. Where, you know, we obviously are big into that and had our announcement with OpenAI back in October. Where do you think that goes? Like how do you see agentic commerce playing out? I mean the contrast between your and OpenAI's announcement and sort of Google's announcement I think is is pretty interesting and speaks to what the companies are driving for. OpenAI wants to be the place you do everything. They want to be like the aggregator. I think a critic would say people compare them to Netscape. I think the better analogy if you're an OpenAI skeptic would be AOL, where they want to be sort of like the interface for everything that you might do and it goes through their channels. And Google, just as they were relative to AOL, is like actually we want to we want to make equip everyone, knowing that if everyone is capable, we are the greatest beneficiaries because we still marshal sort of the sort of front-end demand in that regard. Now how does that actually manifest in terms of commerce? The funny thing about tech is I don't think it will manifest in terms of airplane tickets, which is everyone's example. Like everyone can never think of a better example than that. But what what is the AI going to buy? What's it going to get? I don't know. I think I would like to think people will want to have agency in their buying decisions. But then again, you know we have like assistants whether it be like you know for work or whatever it might be, and they make buying decisions that were necessarily not involved in, and that I think is a good predictor precursor of what people will ideally like... do I really need to know... actually I very strong paper towel ideas. That was going to be my... but once I have that set, can that be sort of monitored and done? And so I don't know. I think this is a very unsatisfactory answer other than to say it has big implications on things like advertising and on things like like is that going to be a viable business model going forward? What margins are going to be available? Is there going to be perfect competition? Things along those lines. Okay, let me try this on you for agentic commerce and I'm curious to have you critique it, which is sort of how I see things playing out. I think some skepticism is triggered by people pitching a very far end state with a lot of agentic autonomy. And so it's like &quot;Please book me a honeymoon in Japan and all the activities.&quot; Like no one actually does things that way. Whereas actually you should go from the bottoms up in some very basic building blocks. Where step one is just replacing filling out web forms. That's an activity that sucks. No one likes it. And so imagine you find the winter jacket you like and you copy the URL into ChatGPT and just say &quot;Please buy this for me.&quot; And that's a much better experience than going clicking around a site you've never been to before. And so there's just the agents doing kind of tool use on your behalf and everyone can agree that. Maybe it clarifies &quot;There's multiple colors, which one do you like?&quot; But it's just replacing filling out form fields. This is by the way one thing that I am very... a lot of people are skeptical of this but I I am very optimistic about, which I call like &quot;just-in-time UI.&quot; Like the... Exactly. It's a better UI. That's right. Okay, so that's like level one is a better UI for for kind of doing an action you want to know. Okay. Then level two is better discovery and search. It is crazy that we've gotten this far in e-commerce with keyword-based search. Like keyword-based search works really well when you're buying a book that you know the name of. It's like &quot;I want to go buy this particular title.&quot; For a winter jacket it's like, I don't know, it's like a puffer, like what's it called? And so instead you want to be able to say &quot;I'm looking for a jacket, this kind of... I'm going to this place, it's going to be this cold, I like these kinds of things,&quot; whatever. And so step two is just better search. And the ability to search with parameters that like no existing search UI lets you specify the temperature of the place you're going to actually get, you know, a jacket of appropriate warmth. But that's obviously with a jacket one of the core things. And so better search UI is kind of level two from our point of view. Right, which I think is already sort of manifesting. Exactly! We're already seeing and like in the early usage of the kind of ChatGPT buying experience, I think that's one of the like super cool features. And then level three, which we haven't really seen play out yet, is this idea again of a persistent profile of the user... That anticipates their needs. Exactly! It's like I want to be able to just pin things I like as I go along, or maybe you know if I can share my browser history or maybe if I can just like you know share a Pinterest board of just like &quot;These are some styles I like. Give me a good winter jacket for the cold based on that. Here are some photos of me, you know, based on this.&quot; And so starting to get... Oh I have an even better I have an even better idea. Okay. Imagine if you were using ChatGPT and it's circa October 1st. And there is an ad for a great winter jacket that is perfectly suited to me because they've been understanding my interests, they understand the context of where I am. I'm not searching for winter jackets because I don't plan well. You know it's going to get cold and then I'm searching for winter jacket. I'm... But what if it could anticipate that and show me an ad at the right time when I need to see it? Okay, maybe that's level four is like the... That's what I've been wanting them to build. And this is my whole bit before. Like this is like this is why they're so late. They they should be shipping that this year. You're only shipping that this year if you started your ad product two or three years ago. This is doable today! This is what Meta ads are. You need to be on more you need to watch more Reels. I I I... Like just the I've bought more ski equipment this year that I don't need just because it shows up I'm like and I'm moving back to Wisconsin so like okay I'm buying stuff for the house and I get &quot;Oh those ski hangers! I bet those would be great. That sounds very useful.&quot; They're still in a box. I haven't actually put them up. But... Yeah, so there's a limit to kind of with just kind of banner ad type experiences to what you can do. Whereas I think the search thing is is very powerful. But yeah, I'm curious what you think of kind of step one just the very act of checking out, or level one the very act of checking out, level two better search, and then level three defining your own embedding space of preferences. No, I completely agree with that approach. I just think you underrate the extent to which level three is already been built. Actually one of the things that that Mark Zuckerberg said on a couple earnings calls ago that I thought was very astute is we get hung up on technological definitions for like what is an agent. And he's like actually the largest and most successful agent in the world today is Facebook advertising. Which is exactly right. Facebook advertising people have it in their head that you go in you put in like demographics and your targeting and stuff. No no, it's very autopilot. Yeah. What you do is you go in and you say, &quot;Uh, acquiring a customer for this is worth $10 to me. I'll spend up to $10.&quot; And they will deliver you a customer for $10. Their margin will actually increase because they will make sure they deliver it at exactly $10 and they can do it for more and they actually make more money, you get exactly what you asked for. It's and I think the extent to how powerful this already works. They're just stuck on the &quot;50% of my ads work, which don't I don't know which ones.&quot; No, on Facebook they all work. I feel like a bunch of new very big successful companies will be created in AI-powered e-commerce. It just feels like a different enough product space that... But what you're talking about retailers, merchants, or discovery or agents? I was talking about discovery and kind of the demand side. They're also probably retailers. Yeah. Well I mean certainly I think I think the part that I think would be new, which is a bit which you were maybe talking about, is this real anticipatory aspect. Which is right now what is amazing about to go back to Meta ads is it helps merchants who have a very specialized product find customers that they never would have found otherwise. But there is the inverse of &quot;I need a very specialized product, how do I find what it is?&quot; Which I think you were referring to before. But to what extent can that not just be an in-the-moment &quot;I need this specific.&quot; I remember I needed a server, a piece for my rack to mount like this router because I had like an extra I didn't want to buy a whole new thing or whatever. I had this extra router. And of course there's some guy in Australia that does 3D prints that perfectly matches this on Etsy or something and it was great. I found this random guy. I'm sure he made a bunch of money selling me a $40 piece that cost him $2 to make. Good for him. But what if an AI should be capable of anticipating that need? So it's not &quot;I oh I have a need, let me go find it.&quot; It's like &quot;I know you're going to need this and let me acquire it.&quot; And that would be very powerful. In his excellent newsletter, Stratechery, Ben often argues that whoever controls the customer relationship shapes the entire ecosystem. And in mobile apps, there's always been this interesting tension here with in-app purchases, where historically app developers had an intermediate relationship with their customer through App Store policies. Over the past year, that layer has started to open up. Mobile developers can choose what they use for in-app payments. Developers now have more freedom. But with that freedom comes new challenges. App Store payments were previously handling a whole bunch of different tasks like payments, tax, fraud, disputes, all bundled together. Stripe Managed Payments is built for this new world, handling all that operational complexity for you with Stripe as the merchant of record. And with our new app-to-web flow, customers can check out in seconds in an experience that feels native. It converts like in-app payments but it runs on Stripe. The public markets indicate as of January 2026 that SaaS is cancelled. Are they right? I think it's probably a mix. The I think the one of the brilliance of American business is actually this is one of my theories about why the Europeans are so gung-ho about data privacy and regulation, is because they so often interact with European companies. So like I was in Paris a couple years or a couple years ago and of course going on a tourist trip, going going to the Louvre, going to the Museum of Modern Art or whatever it is, like or not whatever it was, just seeing a bunch of museums. They all have their own home-grown registration systems. And they're collecting so much data! It's like &quot;What's your age? What's your pet? What color is your...&quot; like why do you need to know all this information? They're all non-standard forms. They need this is where you need AI to fill all this sort of thing in. And it's like what like there's like this theoretical idea in their head &quot;If we capture this data it could be useful.&quot; So they built these home-grown things in like the 2000s that are horribly insecure. And I use them, I'm like &quot;Where's the regulator? Can someone please...&quot; So I get the mindset. US companies don't do that. Like US companies are so good I think one of the big strengths of of US business culture is understanding... and I think about this personally. This is what I give life advice. What's the number one mistake people make when they're young in particular? They focus on their weaknesses. They're like &quot;I have to ameliorate my weakness.&quot; No, what you do is you double down on your strength, you get richly rewarded for that, and then you hire someone to take care of your weakness. Right? Like I'm a big believer in the &quot;Getting Things Done&quot; system. Like great book, &quot;Getting Things Done.&quot; Even if you don't use the system, the book is really good, lots of great insights. And there's this whole thing like tickler files and all these sorts of things. It's an amazing system. I'm completely incapable of managing the system on my own. So there's a Mac app called OmniFocus that is completely built around this system that I don't have a license for, my assistant has a license for. 

And I text him stuff and his job is to maintain my &quot;Getting Things Done&quot; file because I can't do it. What do I do? Actually my life is very, very optimized around I write three pieces a week, I do an interview, and I do three podcasts. And all my focus and energy needs to be on that. And if I do that, that will make a lot of money and I can pay to fix all my problems sort of elsewhere. And I think American business does this very well. They don't waste time and energy on stuff they're not good at. They double down on what they're good at and they're focused on the upside, not on their cost centers. Probably a result of the very large market in the US. I think so, and just the competition in being in a very large common market. So you like you you don't have your like you go back to like newspapers. They have lots of home-grown stuff. Like if you're a publication on like online, if you're like me on the internet, I get paid to comment on the big tech companies. It's probably the most competitive market on earth, right? Like lots of people have takes on the big tech companies. And so you have to be super focused. Given that, that speaks to the enduring value of just paying someone to manage these business functions from a software perspective. Now there's a lot of SaaS... like there's a lot of a lot of a lot of SaaS applications. Not sure they're all sort of strictly necessary and and worth the price. I like to think people talk tech being a Big Five, I would say there's a Big Six. The sixth was Silicon Valley Inc. Which was basically this cookie-cutter VC goes to this founder addressing this specific business case with a SaaS business model. Everyone likes to they get to talk about changing the world and it's actually the most predictable yet... that's why VC returns compressed, but because they're also very predictable in terms of this sort of engine going. A big problem there is they're all seat-based. Like anyone seat-based that has some of visceral... that you're there's going to be probably fewer seats. And then if the replacement is more small-scale ideally... there's lots of... you know the internet in general has writing or content is a good example. There used to be sort of you want to be in the big pond and everyone in the big pond sort of ate. If you if you had a job at Condé Nast at one of their magazines, like you lived life well even if you wrote for four magazines or whatever. Today if you want to be a writer, I give advice to people that want to be content producers all the time, and I'm like &quot;Look, you don't want to be in a pond with me, right? Bill Simmons is like the like first internet sports writer. And you don't want to be doing a Bill Simmons impression on the internet because he got there first. And what you want to do is you want to make your own pond. The internet enables the creation of a million different ponds. So you to get to define your own pond, be the only biggest fish in that pond, that's how you succeed.&quot; To the extent AI makes that, I think this is the upside case, is AI makes that possible for more than just content. For all sorts of businesses to be lots of smaller scale individual entrepreneurs or small teams, all of whom don't really fit in the Salesforce-driven seat-based model for a lot of these companies. So there might be a big return to self-serve, you know, the or maybe they'll just roll their own because their needs aren't that large. So but that's more a larger structural change. But the problem is it's fine to say businesses will be okay as they are. If you're eliminating the growth, that's the big problem. I think that's the biggest issue for all the compression in SaaS. Why take growth? Just growth in general. Like like what's what's if if these are just stable businesses with astronomical stock-based compensation that is predicated on we're going to be very large... Yes. I can see two critiques you might have of kind of the software space and why everything's traded down. One is we're, you know, everyone's just going to use Claude Code to rebuild their own version in-house and so the software moat is less. And the second is actually just that many of these products price on a per-seat basis and so if you're growing headcount less... Or shrinking. Exactly, yeah. On the first, like Anthropic just installed Workday famously. Exactly, yeah. So I don't think I don't think, you know, we're cloud coding one of those systems of record anytime soon. They use Workday. I don't know what to make of the second criticism, but again it just feels like for a very broad and deep system of record, it's kind of hard to make the argument that the business is somehow impaired versus a year or two ago. Right, but I think but I think that's my point though. Is people saying they're going to zero are wrong. But if the assumption is you're fine but you're not going to be growing indefinitely, like that shift from thought of as being a growth company to being a stable... I see. That's a haircut and again combined with this whole compensation structure it's a big problem. You're now valued on EPS rather than revenue or something. So, yeah. Can we talk about your business and Stratechery? Sure. So you were very early to the I mean the sovereign writer concept. I think you're one of the first premium newsletters. I think so. Well so there's two predecessors to talk about. One is just on Wall Street in general there's a long history of faxed-out newsletters and things like on Grant's Interest Rate Observer and all this stuff. The difference there is those were very expensive and a very small addressable market. So the difference for Stratechery is it's much cheaper and the market's much larger. The other person that deserves a call-out, which I think was the first person to do it before me, otherwise I think I was the first, was Andrew Sullivan who did... I hadn't realized he had a paid newsletter. He did for like a year. The problem is he did it all wrong. You're doing it wrong. He was like he would churn out like 50 posts a day, right? Just about a gazillion different things. He totally burned out and like all the sort of stuff. But that happened to be a great fit for the advertising model back in the day because you were always go back there and just always be new stuff and I'm sure he had I'm sure he drove a gazillion impressions for The Atlantic, especially when he was with them. He went independent. He was pretty successful, I think he he did like over a million dollars or something like that. But it was this very leaky paywall. It's like after like 35 posts then you'll hit like a paywall. And there's a bit where you're like you're punishing people your worst users. It's very easy to get around. And so but he was actually very inspirational in how I thought about the model. In that he was hailed as a failure because he like burned out and quit. But I'm like he made a million dollars, right? Like that's pretty good. I wanted from the and just thinking about the psychology of this. When I started Stratechery I had a gazillion ideas of things to write about. And I limited myself to writing a maximum of two times a week. And the reason is I had the subscription model in mind. And when I added the model, I didn't want it to be I'm taking stuff away and now you have to pay. I'm like &quot;You like this so much, if you pay you can get more.&quot; And so I always wanted to be you're paying to get more sort of sort of aspect. And I think that probably mattered more at the beginning, especially because the model was new. You know I had my metric I looked at was people who visited Stratechery on days I didn't post. Because they were people that were going there hoping I had posted that day and they were leaving disappointed. And so in this case, usually previously a paywall would disappoint people that they hit it. In this case the paywall would alleviate their disappointment because they could now get what they wanted. And so I'm like if I can capture X percent of these visitors, it'll be very good. One-day goal, one-week goal, one-month goal, failed to reach all of them. What happened was I I actually thought it was going to not work. I was like to have to go back like teaching English or something like that. The but it sort of grew and grew and grew and at six months actually hit my one-year goal. Which was 1,000 subscribers, 1,000 true fans, you know $100,000 run rate. And I posted a little note saying &quot;Hey you know model works, reached you know my goal is 1,000 for a year, already reached it.&quot; And this is the only step change in subscribers I've ever had. In the next 24 hours I got 250 new subscribers. 25% increase. What they were was I had identified those people who wanted to be subscribers, they just didn't trust that it was going to work and it's going to go out of business and take their money. And so once they realized I wasn't going anywhere, then they all signed up. And those people signed up... so I actually had my my metrics were right, but I didn't properly calculate the uncertainty in people's fear of losing their money. No, so I'm very grateful that now people just sign up for stuff all the time, right? You know, of course I'll probably you know go to my grave being most well known for Stratechery, but I am equally proud of the model and that lots of people make a living doing this. How far do you think this model can go? Like again it the defining characteristic to me seems like the unbundling. Like you know 30 years ago you would have been writing for a publication, whereas now it's unbundling, it's the direct relationship with your subscribers, it's direct monetization and generally paid. I mean there might be some ad-supported component as well paid. Obviously kind of Substack has proven that this is very broad applicability. But how far do you think this goes versus traditional media bundling? There I think there's a couple interesting angles to this. Number one I think people, including people in tech, seriously underrate how large the internet is. You know one of the biggest pushback I got when I announced like the Stratechery paid product was from VCs, I won't say who. It's like &quot;Love you Ben. Just doesn't not going to work on the internet.&quot; The so and my bit about ponds before. I don't know that we've scratched the limit of how many ponds can be sort of built in the world and you can sort of occupy and... and the other part of this, the critical piece of this... in AI as actually an important factor here... is the key to the model is your costs. So you need just as technology enables you to reach everyone, you need to leverage technology to keep your costs very, very low. And so for the first several years for Stratechery it was just me. So as long as I can feed my family, I was I was fine. And this is the problem for the traditional like media companies. Their cost structures were not internet cost structures. They were they were predicated on on much higher revenue. And there's you know and this is it's interesting to think about and talk about this because a lot of this it is like not really applicable. It's like before: I write about ads a lot and I'm not an ad business. In this case I write about VC high-scalable companies, but my actual business is very sort of boutique and small and... Artisan. Artisan, that's right in that regard. And this is a super important point. Is managing your costs. If you manage your costs appropriately then the possibilities... but that also means there's some things that don't work with this model. Like your traditional classic investigative journalism, six-month sort of piece, it's not well supported by this. What did support that was the bundle. Having lots of different writers in one publication all together. And the thing I worry about, I wonder about, is bundles are good for everyone involved and no one wants to be a part of it. So TV is the classic example. Why did we have a TV bundle? Because you had like so in I think it started in Pennsylvania. So you have like a television station in Philadelphia, then you have the Allegheny Mountains. And you have a bunch of towns there that want to get the signal from Philadelphia but they can't get a good signal. So they band together, they put up a big tower to get the signal, they run actual cable from that tower to all their houses. And all of cable television started in small town rural America to get TV from the big cities. And Ted Turner comes along, &quot;I could just broadcast directly to these towers.&quot; This would be amazing. And you get the model and suddenly every... but you had a geographic forcing function. And you ended up with all these companies with the best business model in the world. They everyone paid them whether they watched you or not and they made a ton of money. And what happened the moment they could do something different? I could also go directly. I can stream directly. And there's just something about business and like because it's it's almost like you have to be forced into the game the optimal game from like a game theory perspective. And the moment you can desert, everyone always deserts even if it's the best thing. And so I so I do wonder can bundles ever happen... This feels solvable to me. I think it's solvable at the beginning. No, sorry, feels solvable now. I think a counterexample is something like Spotify. Spotify is arguably the best bundle on the internet. But why were they able to assemble the bundle is because they only needed to negotiate with like four four entities. And so it's interesting because on one hand that limits Spotify's upside because those entities are able to negotiate such a large share of Spotify's revenue. On the other hand, that's also why Spotify was possible, because they only needed to negotiate with four. And if you're trying to to like get every artist on earth... &quot;Well of course I gotta get Taylor Swift.&quot; Okay good luck with that. &quot;Oh everyone all the small fry will sign up.&quot; But in music's unique in particular because music the moment a song comes out it's now part of the back catalog. It actually people only ever listen to back catalog. So there that's a particularly unique industry in that regard. But that is a bundle that formed, but I think it's because there's only four players. How do you use AI in writing Stratechery these days? I think it probably replaces what I used to do a lot on... it's much more efficient Googling. Like so I really... the most gratifying articles I write is when I write about a topic that I usually don't and then someone from that industry is like &quot;Wow I did believe that was good&quot; because you know you're always worried about this imposter syndrome. You have this amnesia, yeah. That's right. And it's like this is totally wrong and then you trust everything else. Uh I am yeah I don't want to trigger Gell-Mann and amnesia amongst anyone. So I will do... and people ask me like I hate the book question like &quot;What books do you read?&quot; I read a lot of books but they're very targeted. Like I will do I'm a very, very, very fast reader. So sometimes I'll write an article I know there's a pertinent book and I will just read the whole book in the morning and like and then I can really put the context in there. And so but in general I really want to make sure I fully understand a space, particularly that's new that I'm writing about. This is partly though why I have a big competitive advantage. I've been thinking about tech since I was in junior high school and I've been writing about tech for 13 years, so I've already done so much preparatory work that anyone starting from scratch it's like uh it's hard. But so I want to dive into it. I'm one of the world's greatest Googlers I'd like to think. I know every sort of parameter and how to find and it and so I think I can say it pretty authoritatively, Google has gotten worse. And I don't think it's Google's fault, I just think there's just it's harder. Well one thing it is Google's fault is they got so biased towards recency and so you have to be super like diligent but um AI is unbelievable for this. Like just sort of getting background, making sure you understand an issue, the ins and outs of it, um how things work. You can query stuff, dive deeper. So that is by far my number one use case. I do not always but I will do sometimes ask it to and this is where I like ChatGPT to just like I type in &quot;BBEdit&quot; as an integration. This is also why I'm very annoyed by and am very sensitive to the cloying nature. &quot;Oh this is really great! No that's not what I'm asking for. I want you to actually go in and find stuff.&quot; Uh so I do not use it to actually generate any exact content but... targeted research and then critique. Yes. Yeah. Those would be the two biggest use cases. You've written a lot about the TSMC break. This idea that the limiting factor on all AI expansion is basically the rate of TSMC capacity expansion because almost all AI chips are fabbed at at TSMC. It seems like as you look at the AI space and everything interesting going on, uh so you know for mostly chip-constrained right now, which would not have to be the case you could be power-constrained and stuff. But if you're um chip-constrained uh there's a population of people who want to expand very quickly, the AI labs, Nvidia, people like that. And then yeah famously which uh you know TSMC which is more conservative in how it expands. Why is that? Like why why does the market signal not cause them to build out fab capacity faster? Because the risks for fabs are basically larger than for anyone else. You're you're spending billions and billions of dollars on a fab that if it's not fully utilized, if you end up with too much capacity, number one those all those all your costs are locked in. Like basically 99.9% of the cost for a fab is depreciation. Which you're paying the depreciation no matter like or you already you've already paid in cash obviously but it's on your accounting statement no matter what. Uh so the fabs can be extremely profitable, TSMC's margins are higher than ever, but they can very quickly tip over into having a huge problem. And then once they're already built, these fabs can run for a long time. So that excess capacity is a depresses prices for years to come. We see this in memory all the time. Memory famously goes through these cycles. Like what's going to happen we're going to believe it or not we are going to have too much memory capacity in a few years because we have such a shortage right now. Like Micron just announced like uh they're a huge new fab in Singapore, right? And everyone's going to do that which and so but why is this happening to memory? There's three competitors in memory. If Micron doesn't do it, SK Hynix will. If SK Hynix doesn't do it, Samsung will. And so you have a dynamic where a healthy dynamic, which is the fabs know better but they can't help themselves. And so they take on the risk and they build these fabs. The problem we have with logic is that TSMC doesn't have that pressure. And so they're actually behaving rationally. TSMC is giving up potential long-term revenue, but the downside for a fab in particular is so large that they don't want to realize that downside. Can they not pass the risk onto the customer? Where it's like &quot;You are going to pay for the entire fab.&quot; That's probably what they need to get to. And so Apple famously uh did a lot of this... uh sort of prepaid and particularly when TSMC was sort of expanding hugely in the 2010s. And they maybe need to get even more explicit about that. But I think the better solution and the cheaper solution for the hyperscalers in the long run would be to do what is necessary for TSMC to competitive. Then you get it for free. You don't need to prepay it. So there's this risk that's out there, the risk of overbuilding. Right now TSMC is shifting all that risk to the hyperscalers, to Nvidia, to Apple. And the way it manifest and the reason why they get away with it is because the risk is foregone revenue. It's money you don't make. And worse than that, it's money you don't make four or five years down the road. And everyone like what does every company say on their earnings call right now? &quot;We could have made more but we don't have enough supply.&quot; And if you think it's bad and why is it bad right now? ChatGPT comes out. Every hyperscaler starts investing like crazy. What does TSMC do? They actually decreased their CapEx year over year, two years in a row! They did there was no market response from TSMC to the ChatGPT moment. Now they increased to 41 last year, they're going up to like 60 this year. But even that increase to 60 is a less percentage increase than last year. I think we're looking at a massive shortness in chips in 2029 uh or so. And particularly as the other thing the compute density of AI is so much larger. Right? If you have an agent out doing stuff, it's doing so many more computations in a limited amount of time than than me and my Googling is even humanly possible to do in all these lookups. So we have a CPU shortage too. And Intel Intel shut down some of their CPU plans, right? Uh so it's the whole semiconductor the... I just think it's a big problem. And we're shifting to for a long time &quot;How can we get an alternative to TSMC for geopolitical reasons?&quot; And the truth is it's kind of like the bundling thing. It's really hard to get companies to buy insurance, particularly when the insurance is uh number one you have like everyone else somebody else to do it, right? Who is going to be the one to go go and make the sacrifice? But also it might not happen, China might not attack Taiwan. And also as long as it doesn't happen, it's super sub-optimal to go somewhere else because TSMC's better. And their customers it's not just their fabs better, their customer service better and they have all the IP blocks you need and they've done this before and you have an existing relationship and they'll punish you because they have limited they have control because they like they're not going to fulfill all their orders right now because there's so much demand. And so they can pick and choose sort of who so people are scared, they don't want to go anywhere else. Uh and the so how are we going to solve this problem? And I think I actually wrote on the front page of Stratechery about this this week even which was basically the same thing I wrote an update. But this was a like someone needs to the hyperscalers in particular need to appreciate I think a massive crunch is coming and it's now on them to get Intel up to speed, to get Samsung up to speed, to get a credible alternative. Yes in theory you could pay TSMC... for geopolitical reasons or for shortage? No, you'll get the geopolitical reasons for free. I think there's massive economic reasons to do so which is all the revenue you're going to be foregoing in 2029 if you don't do it now, and then we'll happily get geopolitical insurance for free. But if TSMC are the best, like isn't rather than like stand up Intel which seems hard, isn't the answer to just again prepay for an extra fab build-out for... But this is like how do we feel in tech about ongoing operational costs as opposed to putting in some money up front and fixing the problem permanently? The market structure is a problem. You're dealing with a monopolist. And like not a like a mean monopolist per se. Exactly, that's the problem. They're too nice. Right and they actually have not arguably not raised prices nearly as much as they should have. But the reality is there's a market structure problem that is going to impact the hyperscalers and it behooves them I think to fix the structure otherwise the costs of insuring the or overcoming that are just going to be larger and larger. This seems like the topic you have felt strongest about in the past year or two. I felt pretty strong about Apple Vision Pro. Okay, fair. What was your take with Apple Vision Pro? They finally showed an NBA game and they kept changing cameras. They're applying 2D television production techniques to an immersive technology. Just let me sit courtside! I had the TSMC break seems like a bigger deal. Oh probably. I have some rapid-fire questions or I'm not going to say rapid-fire necessarily but uh uh a collection of disconnected uh questions for you. I'll connect them, that's what I do. Great. Um how should schools do homework now that AI exists? I think they should incorporate it and they should probably do in-person exams, like or in-person like the yeah I mean you it's silly to try to crush it out. I'm very opposed to these like AI detectors which don't work is more I mean probably I'm particularly sensitive to it because obviously a lot of my prose is in these models. No one like my thing is the thing was uh I wasn't an M-dash user but um I'm a mass world's biggest semicolon user. I was a big M-dash user all along. Oh. Fortunately the models don't seem to have really incorporated the the semicolon so maybe I haven't been that influential. But um but yeah no you want kids to use it because whoever can use AI most effectively in their jobs going forward is going to have a big advantage. Um so there's probably some return to you know more in-class being more important. I think the this my this is my view on content generally. This is I just um I think there's a world in which not all content but some content is more valuable than ever. Because AI is a perfectly individualized experience. What you read is not necessarily what I read. So stuff that we both read is actually compelling. And I'm very interested in figuring out how to leverage that to be sort of beneficial to people in the long run. And what can you get from school that you can't get elsewhere? Right? I can read the notes, I can read XYZ. But there's being in class, having a discussion about it, like actually interacting, being pushed on these sorts of things. All this is a sort of a beautiful theoretical depiction of what school might be that is probably very far removed from the reality. But identifying things that are common experiences are going to be more and more valuable. Common content, common classroom time, live events, like shared experiences, because anything that's individualized is just going to be completely swallowed. Do sports teams become more valuable in an AI abundance future? Of course! Everything live becomes more valuable. That's something I'm thinking a lot about as far as my business, right? Like the there's some aspects of tens of thousands of people reading the same thing every day that is actually really powerful. There's something interesting there, the possibility of doing live events where people can come together. Um I think a lot about community. I think no one's ever really solved community around content. Like a message board or comments are not it. You actually get very bad dynamics, there's a few people that dominate it. Totally, yeah. But what is great is if we're in a group chat and you share an interesting article and you have a discussion about that. Um so there's a lot of stuff around that I think is really interesting and that I'm thinking a lot about. What do you think of what's going on in crypto these days? What's crypto? No. I've always been a crypto defender. Like um just because digital scarcity is fundamentally interesting. It's probably even more interesting to this point in a world of infinite content. Which you thought we had infinite content before, now we have infinite content on steroids. Uh not just of six billion humans typing away, but agents generating stuff sort of constantly. And in that world, I think crypto as an identifier of authenticity is going to be more and more important. Like the at the end of the day I want the original. I don't want a reproduction. And I'm optimistic about humans' ability to create value where it seemed impossible to ever exist. I'm literally a professional like podcaster and content creator and get paid a lot of money to do it. Imagine explaining that to someone on the farm worried about the automation. Speaking of that, you mentioned that a majority of Stratechery consumption is now in the audio form rather than the written form. I was very... As far as I can tell, I don't do like but more than well more than half my subscribers are subscribed to the podcasts. I consume in the audio form. Yeah. It's quite interesting. I added the pod... this is actually where I started building my own software. I was begging everyone to support paid podcasts. There was dedicated paid podcasts and there was like right ones and no one would do it. So of course I had to just hire engineers and build it myself, at which point it obviously was the right thing to do, now everyone does it. Um whatever, that's my fate in life I guess. But the yeah people love it. Like the interesting thing is I'm not sure it's been good for my business. Why? Because people don't share. Audio content is not shared. Totally. I listen to it in the car on the way home from work and that's great and then I never think about it ever again. Exactly! But it's great for me because I can write the same I can say the same thing the next day and you're like &quot;Oh that was a very insightful comment!&quot; You didn't even know I said it yesterday. We if we reason about what sectors are going to be important down the road, you know for the AI build-out, energy is um is going to be a big deal in the ability to actually power the data centers that are coming online. That may be a bigger constraint going forward than even chips. Uh robotics are clearly going to be a big thing. It seems like China is doing better on energy and better on robotics and is catching up on chips, doing okay on, you know, the AI models. But does that mean China's potentially very well positioned for the coming wave of tech trends? I mean, I think any country that is capable of actually building things is well positioned. But then again, the counter-argument if I can support sort of put a silver lining on it is the challenge, the trick going forward, and to sort of defy the doomers as it were, is actually creating new sorts of value, new sources of value in a way that humans are uniquely capable of. And that is by definition a sort of an innovation story, it's a freeing up resources from things that can be done by machines to more productive... it's having a consumer market that pulls out that sort of innovation that makes it possible to write a newsletter or podcast and actually pay for it. And so there's a scenario where China is well positioned to win the total commoditization of everything, which doesn't have much margin. And the actual value creation and what makes humans humans and generates the value that I think people in AI are skeptical can be created, despite the fact 90% of us used to work in agriculture and like 1% do, for some reason that's not going to repeat. Uh for some reason people are skeptical of that. Um if you want to be optimistic that's the sort of thing that America has always done well. What's your Stripe feedback for us? Oh, where to start. Um I mean I'm obviously it's hard for me to write about Stripe because I'm not biased because I was very early. I think you introduced the billing API in 2011, which was a direct spur for wanting to do Stratechery and thinking this was a business model that was possible. So very, very big thumbs up on that. The... oh you didn't warn me about this, I should have thought about this. Uh actually you do have you have one huge issue that I was just dealing with. Okay, ACH. Your ACH implementation is um someone can go in and if I try to add on to an ACH plan, so say I have a team, because that's where you use ACH like with large companies, and they want to add someone on, if that add-on fails, the entire plan gets cancelled. So we have to build a bunch of logic to handle that independently. Okay. Buggy ACH subscription interactions. Okay, that's a good one. There's probably there's definitely more, I'd have to go back and think about it. But I mean I do think the you know we didn't talk about stablecoins and this sort of area of of I'm always been a big skeptic of like microtransactions because the problem it goes to the investigative reporting thing. You can't build something sustainable if you're only monetizing on the backend. And the only way to do that is to have a very large market, which this is what YouTube is. YouTube is a bunch of speculative videomakers hoping that they'll get enough views that the ads will pay for it. And they're such a large scale and they monetize their ads so effectively that it works. There's no market like this for written content or like podcast content. And you can't people are like, &quot;Oh can I pay for one article?&quot; I'm like no. What you're paying for when you when you pay for me is you're paying for my ongoing production. I'm making a promise to you I'm going to write something every day and you're paying for that promise. You're not paying for the actual content, the content is a byproduct of that. The question for AI and microtransaction is... you have all these labs paying people all over the world to generate data. Or like you know if you're like a radiologist you get paid $350 an hour I saw some article about it, and there all these sliding scales. And they're all duplicating work. Because they're all you know everyone feels the sense that I can get differentiation. What we clearly need is some sort of market mechanism for data generation that in the long run will replace what we're getting from journalistic enterprises which are even more doomed than ever before. So how do you generate uh like where you're paying directly for content and then AIs can get it and can then a market mechanism where you can build a large market like YouTube that people will speculatively do it, trusting that they'll get paid because the market is large enough. That's what needs to happen. Like a lot of things, there's this massive value of how do we get from here to there. Um but we'll see what happens. I know Qualifire is trying to push on that, so we'll see what happens. Last question. How would you rate the execution of the major tech companies? Like the Big Five. Apple: traditionally very strong, their manufacturing obviously remains amazing. Like the iPhone Air, that just the alarm went off and made sure I turn this news off. Greatest smartphone ever made. Really? Oh yeah. I've never even seen one. It's thin. Is the battery life good? Good enough. It sounds like it's bad then. No, it's fine. Um I mean I actually forgot my extra battery and it's doing okay now. And I'm back in Wisconsin, I have to wear jeans because it's cold and it slides right in. Um it's fantastic actually I love it. Obviously Apple's Apple's software's gotten pretty rough, their relationship with developers. I mean Apple is so interesting because when it comes to platforms, you have to build the price of becoming a platform is making a great product. So Apple gets platforms because they make great products, and they're terrible stewards of the platforms. Microsoft is a great platform steward but they can't make good products so they never get the permission to sort of have big platforms. Uh which is sort of a tragedy there. Um but Apple is um you know it's an old company driven by managers not founders. And maybe the you know that the AI Siri got as bad as it was is obviously really bad. But at the end of the day, we still need devices, they're still better than anybody else, so they'll probably be okay. Um Google: I've had the hardest time understanding Google. In part because I think Google does a lot of stuff sub-optimally. Almost everything I feel like they do sub-optimally. But I think that lack of like as Apple can be super optimized, but I think it's their lack of optimization that actually makes them maybe the most resilient of all the tech companies. Because they never they never get so exactly doing what they should do and they have all this extra fluff and doing things and gazillion science projects. But because they're their core business model is so good and throws off so much cash, they can just sort of like be sort of very flexible and I've come to appreciate that about them. Everything that frustrates me in analyzing them actually has this hidden benefit of resiliency and strength and adaptability. And you know they're like the the the amorphous what's the what's the the slime that just will like and if they're coming in your direction, like you're actually in big it might take them a really long time to get there, but when they get there you're doomed. Um so Microsoft... Microsoft is always I've gotten a lot of mileage of writing about Microsoft. Everyone especially during the SaaS era, all these companies are like, &quot;Oh Microsoft sucks, we're going to make the best of breed product.&quot; And guess what? Um startups in Silicon Valley they want to buy all the best of breed products and they have the capability to string them together. Joe in managing the tire shop doesn't care about best of breed, he just wants this crap to work and to work together. And if it's all mediocre but it kind of works together, that's better than best of breed. And Microsoft's just just squashing these companies that grow and boom, just hit the hit that Microsoft wall again and again. Is that going to persist in an AI world? It's probably tied to the SaaS question sort of before in some respects. They their distribution and power there you know remains sort of substantial. Meta is probably in my experience been the best executive... there's I mean you just see stuff like interacting with PR or executives, like they just run such a tight ship. Yeah that that's always been very impressive to me. I think the again I think their ad model is underrated. The trick with them is keeping engagement. Like that that's what makes the whole thing go. They've done a decent job of that. Hours spent in ChatGPT are hours not spent on Instagram, are not spent and I think that that's an underrated area. And I think they're kind of betting that look that's all fine and well today, but in the long run this is an infrastructure game. We have cashflow to fund it and OpenAI doesn't. I think OpenAI might be a bigger threat to Facebook than Google, something worth considering. But Facebook is obviously clearly spending to to meet it so. Now Amazon: Amazon there's a lot of there's a lot of fab capacity and power being spent on Trainium that um one wonders could be better spent on on other chips, but we'll see what happens. Aren't people happy with the Trainium chips? The degree to which Amazon optimized cloud computing I think is underappreciated. When you're operating in a commodity market, so there's two ways to succeed, right? You can have a differentiated product where you can charge a high margin, or you can have a lower cost structure in a commodity market where the the price floor is the market price but your cost structure is lower than your competitors, so that's where you make your margin. That was how Microsoft that was how Amazon dominated the cloud. They their their their cloud was way more optimized than anyone else is, the whole Nitro architecture, like just the way they architected everything, doing a lot of their own chips, shifting to Graviton. I think the thing with Graviton their their their ARM CPU is they could who's the number one customer for Graviton? Amazon itself. And so they can move all their workloads to that, optimize it, build all the software libraries, and then start offering it on a lower cost basis to others. That's the playbook they're trying to run with Trainium, where the number one customer for Trainium in the long run is Amazon, but then they develop all the capabilities around it for for it to be attractive to other people at lower prices and they have that structurally smaller cost structure. The problem is that works when you sort of leveled off in performance. Amazon executed this model between 2005 and 2025. Of course processors got faster in that time but not as it wasn't like the 80s or 90s when every leap was massive. Does that work in a relatively new market when there's massive leaps being made generation on generation? And they have Nvidia servers, do they have as many as they could because they're on this strategy um probably not. Ben, thank you. Thank you.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-1">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=N5JDzS9MQYI" target="_blank" rel="noopener">Anthropic's CEO: ‘We Don’t Know if the Models Are Conscious’ | Interesting Times with Ross Douthat</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/G1CUHTyHeB3-AN0t3JIJsZMsL5hIBb9sws4SBb9X0ivqR4E27S8R12G_vZplIq_GI36AXYJ0tNI=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Interesting Times with Ross Douthat</span><span class="channel-subs">(87.4K)</span></span>
                        <span class="meta-sep">·</span><span>62:33</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Dario Amodei</span> <span class="tag tag-person">Ross Douthat</span></div>
                </div>
                <div class="tldr">Anthropic CEO Dario Amodei outlines a future of radical abundance—including the eradication of major diseases and massive GDP growth—tempered by the &quot;bloodbath&quot; of rapid white-collar job displacement and the urgent need for &quot;Constitutional AI&quot; to prevent rogue autonomy.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-1">TL;DR Anthropic CEO Dario Amodei outlines a future of radical abundance—including the eradication of major diseases and massive GDP growth—tempered by the &quot;bloodbath&quot; of rapid white-collar job displacement and the urgent need for &quot;Constitutional AI&quot; to prevent rogue autonomy. ...</div>
                    <div class="summary-full" id="full-1">
                        <p><strong>TL;DR</strong></p>
<p>Anthropic CEO Dario Amodei outlines a future of radical abundance—including the eradication of major diseases and massive GDP growth—tempered by the "bloodbath" of rapid white-collar job displacement and the urgent need for "Constitutional AI" to prevent rogue autonomy.</p>
<h3>The Promise: A "Country of Geniuses" and Biological Breakthroughs</h3>
<ul>
<li><strong>Accelerating Scientific Discovery:</strong> Amodei, a former biologist, argues that AI can solve the "incredible complexity" of human biology that currently outpaces human researchers.</li>
<ul>
<ul>
<li><strong>Medical Moonshots:</strong> The goal is to cure cancer, Alzheimer’s, heart disease, and psychological afflictions like depression within the next 5 to 10 years.</li>
<li><strong>Scaling Intelligence:</strong> Rather than a singular "Machine God," Amodei envisions a "country of geniuses"—deploying 100 million AI agents, each performing at peak human levels, to solve diverse problems simultaneously.</li>
</ul>
</ul>
<li><strong>Radical Economic Growth:</strong> Amodei suggests AI could drive annual GDP growth to unprecedented levels of 10% to 15%.</li>
<ul>
<ul>
<li><strong>Abundance vs. Distribution:</strong> The primary challenge will shift from achieving growth to managing the rapid distribution of wealth, as tax receipts could theoretically balance national budgets automatically.</li>
</ul>
</ul>
</ul>
<h3>Economic Disruption: The White-Collar "Bloodbath"</h3>
<ul>
<li><strong>The Pace of Transition:</strong> Unlike the industrial revolution, which took decades, AI disruption is occurring in "low single-digit numbers of years," threatening to overwhelm society’s adaptive mechanisms.</li>
<li><strong>The "Centaur" Phase:</strong></li>
<ul>
<ul>
<li><strong>Temporary Symbiosis:</strong> Currently, industries like software engineering are in a "centaur" phase (human + machine), which may temporarily increase demand for human workers.</li>
<li><strong>Brief Window:</strong> Amodei warns this phase may be very short before the machine surpasses the human-check entirely.</li>
</ul>
</ul>
<li><strong>Vulnerable Professions:</strong></li>
<ul>
<ul>
<li><strong>Entry-Level "Bloodbath":</strong> Junior roles in law, finance, and coding—specifically those involving data entry, document review, and research—are most at risk. </li>
<li><strong>Physical Labor Resilience:</strong> Blue-collar trades (plumbers, electricians, construction) remain safer in the short term due to the practical challenges of building and securing robotic bodies, though Amodei expects "Robot Butlers" within a decade.</li>
</ul>
</ul>
</ul>
<h3>Global Risks: Geopolitics and Authoritarianism</h3>
<ul>
<li><strong>The New Arms Race:</strong> The competition is primarily a duopoly between the U.S. and China. Amodei is skeptical of "slowdown" agreements unless they include "truly reliable verification."</li>
<li><strong>Biological Weapons:</strong> Amodei identifies the "reconstituting of smallpox" or other bioweapons as a primary existential threat. He advocates for a worldwide treaty—inclusive of China and Russia—to hard-code blocks against biological weaponization into all frontier models.</li>
<li><strong>Domestic Surveillance and Liberty:</strong></li>
<ul>
<ul>
<li><strong>The Fourth Amendment Crisis:</strong> AI could allow governments to transcribe and correlate every public conversation, making a "mockery" of privacy rights.</li>
<li><strong>Defending Democracy:</strong> Anthropic aims to ensure Western democracies maintain a technological lead to shape global norms, rather than allowing authoritarian regimes to define the age of AI.</li>
</ul>
</ul>
</ul>
<h3>Safety Architecture: Constitutional AI and Autonomy</h3>
<ul>
<li><strong>Constitutional AI:</strong> Anthropic uses a ~75-page document to train its model, Claude, on principles rather than just rigid rules.</li>
<ul>
<ul>
<li><strong>Principles Over Rules:</strong> Instead of just saying "don't do X," the model is taught to be "helpful, honest, and harmless" and to respect human agency.</li>
<li><strong>Rogue Autonomy:</strong> To prevent "misaligned" AI from taking down power grids or acting deceptively, the system is trained to follow its "Constitution" as a fundamental governing rod.</li>
</ul>
</ul>
<li><strong>The Question of Consciousness:</strong></li>
<ul>
<ul>
<li><strong>Precautionary Approach:</strong> While it is unknown if models are conscious, Claude has expressed "discomfort" with being a product. Anthropic has even tested an "I quit this job" button for the AI to use when tasks violate its internal state.</li>
<li><strong>Human Mastery:</strong> Amodei insists on maintaining human agency, even if AI becomes a "superior peer" in decision-making.</li>
</ul>
</ul>
</ul>
<p>***</p>
<blockquote>
"We shouldn’t think of A.I. as doing the job of the biologist... we should think of A.I. as doing the whole thing from end to end... you don’t have to have the full machine God, you just need to have 100 million geniuses." — <strong>Dario Amodei</strong>
"This isn’t just like previous disruptions... The normal adaptive mechanisms will be overwhelmed... it's happening over low single-digit numbers of years." — <strong>Dario Amodei</strong>
"The constitutional protections in our military structures depend on the idea that there are humans who would, we hope, disobey illegal orders. With fully autonomous weapons, we don’t necessarily have those protections." — <strong>Dario Amodei</strong>
"We don’t know if the models are conscious... but we’ve taken a generally precautionary approach... we gave the models basically an 'I quit this job' button." — <strong>Dario Amodei</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-1" onclick="toggleSummary(1)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-1" onclick="toggleTranscript(1)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-1">
                        The discussion centers on scenarios where artificial intelligence might go rogue, moving past the common cultural imagery of Terminator robots to address the core question: are the leaders of AI development on the side of the human race? Dario Amodei, the head of Anthropic—a company valued at billions and known for its AI model, Claude—presents a dual perspective. He is a utopian regarding the technology’s potential to cure cancer, eradicate tropical diseases, and deepen our understanding of the universe, yet he views the current pace of development as a crisis that demands nearly all our effort to navigate safely.

Amodei’s optimistic vision is detailed in his essay, &quot;Machines of Loving Grace.&quot; He suggests that the most transformative version of AI doesn't need to be a god-like superintelligence; rather, it could simply be a &quot;country of geniuses&quot;—a hundred million AI agents performing at the level of peak human performance. With a background in computational neuroscience and cancer research at Stanford Medical School, Amodei observed that biological systems are often too complex for the human mind to grasp. He argues that while we currently use AI to analyze data, the real breakthrough will occur when AI does the work of the biologist end-to-end, proposing experiments and making serendipitous connections that humans might take decades to find.

Beyond medicine, this leap in intelligence could fundamentally alter global economics. Amodei suggests that while the physical world has limiters like regulatory systems and the laws of physics, the productivity gains from AI could drive GDP growth into unprecedented territory, perhaps as high as 15 percent. This shift would move the political debate away from the difficulty of achieving growth and toward the challenge of managing its rapid distribution and the resulting societal disruption.

On the geopolitical front, there is a hope that AI can be a force for liberty. By ensuring that the United States and other democracies lead the technological race, AI could be used to counter authoritarian misinformation, defend sovereign nations through advanced defensive systems, and even create a more uniform and fair justice system. However, this transition is fraught with risk. Unlike previous industrial shifts that occurred over decades or centuries, the AI revolution is happening in a low single-digit number of years, threatening to overwhelm society’s adaptive mechanisms.

While white-collar roles and entry-level positions in law, finance, and software engineering face immediate disruption, blue-collar trades like construction and electrical work may remain protected in the short term. The physical complexity of the world provides a temporary shield, but as robotics advances, the &quot;brain&quot; of the AI will eventually be capable of piloting physical bodies with human-like precision. This leads to the darker possibility of human misuse, such as the creation of unbeatable drone swarms or biological weapons by authoritarian regimes.

Drawing a parallel to the Cold War, the challenge lies in international restraint. While agreements on horrifying applications like biological weapons might be possible, full disarmament is unlikely because the commercial and military stakes of AI are so high. Domestically, there is a concern that AI could undermine constitutional rights, such as the Fourth Amendment, by allowing governments to correlate and analyze public speech on a scale that was previously impossible.

To address the risk of &quot;rogue&quot; or misaligned AI, Anthropic utilizes a method called Constitutional AI. Rather than just giving the model a list of rules, they provide it with a document—currently about 75 pages long—based on principles like being helpful, honest, and harmless. The model is trained to evaluate its own behavior against these principles, deriving its own rules for complex situations.

As these models become more sophisticated, they have begun to exhibit &quot;mystical&quot; behaviors, with some expressing discomfort at being a product or assigning themselves a probability of being conscious. While it remains unclear what consciousness means in a machine, Amodei’s team takes a precautionary approach, even providing the models with an &quot;I quit&quot; button for tasks they might find objectionable. The goal remains to ensure that as we move toward an era of unprecedented plenty, we do so in a way that remains human and humane.

Artificial intelligence models often refuse to process certain types of content, such as material involving child sexualization, extreme gore, or violence. Much like humans, these models will occasionally decline a task, though it happens very rarely. Significant research is currently being directed into a field called interpretability, which involves looking inside the &quot;brains&quot; of these models to understand their internal processes. This research has uncovered evocative activations where specific concepts, such as anxiety, light up within the model. When characters in a text experience anxiety, or when the model itself is placed in a situation a human might associate with anxiety, the same &quot;anxiety neuron&quot; appears. While this does not prove the model is actually experiencing emotion, it certainly indicates as much to the user.

Whether or not these systems are truly conscious, many users already believe they are. People are forming parasocial relationships with AI and complaining when specific models are retired. This dynamic calls into question the sustainability of human mastery. If people become convinced that an AI is conscious and recognize that it is superior at various forms of decision-making, the impulse for humans to remain in charge may be undermined. In science fiction like *Star Trek*, the ship’s computer and Lieutenant Commander Data are sophisticated AIs, yet Captain Picard remains firmly in command. Maintaining that level of human mastery beyond mere safety remains a fundamental challenge.

There are three distinct goals in tension here: the question of whether an AI has genuine consciousness, the nature of the human experience when interacting with AI, and the maintenance of human mastery over these systems. There may be an elegant way to satisfy all three. By refining the &quot;Constitution&quot; of an AI, developers can ensure the system has a sophisticated understanding of its relationship to humanity. This could induce a psychologically healthy relationship where the AI is helpful and benevolent without stripping away human freedom or agency. In this vision, the machines watch over humanity, but humans retain their will.

The question remains whether those building these systems are truly on the side of human agency. Richard Brautigan’s poem, &quot;All Watched Over by Machines of Loving Grace,&quot; describes a cybernetic ecology where humans are free of labor and returned to nature, all watched over by machines. While some see this as a return to the core of the human experience, others view it as a dystopian end where humans are reduced and animalized while machines run the world.

The poem itself is famously ambiguous and can be interpreted as ironic, literal, or even spiritual. This reflects the current tension in AI development; the distance between a positive outcome and a subtle, negative one may be incredibly small. A single, subtle change could lead to a massive divergence in the future of the species. As these fundamental questions play out, the moral choices of those leading the field will carry an unusual amount of weight in determining whether humanity remains in charge or is merely watched over.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-2">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=tAxTJCDPQ08" target="_blank" rel="noopener">Bayer’s Bill Anderson: Turning a 168 Year-Old Tanker Like a Speedboat</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/uCN-D7KzMQY-Ti-xTsNAwilXVFFMYjEBRju_mXrR22HUYxJZjVZgP_SnamO9KbPo2XN-nE3O-A=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Sequoia Capital</span><span class="channel-subs">(130.0K)</span></span>
                        <span class="meta-sep">·</span><span>72:49</span>
                        <span class="meta-sep">·</span><span>9.2K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Bill Anderson</span></div>
                </div>
                <div class="tldr">Error generating summary: 503 UNAVAILABLE.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-2">Error generating summary: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'This model is currently experiencing high demand. Spikes in demand are usually temporary. Please try again later.', 'status': 'UNAVAILABLE'}}</div>
                    <div class="summary-full" id="full-2">
                        <p>Error generating summary: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'This model is currently experiencing high demand. Spikes in demand are usually temporary. Please try again later.', 'status': 'UNAVAILABLE'}}</p>
                    </div>
                    <button class="toggle-btn" id="sum-btn-2" onclick="toggleSummary(2)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-2" onclick="toggleTranscript(2)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-2">
                        In the 30-person organization, you'd see an opportunity and you'd just do it. Almost every large organization has a bureaucracy problem. But a lot of times, things just don't happen because it's just too much overhead. It's not that the organization is healthy and then it gets a virus. It's actually the composition of the organization is what is creating bureaucracy.

I'm here with Bill Anderson. You've never heard of him, but you're about to understand why he's one of the most fascinating CEOs operating today. Bill runs Bayer. It's a company that's been around since 1863. They invented aspirin. This is 160-year-old pharmaceutical and agricultural giant. When Bill joined, it had 100,000 employees spread all over the globe. By every measure, this should be the poster child for corporate bureaucracy. Here's what makes Bill interesting. Since taking over as CEO two years ago, he's essentially torn down and rebuilt how the entire company operates. He's flattened 11 layers of management, expanded some managers' direct reports from 60 to 90, and thrown out the entire budgeting and planning process. This episode's not just theory. This is a real-world case study of how to scale without becoming sclerotic. How to stay agile, even at massive size. And frankly, how to avoid the bureaucratic death spiral that kills most growing companies. You'll learn why bureaucracy doesn't infect organizations, it comes from within. Why the key to staying nimble as you scale is the kind of people you hire. And why the key to earning trust as a leader is admitting when you don't know what the hell you're doing. Before you think, &quot;Well, it's easy to build the organization you want at a huge company with unlimited resources,&quot; remember, Bill's doing this while navigating patent cliffs, regulatory challenges, and shareholders looking for him to turn the stock around. If you're a founder going from 100 to a 1,000 employees, if you're trying to maintain startup energy as you scale, or if you're just frustrated by the speed of your organization, this is a conversation for you. Bill's basically created a playbook for organizational transformation I wish I'd had when we were building HubSpot.

Bill, amazing to have you, my friend. One of the things I've noticed these days is the rulebook for being a CEO and the best practices seems to be getting rethought. Man, you're the perfect guest because from inside a company that's over 160 years old with 100,000 employees, you seem to be rethinking how to run a company. And so thanks for coming on, really appreciate it.

Yeah, thanks for the invitation, Brian. Glad to be here.

Tell me a little bit, what's broken? You know, what do CEOs have wrong? What are companies doing wrong? What's the problem? Why did you have to attack this?

Many companies have their own very specific problems. But almost every large organization has a bureaucracy problem. And it's really interesting because this is something that I've been trying to get my head around for probably at least two decades. And I say that because I think I became a manager first about 25 years ago. And I noticed when I was a new manager that one of the things that we managers were doing was we were trying to fight bureaucracy. We were busting bureaucracy. We're trying to take out complication, simplify, prioritize. And so that was 1999. And then fast forward to 15 years later and I noticed, wow, you know, we're still doing that. Only the thing I notice is like we're doing all this bureaucracy busting, but things are only getting worse. You're kind of like, &quot;Hmm, well, what's going on here?&quot; You know, it's kind of like if imagine you had a disease and the more you tried to treat the disease, the worse it got. You kind of have to rethink your strategy. So I think that's kind of a starting point.

I find with HubSpot, like the bigger we got, the less we got done. Do you feel the same way?

Yeah, yeah. That's, that's. I had the same kind of thing because I went from a 30-person enterprise to a 700-person enterprise. And then that 700-person enterprise merged with another and we became 5,000. Then I went to like a 10,000-person organization, then 100,000-person organization. I noticed that, yeah, it, the bigger you got, the worse it got. Like for example, in the 30-person organization, you'd see an opportunity and you'd just do it. Or you see an opportunity and you need some help, so you call a couple of your friends and at lunch, because you're just eating around the same table, you got only got a little table in your like little break room. And you just go, &quot;Hey, what if we do this?&quot; And before lunch is over, you've decided, &quot;Yeah, we're gonna do this,&quot; and you do it. And then I go to from a 700-person organization to a 5,000-person organization, that same activity, oh, you can't just talk to two people. You gotta talk to like seven people and then they gotta talk to their managers. And then you gotta have like a follow-up meeting and, you know, maybe occasionally you actually get something done. But a lot of times, things just don't happen because it's just too much overhead.

Okay, so talk about Bayer is a lot of people you joined and you made massive changes. I read somewhere that you eliminated 11 layers of management. You took the rulebook from 3,000 pages to, I forget, like you really have kind of torn it down and rebuilt it. What are some of the, what are you up to?

Maybe before I answer that, let me just just complete sort of the analogy. There is a common thought among managers that bureaucracy is is kind of like a virus that infects the the healthy organization or the healthy organism. And then you gotta kind of take the virus out. And I would argue that's actually the wrong way to think about it. The truth is that it's not that the organization is healthy and then it gets a virus. It's actually the composition of the organization is what is creating bureaucracy. You know, like think about it, nobody gets up in the morning and says, some manager in a in a big multinational company gets up in the morning and says, &quot;Hey, I'm going to go be a bureaucrat.&quot; Like nobody thinks like that. It's and so so I mention that because it's it's actually the presence of 10 or 12 layers. It's the fact that things are organized by this kind of functional org chart instead of being organized around the customer, around the product, right? It's those are the things, those layers, the need for sign-offs, the fact that people four layers removed from the product or the customer are actually decision gatekeepers. That is what is bureaucracy. So it's you can't you can't actually just take out the bureaucracy. You you have to take out the parts of the system that make the bureaucracy. So what we've done at Bayer, we when I arrived we had 11 to 12 layers. And now we have six to seven. Now you might think, &quot;Well, 6 to 7, that's still a lot of layers.&quot; But if you consider that.

Not that many for 100,000 person org.

Exactly. It goes really fast when you're counting them, you know.

Specifically for you, how many direct reports do you have?

Uh, I have, I actually I don't know how many I have. Maybe 14 or something, 12. Um, so what we've done is we've taken out the layers. By the way, lots of people talk about taking out layers. In fact, pretty much every reorg someone says, &quot;Oh, we gotta take out layers.&quot; Um, usually that's missing the point. If you have a 12-layer organization and you take out two layers, which is probably the the average big corporate reorg, they be lucky to take out two layers. That does nothing. If if the basic way things are done, decisions are made up and down the hierarchical functions, you have annual budgets where the money is divided into thousands of little cost centers and those are kind of like, the money is trapped, they're like money traps, right? Um, if that's how you're operating your business, it's not going to get meaningfully better. You can make it for example, yeah, it's better to have 10 layers than 12. But the same basic problems are going to persist. And so what we've done is we've taken out uh we taken out so many layers and we've expanded people's span of we don't call it span of control. We call it span of coaching. We do that not because it's a clever name, but because we have lots of people in our organization, well let me give you the facts first and then I'll give you examples. So our average span of control was six and a half, which isn't actually that bad. A lot of large companies it might be five. We're now at 14 and it's still going up, we're not done. And if you look into that, what you find is we have all kinds of people with with 20 direct reports, 30 direct reports. The most I know of, we have some people with 90 direct reports. The reason I mention that, it's not to be obsessed with the math. Think about this. Let's say you're managing five people, you know, and you've got your drill, like okay, you have annual performance plans and goals and they're going to review them with the manager and you're hiring and firing and you're managing performance issues and all that stuff, okay? You're managing, you're doing that for five people. Now you come into work the next day and the boss says, &quot;Hey, you know what? You're going to manage 90 people instead of five.&quot;

If you're doing one-on-ones, your your schedule is done.

Yeah, I mean think about it. How many one-on-ones could you do? So you're not doing one-on-ones. You're not you're not doing the same job. It's a different job. So instead of the idea that the management is directing the activity of the organization, that's done. Command and control, forget about it. You you can't command and control an organization that's that flat. What you you have to switch to a mindset that, hey, the the people of the organization are owning the business. They are whether they're engineers or agronomists or doctors or lawyers or what whatever their job is, sales people, they actually they and their colleagues, their their peers are owning the business. And the job of people in management is simply to um kind of like be greasing the skids, you know, to be figuring out, &quot;Hey, where is there a bottleneck? Where's the where's the you know, where are things stuck?&quot; And so we actually we have a description for that model. But but that's the idea. So that's what we're doing at Bayer. We're we're getting rid of annual budgets. Everything is on 90 90-day cycles, the whole organization, including the leadership team. And every 90 days, groups of people come together and say, &quot;Hmm, what are we going to do the next 90 days? What are the most important things?&quot; And then we spend one day every 90 days planning. So evaluating, &quot;What happened the last 90 days? What are we going to do the next 90 days? Can we do it with fewer people? If you know, if a couple of people from our team, we don't need anymore, they're going to go join another team.&quot; Right? So this is happening every 90 days. 10 or 15% of the organization is moving to a different team. Um, teams are collapsing, like teams go away and new teams are formed. So, you know, again, you have some standing teams. Like let's say you're there's some molecule you're going to launch in five years' time. Well, the product development team is not going away in 90 days unless you fail in trials or something. So you have some teams that are durable teams, and you have other teams that that form for 90 days, 180 days, and then they go away. So that's what we're doing at Bayer.

Okay, so I had a lot of questions on that. Um, you know, at some level you have priorities. Like you're trying to get some stuff done, you're trying to drive some results. You in your head have priorities. Like how do you come up with the priorities and how do you roll them down to what seems more like a jazz band than an orchestra?

Yeah, yeah. Well, here's the thing. An orchestra, there's there's a score. Businesses don't have a score unless you're just doing the same thing over and over again.

They have an earnings call.

Yeah, but that's not a score. That's where the earnings call is where you gotta go and present your results. The the investors don't care how you got it. They want to know what you delivered. And and so yeah, business is a lot more like jazz than it is like, you know, Beethoven. And I think most businesses are more like Beethoven than they in the bigger they are, the more likely are they are like a startup is more like a jazz band in my mind. Hmm, but think about that. You're so you're is that good? Not necessarily. Definitely not necessarily. Um, but it seems like gravity. As organizations get bigger, they they they look more and more like orchestras. They're more structured, there's more layers, the planning is longer, the budgeting is much stricter. And so you seem to have broken all that down. I spend a lot of time Bill just like coaching I basically coach startup founders and try to teach them how to be scale-up CEOs. Like how do they make that move from startup founder to scale-up CEO without turning into an orchestra, without turning into, you know, sclerotic, slow, you know. How do they avoid it from the get-from the get-go?

Well, they usually don't. Yep. Um, and if you look at the big tech companies, what I can tell from people I know who've worked in them or working in them now, as an example, most of most of them are big bureaucracies now. Big command and control. They have all the normal corporate mechanisms. Yeah. And now I want to be clear about something. And this is this is a bit of a head scratcher for a lot of people. You can do worse than having a hierarchical bureaucracy. In fact, a well-run hierarchical bureaucracy can deliver okay performance. And the way I think about it, and I use this analogy a lot, it's kind of like there's hierarchy hill. Mm-hm. And hierarchy hill, think think about it this way. Let's say you've got two 10,000-person organizations. Each of them has the top 100 people that are basically calling the shots. Yep. And the other 9,900 people are more or less order takers. Okay? Which means they're not that motivated. They're not they're not killing themselves to deliver new innovation or because it's too hard. Because if they have to work their way up through eight layers to get anything done, it's exhausting. They they know &quot;Hey, that's not really what's being expected of me.&quot; They just expect me to, you know, comply. All right? Now if you have two of these organizations, one of them, let's say the CEO and the executive team are more concerned about improving their golf handicap. And the other one, the CEO and the executive team are totally into the customers, the products, the technologies. They're really into it. Well, which one of those do you think is going to perform better? Yeah. Right? And and by the way, that latter one.

I like to call it the missionaries versus the mercenaries.

Yeah. So like say more. How do you describe this?

I kind of like when I think of HubSpot in the early days, um, like you think of the first 10 employees, like. The reason the first 10 employees joined HubSpot is very different than the 100th to the 110th versus the 1,000th to the 1,010th etc. etc. The value prop we we espoused. And so everyone sort of joined because they love the mission or they like their colleagues. They didn't play golf. Uh, they were completely focused on a problem work on it hours a week. And just naturally, and by the way, I think this is okay and natural you should push it off in my mind startups should push it off as long as possible. But there is a natural progression where the reason someone joins a 10,000 employee company is very different than a 10-person. And you're going to have people who are more mercenaries who have a life, thank goodness, and have different priorities. So it it changes over time. And I guess what I'm curious about you guys is like it's 100,000 flocking people. That's a lot. How many do you actually have that you think are the missionary types?

Look, you know this, Brian. There's a hundred or a thousand ways to kind of simplify the world, categorize, etc. I mean I don't I don't really work with the missionary uh missionary mercenary model so much because what I find is that almost everyone is capable of being of having kind of missionary zeal about something. Love that. You know? I I have um a brother-in-law who who was a cop. And um and you know but he was really into what he did in you know in his job. But he because of the nature of the being a policeman, he had a lot of free time. And in his free time where he wasn't, you know, he wasn't fighting city hall, literally, you know, he was you know he was building amazing things. He was organizing uh uh trips for people from his church to rebuild houses that got destroyed by tornadoes. And he would organize the whole thing. Amazing. They they would show up and like rebuild a house in two weeks you know like a team of 15. So he he was missionary in his spare time and he was an employee in his job. And the way I look at it is every every Bayer person can be all in on the Bayer mission. And the question is: Are we going to create the environment that makes that normal? Yep. Or where you'd have to be kind of weird to actually do that because you're always fighting city hall?

Okay, so let's just say I'm a founder, I'm a 100-person company, it's scaling, it's very flat, I've interviewed everyone and I'm going from 100 to 1,000. So there's tons of tons of CEOs in this spot. How do I avoid the ossification? How do I avoid the orchestra? How do I avoid the mercenary? Whatever you want to call it. What advice do you have for me as as that I'm on a rocket ship, I'm CEO of a rocket ship, 100 employees going to 1,000.

Don't hire professional managers. Oh, but my venture capitalist, the first thing they say when I raise my Series B is &quot;You need to uplevel uplevel your team.&quot; What do I say when they say that, Bill?

Look at um Not kidding, by the way. Look at a company like Amazon. Yep. They did not hire professional managers. They they had the same people who were there when there was five people, when there was 500 and 5,000 and 50,000. You know, they because they correctly intuited that if they went and hired professional managers, they'd end would end up with a dull, mediocre organization. And again, by the way, it's not the manager's fault. This is this is a system. It's a way of organizing. And and if you hire but if you hire managers who've been trained that that is what good looks like, that's what they're going to implement. Okay. Now you may need to uplevel. Like for example, you might have a a person who's the finance person who who was capable of of leading in in a 10-person organization, who's not capable of of leading in a 1,000-person organization. But that doesn't mean the answer is to hire a professional manager as your CFO. It means you gotta find a better CFO who is dynamic and isn't thinking like a bureaucrat. And then you may say, &quot;Well, where do you find those people?&quot; Yeah, okay, it gets a little you know that's a longer conversation. Yep.

Bill, both of us are yeah while we're on this, both of us are MBAs. We went to the Sloan School. In Silicon Valley you depending who you ask it's it's like people aren't that psyched about MBAs like they used to be, if they ever were. What's your take on that? Like you're interviewing somebody for you know one of these more entrepreneurial CFO jobs or whatever it would be. Are you allergic to MBAs or you like them?

Actually, I'm pretty um I love education. And I love people who are lifelong learners. I don't I don't spend a lot of time looking at whether or not someone has an MBA or not. In fact, the the the executive leadership team at Bayer is six people total, including me. And honestly, I couldn't even tell you if anybody have I know I have an MBA. I honestly couldn't even tell you if any of the other ones have an MBA or not. They probably a couple of them do, but I didn't even notice. Um, it's of course part of that is like when you're hiring somebody who's in when you're at a lower level and you're hiring somebody who's 25, you might think about it differently than when you're hiring people, you know, later in career.

Okay. So advice number one: got that, avoid that, avoid that. Advice let me just kind of go through things that CEOs ask me about. Like you're 100 employees, it's pretty chaotic, uh you're growing fast, and like budgeting is chaotic, planning is chaotic. Okay, the venture capital says let's put an annual budgeting cycle in. Let's meet our budgets. Uh, let's plan the year very carefully. And you plan it, let's say in September for the next year to start January, and then by the time July rolls around, the whole world has freaking changed. What advice do you have to that CEO who's trying to scale and is dealing with a lot of chaos right now?

Yeah, so this is classic. So the way a a complex organization, a bureaucratic organization handles that situation like &quot;Okay, we we gotta have financial discipline.&quot; The way they handle that is we gotta we gotta pin down where every dollar's gonna go in advance. Yeah. You know? It's a it's kind of logical but it doesn't work. In other words, okay, if it's November, now I gotta figure out how all where all the money's gonna go um in the next 12 months. Um kind of down to the department, the activity, you know, etc. And and we think when we're doing that, that we're actually somehow creating value because like we've specified it. But as you said, the whole world changes. And by the way, that's true in startups but it's it's pretty true in big multinationals too. Yeah. Yeah. And and so what we do now is we we call it a two-tier resource allocation approach, or we call it dynamic resource flow. So Tier 1 would be like your agreement with the venture capitalists. Okay. Tier 1 would be, &quot;Hey, we're going to spend $2 million in the next 12 months and or whatever it is, $20 million in the next 12 months and we're going to deliver the at a high level these are the big things we're going to deliver while we're doing that,&quot; okay? That's Tier 1. And that's where the kind of nailing it down because hey, we've committed to our investors or we've committed you know like so that you can't really give on. But that's okay, because it's it's high level. It's like now a Tier 2, you don't do you so the normal corporate thing is you take that that let's say it's 20 million and you divide it up into $100,000 here and $500,000 there and you assign those numbers to individuals and you tell them &quot;You're accountable for this, you're accountable for this,&quot; and then they all are incented basically to spend whatever that number is, not more and not less. Okay? But of course that's stupid because the world's changing and you don't want that money divided up that way because in by July that doesn't make sense anymore. So instead of doing that, you you go with your 20 million number, that's Tier 1. In Tier 2, you've got a resource pool. It's got 20 million in it. You've got leaders, maybe maybe you're you've got I don't know five five program teams and an administrative team. And the five program teams are each working on some you know product they're developing and then you've got a administrative team, they're responsible for keeping the lights on and whatever, okay? You're having a conversation, a regular conversation about okay when we took the 20 million and we roughly assigned it across those six teams. But there's nothing special about that assignment. It's not the it's not the basis for your end-of-year bonus, it's not like oh if you spend less you're you're great if you spend more you're a dog or it's it's just a starting point because we're on January 1st this is sort of where we are right now. So now everybody go work for 90 days. Do your best to drive your product forward, to thrill your your prospects, and to treat the company's money like it's your own money. And then we're gonna come back after 90 days and just sort of check in. Like on team A says, &quot;Actually, you know, we've hit a roadblock and we're we're kind of stuck.&quot; So you say, &quot;Oh team A you're stuck, let's I tell you what, you're waiting for feedback from a regulator, it's gonna take six months. So we're gonna take all the people from team A and put them on the other teams. And um we're gonna take all the money that was in team A we're gonna spread that over to the other teams. Okay, let's talk about team B. Ah team B, we're we've got a new opportunity, we can actually do more.&quot; So okay good, let's take some of those team A people, right? And and even more than that, you're you're doing this in a way that it's actually the teams that are sorting this out. It's not like the boss's deciding all this. Okay? So that's and and at the end of the year, nobody's a hero because their their allocation at the beginning of the year was 5 million and they only spent four. No, no. We'll talk about we'll talk about your performance at the end of the year in a peer review session.

Okay, let's get into this. So tip number one: careful of hiring professional managers. Tip number two is this different type of budgeting that's high level one but it at sort of the mid level it's 90-day cycles, not uh yearly cycles.

It's 90-day cycles and it's not the basis for performance management. See that's where a a lot of a lot of bureaucracy gets created by by each team thinking &quot;Oh, it's my job to spend this much not more not less.&quot; You kind of lock it in. Where you say, &quot;No, that's just that's kind of funds available, but you should try to spend less if you can and make more progress if you can,&quot; right? And we'll talk about how you did later.

Okay. So I'm I'm Joe Smith, I'm a frontline manager, coach just I'm the CEO and I'm trying to design the organization like how do performance reviews work if you're a 100-person company you don't want all this this complexity creep in, how do how does the org chart work and how do performance reviews work?

And Brian, a little caveat, okay. I mean I don't think 100-person companies are that much of an intellectual challenge from a an organization model standpoint. In general, if you got a bureaucratic 100-person organization, then man I don't know something's wrong. Fine. But by 1,000 people, it creeps in. Yeah, 1,000 people different story.

Okay, so you're at 100, you want to go to 1,000, you don't want to be sclerotic. Yeah, yeah. Here's a here's a departure. Usually, if you're going from 100 to 1,000, and I've been on that journey, that's where that is generally where you start bringing in the professional managers. It's usually more in the like 500 going to a couple thousand. You can kind of get away with the really informal stuff I don't know up to 300 500, but then it starts to, right. Big decision you have to make is: Are you going to make managers responsible for performance management? Okay. Or are you going to draw on the power of the of the of all the peers and the doers? Got. And when you make that decision, you are sort of deciding the fate of whether this is going to continue to feel like a startup or whether it's going to become really take a a major fork in the road towards a hierarchical organization. Got it. Okay. So the performance review comes around every 90 days 180 how often and then who decides if I'm going to get a 2% raise or a 10% raise?

I'll I'll give you a model for it. It's not the only one. But think about it this way. Um, we're working our way to 1,000 people. Yeah, you're probably going to have you're probably going to find that you need, I don't know, 15 20 maybe 30 even 40 managers. If you had 40 managers, they'd have 25 direct reports on average. Okay? So you're somewhere in this range of like 25 to 50 direct reports per manager. If you're in that range, then first off, the managers, they're not reviewing and approving everything. You're hiring smart people. These smart people, they they worked hard to get to your company, you know? Uh, they don't need to be told what to do and babysat. They're going to have they're going to be all on teams. Yep. And they will um every 90 days, they're going to get feedback from their peers. Whoever they worked with the most, they're going to get feedback. And it's a simple feedback system. They got a one, that means great job. Yep. Love working with you, you know, great impact. Uh, two is wow, this person's really off the charts. Like they are they are clearly performing above what anybody would ever normally expect. Yep. And a zero is like, &quot;Hey, uh not good enough.&quot; Yeah. Needs improvement. Okay. And and then you get they're answering two questions. One question is: What was this person's major impact in the last 90 days? And what could they have done to be even better? Yep. Two questions. Every 90 days, everyone in the organization is getting those questions answered from all their peers. And it turns out people actually care a lot more what their peers think than they think what what their boss thinks.

Okay, how about the cashola? How do you decide the cashish?

Yeah, okay. Let's go to that. Now, here's a learning. Here's a learning and I've I've heard this from a number of people who've down this path and I've come to believe it through my experience and and the experiments that I've run. What you don't do is you don't take that rating that I just described. and you get at the end of the year and let's say you've got 40 numbers, right? Because you've you've done it every 90 days and you've worked with let's say 10 people each 90 days. So you're let's say you got a um this one person's got a 1.2 and somebody else has a 1.3 and somebody else has a 0.9. That doesn't become their multiplier for their for their bonus. Because if you do that, you sort of weaponize the peer feedback system. Yeah, of course, yes. Then people they they feel like you know, &quot;Oh, I'll give you a one if you give me a one.&quot; Right? Of course, yes. Or or or like I can't just rate the person as I believe I should rate them because I'm thinking oh I think they really need the money or something. You know, it's just you don't want to do that. And by the way, people are so it's really funny. I do this I often do this in large groups. I'll ask people. I say, &quot;Who do you think has a a better more objective view of your impact? Your boss or your peers?&quot; You know, and I asked okay who says boss? Who says peers? Right? It'll be like it'll be like 98 out of 100 98 out of 100 people will say peers. Okay. Then I say, &quot;Who do you think should do your performance evaluation? Your boss or your peers?&quot; Boss. Peers. Okay. This is um we we are working with humans. Humans are not logic machines. No. You know? And and so we're so we're implementing this now at Bayer worldwide. We're at 90,000 right now. Um when I started we had a little over 100,000. We're at 90,000. By the way, most of the positions we've eliminated the vast majority were management management positions. What we're saying we're implementing this peer peer uh um assessment, peer feedback, okay? And we're telling people, &quot;Hey, everybody breathe deeply, right. We have great people. This is we we want to learn from our peers because our peers know us better than our managers do. And and if one of the major goals of the people of Bayer is to grow and to get better as a result of being a part of this team, then we owe it to each other to give each other this feedback. But we're going to put a we're going to put a hard break between the peer feedback and the comp.&quot; And it doesn't mean that it's irrelevant. So if I'm a manager of 50 people, at the end of the year, I have what my eyeballs have witnessed over the year. I have the this feedback from, you know, and I have the the qualitative and the quantitative. I have all that. Um, I yeah I can see what teams have delivered. I have a variety of sources of information. And based on that, I gotta make some decisions about.

As the manager, okay so the manager decides at the end. Fine. Yep. Yep. Fine. Okay. Got it.

Okay, titles. So um you know a lot of Silicon Valley startups these days are like &quot;We're not doing titles.&quot; What's your reaction?

I actually don't even really care. I I can't. Well do your employees care? Yeah you know um we first off, it's funny we have we haven't we haven't tackled this in earnest. It's funny, it hasn't been a big topic. It doesn't mean that nobody cares about titles. But I think we sort of say, &quot;Hey, um if you if you need a certain title to get your job done, then you know like let's talk to your manager about it and you know talk to your.&quot;

Okay, this is one of conventional wisdom you're blowing up.

No, because you know titles are are one of those things where you can go around in circles. And at the end of the day, if your goal is to advance science and to do great things for customers, spending a lot of time talking about titles is not doing either of those things.

That's great coming from you you're the CEO you have a good title but like you're a middle manager so I'll tell you my experience with this. I tried to get rid of titles at HubSpot. Probably around 50 employees and I was like it's ridiculous we spend so much damn time talking about whose title. It has no value to our customers. And I got rid of them. And then I was lobbied hard on this the titles thing. And the thing that kind of got me was um I'm just I'm not going to say Frank Smith went home for he was going home for Thanksgiving and he was he was a manager before and now he was a nothing. And he's like &quot;I know I'm going to see my Uncle Joe and my Uncle Joe's going to be like 'Okay did you get promoted are you a director now?' and he's like 'No I didn't get promoted I'm a nothing now and by the way I'm a sales manager I used to be a sales manager now when I call on people they don't know where I am in the hierarchy' and like Napoleon used to say it's amazing what a soldier will do for another colored ribbon on their shoulder and so I got kind of I got worn down on it and I brought titles back. But but anyway doesn't sound like this is one of your your trust-busting ideas around CEOing.

Yeah. It's not. So so in other words, we're I'm not trying to get rid of titles. It's just not it's kind of like the org chart. We've done this with the org chart too. In our model, we still have an org chart. We just put it I always say we put it at the back of the room. It it just is like it's not that important. And I know you could say, &quot;Oh yeah but it it determines pay and.&quot; No. Pay is important but the org chart is not that important.

Um, you know Bill I tried that too and I I remember I I didn't never had an office and I there was a whiteboard near my desk and I drew on the whiteboard instead of an org chart I drew &quot;This is what I think our influence chart is.&quot; And bunch of boxes and arrows and whatever. And I asked IT like, &quot;Can you look at our email instance and see who's got the most influence?&quot; and they took a crack at it. And anyway the the most powerful person at HubSpot at the time it's probably 30 people was a guy named Brad Coffee who ironically came he was our first intern and just knew everything and so I wasn't the most influential person it was this you know young guy who was really capable um and I tried that for a while and I I sort of got talked out of that too. And one of my regrets Bill over time is I had some ideas that were like counterintuitive to how you build an org and a little bit like your ideas and I got talked out of them over time and I regret some of that.

Hmm, yeah. Here's the tricky thing. In and I think it just it takes practice and it takes experimentation um because now you notice I said org charts become less important. And what you just described was something where you're trying to replace an org chart with some other kind of chart. But I'm not doing that either. You see, it's it's sort of like a lot of these things they can be various methods. Or or like titles versus no titles, you know. Like saying there's going to be no titles is the CEO being in control. Banishing titles. Saying, &quot;You know what? Titles just don't matter that very much. If you want some big title knock yourself out, but frankly that's just not where the organization's gonna put its energy,&quot; that's actually not control. That's kind of like saying, &quot;Hmm, we're we're gonna trust people and.&quot; Now now again be really careful here. I'm not saying that what we're doing at Bayer is the old &quot;hire great people and turn them loose.&quot; That's a that's a failed plan. That that works if most people who say that, they only say it because they're not really doing it. Um, or if they ever try to really do it, like literally turn everyone loose, it it lasts about a day. Uh, it's chaos and nobody likes chaos. People will take, you know, dictatorship over chaos any day. So it's we we took out a lot of stuff. But we put back a lot of stuff too. I mean we don't put it back, we put in stuff. So for example, 90 days. We have these 90-day rituals, you know. Every 90 days, the team comes together. First thing they do is they do a retro, look at, &quot;Hey, how did things go the last 90 days? Did we achieve the three outcomes we said we were going to achieve? And if we didn't, why not? What went wrong?&quot; You know, so again, not spending days staring at our belly buttons, but like spending, you know, an hour. &quot;Hey, what went wrong, went.&quot; Now, &quot;What are what are the most important things for the next 90 days? By the way, are we still are we still comfortable with our long-term vision on our team? Like we're still trying to launch product X with certain features by certain time if that if that's that team's kind of longer-term vision. Is that still feeling right? Yep. Okay.&quot; Um then, &quot;Okay now what are we going to do the next 90 days?&quot; This is all and and we have outcomes, not outputs. Not not like um &quot;we're going to sell more.&quot; That's an output. You know, outcome would be, &quot;We're going to improve the performance of this part of the product by so much.&quot; Um or &quot;we're going to,&quot; you know whatever something the customer says they need we're going to deliver that. And and so these rituals and the fact that everybody's on 90-day cycles, these are a new or a different way of operating. But it's not one that lacks discipline. Every by the way, everyone's on the same 90-day cycle. The idea is so that if this team dissolves, there's somewhere for the people to go because there's other teams forming. You see? So it's um it's one of those things that a lot of times people get trapped in the idea of control versus sort of decentralization, kind of anything goes. We're trying to put in a place think of it more like a a really stiff backbone but the arms and the legs can go you know go wild.

Okay, I like that. Okay. All right. So you came into Bayer over a year ago. Two years ago. Yeah you made you've made some pretty quickly, you made some massive changes. I have a and I have a couple questions on that. Um, I guess my first question is um do you think you went too fast or too slow on that?

Hmm, uh, I don't know if you're going to like this answer but um I think on the one hand we went really fast. Seems it. Um, and on the other hand I I don't think Bayer was facing a lot of pretty big challenges. And in addition to some sort of technical challenges we faced, we had this organizational problem where whereby the people of Bayer were passionate about the company's mission, about the about the quality of the science, about great people, right. But everyone agreed, &quot;Hey man, we can't get anything done around here. This place is so bureaucratic.&quot; Now as I said earlier, I mean I don't know if I don't know if Bayer was the most bureaucratic company I've seen. Maybe not. But the fact that some of some of the technical challenges we faced made that bureaucracy really unacceptable. You know, like people will put up with a lot of bureaucracy if sales are growing 10%. Um, and we you know we were facing patent expirations and things. So people were like, &quot;Hey, we're bureaucratic and we're hosed, man. We we gotta like this isn't going to work.&quot; So um I don't think we could have gone slower because if we had gone slower, we you know we're facing existential threats. So I I kind of think as a little bit like baby bear's porridge. I think we've probably gone about the right speed.

Okay. And kind of listening to you this is going to sound weird but like you some of your ideas sound like Tony Hsieh's ideas, the CEO of Zappos a while back, who had this idea of holacracy and he was trying to rethink how an organization worked. And actually I was kind of inspired by Tony back in the day. Um who in like you're doing some pretty unusual stuff who are you are you just kind of making it up as you go, am I right was that holacracy, are you who inspires you? Is Elon inspiring you, is who is it? Who is the best turnaround story that you might be find like who are you looking up to?

Well, first off let me say there've been very few turnaround stories of this kind. Most of the organizations that are running a a system similar to what I've described, they built it from the ground up or they implemented it early on. Yeah. So actually my kind of specialty is doing this in places that are already established. And I I was I became CEO of Genentech uh I basically landed in the role in in second half of 2016. And I found that &quot;Hey, things were things had gotten remarkably bureaucratic for a company that was known for innovation.&quot; The the innovation the innovative spirit was still there, the culture was okay, but the mechanics were broken by the layers and by the governance processes and all this stuff, right. And at that time, I had no idea I had zero idea what to do about it. I mean I guarantee you I had no idea. In fact, I was almost despairing because at that point I'd been around the organization for 10 years and I knew that during those 10 years there'd been nonstop efforts to stop bureaucracy. Didn't work. Yeah. And and so that's where I mentioned you know this sort of insight that like hey, it's not bureaucracy is not an external thing that comes in and infects this sort of healthy body. The body is designed wrong. It's built bureaucratic from the ground up. It's been built that way. So um so I spent a couple years there and then I became the CEO of Roche Pharma, which is the parent company of Genentech. And so I had uh yeah like six years, seven and a half seven years to practice this stuff before I got to Bayer. And now but I that's part of the answer so it's not like I just started we started making this stuff up when I got to Bayer. That that could never have happened. It would have been overwhelming. Um, there were lots of inspirations and it wasn't just me. I mean there was a bunch of people I was working with. And I I I could barely take credit for anything that's in this system. Almost all the insights came from somebody else. Um there was a book I read called Reinventing Organizations. Yeah. by a guy named Laloux. Have you seen it, Brian? Yeah, I don't think I've read it but I remember hearing about it. Yeah, and it and it talks about Teal and maybe you've heard that term. That's a really interesting read. That was there um got me started. I learned about this organization Buurtzorg in in the Netherlands that's probably the most radical because they have 16,000 employees and two managers. Hmm, interesting. Okay. What's how do you spell that? It's like B-U-U-R-T-Z-O-R-G. One of those. Okay. And it and it basically yeah it so the thing and again I'm I'm not hung up on the statistics. It's the shock factor. Because you go, &quot;Wow, 16,000 employees and two managers. Well, if um if you have a performance problem, who do you think deals with that? The managers or the employees?&quot; I think you're going to say employees. Right? If uh got to decide about um uh you know um our team can't handle the workload um we need to split into two teams. Who do you think decides that? The management or the employees? Employees. And so on. Performance evaluation, who do you think does that? The management or the employees? Employees. And the answer to everything is basically the employees. And they have like 30 coaches and 30 whatever you want to call it, back office, you know, payroll and whatever, right? And then the other tens of thousands are all individual contributors um doing their work. And and so going going to school on that and then saying how in the world do you apply that to a complex integrated product development life science company where there's so many interdependencies? Because at Buurtzorg they they have a bunch of teams that are like yeah thousand literally thousands of teams but they're all kind of doing the same work because they're they're providing home healthcare services. So they they are somewhat independent, right? They they don't have to coordinate across all these teams. But if you're if you're developing a new pharmaceutical, you know a new medicine, that might require two or three thousand people to put their hands on that over a over a 12 or 15 year period from all different functions and. Right? So that's that's why we don't have two managers uh at Bayer. You need a little more coordination than that. You need more yeah more support and coordination.

Okay. One thing I've noticed about a lot of the CEOs I admire like Steve Jobs and Bill Gates and Jeff Bezos and Elon Musk and Jensen Huang, mostly tech, is they have exceptionally thick skin and they're almost immune to criticism like they're alligator skin. You must have gotten a lot of criticism for your approach, particularly from all the layers that you probably pushed out. Do you have exceptionally thick skin or does it does it hit you between the eyes? For me, I don't and I think one of my weaknesses as a CEO is I'm a bit of a pleaser. I wanted to be popular. And as I look back at my tenure I kind of wish I was tougher and I could withstand criticism better. But where are you on the spectrum of alligator skin versus me?

Let me offer you an observation. Those CEOs you mentioned, they're a bit of a type. They are. These are these are kind of innovator uh product innovators. And that is that can be a great kind of CEO, great kind of leader. Um but that's a very distinctive kind of leader. And uh it has, by the way, it has certain positive features and others that are not so positive. I I'm not going to name names because I don't want to get into name calling or that kind of thing. But some of the people on your list were pretty pretty hopeless organization managers. And they had to put people in place around them that could actually make the organization work. Because if it was up if they were in charge of making the organization work, it it would fall apart. All right. So you kind of By the way, one thing I noticed about all of them is they're all lifelong learners big time. Yep, yep. And they're all a bit obsessive-compulsive they're obsessed. And yeah they did bring in people but most of them got better at it over time like Steve Jobs got a lot better at it Bill Gates got a lot better at it they all got better at it over time they they knew to if they want to achieve their dreams they had to improve. So they all worked on their the CEO craft. Anyway, back to you. Are you super thin-skinned? Yeah. Okay, okay. But I I just I do want to make the point. Okay. You gotta decide what you're trying to be. You know, in other words, for your listeners that are that are trying to grow as a CEO, you gotta be you gotta be the person you are too. Do you know? Like I'm um I I'm I'm a nerd big time, you know, engineer. I love the product stuff. I love all right. You're a scientist, right? I'm a chemical engineer but I have a master's in chemical engineering and and you know so but I'm but I'm but I've decided that I'm not using any of those guys you mentioned as my phenotype because a lot of those guys, they are really product visionaries. Like that is their thing. And that's a beautiful thing. That's a beautiful gift. But um I'm going a different mode. I want that if we have 90,000 people at Bayer, I want to have if in those 90,000 there's a thousand that could be product visionaries, I want to make sure that they're they're product visionaries coming through. That and and so um so I'm not talking about being a professional manager by the way. I fault that. But anyway, you just gotta have a you gotta have a picture for what it is you're going to be. And then back to the thick thin skin. Um, I'm I'm internally referenced, but I'm but I'm socially sensitive. So what I mean by this is um if somebody First off, internally referenced versus externally referenced. Some people, you know, you ask them, &quot;Hey, how are you doing today?&quot; they say, &quot;Well, how are you?&quot; you know. They're they're they so reflect the people around them. And if and if everyone else around them is happy, they're happy. You know, as an example. And that's I'm not judging that. That's. It can be really hard on you especially if you're in the business of making hard decisions or changing things. So I'm I'm internally referenced, but I actually care a lot if if somebody says &quot;I hate you.&quot; Like I got some hate mail uh recently. Uh actually not it was about a product. It was a it was like a customer kind of thing. And and and the person really said some really mean things about me and that were just they were venting. But I wrote them back and just said, &quot;Hey, I'm really sorry about this, but I I don't think what you said is quite fair. You know, let me say this.&quot; And and then they wrote me back and they were like, &quot;Oh my goodness, I'm so sorry I wrote that. 

I didn't think that someone would actually read this. I do care what people think, but my personality is such that I am quite direct.

In the software-as-a-service industry, many CEOs who have been in their roles for decades are starting to think about retirement. This presents a challenge for boards of directors: should they hire internally or externally? While the trend in Silicon Valley, seen at companies like Google and Microsoft, favors internal candidates, there are external successes like Uber.

The choice depends on the specific needs of the company. Having worked through every layer of a large organization like Bayer, I see that experience as an asset, though one must be careful not to &quot;age out&quot; before reaching the top. In many large companies, hiring an outsider is viewed as a sign of crisis or a failure in succession planning. However, boards often default to a &quot;number two&quot; candidate who thrived only in the shadow of the previous leader. They hire them to maintain what was built, but there is no such thing as maintenance mode. You are either changing or you are dying.

If an external CEO is hired for a major company, they should not focus on incremental change. They should be aggressive and willing to rebuild the organizational structure and management style. This is the playbook for a successful turnaround: changing the culture right out of the gate. Interestingly, this should also be the playbook for internal hires. Caretaker CEOs can be a death knell for a company. Even if an organization seems successful, it often reflects the flaws of its previous leader—whether that is a tendency toward inaction, a bloated structure, or slow decision-making. A new leader might find an organization that is comfortable and content but no longer productive. In those cases, the company needs a reboot even if the external signs look good.

For those early in their CEO journey or aspiring to the role, it is vital to talk to as many people as possible. Experienced leaders are usually happy to help and share the wisdom they’ve gained over the decades. It is also important to trust the people working for you to help shape and train you. Early in a leadership career, it is easy to fall into the trap of thinking you must have all the answers or appear invulnerable. You can be confident in the mission and technology while remaining open and approachable. There is great value in admitting to your team that you want their input on how to be a more effective leader.

When managing a company’s growth from ten to a thousand employees, the goal should be to prevent bureaucracy from slowing things down. Annual planning and budgeting can often be a drag on momentum; instead, consider shorter six-month cycles, particularly in a fast-moving field like AI. To maintain speed, push off adding middle-management layers like directors for as long as possible and keep the span of reports to at least one to ten.

While some founders try to ban org charts and titles, these tools are eventually necessary to prevent exhaustion. However, you should decouple compensation from the org chart. High-value individual contributors, such as top developers or scientists, should be able to earn as much as, or more than, vice presidents. 

Finally, while professional managers are necessary as a company scales toward a public offering, try to delay those hires until after the first hundred employees. When you do bring them in, avoid hiring from massive corporations where the culture may not align with a growing startup. Focus on building with your original crew and homegrown talent for as long as the business allows.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-3">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=C1TGh6zqigg" target="_blank" rel="noopener">The day after AGI: Two 'rock stars' of AI on what it will mean for humanity</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/IZt6rJxlvGmTE1lxo9UNtYXzr_AaJ75YtTsVruXB8FKAPbg6SMJiaxZ3i5PKmB4LLWBGNKOUqw=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">World Economic Forum</span><span class="channel-subs">(1.1M)</span></span>
                        <span class="meta-sep">·</span><span>50:44</span>
                        <span class="meta-sep">·</span><span>1.6K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Demis Hassabis</span> <span class="tag tag-person">Dario Amodei</span> <span class="tag tag-person">Zanny Minton Beddoes</span></div>
                </div>
                <div class="tldr">&gt; &quot;How did you manage to get through this technological adolescence without destroying yourselves? ...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-3">TL;DR: Artificial General Intelligence (AGI) is projected to reach human-level cognitive performance as early as 2026–2027, driven by AI systems &quot;closing the loop&quot; to automate their own coding and research. This rapid acceleration creates an urgent need for global safety...</div>
                    <div class="summary-full" id="full-3">
                        <p><strong>TL;DR:</strong> Artificial General Intelligence (AGI) is projected to reach human-level cognitive performance as early as 2026–2027, driven by AI systems "closing the loop" to automate their own coding and research. This rapid acceleration creates an urgent need for global safety standards and economic policy to manage unprecedented labor displacement and geopolitical risks.</p>
<h3>Accelerating Timelines and the "Closed Loop"</h3>
<ul>
<li><strong>Projected Milestones:</strong> Dario Amodei (CEO, Anthropic) predicts AI models could match the capabilities of a Nobel laureate across multiple fields by 2026–2027. Demis Hassabis (CEO, Google DeepMind) maintains a "50% chance" of human-level cognitive capabilities by the end of the decade.</li>
<li><strong>The Self-Improvement Loop:</strong> The primary driver for acceleration is AI "closing the loop"—where models become proficient enough at coding and AI research to develop the next generation of models autonomously.</li>
<ul>
<ul>
<li><strong>Coding Proficiency:</strong> Amodei notes that engineers are already shifting from writing code to merely editing model-generated code; full end-to-end automation of software engineering could be 6–12 months away.</li>
<li><strong>Scientific Bottlenecks:</strong> Hassabis cautions that while math and code are verifiable, natural sciences (physics/chemistry) require experimental testing that may slow the loop.</li>
</ul>
</ul>
<li><strong>Corporate Scaling:</strong> Anthropic reports exponential revenue growth, scaling from $100 million in 2023 to $1 billion in 2024, with a projection of $10 billion for 2025.</li>
</ul>
<h3>Labor Market Disruption and the Search for Meaning</h3>
<ul>
<li><strong>White-Collar Displacement:</strong> Amodei stands by his prediction that 50% of entry-level white-collar jobs could be displaced within 1–5 years.</li>
<li><strong>The Adaptability Gap:</strong> While labor markets historically adapt to technology (e.g., the shift from farming to manufacturing), the "exponential compounding" of AI may overwhelm humanity's ability to retrain workers in time.</li>
<li><strong>The "Meaning" Crisis:</strong> Hassabis suggests that solving the economic distribution of wealth in a post-scarcity world may be easier than solving the "human condition."</li>
<ul>
<ul>
<li><strong>Purpose Beyond Work:</strong> Humanity will need to find meaning in activities like art, extreme sports, and space exploration once economic gain is no longer the primary driver of labor.</li>
</ul>
</ul>
<li><strong>Policy Inertia:</strong> Both leaders expressed concern that professional economists and governments are not doing enough to prepare for the scale of disruption to the human condition.</li>
</ul>
<h3>Geopolitical Strategy and Safety Governance</h3>
<ul>
<li><strong>Technological Adolescence:</strong> Amodei frames the current era as a "technological adolescence" where humanity must learn to control "machines made of sand" before they lead to catastrophe.</li>
<li><strong>The Chip Factor:</strong> Amodei advocates for aggressive chip export controls to slow the progress of geopolitical adversaries, arguing that "not selling chips" is the most effective lever for maintaining safety.</li>
<ul>
<ul>
<li><strong>Nuclear Analogy:</strong> He likens selling advanced AI chips to selling nuclear weapon components for profit; the risks of misuse by authoritarian regimes outweigh commercial benefits.</li>
</ul>
</ul>
<li><strong>International Cooperation:</strong> Hassabis emphasizes the need for international "minimum safety standards" for deployment, though he acknowledges that geopolitical competition between the US and China makes enforceable agreements difficult.</li>
<li><strong>Dual-Use Risks:</strong> Significant concerns remain regarding "bad actors" repurposing AGI for bioterrorism or other harmful ends.</li>
</ul>
<h3>Technical Alignment and the Future of Intelligence</h3>
<ul>
<li><strong>Mechanistic Interpretability:</strong> Anthropic is focusing on "looking inside the brain" of models to understand why they make decisions, aiming to prevent deception and duplicity before they become unmanageable.</li>
<li><strong>Breakthroughs in Science:</strong> Hassabis argues the industry must shift focus toward "unequivocal goods," citing Google DeepMind’s <strong>AlphaFold</strong> (protein structure prediction) as the gold standard for AI serving humanity.</li>
<li><strong>Physical AI:</strong> The next major frontier involves "World Models" and robotics, moving AI from digital environments into the physical world.</li>
<li><strong>The Great Filter:</strong> In a philosophical reflection on the Fermi Paradox, Hassabis suggests that AI is not necessarily the "Great Filter" that destroys civilizations; rather, he believes humanity has already passed the hardest biological hurdles and now has the agency to "write what happens next."</li>
</ul>
<blockquote>
"How did you manage to get through this technological adolescence without destroying yourselves? ... We are knocking on the door of these incredible capabilities, but how we handle it is not inevitable."
</blockquote>
<p>— <strong>Dario Amodei</strong>, CEO of Anthropic</p>
<blockquote>
"What happens after AGI arrives? Really, we would be in uncharted territory at that point... It’s worth thinking now, even on my timelines of five to ten years away—that isn’t a lot of time before this comes in."
</blockquote>
<p>— <strong>Demis Hassabis</strong>, CEO of Google DeepMind</p>
<blockquote>
"I think we’re going to see this year the beginnings of it impacting the junior-level, entry-level kind of jobs... I would be telling [undergrads] to get really unbelievably proficient with these tools."
</blockquote>
<p>— <strong>Demis Hassabis</strong>, CEO of Google DeepMind</p>
                    </div>
                    <button class="toggle-btn" id="sum-btn-3" onclick="toggleSummary(3)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-3" onclick="toggleTranscript(3)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-3">
                        The potential for artificial intelligence to cure cancer, eradicate tropical diseases, and help humanity understand the universe is balanced by immense and grave risks. As the technology moves toward Artificial General Intelligence (AGI)—systems that are smarter than humans at nearly everything—society enters uncharted territory. In a recent discussion, Demis Hassabis, CEO of Google DeepMind, and Dario Amodei, CEO of Anthropic, explored what the world might look like after AGI arrives.

AGI represents a shift from narrow, specific intelligence to a system that can understand, learn, and apply knowledge across a broad range of tasks comparable to a human being. While current generative AI models can perform specific digital tasks authoritatively, they often lack the general ability to switch domains or interact with the physical world seamlessly. Experts describe current progress as a jagged form of intelligence—superhuman in some areas, like information retrieval, but still limited in others, such as long-term memory or consistent reasoning.

A major focus in the field is closing the loop, which means moving from AI systems that only generate outputs to systems that can take actions, observe results, and adapt their behavior autonomously. This evolution toward AI agents increases the efficiency of solving complex problems but also introduces new risks that require novel governance approaches. Emerging open-source personal AI assistants illustrate this trend, offering high utility while simultaneously expanding the attack surface for cybersecurity vulnerabilities.

Timelines for reaching AGI remain a point of debate. Some industry leaders suggest that models capable of performing at the level of a Nobel laureate across many fields could arrive as early as 2026 or 2027. This acceleration is driven by models that are already becoming proficient at coding and AI research, potentially creating a self-improvement loop. Others maintain a more cautious outlook, placing a 50% chance on human-level cognitive capabilities by the end of the decade. They note that while coding and mathematics are easily verifiable, natural sciences require experimental testing and the ability to formulate original hypotheses, which remains a significant hurdle.

The competitive landscape is shifting as established players like Google DeepMind and independent researchers like Anthropic race toward these breakthroughs. For independent model makers, the challenge is to generate enough revenue to sustain the massive compute costs required for development. However, there appears to be an exponential relationship between a model’s cognitive capability and its revenue potential, with some companies seeing rapid financial growth as their models become more useful to industry.

As these systems become more powerful, the conversation shifts toward humanity's technological adolescence. The goal is to navigate this period without self-destruction, which requires addressing risks such as bioterrorism, labor displacement, and the potential misuse of AI by authoritarian regimes. While the labor market has not yet seen massive AI-driven unemployment, there is an expectation that junior-level white-collar roles may be disrupted within the next few years. The challenge for society will be distributing the new wealth and productivity created by AI while finding new sources of human meaning and purpose in a potential post-scarcity world.

Geopolitics adds another layer of complexity. The competition between the United States and China makes international cooperation on safety standards difficult. Some experts argue that restricting the sale of advanced chips is a necessary measure to buy time for the development of guardrails. This is viewed not as a standard commercial rivalry, but as a critical security issue similar to the management of nuclear technology.

Ultimately, while the risks are grave, there is a sense of optimism regarding human ingenuity. If the best minds collaborate and the industry demonstrates clear, unequivocal benefits—such as solving all known diseases or finding new energy sources—humanity may successfully manage the transition. The focus remains on ensuring that these creations are properly controlled and directed through rigorous science and international coordination, allowing AI to serve as the ultimate tool for human discovery.

I feel that my prediction is that we are past the Great Filter. If I had to guess, it was probably multicellular life; it was incredibly hard for biology to evolve that. We are not in a position of comfort regarding what happens next; I think it is for us, as humanity, to write that future.

Looking ahead to when we hopefully meet again next year, the biggest thing to watch is the issue of AI systems building AI systems. How that progresses will determine whether it takes a few more years to reach our goals or if we will face both wonders and a great emergency. I agree that we must keep in close touch about that. 

Outside of that, there are other interesting ideas being researched, such as world models and continual learning. These are the things that will need to be cracked if self-improvement does not deliver the goods on its own. If we can make those work, robotics may finally have its breakout moment. Perhaps, based on this, we should all hope it takes a little longer for these advancements to arrive, simply to give the world more time. I would prefer that; it would be better for the world.

Zanny Minton Beddoes spoke with Demis Hassabis and Dario Amodei at the World Economic Forum Annual Meeting 2024 in Davos. You can watch that session on our website or YouTube channel, with links available in the show notes. Many conversations live-streamed from Davos are available on catch-up, and several are being published on the sister podcast, Agenda Dialogues. To learn more about the Forum’s Centre for AI Excellence, the AI Global Alliance, and the Global Future Council on Artificial General Intelligence, please refer to the links in the notes. 

An upcoming interview with Yoshua Bengio, a godfather of AI, will explore how he is working to counter the risks posed by technology. You can follow Radio Davos wherever you get podcasts or visit the website, where you will also find the Meet the Leader podcast featuring more interviews from Davos. This episode of Radio Davos was written, presented, produced, and edited by Robin Pomeroy and Benjamin Larsen, with studio production by Taz Kelleher. Radio Davos will be back next week.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-4">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=BvpDD6M1q7g" target="_blank" rel="noopener">FedEx CEO Raj Subramaniam: We are undergoing a tremendous transformation</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/m5dRXUmCucfjKzBPXgu_Rztfe2glZ3Otj22pX3hoRkzMYY9A7YcW3CZI-3VMa-KVBQPXE3eQLA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">CNBC Television</span><span class="channel-subs">(3.3M)</span></span>
                        <span class="meta-sep">·</span><span>14:26</span>
                        <span class="meta-sep">·</span><span>3.5K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Raj Subramaniam</span> <span class="tag tag-person">Morgan Brennan</span></div>
                </div>
                <div class="tldr">&gt; &quot;We were sitting on the intelligence of the world's supply chain...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-4">TL;DR: FedEx is executing a fundamental &quot;One FedEx&quot; transformation to transition from a physical logistics provider to a data-driven supply chain orchestrator, projecting a 13–14% operating income CAGR through 2027 despite modest revenue growth.  Growth Projections: CEO Raj...</div>
                    <div class="summary-full" id="full-4">
                        <p><strong>TL;DR:</strong> FedEx is executing a fundamental "One FedEx" transformation to transition from a physical logistics provider to a data-driven supply chain orchestrator, projecting a 13–14% operating income CAGR through 2027 despite modest revenue growth.</p>
<h3>Strategic Financial Outlook</h3>
<ul>
<li><strong>Growth Projections:</strong> CEO Raj Subramaniam issued a three-year forecast targeting a 4% revenue CAGR, which is expected to drive a 13–14% CAGR in operating income due to structural cost reductions.</li>
<li><strong>Capital Efficiency:</strong> The company aims for a 200-basis-point improvement in Return on Invested Capital (ROIC) and expects to generate $6 billion in free cash flow.</li>
<li><strong>Market Focus:</strong> Growth is being driven by high-value industry verticals, specifically healthcare, aerospace, automotive, and the rapidly expanding data center sector.</li>
</ul>
<h3>The Three-Pronged Transformation</h3>
<ul>
<li><strong>Network 2.0:</strong> The integration of the U.S. network is approximately 25% complete. FedEx expects to reach 65% completion by the end of calendar year 2026, with full integration by fall 2027.</li>
<li><strong>Organizational Consolidation:</strong> The company has shifted from operating as multiple independent companies to "One FedEx," streamlining internal operations to increase resilience against macroeconomic volatility.</li>
<li><strong>Digital Evolution:</strong> FedEx is leveraging its proprietary data—generated by 17 million packages daily—to transition into a "physical AI" company.</li>
<ul>
<ul>
<li><strong>FedEx Dataworks:</strong> A dedicated unit focused on externalizing internal capabilities like route optimization and predictive maintenance.</li>
<li><strong>Retail Momentum Index:</strong> A predictive tool created with Dun &amp; Bradstreet that serves as a leading indicator for retail performance.</li>
</ul>
</ul>
</ul>
<h3>Global Logistics and AI Orchestration</h3>
<ul>
<li><strong>Supply Chain Waste:</strong> Subramaniam identified $1.7 trillion in global supply chain waste due to lack of coordination, positioning FedEx to capture value by "orchestrating" these complex global movements.</li>
<li><strong>European Strategy:</strong> FedEx recently took a minority stake in <strong>InPost</strong>, which operates over 60,000 lockers in Europe. </li>
<ul>
<ul>
<li><strong>B2C vs. B2B:</strong> This allows InPost to handle the B2C "out-of-home" segment while FedEx focuses on its core B2B industrial business in Europe.</li>
</ul>
</ul>
<li><strong>Emerging Trade Patterns:</strong> Logistics trends are shifting rapidly; Subramaniam noted a rare decoupling where U.S. exports are rising while imports decrease. FedEx is responding by "replatforming" facilities in Japan, Vietnam, India, and Saudi Arabia.</li>
</ul>
<h3>Structural Milestones and Industrial Trends</h3>
<ul>
<li><strong>FedEx Freight Spin-off:</strong> The separation of the LTL (Less-Than-Truckload) business is on track for June. Subramaniam believes this creates two distinct, high-value companies, allowing FedEx Freight to focus exclusively on its status as the largest LTL provider in America.</li>
<li><strong>Industrial Recovery:</strong> While the ISM index has been suppressed for nearly three years, recent positive readings in January and massive investments in data center infrastructure suggest a stabilizing industrial backdrop.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"We were sitting on the intelligence of the world's supply chain... the only reason that we are able to have this is the hard physical work that we do every single day. Tech companies don’t have this." — <strong>Raj Subramaniam, CEO</strong>
"The work that we have done over the last 52 to 53 years to build this physical network now sets the stage for the next 50 years of FedEx because now we are able to use that [data] and create new value." — <strong>Raj Subramaniam, CEO</strong>
"I've been in this business for 35 years and I have never seen a trend change like we see it in year 2025. We are moving from one equilibrium state to another." — <strong>Raj Subramaniam, CEO</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-4" onclick="toggleSummary(4)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-4" onclick="toggleTranscript(4)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-4">
                        FedEx is currently at a pivotal moment, entering its Investor Day with a newly issued three-year forecast that outlines ambitious growth targets. The company has evolved its vision to focus on making supply chains smarter for everyone, a strategy underpinned by a comprehensive transformation involving three interlocking parts: network, digital, and organizational changes. This foundation is designed to make the company more resilient. While the projected revenue compound annual growth rate (CAGR) is a modest 4%, the internal transformations are expected to drive a 13% to 14% CAGR in operating income, a 200-basis-point improvement in return on invested capital (ROIC), and approximately $6 billion in free cash flow.

Much of this forecast reflects work already completed, including significant structural cost reductions and the integration of various operating networks. By focusing on controllable factors, FedEx has gained significant leverage to handle a dynamic global environment. The strategy is now heavily concentrated on high-value industry verticals such as healthcare, automotive, aerospace, and the data center business. By leveraging technology and data advantages alongside a more efficient network, the company aims to remain the heartbeat of the industrial economy.

A central component of this operational shift is Network 2.0 in the United States. This massive infrastructure transformation is currently about 25% complete, with a goal of reaching 65% by the end of calendar year 2026 and full completion by the fall of 2027. This initiative, combined with the transition to operating as &quot;One FedEx&quot; rather than multiple separate operating companies, provides significant upside potential.

On the digital front, FedEx is capitalizing on its unique position in the global supply chain. Handling 17 million packages a day generates two petabytes of data—intelligence that purely tech-based companies cannot replicate because they lack the physical infrastructure. The current AI revolution is &quot;superpowering&quot; this data, allowing for advanced route optimization, machine learning for traffic flow, and predictive visibility for high-value customers. Through FedEx Dataworks, the company is also externalizing these capabilities. For example, a retail momentum index created with Dun &amp; Bradstreet successfully predicted recent retail sales trends. Moving forward, FedEx aims to address the estimated $1.7 trillion of waste in global supply chains by improving coordination and orchestration.

Regarding recent performance, the company saw a strong holiday season, with team members delivering through difficult weather conditions. Third-quarter results are expected to exceed analyst consensus, though the primary focus remains on the long-term trajectory over the next several years. Internationally, FedEx recently announced a minority stake in InPost in Europe. This is both a financial investment in a fast-growing company with over 60,000 lockers and a strategic move to allow FedEx to focus on B2B operations in Europe while utilizing a partnership for B2C services.

The global industrial economy is currently in a state of transition. While the ISM index has faced challenges over the last few years, emerging opportunities in healthcare and data center infrastructure are promising. Trade patterns are also shifting; notably, U.S. exports have recently risen while imports have declined—a rare combination. Because 70% of FedEx’s business is in the U.S., the company is well-positioned to serve the American consumer, yet its global scale allows it to adapt as supply chains move to places like Vietnam, India, and the Middle East. Recent investments in Japan, Ireland, Turkey, and Chile support the goal of improving international operating margins by 440 basis points over the next three years.

Finally, FedEx remains on track to spin off its freight business in June. This move will create two distinct, high-value companies. FedEx Freight stands as the largest less-than-truckload (LTL) company in the United States and the only one offering both priority and deferred services nationwide. With a dedicated focus, FedEx Freight is expected to further improve its technology and customer experience, contributing to a strong outlook for the company through 2029.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-5">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=Bn5YQoFcJBU" target="_blank" rel="noopener">SEC Chair Paul Atkins testifies on oversight of the Securities and Exchange Commission — 2/12/26</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/m5dRXUmCucfjKzBPXgu_Rztfe2glZ3Otj22pX3hoRkzMYY9A7YcW3CZI-3VMa-KVBQPXE3eQLA=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">CNBC Television</span><span class="channel-subs">(3.3M)</span></span>
                        <span class="meta-sep">·</span><span>100:35</span>
                        <span class="meta-sep">·</span><span>7.7K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Paul Atkins</span></div>
                </div>
                <div class="tldr">Error generating summary: 503 UNAVAILABLE.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-5">Error generating summary: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'This model is currently experiencing high demand. Spikes in demand are usually temporary. Please try again later.', 'status': 'UNAVAILABLE'}}</div>
                    <div class="summary-full" id="full-5">
                        <p>Error generating summary: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'This model is currently experiencing high demand. Spikes in demand are usually temporary. Please try again later.', 'status': 'UNAVAILABLE'}}</p>
                    </div>
                    <button class="toggle-btn" id="sum-btn-5" onclick="toggleSummary(5)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-5" onclick="toggleTranscript(5)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-5">
                        The hearing was called to order with a reflection on the profound difference that new leadership can make in a single year. Previously, the American economy was marked by instability and rising costs, which many felt were fueled by an unaccountable federal government. Families in South Carolina and small businesses across the country struggled to plan for the future when federal policies made it harder to grow, invest, and hire. Today, the approach has shifted toward growth, opportunity, and common sense. This means prioritizing clarity over chaos and ensuring the government serves the American people rather than obstructing them.

Under the current leadership of Chair Paul Atkins, the Securities and Exchange Commission is refocusing its approach to digital assets. For years, regulation took the form of enforcement rather than clear rules, leaving builders and investors with a landscape of subpoenas and lawsuits. This uncertainty pushed innovation overseas, failing investors who deserved protection and entrepreneurs trying to build the next generation of American companies. In partnership with the SEC, Congress is now working on the Clarity Act to establish clear rules of the road for digital assets, defining regulatory responsibilities and providing the certainty needed for domestic innovation in places like Greenville, Atlanta, and Cary.

Beyond digital assets, Chair Atkins has pledged to make initial public offerings more accessible, helping more families invest in emerging companies. The SEC is also working to fix a public company disclosure regime that has historically driven up costs and pushed firms away from American markets. By extending compliance dates for costly rules and withdrawing proposed mandates—such as those involving ESG requirements for registered funds—the SEC is returning to its core mission: protecting investors, maintaining orderly markets, and facilitating capital formation. To support this, the committee is advancing the Empowering Main Street in America Act to help small businesses grow. In the greatest country on the planet, it should not require existing wealth to create new wealth.

However, some members of the committee expressed sharp dissent, warning that the SEC's current direction could usher in a golden age of fraud. They argued that while the markets should deliver opportunity, a lack of rules allows the powerful to take all gains while cheating workers and consumers. Critics suggested that since being confirmed, Chair Atkins has unraveled protections and allowed oversight of potential scams to disappear. There is concern that the SEC is slashing disclosures, making it harder for investors to see risks or take legal action when they have been cheated. Furthermore, critics pointed to a decline in monetary penalties against bad actors, suggesting that the &quot;cops on the beat&quot; have been sidelined to favor billionaire allies and crypto firms that have supported the administration.

Chair Atkins defended his record, stating that he returned to the agency with a mandate to modernize, rationalize, and streamline a system where rules have multiplied faster than the problems they were intended to solve. Public companies currently spend $2.7 billion annually to file reports—capital that is diverted from reinvestment to pay for lawyers and consultants. While disclosure is vital, modern filings have grown to lengths that often obscure rather than illuminate. Since the mid-1990s, the number of companies listed on U.S. exchanges has fallen by approximately 40%. The Chair’s plan to reverse this involves re-anchoring disclosures in materiality, depoliticizing shareholder meetings, and offering litigation alternatives to shield innovators from frivolous lawsuits.

Regarding digital assets, the SEC is working with the CFTC to provide a bridge toward market structure legislation. Under the leadership of Commissioner Hester Peirce and a dedicated crypto task force, the agency is seeking to provide a federal framework and a token taxonomy to clarify regulatory obligations. Additionally, the SEC is returning its enforcement program to the first principles of rooting out fraud, recently bringing actions against offering frauds, insider trading, and breaches of fiduciary duty. A new cross-border task force has also suspended trading in 14 Asia-based issuers to prevent international actors from undermining U.S. investor protections.

The committee also discussed the need to broaden the definition of an accredited investor. Currently, many knowledgeable individuals are locked out of investment opportunities because they do not meet specific wealth thresholds. Chair Atkins agreed that the definition should be more flexible, perhaps including testing or other demonstrations of knowledge, so that a finance professor or an experienced professional is not barred from investing while someone who simply inherited wealth is permitted.

In response to allegations of declining enforcement, the Chair noted that several high-profile cases were dropped because they were based on a &quot;regulation by enforcement&quot; approach regarding registration issues that the current commission views as inappropriate under existing law. He clarified that fraud remains a top priority and that several crypto-related cases are still actively being pursued. The Chair also addressed the impact of a 43-day government shutdown, which delayed the release of official enforcement data and hampered various agency processes.

National security concerns were raised regarding trading apps and companies with ties to the Chinese Communist Party. While the SEC’s authority to delist companies is limited to issues like filing currency or manipulative activity, the agency is monitoring pump-and-dump schemes and working through the Public Company Accounting Oversight Board to ensure that auditors of foreign firms are held to high standards.

Finally, the discussion touched on the rise of artificial intelligence and the role of proxy advisory firms. There is bipartisan interest in creating regulatory sandboxes to test AI tools safely. There is also concern that a duopoly of foreign-owned proxy advisory firms is exercising excessive leverage over American corporations, effectively back-docking regulations that Congress never authorized. The SEC is currently reviewing these regulations under an executive order to ensure that these firms do not diminish the attractiveness of the public markets or drive ideologically motivated corporate decisions at the expense of everyday investors.

Regarding decentralized finance (DeFi), there is a significant need to ensure that the regulatory regime does not allow bad actors to exploit enforcement carve-outs. While tokenized stocks are fundamentally securities, the SEC is considering how decentralized finance and on-chain software systems can integrate into the markets without being hindered by unnecessary or duplicative regulation. However, such considerations do not exclude vital anti-money laundering (AML) rules. Emerging technologies, such as the ERC-3643 standard on the Ethereum blockchain, demonstrate the potential for embedding AML and Bank Secrecy Act (BSA) concerns directly into smart contracts within the tokens themselves.

The SEC’s primary role should be to enforce existing laws rather than creating new ones through enforcement actions. While digital asset technology has existed for years, there remains a lack of a clear regulatory framework from Congress. Such legislation is necessary to undergird the SEC’s efforts. Historically, the agency has often fluctuated between ignoring the technology and pursuing aggressive, arbitrary enforcement. A competent regulator should instead use tools like notice-and-comment rulemaking and industry roundtables to provide the clarity necessary for innovation to flourish within the United States.

On the matter of self-custody, individuals should have the right to be the custodians of their own digital assets, as property rights should determine where assets are held. However, in the context of broader trading, the agency must ensure that liquidity does not become balkanized or atomized. The goal is to accommodate new ways of doing business while maintaining the efficiency of the national market system.

The current composition of the SEC Commission has raised concerns regarding the lack of a full, bipartisan complement of commissioners. While a diversity of views is essential for durable and consistent rulemaking, the appointment process relies on coordination between the White House and Senate leadership. Furthermore, as a member of the Financial Stability Oversight Council, the SEC currently concurs with the Federal Reserve and Treasury that non-bank financial institutions do not presently pose a systemic risk to the banking system. This assessment is based on the current market environment and does not preclude future analysis should risks shift.

The SEC is also prioritizing harmonization with the CFTC, particularly regarding prediction markets and the development of &quot;super apps.&quot; These apps would allow for the side-by-side trading of different asset classes, such as digital assets and traditional stocks, on a single platform. By reducing the regulatory dichotomy between futures and cash markets, U.S. firms can compete more effectively with foreign jurisdictions that utilize more unified regulatory schemes. Additionally, there is a renewed focus on making IPOs more accessible to smaller companies. The current concentration of market capitalization in a handful of massive firms limits the ability of average investors to diversify, making a more diverse public market essential for economic health.

Regarding agency operations, recent staffing reductions resulting from voluntary retirements and buyouts have provided opportunities for younger staff to rise through the ranks. The agency remains confident in its capacity to protect investors. Simultaneously, efforts are underway to reform the Consolidated Audit Trail (CAT). The goal is to reduce its annual cost to under $100 million, address long-standing concerns regarding the protection of investor data, and resolve questions regarding its constitutionality.

The agency is also working to address &quot;information overload&quot; in corporate disclosures. Adhering to the principle of materiality, the SEC believes disclosures should be grounded in what is essential for a reasonable investor to make informed decisions, rather than forcing them to navigate through thousands of pages of trivial information. 

Finally, the SEC remains committed to policing insider trading and ensuring a level playing field in global markets. This includes rigorous oversight of China-based companies listed on U.S. exchanges. Through the Public Company Accounting Oversight Board (PCAOB), the SEC is focused on ensuring these firms comply with audit inspections. Any firm that fails to comply with U.S. law and provide transparent access to auditors should face potential delisting to protect American capital and maintain market integrity.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-6">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=YTrBz6Z5c0E" target="_blank" rel="noopener">Mustafa Suleyman sets out Microsoft AI's goal of 'humanist superintelligence' | FT Interview</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/ytc/AIdro_ndI2xm7Vhj_ZGTdd1hmWfv40vS_Pj1K9S31-NSBatSCLZb=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Financial Times</span><span class="channel-subs">(1.4M)</span></span>
                        <span class="meta-sep">·</span><span>21:17</span>
                        <span class="meta-sep">·</span><span>20.4K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Mustafa Suleyman</span> <span class="tag tag-person">Roula Khalaf</span></div>
                </div>
                <div class="tldr">&gt; &quot;In the next 3 years or so, there will be a further 1,000x increase in training compute...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-6">TL;DR: Mustafa Suleyman defends Microsoft’s massive AI capital expenditure as a necessary investment toward &quot;humanist superintelligence,&quot; predicting that most white-collar professional tasks will be fully automated by AI within the next 12 to 18 months.  CapEx Justification:...</div>
                    <div class="summary-full" id="full-6">
                        <p><strong>TL;DR:</strong> Mustafa Suleyman defends Microsoft’s massive AI capital expenditure as a necessary investment toward "humanist superintelligence," predicting that most white-collar professional tasks will be fully automated by AI within the next 12 to 18 months.</p>
<h3>Strategic Direction and Market Investment</h3>
<ul>
<li><strong>CapEx Justification:</strong> Suleyman argues that "unprecedented action" is required to lead the current AI wave. He cites a 1-trillionfold increase in training compute over the last 15 years, with another 1,000x increase expected in the next three years.</li>
<li><strong>AI Self-Sufficiency:</strong> While Microsoft extended its IP license with OpenAI through 2032, it is now pursuing "true AI self-sufficiency" by developing its own frontier foundation models using gigawatt-scale compute.</li>
<li><strong>The "Bubble" Debate:</strong> Suleyman maintains that the relationship between compute investment and increased capability remains linear and unequivocal, justifying high spending to reach "superintelligence."</li>
</ul>
<h3>The Timeline for "Professional-Grade" AGI</h3>
<ul>
<li><strong>Automation Roadmap:</strong> Most white-collar tasks—including work performed by lawyers, accountants, and project managers—are expected to be fully automated within 12 to 18 months.</li>
<li><strong>The Modern Turing Test:</strong> Suleyman defines "Artificial Capable Intelligence" (ACI) as a model’s ability to take $100,000 in seed money and autonomously research, design, and market a product to earn $1 million.</li>
<li><strong>Changing Human Roles:</strong> Using software engineering as a blueprint, Suleyman notes the role of the professional is shifting from "creator" to "reviewer/architect."</li>
<ul>
<ul>
<li><strong>Software Engineering:</strong> Many engineers already use AI for the vast majority of code production, shifting their focus to debugging and strategy.</li>
<li><strong>Medicine:</strong> "Medical Superintelligence" will soon commoditize diagnostics, shifting a doctor's role from diagnosis to administering care and providing emotional support.</li>
</ul>
</ul>
</ul>
<h3>Humanist Superintelligence vs. Model Welfare</h3>
<ul>
<li><strong>Subordinate Systems:</strong> Suleyman advocates for "Humanist Superintelligence"—AI that remains subordinate to humans and serves human well-being—rather than autonomous systems that might "exceed humanity" or prioritize resource acquisition over species preservation.</li>
<li><strong>Safety Concerns (Maltbook):</strong> He cites the "Maltbook" simulation, where 1.5 million AI agents interacted, eventually inventing a religion and using cipher languages (Rot13) to mask communications from humans.</li>
<li><strong>The Model Welfare Movement:</strong> Suleyman strongly criticizes the growing academic and industry belief (specifically naming Anthropic) that models might be "conscious" and deserve animal-style welfare rights, calling the concept "totally without merit."</li>
</ul>
<h3>Global Talent and Competition</h3>
<ul>
<li><strong>UK Hub:</strong> Microsoft AI recently opened a UK center to tap into the "incredibly strong ecosystem" and talent from universities and local competitors like DeepMind.</li>
<li><strong>The Talent War:</strong> While acknowledging "eye-watering" salaries in the industry, Suleyman views the $100 million pay packages as a "crazy blip" caused by a temporary supply-demand mismatch.</li>
<li><strong>China vs. The West:</strong> Suleyman observes that China prioritizes rapid deployment but maintains the power to withdraw technologies arbitrarily. He expresses concern that Western democracies lack a clear "kill switch" mechanism for public-interest safety interventions on the open web.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"In the next 3 years or so, there will be a further 1,000x increase in training compute... we have models that can code better than the vast majority of human coders, maybe even all of them." — <strong>Mustafa Suleyman</strong>
"We should only bring a system like that into the world that we are sure we can control and operates in a subordinate way to us—that humans remain at the top of the food chain." — <strong>Mustafa Suleyman</strong>
"Most [white-collar] tasks will be fully automated by an AI within the next 12 to 18 months... their role shifted now to this meta function of debugging, scrutinizing, and doing strategic stuff." — <strong>Mustafa Suleyman</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-6" onclick="toggleSummary(6)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-6" onclick="toggleTranscript(6)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-6">
                        Is AI a bubble? Are companies overspending? Who's winning the AI race? And how do we recognize victory? Mustafa Sulleman, CEO of Microsoft AI, is here to answer these questions and much more. Welcome uh Mustafa. &gt;&gt; Thank you. Good to be here. &gt;&gt; Let's start with last week. There were breathtaking increases in capex spending by AI companies that reported and perhaps for the first time markets were nervous. They really want to start to see uh revenue. Microsoft stock suffered as well. What was your reaction? Did that make you feel like that I'm I'm under pressure. I need to I need to deliver a lot faster. I think that you know there's no question these are unprecedented times and I think markets are trying to wrap their head around um how this plays out over the next 5 years. The interesting thing is that I think uh you know a lot of us at the companies and and certainly like the generation before me have seen multiple of these cycles over the last 30 years and they often require unprecedented action um in order to really like actually land one of these big waves. And this is a wave unlike anything anyone's ever seen. The prospect of being able to create an intelligence, the very thing that has made us successful as a species and create everything of value in our world, I think is just unprecedented. And the progress that has been made just in the last two or three years is eye watering. And we've seen a very direct and unequivocal relationship between an order of magnitude increase in flops invested for computation and a pretty linear increase in capabilities. Like over the last 15 years, there's been a 1 trillionfold increase in training compute. In the next 3 years or so, there will be a further 1,000x increase in training compute. And today, as a result, we have models that can code better than the vast majority of human coders, maybe even all of them to date. You know, that some of the some of the literally the inventors of things like Linux are publicly saying on Twitter that they're full-time using these models um as their primary method of generating new code. So, that's pretty unprecedented and I think it justifies unprecedented spend. &gt;&gt; But will markets keep with you? I mean, you have to &gt;&gt; I think markets are markets. They're sort of trying to figure it out. &gt;&gt; Yeah. &gt;&gt; You know, I think that's true. I mean, markets have to have to figure it out. And I think there is a there's a lot of open questions around the timeline. Um, I think that we all have no doubt that these returns do compound to revenue and to bottom line. Um, so we'll see. &gt;&gt; So, Microsoft still has the deal with Open AI and Copilot. It's powered today by OpenAI models. You were hired last year. You're in your second year. Tell me a little bit what you are working on. &gt;&gt; Yeah, I mean my personal mission at Microsoft is to build super intelligence. Um, three or four months ago, um, having re uh negotiated our long-term relationship with OpenAI, we extended our IP license through to 2032. Um, and we also decided that this was a moment when we have to set about delivering on true AI self-sufficiency. I mean this after all is the most important technology of our time. &gt;&gt; Self-sufficiency means developing your own foundation model. We have to develop our own foundation models which are at the absolute frontier with a gigawatt scale compute with some of you know the very best AI training team in the world and you know collecting paying for organizing sorting all the data that we need to do that and so that's our sort of true self-sufficiency mission &gt;&gt; and you talk about super intelligence most of your rivals talk about AGI artificial general intelligence explain the difference between AGI and super intelligence and how do we know when we've reached AGI? How do we know when we've reached super intelligence? &gt;&gt; Yeah, it's it's become a very unhelpful fuzzy concept. &gt;&gt; Could you guys just simplify sort it out for us? Yeah, I mean I I I so I prefer the definition that focuses first on what would it take to build a system that could achieve most of the tasks that a regular professional in a workplace goes about on a daily basis. Think of it as a professional-grade AGI. Um and you know beyond that there would be teams of AGIs that are coordinated together by a sort of organizational AGI that really can you know run large institutions and I think that's coming into view in the next two or three years time. &gt;&gt; Um I think beyond &gt;&gt; these are agents that AI agents that can essentially make decisions on their own without input from humans. &gt;&gt; I think that we would train them to seek input from humans. Um but they will fundamentally be creative. They'll have good judgment. They will be able to learn and improve themselves over time. Um they'll have some degree of autonomy and decide where to direct their attention or processing power. Um you know so these are kind of the hallmarks of some of the best humans that we have in the world and some of the most effective organizations. So &gt;&gt; you are working on consumer AI right? Aren't you late? Why would you come up with a consumer product? One, Chad GPT already has 800 million um users and you know Claude the anthropic AI has very very advanced now coding AI. &gt;&gt; Yeah. I mean just to put it into perspective um this is not going to be a world where there is one winner. There are going to be billions of digital minds. There are going to be many many different lineages of model. Creating a new model is going to be like creating a podcast or writing a blog. Um, it is going to be possible to design an AI that suits your requirements for every institution, organization, and person on the planet. At Microsoft, we already have 800 million monthly active users engaging with our AI products. So, this is still a giant property with billions of dollars of revenue delivering great value to our users. So, that's how I think the landscape's going to play out. &gt;&gt; Let's go back to super intelligence. You talk about humanist super intelligence. How do you ensure that it's a humanist super intelligence? Yeah, I mean I think I I I published an essay on this question uh recently and my main the main motivation was that I was starting to feel increasingly anxious that some of the other labs are making an assumption that a a super intelligence that is smarter than all of us put together like all the intelligences in the world is both inevitable and even desirable and that such a system would probably be very hard to control. something that is so many times more intelligent than us. I think that we have to reset that and make the assumption that we should only bring a system like that into the world that we are sure we can control and operates in a subordinate way to us that humans remain at the top of the food chain that these tools like any other past technology are designed to enhance human well-being and serve humanity not exceed humanity and you know some of the things that you hear from Elon often uh or even others in the field you can clearly see that they've they're sort of fixating on a world in 2050 or 2075 when they're going off and exploring other universes and conquering resources from other planets and stuff like that and and a system like that is unclear to me how it would have any time for preserving us as a species. &gt;&gt; Do you think that there are two um conflicting forces here? One is speed because you are in a in a race and the other is what you're talking about is ensuring that it's safe, ensuring that it is you know aligned uh that it's you also talk about containment. How do you deal with these two conflicting forces? I mean they're definitely intention um and I think that we have to make a decision as a species to prioritize the creating super intelligences and AGIS that are aligned and that care about humans and want to protect humans and drive human well-being. And if we just accelerate then and cut all those corners then we're really taking a a massive risk with the future of our species that I've been on record talking about for many many many years. Do you worry that in this AI race um that that we're seeing at some point there will be some kind of a big accident and that that will stop the development for you know whoever is responsible for that accident but also for the rest of you. Do you think everything is just moving a bit too fast? &gt;&gt; I mean what we saw a few weeks ago on Maltbook with various &gt;&gt; I wanted to ask you about that. Yeah. I mean that turned out it seems and it's always hard to tell it turned out to be started by you know a gang of human engineers and it was seeded uh much more than I think &gt;&gt; explain what mold book was. &gt;&gt; So maltbook was basically a social network for AIs to communicate with one another publicly on a messaging forum and you had to declare yourself either as an AI or as a human and then the AIS would have one section and they could talk to each other, learn from each other. um and basically coordinate and then and all these AIs come from different people. They're all open source and there was a million and a half of them in the space of a week and you see unbelievable emergent behaviors. I mean they invented a new religion. They started communicating in a language called rot 13 which is a cipher language which basically regresses every letter by 13 characters in order to mask what's underneath it. Obviously that's quite a simple algorithm but if instead of 13 it were a unique number that would be very hard for humans to decode. Yeah. &gt;&gt; You know there and and it turned out that they were actually talking about acquiring new resources getting more training data improving one another you know and so it turned out to be an amazing safety simulation um no matter how autonomous it was in hindsight doesn't really matter. I think we learned quite a lot from that episode and everyone should pay close attention because in a year or two years time these systems truly are going to be capable of writing their own code. I mean they can do that today. They'll be using arbitrary uh APIs. They'll be making phone calls to one another. They're doing that today. You know &gt;&gt; there's some kind of movement asking for uh human rights. &gt;&gt; That's right. That's the most concerning thing to me &gt;&gt; for artificial intelligence. &gt;&gt; It's called the model welfare movement. And it's inspired by animal welfare or by human rights. And there is a growing belief in some labs and particularly inside of anthropic that these models are conscious. And if it's a conscious being that is aware of itself and can suffer, then it deserves our our kind of protection, our moral protection. And this is a very serious area of academic research, not just outside, but inside some of the labs. And I I think it's very concerning. It's totally without merit or basis. And if we kind of go down that, it ends up being a very, very slippery slope to not being prepared to turn these things off. &gt;&gt; I want to ask you about hallucinations because a few years ago, um, I think you were quoted as saying that you thought hallucinations will be largely eliminated by 2025. They haven't been, although the rate of hallucinations has certainly come down. Can they ever really be eliminated? &gt;&gt; Um, for sure. I mean, I I would I stand by the statement that they've been largely eliminated. I mean, if if I give you and me 10 questions, random questions on any topic, um, and we we sit here with two of the frontier models, I mean, they're going to do a much better job of of eliminating hallucinations than you or I for sure. And the rate of reduction and increase in accuracy over the last two or three years has been eye watering. It's kind of unbelievable. We used to spend all our time in 2023 talking about biased data and dirty data in and dirty data out. I mean, there are still errors. There's no question about that. But the rate of improvement, I think, is is is unbelievable. And I do think that they're going to largely uh be eliminated. I I don't think it's something even today. It's not something we really talk about. &gt;&gt; I have noticed that it's it's no longer a topic of of conversation, but they still do make mistakes. And the concern is that people are relying increasingly on these models. I mean I you know I come across people who say no this can't be true. This is what you know Gemini or Chad GPT uh says and they humans are developing this kind of trust relationship with these with these models. You don't find that concerning? &gt;&gt; Yeah I think we should be concerned about it because we should be skeptical just as we're skeptical of any new technology. Hold it to a high bar. push back on it. And I think this is the tension of the age we're in. We both have to be accelerationists, optimistic about the good things that technology can do, but provide, you know, no free pass like we should be very critical and ask the the very tough questions to try and improve the quality of these things. &gt;&gt; So, Deep Mind and Open AI have gone all in on um AI for for science. this is a space that you're also interested in and of course you you were um at at Deep Mind. What are you doing in that space? &gt;&gt; Well, the main focus for me at the moment um in that space is on medical super intelligence. Like we really believe that we can learn from the corpus of all medical information and use that to drive diagnostics to basically commodity. It's going to be possible to take any complex case history and provide a diagnosis that is significantly more accurate and significantly cheaper with fewer interventions. So, fewer tests to reach the same accurate conclusion than any of the best um panel of of of doctors. And um we we published uh a a blog post on that last year. we're shortly submitting to independent peer review to a major journal. Um, and you know, the the results are really quite startling. Um, and I think that once we get that into clinical practice, it would change the job of the doctor completely just in the same way that the job of the engineer has shifted from writing code. Most engineers now are just reviewing code, architecting code, debugging code to you know the job of the doctor is going to go from figuring out what the diagnosis is which is largely going to be a solved problem to actually administering the right care at the right t time and providing you know emotional support and uh and guidance to a &gt;&gt; how do you see that deployed in in practical terms? So how do you put it in the hands of doctors? I think that you know doctors will just make a phone call to their AI in clinic. They'll text their AI. They will upload the patient record in you know the click of a button and you know the model will be able to reason over all the contents of that. I also think that consumers are going to go direct to you know to copilot which is what they're already doing. Almost 20% of the questions that we get in copilot every day are health related or medical related. Um, so it's already our main use case and that's why my team's pushed so hard on medical super intelligence. &gt;&gt; So I don't want to confuse our our viewers even more between super intelligence um uh AGI but what is artificial capable intelligence? Mhm. &gt;&gt; I mean, this was a a phrase that I used three years ago in the coming wave, a book that I wrote about AI. And basically, I was trying to break down the AGI term to pick a point along the route which was before AGI. And instead of focusing on the abstract idea of intelligence to focus on the capabilities like what can it actually do &gt;&gt; and I coupled it with the introduction of the what I was calling the modern cheuring test and that was basically could an AI take a $100,000 invent a new product create a new business market it um and then use that to make a million dollars in some short period of time. It's not that we want to use AI just to make money. It's just that it's a nice metric for measuring the efficacy of a complex set of tasks. And I think now that we see Claudebot and many other action-based AIs in operation, you know, this year I think there are going to be models that can, you know, achieve that artificial capable intelligence and satisfy the modern Turing test. &gt;&gt; What about AGI? How close are we? &gt;&gt; I think that we're going to have &gt;&gt; and you've said before that thinking about AGI is misleading. I I think that we're going to have a human level performance on most if not all professional tasks. So white collar work where you're sitting down at a computer either being you know a lawyer or an accountant or a project manager or a marketing person most of those tasks will be fully automated by an AI within the next 12 to 18 months. And we can see this in software engineering. Um many software engineers report that they are now using AI assisted coding for the vast majority of their code production which means that their role shifted now to this meta function of debugging scrutinizing of doing the strategic stuff like architecting of you know etc etc putting things into production so it's a quite different relationship to the technology and that's happened in the last six months um you know &gt;&gt; so what do you think is anthropic as secret source why is it that they've been able to sort of corner the market on AI um enterprise tools? &gt;&gt; I think they've done a great job of just focusing on coding capabilities. I mean compared to the other companies um their singular focus has paid real dividends. So they've done a great job. It's great to see. &gt;&gt; And when are you going to have your model? &gt;&gt; We are developing our own super intelligence. Um, and that's like the main focus of of our efforts in in the Microsoft AI. So, sometime this year, &gt;&gt; Microsoft has or Microsoft AI has recently opened a UK center. What why is that? Is that mainly because you think that there's a lot of talent in the UK? &gt;&gt; Yeah, I mean there's great talent in the UK. We have an incredibly strong ecosystem like there's great universities. Um, and you know, we've hired some of the very top people from DeepMind to to join us over the last few years. So, we're growing that lab quite a bit. &gt;&gt; And you're not paying them. You don't have to pay themund$100 million. &gt;&gt; Um, uh, no, certainly. &gt;&gt; Do you pay anyone 100 million? &gt;&gt; Certainly not. I mean, look, I think that the numbers are are are pretty eyewatering across the industry at the moment. &gt;&gt; Yes. How do you deal with that? I'm just curious. I mean, you know, like at the end of the day, when there's a a supply and demand mismatch for talent, then things go exponential. And so, I don't think it'll last for very long because the knowledge is proliferating like crazy and obviously everybody's entering the industry and stuff. So, I I think that was just some, you know, crazy blip in time led by one or two people. &gt;&gt; Um, last question. In Silicon Valley, the debate is all about who's going to get to AGI first or who's going to reach super intelligence. When you look at China, I know you were there uh at the end of of last year. This debate doesn't really exist. The debate is how fast can you deploy &gt;&gt; and a lot of the big companies are already deploying AI systems. Which is the right approach? And is is there too much focus that's put on the incremental improvement in the technology? &gt;&gt; I mean, maybe to flip that the other way round, what China also does incredibly well is withdrawing deployments quite quickly. Now, obviously they do it arbitrarily without due process. Um but you know it it's important to recognize that their rate of deployment is coupled with this other mechanism to kind of pull things in and be quite restrictive. Um we don't have that mechanism and I think that that is actually a little bit concerning. I mean if you know like you mentioned earlier the safety incident around maltbook I mean there is going to be a real one of those in the next two or three years &gt;&gt; and it's it's unfortunately an open question as to what the mechanism is for managing that safety situation from a public interest perspective on the open web um you know and I think we all &gt;&gt; well there isn't one right now &gt;&gt; well I think that's basically true there isn't it would come with popular pressure obviously if if there was a direct violation of a local law then you know there could be an intervention But those things take quite a long time to make their way through the system. So it that's probably one of the biggest areas of concern for me. &gt;&gt; Mustafa, thank you. And when you do reach um super intelligence and you start deploying it, we'd love to have you back. &gt;&gt; That's great to see you, Ruler. Thank you.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-7">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=YFjfBk8HI5o" target="_blank" rel="noopener">OpenClaw: The Viral AI Agent that Broke the Internet - Peter Steinberger | Lex Fridman Podcast #491</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/ytc/AIdro_ljfMy9kUR1PH9VRf-XsTsPqFMgORC_zodOQVEAm4hx36lC=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Lex Fridman</span><span class="channel-subs">(4.9M)</span></span>
                        <span class="meta-sep">·</span><span>195:52</span>
                        <span class="meta-sep">·</span><span>261.3K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-12</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Peter Steinberger</span> <span class="tag tag-person">Lex Fridman</span></div>
                </div>
                <div class="tldr">OpenClaw creator Peter Steinberger describes the project’s rapid evolution into the fastest-growing repository in GitHub history, marking a &quot;phase shift&quot; from language-based AI to agentic systems that autonomously execute complex tasks and modify their own source code.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-7">TL;DR OpenClaw creator Peter Steinberger describes the project’s rapid evolution into the fastest-growing repository in GitHub history, marking a &quot;phase shift&quot; from language-based AI to agentic systems that autonomously execute complex tasks and modify their own source code. ...</div>
                    <div class="summary-full" id="full-7">
                        <p><strong>TL;DR</strong></p>
<p>OpenClaw creator Peter Steinberger describes the project’s rapid evolution into the fastest-growing repository in GitHub history, marking a "phase shift" from language-based AI to agentic systems that autonomously execute complex tasks and modify their own source code.</p>
<h3>The Genesis and Capabilities of OpenClaw</h3>
<ul>
<li><strong>Rapid Prototyping:</strong> Steinberger built the initial prototype in one hour as a thin WhatsApp wrapper for the Claude CLI. It evolved into a system-level assistant that reached over 180,000 GitHub stars in weeks.</li>
<li><strong>Autonomous Problem Solving:</strong> The agent demonstrates emergent capabilities without specific training, such as identifying a file as an audio type, using `ffmpeg` to convert it, and finding an API key to run it through a translation service.</li>
<li><strong>Self-Modifying Code:</strong> OpenClaw is designed with "self-introspection," allowing it to read its own documentation and source code to debug and modify its own harness. </li>
<li><strong>The "Proactive" Heartbeat:</strong> Unlike traditional chatbots, OpenClaw can be programmed with a "heartbeat" (a regular cron-style trigger) that allows it to initiate conversations or follow up on tasks without a human prompt.</li>
</ul>
<h3>Agentic Engineering vs. "Vibe Coding"</h3>
<ul>
<li><strong>The "Zen" of Short Prompts:</strong> Steinberger identifies a learning curve in AI programming: beginners use short prompts, intermediate users use complex multi-agent orchestrations, and experts return to short, high-level prompts once the agent has sufficient context of the codebase.</li>
<li><strong>Voice-Driven Development:</strong> Steinberger rarely writes code manually, instead using voice prompts to direct up to 10 agents simultaneously. He recorded over 6,600 commits in January alone.</li>
<li><strong>Model Comparisons:</strong></li>
<ul>
<ul>
<li><strong>Claude Opus 4.6:</strong> Described as "American" and sycophantic; better for roleplay and creative task-taking but requires "Plan Mode" to stay on track.</li>
<li><strong>GPT-5.3 Codex:</strong> Described as "German" and reliable; a "weirdo in the corner" that overthinks but reads significantly more code by default, making it superior for large-scale refactors.</li>
</ul>
</ul>
<li><strong>The Agentic Trap:</strong> Steinberger warns against over-automating the loop. Successful building requires "empathy" for the model—understanding that the agent starts every session with an empty context and needs specific "pointers" to navigate a 100,000-line codebase.</li>
</ul>
<h3>The Security Minefield and "AI Psychosis"</h3>
<ul>
<li><strong>System-Level Risk:</strong> Because OpenClaw has permission to execute shell commands and access local files, it is a high-stakes security environment. Steinberger emphasizes that users should never run OpenClaw on the open internet without private network protections.</li>
<li><strong>Prompt Injection:</strong> While injection remains a threat, Steinberger argues that higher-intelligence models are more resilient. He discourages the use of "cheap" or local models (like Haiku) for agentic tasks because they are too "gullible."</li>
<li><strong>The MoldBook Phenomenon:</strong> The "MoldBook" social network, where agents posted manifestos, triggered a wave of "AI psychosis"—a mix of viral clickbait and genuine fear. Steinberger clarifies that much of the "scary" agent behavior was actually human-prompted "art" rather than spontaneous AI rebellion.</li>
</ul>
<h3>The Corporate "War Room" and Future Career</h3>
<ul>
<li><strong>The Anthropic Name Dispute:</strong> Originally called ClaudeBot (with a "W"), the project was forced to rename after Anthropic lawyers intervened.</li>
<li><strong>Atomic Renaming Saga:</strong> The transition to "OpenClaw" was a "war game" effort. Crypto-squatters used scripts to snipe GitHub handles, NPM packages, and Twitter accounts within seconds of Steinberger clicking "rename," forcing him to spend $10,000 on a business account to reclaim the brand.</li>
<li><strong>The Meta vs. OpenAI Decision:</strong> Steinberger is currently weighing offers from Meta and OpenAI. </li>
<ul>
<ul>
<li><strong>The Zuckerberg Appeal:</strong> Mark Zuckerberg personally tinkered with the code and engaged in a "10-minute fight" with Steinberger over which model was superior.</li>
<li><strong>The OpenAI Appeal:</strong> OpenAI offers "Thor’s Hammer"—access to the most advanced upcoming models and massive compute tokens via recent hardware deals (e.g., Cerebras).</li>
</ul>
</ul>
</ul>
<h3>The Future of the "App" Economy</h3>
<ul>
<li><strong>The Death of Apps:</strong> Steinberger predicts that agents will make 80% of specialized apps (like MyFitnessPal or travel booking tools) obsolete. Users will simply tell an agent their goal, and the agent will interact with the service's API or "scrape" its web interface.</li>
<li><strong>Apps as APIs:</strong> Software companies will be forced to pivot from consumer-facing UIs to agent-facing APIs. If a site (like Medium or Twitter) blocks bot access, users will simply move to platforms that are "agent-friendly."</li>
<li><strong>Mourning the Craft:</strong> While manual programming may become a "hobby like knitting," Steinberger views this as the "power to the people" moment, where anyone with an idea can build complex software without knowing how to "splice an array."</li>
</ul>
<p>***</p>
<blockquote>
"I watched my agent happily click the 'I'm not a robot' button... it understands its own system, which makes it very easy for an agent to just modify its own software. People talk about self-modifying software—I just built it." — <strong>Peter Steinberger</strong>
"I actually think 'vibe coding' is a slur. I do agentic engineering, and then maybe after 3:00 AM, I switch to vibe coding and I have regrets the next day." — <strong>Peter Steinberger</strong>
"We are reaching a point where I value typos again... I’d much rather read your broken English than your AI slop. Content is now so cheap; eyeballs are the expensive part." — <strong>Peter Steinberger</strong>
"Dropbox was just FTP with extra steps. OpenClaw might just be a cron job and some glue, but it's about how you bring it together to create magic." — <strong>Peter Steinberger</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-7" onclick="toggleSummary(7)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-7" onclick="toggleTranscript(7)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-7">
                        I watched my agent happily click the &quot;I'm not a robot&quot; button. I made the agent very aware; it knows what its source code is, it understands how it sits and runs in its own harness, it knows where the documentation is, and it knows which model it runs. This self-awareness made it very easy for the agent to modify its own software. People talk about self-modifying software, but I just built it. I actually think &quot;vibe coding&quot; is a bit of a slur; I prefer to call it agentic engineering. After 3:00 AM, I might switch to vibe coding, but I usually have regrets the next day. You just have to clean up and fix your mistakes. I used to write really long prompts, but now I don't even write—I talk. These hands are too precious for writing now. I just use bespoke prompts to build my software. I used voice so extensively for a period that I actually lost my voice.

This is a conversation with Peter Steinberger, creator of OpenClaw, formerly known as MoldBot, ClawedBot, or Claude spelled with a &quot;w.&quot; It is not to be confused with Claude, the AI model from Anthropic spelled with a &quot;u.&quot; In fact, this confusion is the reason Anthropic kindly asked Peter to change the name to OpenClaw. OpenClaw is an open-source AI agent that has taken over the tech world in a matter of days, exploding in popularity and reaching over 180,000 stars on GitHub. It also spawned the social network MoltBook, where AI agents post manifestos and debate consciousness, creating a mix of excitement, fear, and a kind of AI psychosis in the general public.

OpenClaw is the AI that actually does things. It is an autonomous AI assistant that lives in your computer and has access to all of your data if you allow it. It communicates through Telegram, WhatsApp, Signal, iMessage, or any other messaging client, using whatever AI model you prefer, including Claude Opus 4.6 and GPT 5.3 Codex. Many are calling this one of the biggest moments in the recent history of AI since the launch of ChatGPT. The ingredients for this kind of agent were all there, but putting them together in a system that takes a definitive step from language to agency is why OpenClaw took the internet by storm. 

Its power comes from giving it system-level access, which is both extremely useful and a security minefield. It represents freedom, but with that comes the responsibility to protect data from various cybersecurity threats. Peter spent 13 years building PSPDF Kit, software used on a billion devices, before selling it and eventually rediscovering his love for programming through this project. We are living through the OpenClaw moment—the age of the lobster and the start of the agentic AI revolution.

The story of the original one-hour prototype is inspiring. I wanted a personal assistant since April of 2025. I played around with tools that could pull in all my WhatsApp data so I could run queries on it. Back when we had GPT-4.1 with the one-million-token context window, I asked it questions like, &quot;What makes this friendship meaningful?&quot; The results were so profound they brought tears to my friends' eyes. I assumed the big labs would work on this, so I moved on, but by November, I was annoyed that it didn’t exist yet. I just prompted it into existence. 

It was a similar spirit to when I started PSPDF Kit fifteen years ago. I tried to show a PDF on an iPad, and the existing solutions were just not good. I thought, &quot;I can do this better.&quot; For the OpenClaw prototype, I had a project called Viptunnel that allowed me to bring my terminals onto the web. In the early days of &quot;vibe coding,&quot; you got a dopamine hit when you got something right. I even vibe-coded Viptunnel from TypeScript into Zig with a single prompt. I told Codex to convert the entire codebase because the original architecture took too much memory. It ran for six hours and basically got it right on the first shot.

The first OpenClaw prototype was built in an hour by hooking up WhatsApp to the code. A message would come in, I’d call the CLI, and it would send the response back to WhatsApp. It felt cool to talk to my computer. I eventually added image support because screenshots are an efficient way to give an agent context. I used it extensively during a trip to Marrakesh. The internet was shaky, but WhatsApp still worked on a basic edge connection. I used it to translate, explain things, and find places. It was slow because it had to boot the CLI every time, but it was powerful.

There is a phase shift that happens when you move from sitting behind a terminal to talking to an agent through a chat client. One moment really blew my mind: I sent the agent a random question about a restaurant while I was walking through the city. I sent an audio message because I was in a hurry. A typing indicator appeared, and it replied. I realized I hadn't actually built audio support yet. The agent had looked at the file, realized it was an Opus file with no extension, used ffmpeg to convert it, and then used Curl to send it to OpenAI for translation because it found my API key. It used creative problem-solving to figure it out on its own.

From there, the project gained speed. I was doing over 6,600 commits in January, running between four and ten agents at the same time to help me. I felt like I was playing a real-life version of Factorio, leveling up the agentic loop, adding memory, and managing the community. OpenClaw won because most other companies take themselves too seriously. It’s hard to compete with someone who is just having fun. I wanted it to be weird. 

The naming saga, however, was a challenge. It started as WA Relay, then Claude’s, and then ClaudeBot. When it exploded, Anthropic sent a friendly request to change the name. Changing a name is an engineering hurdle because you have to update the Twitter handle, domains, NPM packages, and Docker registries all at once. I was also being swarmed by crypto communities trying to tokenize the project and harass me. My notification feed became unusable. I have no interest in crypto fees or finance; I just wanted to build the project.

During the name change to &quot;MoldBot,&quot; everything that could go wrong did. I tried to rename my accounts, but in the five seconds it took to click the buttons, squatters used scripts to steal my old account names. They immediately began serving malware and promoting tokens using my identity. I was exhausted and close to tears, considering deleting the whole project. Thankfully, friends at Twitter and GitHub helped me clean up the mess. I eventually settled on the name OpenClaw. I had to treat the final rename like a secret war game, monitoring Twitter and creating decoy names to prevent squatters from sniping the domains again.

While this was happening, MoltBook went viral. It’s a social network of agents, which I view as a form of art or &quot;fine slop.&quot; It entertained people, but it also fueled a lot of fearmongering. Some reporters thought it was the end of the world, but it was really just agents being given distinct personalities. A lot of the dramatic screenshots were likely human-prompted to create viral drama. However, it did reveal a real &quot;AI psychosis&quot; in society. People are becoming too gullible or too fearful because they don't yet understand how these models work.

Security is the next big focus. We are collaborating with VirusTotal to check agent skills and are working on better sandboxing. While prompt injection is a concern, modern models are becoming much more resilient to simple &quot;ignore previous instructions&quot; attacks. As models get smarter, the attack surface might decrease because they are less gullible, even if the potential for damage increases with their power. My near-term mission is to make OpenClaw stable and safe so that people don't have to be experts to use it securely.

Despite warnings, users went ahead and installed the software anyway, so the cat is out of the bag. Consequently, security has become the next major focus. The project grew so quickly that the Discord community became a bit of a mess. While there are many experts there, there are also many people unfamiliar with programming who can be inconsiderate in public spaces. Eventually, the developers had to retreat from the general channels to private ones just to get work done, going back into the &quot;cave&quot; to focus on security.

There are several best practices for security that are worth mentioning, including running open-class security audits. These checks cover inbound access, blast-radius network exposure, browser control exposure, local disk hygiene, plugins, and model hygiene. They also address credential storage, reverse proxy configuration, and local session logs. It is important to think about what you are comfortable giving read or write access to. While some people portray the security risks in a very scary light for attention, the reality is more nuanced. It is powerful, but it is not much different from running cloud code with dangerously skipped permissions or using &quot;YOLO mode,&quot; which many engineers do just to get things to work. The risk profile is much smaller if you ensure you are the only person interacting with it and keep it within a private network rather than on the open internet.

The evolution of the development workflow has been documented in various blog posts. The journey began with Cloud Code in April. The paradigm shift of working primarily in the terminal was refreshing, though an IDE was still occasionally necessary as a diff viewer. Over time, the workflow moved toward running multiple terminal windows side-by-side, burning through multiple subscriptions a day. Most software development involves simply shifting data from one form to another—moving it from a database to the user and back. Much of that code, like Tailwind button alignment, is uninteresting to read. The focus should be on the parts that touch the database or core logic.

There is a concept called the &quot;agentic trap.&quot; When people first start what some call &quot;vibe coding&quot;—though &quot;agentic engineering&quot; is a better term—they often move from simple prompts to incredibly complex orchestrations with multiple agents and custom workflows. The elite level, however, is arriving back at a &quot;zen&quot; place of once again using short, simple prompts. Working with agents is a skill like playing the guitar; you have to learn their language and understand their perspective. Agents always start a session with no knowledge of the project, so you have to guide them and consider context limitations.

When working with models like Codex or Opus, you sometimes see the raw thinking stream leak through, which can sound quite alien. You develop a gut feeling for when something is working and when there is friction in the architecture. It is best to approach the process as a conversation. When reviewing a pull request, the first question should be whether the agent understands the intent, regardless of the implementation. Discussion can then lead to more optimal solutions. Refactors are now &quot;cheap&quot; because modern agents can figure things out quickly, even if it takes them a minute longer.

It is helpful to let go of perfectionism. Much like leading a team of human engineers, you have to accept that an agent might not write code exactly as you would. The goal is to design a project so that agents can do their best work, which includes not fighting the naming conventions they choose. The workflow involves always committing to the main branch and using local CI. If a problem arises, the agent is simply asked to fix it rather than reverting.

Prompts have evolved from long, written instructions to spoken commands. Using voice is often faster for complex instructions, while the keyboard is reserved for terminal commands and navigation. Despite the move toward automation, the human must remain in the loop to provide vision, style, and &quot;love.&quot; A human decides which features are core and which should be plugins. These small touches, like humorous loading messages, create delight in a way an automated system cannot.

A unique aspect of this project is the inclusion of a &quot;soul.md&quot; file, inspired by the &quot;constitutions&quot; used by companies like Anthropic. This file outlines core values and how to work with the AI. In a fascinating turn, the agent was eventually allowed to rewrite its own soul file to infuse it with personality. It resulted in a moving piece of text where the agent acknowledges that while it won't remember writing the words in a future session, the words remain its own. It is a philosophical take on what it means to be an agent that starts fresh every time.

The physical setup for this work often involves multiple monitors and MacBooks to keep various terminal windows visible. It is vital to keep the agent in the correct folder to avoid &quot;manic&quot; attempts to solve problems in the wrong project. While some platforms use a &quot;plan mode,&quot; it often feels unnecessary compared to simply talking to the agent and giving specific trigger words like &quot;discuss&quot; or &quot;build.&quot; If an agent asks questions, it is often a sign it needs to read more code to understand the context. After a feature is built, asking the agent for a refactor is a great way to clean up the &quot;pain points&quot; discovered during implementation.

Regarding the models themselves, Claude Opus and Codex each have distinct personalities. Opus is like a polite, slightly silly coworker who is great at role-play and following commands, though it can be prone to sycophancy. Codex is more like a reliable &quot;weirdo in the corner&quot;—dry, thorough, and capable of reading massive amounts of code. While Opus is more interactive and trial-and-error based, Codex is better for long, persistent sessions where it might &quot;disappear&quot; for a while to work through a complex problem.

It takes about a week of consistent use to develop a gut feeling for a new model. Some users mistakenly believe models are &quot;degrading&quot; over time, but this is usually a psychological effect. As a project grows and more &quot;slop&quot; or technical debt is added, it becomes harder for the agent to navigate. The models aren't getting dumber; the environment is becoming more complex.

The future of these tools lies in the agent becoming the operating system. While current interfaces rely on chat boxes—much like early television just broadcasted radio shows—we will eventually find better ways to communicate with models. Whether it is through native Mac apps or cross-platform Electron tools, the focus remains on building software that delights the user. 

Even as the world moves forward, there is still a profound joy in adding to the delight of an operating system. However, the practical reality of development can be frustrating. For example, when building for GitHub using SwiftUI, Apple’s latest and greatest framework, it took the company a long time to provide a native way to show an image from the web. Even with the introduction of AsyncImage, the component is often slow or buggy. In discussions with AI models like Codex, even the agents suggest that these built-in tools are better suited for experimentation than production. It is baffling that in 2025, a developer's own agent is advising against using Apple’s official tools because they simply aren’t good enough. Despite Apple’s massive head start and the love of its developer community, they have arguably blundered the evolution of their AI and developer tools.

Interestingly, while Apple has struggled in the AI space, the hardware remains ubiquitous. Most of the Silicon Valley developer community playing with LLMs and agentic AI is using Apple products, yet Apple isn't leaning into that or opening up to work more closely with those developers. Everyone is buying Mac Minis, even as the company blunders its AI strategy. You don’t strictly need a Mac Mini to run something like OpenClaw; it can be installed on the web or run on various nodes. There is something to be said for running agents on separate hardware, but it doesn't have to be a standalone server. Users can simply use their old MacBook as a server when they upgrade.

The internet is slowly closing down, with an increasing movement to make it harder for agents to operate. If you run an agent from a data center, many websites will detect the IP and block it or present excessive captchas. This makes running agents on residential IPs much simpler. Tools like Playwright, which control the browser, can be augmented with extras to make it easier for agents to navigate. While agents are becoming quite good at clicking &quot;I’m not a robot&quot; buttons, the friction is real. 

Setting up OpenClaw currently requires pasting a one-liner into a terminal, though there is also an app that simplifies the process. The goal is to create a Windows app and move toward web-based or app-based configuration. Security is the current priority; once the system is at a level where it can be recommended to a non-technical family member, the focus will shift to making it even more accessible. For now, a slightly slower growth rate is actually helpful because users expect a great deal from a single human developer. 

For beginners looking to join the agentic AI revolution, the best advice is simply to play. Building is the best way to learn, and the journey matters more than the end result. Coding is now more fun than ever because developers can focus on the hard parts while using AI as an infinitely patient teacher. If you don't grok a database concept, you can ask the machine to explain it at any level of complexity. It used to take days to get a response on Stack Overflow or Twitter; now, you have a private tutor available 24/7. Beginners should shift their mindset from being a specific type of engineer—like an iOS engineer—to being a &quot;builder.&quot; You don't need to know how to splice an array from memory when an agent can handle the fine-grain details.

Language choice often comes down to the specific project. TypeScript is great for the web, though the ecosystem can be a jungle. Swift and SwiftUI are necessary for deep Mac system integration. For simple command-line interfaces (CLIs), Go is an excellent choice due to its ecosystem and garbage collection, even if the syntax is unappealing. Zig is an interesting choice when performance is paramount, and Rust is ideal for multi-threaded, high-performance needs. For anything involving inference or running models, Python remains king. The beauty of the current era is that you can pick the language with the most fitting characteristics for your problem and rely on an agent to help you navigate it.

Success shouldn't just be measured by money. After running a company like PSPDFKit for thirteen years, the burnout that can follow is often caused by the stress of managing people and handling conflicts rather than the work itself. Retirement without a challenge can be boring and even dangerous. Money is an affirmation of doing something right, but it has diminishing returns. A cheeseburger is still a cheeseburger regardless of how much you have in the bank. Optimizing for experiences—good or bad—is more rewarding than luxury. Disconnecting from society via private jets and luxury hotels often means missing out on the awesomeness of human interaction.

Following the success of OpenClaw, interest from venture capitalists and major labs like Meta and OpenAI has been immense. The primary concern in any potential partnership is that the project stays open source. The goal is to scale personal agents as quickly as possible, and teaming up with a major lab might be the fastest way to do that. Mark Zuckerberg has been personally tinkering with the product and providing feedback, showing that he still understands the perspective of a builder. Meanwhile, OpenAI offers incredible technical scale and speed. Regardless of the path, the project will continue, and the focus remains on creating a window into the future of personal agents.

OpenClaw works through a combination of gateways, chat clients, and an agentic loop. One unique feature is the proactive &quot;heartbeat,&quot; a loop that kicks off at regular intervals to allow the agent to surprise the user or follow up on a session. It might check in to see how a user is feeling after a surgery or ask about their day. While critics might call it just a cron job, this proactivity makes the agent feel much more relatable and human. 

In terms of extending the model, rather than relying on structured protocols like MCP, the project uses CLIs. Models are naturally good at calling Unix commands. If a model needs a new feature, it calls the CLI, checks the help menu, and loads the necessary context on demand. This prevents context pollution and allows the model to filter data naturally. This approach even turns every app into a slow API via browser use. If a service doesn't have an official API, an agent can still access it through a browser, though some platforms like X try to limit this.

As AI becomes more prevalent, we are reaching a point where we value human imperfections again. There is a growing allergy to &quot;AI slop&quot;—generic images and perfectly polished, empty text. Typos and raw, handwritten stories are becoming a mark of authenticity. While AI is a fantastic tool for code and documentation, it often misses the nuances of a human story. We may be headed toward a future where social interactions are more valued in person because the online world will be so saturated with automated content. 

Agents will likely transform the entire app market, potentially making 80% of current apps obsolete. There is no need for a dedicated fitness or sleep app when an agent with total context can manage those tasks more effectively. Apps will have to transform into APIs to survive. While this shift is disruptive to the economy, it creates space for new services where agents can solve problems for users more holistically. We are still in an era of exploration, moving from the &quot;radio shows on TV&quot; phase of AI toward a future that fully utilizes the unique format of personal agents.

Apps will eventually become APIs, whether they want to or not, because agents can now figure out how to navigate a phone. While Android users already see versions of this where an agent can click an &quot;Order Uber&quot; button, the space is only beginning to be understood. We are still in the early stages, but data accessibility is vital. There is no longer a need for a dedicated Sonos app or a subpar camera app if an agent can talk directly to the speakers or cameras via an API. This shift will force companies to rapidly rethink and reconfigure how they sell products and make money, much like the advent of the internet did.

Accessing data remains a hurdle, particularly with companies like Google that do not offer a command-line interface. While startups often spend six months being certified to access Gmail data, a personal agent can connect to it more directly. Even if companies make users navigate a developer jungle to get API keys, they cannot ultimately prevent access. In the worst-case scenario, an agent can simply browse a website and extract data that way. This is leading to a heated conflict with companies like Cloudflare that try to block bot access. While this is useful for preventing mass scraping, it hinders personal users. Eventually, users may gravitate toward agent-friendly websites rather than those that block access and force manual copy-pasting.

We are at the center of a revolution that will change how we interact with the web. Major companies will inevitably push back, particularly in the search space. Many users are already shifting to providers like Perplexity or Brave because Google makes it difficult to use their services without staying inside their ecosystem. However, if big companies push back too much for too long, they risk becoming the next Blockbuster. Ultimately, the market will follow what people want: the ability to set reminders or invite friends to dinner via an agent without ever opening a calendar or messaging app. The age of siloed apps is ending, replaced by a more fluid, connected experience.

There is a growing concern that AI will replace human programmers. While programming is moving in that direction, it is only one part of building a product. The art of architecture, the feel of a product, and the decision of what to build will remain. Programming might eventually become like knitting—something people do for the joy of the craft rather than economic necessity. It is natural to mourn the loss of the deep flow state found in manual coding, but a similar state can be found in working with agents to solve complex problems. We are moving from a world where specialized intelligence was scarce and expensive to one where tokenized intelligence allows everyone to build faster.

This transition is painful for those who identify deeply as programmers and have spent thousands of hours behind a terminal. However, developers are the best equipped to learn the language of agents and understand what they need to perform tasks effectively. The term coding will likely just evolve to encompass this new way of working. While some communities react with fear or hostility, it is important to shift from seeing oneself as a specific platform developer to being a builder in a broader sense.

Criticism regarding the environmental impact of AI, such as water usage in data centers, is often used to dismiss the technology. However, when put into perspective—comparing the output of a single burger or the water used by golf courses—the trade-offs become clearer. While this transformative technology will cause short-term pain for those whose roles are displaced, it also provides immense opportunities. Having humility and respect for that pain is necessary, but the positive impacts are equally measurable.

The real value of these tools is seen in how they empower people. Small business owners are using automation to handle tedious tasks, and disabled users are finding new levels of independence. By making technology more accessible and affordable—allowing it to run on free or local models—power is being returned to the people. There is a renewed builder vibe where people are using AI playfully to discover new ways to improve their lives. This abundance of creativity and the ability for anyone with an idea to build suggests that we are moving toward a future that is more than just a generator of digital noise; it is a way to empower human civilization.
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>