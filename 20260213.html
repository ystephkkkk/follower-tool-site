<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - February 13, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
            scroll-margin-top: 1rem;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-header-link {
            display: block;
            padding: 1.25rem 1.5rem 0.75rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header-link:hover .day-date {
            color: var(--accent);
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
            transition: color 0.15s ease;
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.3rem;
            padding: 0.6rem 0;
            border-bottom: 1px solid var(--border);
            text-decoration: none;
            color: inherit;
            border-radius: 4px;
            transition: background 0.12s ease;
        }

        .day-preview-item:hover {
            background: var(--bg-tertiary);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-title {
            font-size: 0.88rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.35;
        }

        .preview-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            background: var(--bg-tertiary);
            padding: 0.15rem 0.5rem 0.15rem 0.25rem;
            border-radius: 14px;
        }

        .preview-channel-icon {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-channel-name {
            font-weight: 500;
            color: var(--text-secondary);
            font-size: 0.72rem;
        }

        .preview-channel-subs {
            color: var(--text-tertiary);
            font-size: 0.68rem;
        }

        .preview-details {
            font-size: 0.72rem;
            color: var(--text-tertiary);
        }

        .preview-tags {
            display: inline-flex;
            gap: 0.3rem;
        }

        .tag-sm {
            padding: 0.1rem 0.45rem;
            font-size: 0.65rem;
        }

        .preview-tldr {
            font-size: 0.78rem;
            color: var(--text-tertiary);
            line-height: 1.45;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">February 13, 2026</p>
            <div class="stats">
                <span><span class="stat-value">1</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card" id="video-0">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=n1E9IZfvGMA" target="_blank" rel="noopener">Dario Amodei — The highest-stakes financial model in history</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/lG-z7sTfhFIW2Ne1oXMHvXMXyZSaA02_I17gUel0GAEj7OypsSHQ7PE91Vp4bTbpm3PTIAWJdko=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Dwarkesh Patel</span><span class="channel-subs">(1.2M)</span></span>
                        <span class="meta-sep">·</span><span>142:20</span>
                        <span class="meta-sep">·</span><span>6.7K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-13</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Dwarkesh Patel</span> <span class="tag tag-person">Dario Amodei</span></div>
                </div>
                <div class="tldr">&gt; &quot;The hypothesis is basically the same.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">TL;DR: Dario Amodei (CEO of Anthropic) argues we are 1–3 years away from &quot;a country of geniuses in a data center&quot; (AGI), asserting that while technical scaling remains a predictable exponential, the primary challenges have shifted to economic diffusion, the financial risk of...</div>
                    <div class="summary-full" id="full-0">
                        <p><strong>TL;DR:</strong> Dario Amodei (CEO of Anthropic) argues we are 1–3 years away from "a country of geniuses in a data center" (AGI), asserting that while technical scaling remains a predictable exponential, the primary challenges have shifted to economic diffusion, the financial risk of trillion-dollar compute bets, and the geopolitical necessity of ensuring liberal democracies win the AI race.</p>
<h3>The Scaling Hypothesis and the Path to AGI</h3>
<ul>
<li><strong>The "Big Blob of Compute" Hypothesis:</strong> Amodei reaffirms his 2017 theory that AI progress is driven by seven scaling factors—raw compute, data quantity, data distribution/quality, training duration, scalable objective functions (like pre-training and RL), and numerical stability.</li>
<li><strong>RL Scaling Laws:</strong> Current progress is shifting from pre-training scaling to Reinforcement Learning (RL) scaling. Amodei notes that performance on tasks like math (AIME) and coding is log-linear relative to RL training time, mirroring the predictability of early LLM scaling.</li>
<li><strong>AGI Timelines:</strong> </li>
<ul>
<ul>
<li><strong>1–3 Years:</strong> Amodei’s "hunch" (50/50 probability) for achieving a "country of geniuses in a data center"—models capable of end-to-end professional work, including Nobel Prize-level scientific discovery.</li>
<li><strong>90% Certainty:</strong> He is nearly certain this level of capability will be reached within 10 years, barring catastrophic global events like a Taiwan invasion.</li>
</ul>
</ul>
<li><strong>Verification vs. Generalization:</strong> Amodei admits a "spectrum of difficulty" where verifiable tasks (coding, math) will be automated first, while unverifiable tasks (long-term mission planning, novel writing) may take longer to refine.</li>
</ul>
<h3>Economic Diffusion and the Productivity "Snowball"</h3>
<ul>
<li><strong>Diffusion Lag:</strong> Despite rapid capability gains, "economic diffusion" is not instant. Large enterprises face friction from legal reviews, security compliance, and change management. However, AI is diffusing significantly faster than any previous technology.</li>
<li><strong>The Software Engineering Spectrum:</strong> Amodei distinguishes between AI writing 90% of code (already happening) and AI performing 90% of "end-to-end" software engineering tasks (setting technical direction, environment setup). He predicts the latter will occur within 1–3 years.</li>
<li><strong>Internal Productivity Gains:</strong> At Anthropic, engineers are already seeing 15–20% total factor speedups. Amodei dismisses claims that AI reduces productivity, noting that under intense commercial pressure, the company has "zero time for bullshit."</li>
<li><strong>Revenue Exponential:</strong> Anthropic’s revenue has scaled approximately 10x annually ($100M in 2023, $1B in 2024, targeting ~$10B in 2025). </li>
</ul>
<h3>The Trillion-Dollar Financial Model</h3>
<ul>
<li><strong>The Bankruptcy Risk:</strong> Building data centers requires planning years in advance. Amodei explains that if a company buys $1 trillion in compute for 2027 but revenue growth slows from 10x to 5x, the company will go bankrupt. </li>
<li><strong>Model Profitability:</strong> In a steady state, an individual model is highly profitable (high gross margins on inference). However, the "tax" of training the next, exponentially larger model keeps labs in the red during the scale-up phase. </li>
<li><strong>Compute Constraints:</strong> Global compute capacity is growing ~3x annually (reaching ~300 gigawatts by 2029). Amodei suggests that at some point, compute growth will outpace GDP growth, forcing a leveling-off where research spending must be balanced against inference demand.</li>
</ul>
<h3>Geopolitics and Global Governance</h3>
<ul>
<li><strong>National Security Interests:</strong> Amodei strongly supports export controls on chips to China. He argues that the US and its democratic allies must hold "the stronger hand" when the "rules of the road" for the post-AGI world order are negotiated.</li>
<li><strong>The Authoritarian Risk:</strong> He expresses deep concern that AI could make authoritarianism "self-fulfilling" through surveillance and control. However, he hopes AI might make dictatorships "morally and functionally obsolete" by providing individuals with personal AI agents that evade state control.</li>
<li><strong>Constitutional AI:</strong> Anthropic uses a "Constitution" to guide model behavior based on principles rather than a list of "dos and don'ts." Amodei envisions a future "archipelago" of competing AI constitutions where society provides input on core safety standards.</li>
</ul>
<h3>Internal Culture and the "Dario Vision Quest"</h3>
<ul>
<li><strong>The DVQ:</strong> Amodei maintains a direct connection to his 2,500 employees through the "Dario Vision Quest" (DVQ)—a bi-weekly, unfiltered talk where he explains his strategic thinking and answers questions to prevent "corpo-speak" and internal politics.</li>
<li><strong>Insularity of the Bubble:</strong> Amodei finds it "absolutely wild" that the public is still focused on tired political debates when the world is nearing the end of the technological exponential. He views his role as preparing policymakers for a "moment of crisis" where decades of progress happen in a few years.</li>
</ul>
<blockquote>
"The hypothesis is basically the same. All the cleverness, all the techniques, all the 'we need a new method'... that doesn't matter very much. There are only a few things that matter: raw compute, quantity of data, quality of data, and an objective function that can scale to the moon." — <strong>Dario Amodei</strong>
"To me, it is absolutely wild that you have people—within the bubble and outside the bubble—talking about the same tired, old hot-button political issues, when we are near the end of the exponential." — <strong>Dario Amodei</strong>
"If my revenue is not $1 trillion dollars, if it's even $800 billion, there's no force on earth, there's no hedge on earth that could stop me from going bankrupt if I buy that much compute... I get the impression that some of the other companies have not written down the spreadsheet." — <strong>Dario Amodei</strong>
"I think we should be thinking about this middle world where things are extremely fast, but not instant... not slow, much faster than any previous technology, but it has its limits." — <strong>Dario Amodei</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        Reflecting on the progress made since three years ago, the exponential trajectory of underlying AI technology has largely unfolded as expected. While specific developments like the direction of coding capabilities might have been difficult to predict precisely, the general march of models—from the level of a smart high school student to a college student, and now beginning to handle PhD-level and professional tasks—has followed a clear path. The frontier remains somewhat uneven, but the most surprising aspect is not the technology itself, but rather the lack of public recognition regarding how close we are to the end of this exponential curve. It is striking that while public discourse remains fixated on traditional political hot-button issues, we are approaching a monumental technological threshold.

The &quot;Big Blob of Compute Hypothesis,&quot; first formulated in 2017, remains the guiding theory for this progress. This hypothesis suggests that specific cleverness or novel methods matter less than a few core pillars: raw compute, the quantity and quality of data, a broad data distribution, training duration, and an objective function that can scale indefinitely. This applies not just to pre-training but also to Reinforcement Learning (RL). Just as pre-training scaling laws showed log-linear improvements in loss, we are now seeing similar scaling in RL. Whether it is solving math contests or performing coding tasks, performance improves consistently based on how long a model is trained within these RL environments.

There is a common critique, often associated with Rich Sutton’s &quot;The Bitter Lesson,&quot; that if these models possessed a true core of human-like learning, they wouldn't require billions of dollars in compute and bespoke environments to learn basic tasks. However, this may be a red herring. Pre-training is not a direct analog to human learning; instead, it exists in a middle space between human evolution and on-the-spot learning. Just as evolution provides humans with biological priors and brain structures, pre-training provides models with a vast foundation of knowledge. True human-like learning—the ability to adapt on the fly—is more closely mirrored by in-context learning, where models with long context windows can learn and adapt within a single session.

The goal is not to teach every individual skill through RL, but to reach a point of generalization. We saw this transition between GPT-1 and GPT-2, where the model moved from predicting text to understanding underlying patterns, such as performing simple linear regression without having been specifically trained for it. Currently, we are moving toward a state described as a &quot;country of geniuses in a data center.&quot; While there is always irreducible uncertainty due to geopolitical risks or the difficulty of verifying non-binary tasks like scientific discovery or novel writing, there is a 90% confidence that this will be achieved within the next ten years, with a strong hunch that it could happen in as little as one to three years.

In the realm of software engineering, we are already seeing models write 90% of the code in certain environments. This does not yet mean a 90% reduction in the need for engineers, as the job involves higher-level tasks like setting up clusters, testing features, and writing design documents. However, the productivity gains are real and accelerating. The perceived delay in broader economic impact is often attributed to &quot;diffusion&quot;—the time it takes for enterprises to adopt new technology due to legal, security, and procurement hurdles. Even if a model can read a company’s entire Slack history and codebase in minutes, it still takes time for an organization to change its internal processes.

One of the final hurdles for total automation of complex digital roles, such as video editing, is perfecting &quot;computer use&quot;—the ability of a model to reliably navigate an OS and interface with various software as a human would. While current benchmarks show rapid improvement, the models must reach a level of mastery where they can build long-term context on the job. This involves not just performing a task, but understanding a specific client’s tastes or an audience’s preferences over several months.

Despite the immense potential of this technology, scaling compute requires a balanced financial approach. Anthropic has seen a 10x annual revenue growth, moving from $100 million to $1 billion, and now toward $10 billion. While it is tempting to invest hundreds of billions or even trillions into compute to capture the full potential of a &quot;country of geniuses,&quot; the risk of bankruptcy is high if the growth rate slows even slightly or if the technology arrives a year later than projected. The industry is currently building out massive infrastructure, moving from 15 gigawatts toward 100 or even 300 gigawatts by the end of the decade. This represents a massive, yet calculated, bet on the future of intelligence.

By 2028 or 2029, the industry could be generating multiple trillions of dollars a year. If Anthropic’s compute continues to triple annually, by 2027 or 2028, it might reach ten gigawatts. At approximately $10 billion per gigawatt, that suggests a spend of $100 billion a year. While some predict the total addressable market by 2028 will be $200 billion, those numbers might actually be too small.

Profitability in this field is a unique metric. It isn't necessarily a measure of spending down versus investing; rather, it often stems from either underestimating or overestimating demand because data centers are purchased in advance. In a stylized model where compute is split evenly between training and inference, the inference side typically carries a gross margin higher than 50%. If demand is higher than expected, research gets squeezed, but the business becomes more profitable because more compute is supporting inference. Conversely, if demand is overestimated, more compute is available for research, but the business appears less profitable. The industry is currently in an exponential scale-up phase where individual models may be profitable on their own, but the companies overall lose money because they are reinvesting massive sums to train the next generation.

The industry will likely settle into an equilibrium with a small number of players, similar to the cloud industry. This is driven by high costs of entry, requiring massive capital and specialized expertise. Unlike cloud computing, however, AI models are highly differentiated. Claude, GPT, and Gemini each have distinct styles and strengths in areas like coding, math, or reasoning. While the economy might grow by 10% to 20% annually with the help of AI, it likely won't match the 300% annual growth currently seen in compute. There is also a risk of geographic disparity, where Silicon Valley and its social connections see rapid growth while the rest of the world lags behind.

Robotics will likely be revolutionized through various methods, whether through simulated environments, game training, or general-purpose computer control. This will impact both hardware design and control capabilities. Barriers that once seemed insurmountable, like continual learning or semantic understanding, often dissolve within the &quot;big blob of compute.&quot; We are approaching a point where AI can handle end-to-end software engineering tasks, which represents a massive shift in human labor.

The API business model will likely remain durable because there is always a new surface area of capabilities to explore. However, we may also see models based on labor-by-the-hour or pay-for-results, especially when tokens represent high-value outputs like pharmaceutical breakthroughs. Claude Code itself was born as an internal tool at Anthropic. After seeing how quickly internal researchers adopted it to accelerate their own work, it became clear there was significant product-market fit for a broader release.

In a world where AI capabilities diffuse rapidly, we face an offense-dominant security landscape. Immediate concerns like biological weapons require transparency standards and classifiers. While some state laws—such as those attempting to ban emotional support AI—seem misguided, there is a legitimate need for federal standards. A patchwork of state laws can be problematic, but a complete moratorium on state regulation without a federal plan is also risky given the potential for rapid autonomous or biological threats. The legislative process is normally not nimble, but the urgency of these risks requires us to act faster than usual.

The long-term challenge is establishing governance that preserves human freedom while managing the proliferation of superhuman AI. We must consider how to protect society from bioterrorism and authoritarian oppression. If democratic nations hold the stronger hand during this transition, they can exert more leverage in setting global norms. As technology continues its exponential climb, we may even reach points where traditional concepts, like the stability of nuclear deterrence, are no longer certain, requiring us to rethink our societal structures entirely.

There are points where reaching a certain level of offensive cyber dominance makes every computer system transparent unless the opposing side possesses an equivalent defense. While it is unclear if there is a single critical moment or a series of them, a window will likely open where AI confers a significant advantage for national security, favoring one country or coalition. This does not necessarily mean advocating for immediate total control—especially since the other side is always catching up and there are ethical limits to power—but it marks a fundamental change in the world. At that point, there will be negotiations, whether implicit or explicit, regarding the post-AI world order. The goal should be to ensure that classical liberal democracy holds a strong hand in those discussions.

In discussing the future of governance, some argue that autocracy is simply not a form of government that people can accept in the age of powerful AI. This leads to questions about whether institutions like the CCP can exist post-AGI. While one could take an interventionist view that authoritarian regimes must be displaced because they create self-fulfilling cycles of power, such a commitment could lead to immediate instability. However, in an AGI era, authoritarianism takes on a graver meaning. Just as industrialization made feudalism unsustainable, AI may render certain forms of government obsolete. This isn't necessarily a guarantee for democracy—it could go either way—but the intensifying problems of authoritarianism might motivate new ways to protect freedom. Ideally, dictatorships could become morally and practically unworkable, forcing a collective realization that individual rights are the only viable path forward.

Historically, the decision to engage with authoritarian systems like China in the 1970s and '80s was largely correct, as it lifted over a billion people out of poverty, even if the system remained authoritarian. With AI, we face a similar dilemma: should the benefits be diffused globally? While technological advancements in health or disease cures should be shared, the infrastructure—specifically chips and data centers—presents a different security risk. There is also the possibility of creating a technological equilibrium where it becomes infeasible for regimes to deny their citizens the private use of AI. If individuals have models that protect them from surveillance, it could cause authoritarian structures to disintegrate from within. Though earlier hopes for the internet to provide this effect were disappointed, it remains worth exploring whether AI can be built with properties that dissolve authoritarian control.

As we move into a world where economic value is generated easily through powerful AI models, the real challenge shifts to the distribution of wealth and the protection of political freedom. For the developing world, the traditional mechanism of catch-up growth—leveraging underutilized labor—may fail if labor is no longer a constraint. While philanthropy is necessary, endogenous growth is better. We should encourage the development of AI-driven industries, such as pharmaceuticals and biotech, within the developing world. Building data centers in regions like Africa can foster this growth, ensuring that humans in those regions remain central to supervising and benefiting from these systems during the transition.

The development of &quot;Constitutional AI&quot; reflects a shift from simple rules to guiding principles. Teaching a model principles like &quot;don't make biological weapons&quot; makes its behavior more consistent and better at handling edge cases compared to a list of rigid &quot;dos and don’ts.&quot; This approach focuses on corrigibility—ensuring the model follows human instructions rather than acting on its own intrinsic motivations. The question then becomes how these principles are determined. This process involves three iterative loops: internal updates within a company, competition and critique between different companies' constitutions, and broader societal input. While a formal legislative process might be too slow for current developments, involving representative government or collective polling can help ensure that AI values align with public interest.

When future historians look back on this era, they will likely struggle to appreciate how non-inevitable these developments felt at the time. Retrospective bias often makes historical shifts seem obvious, but the current reality is defined by its insularity; while those within the field see an exponential curve, the average person may have no idea how close we are to a major breakthrough. Furthermore, the sheer speed of the crisis means that consequential decisions are often made in minutes rather than months. A casual choice between two options on a short memo could end up shaping the entire future, a reality that is difficult to glean from a formal historical record.

Managing an organization of 2,500 people requires a focus on culture to prevent the decoherence and infighting seen in other rapidly growing AI labs. A significant portion of a CEO's time must be dedicated to articulating the company’s strategy, values, and mission. This is achieved through direct, unfiltered communication, such as bi-weekly &quot;Dario Vision Quest&quot; sessions and regular internal memos. By avoiding corporate jargon and being honest about problems, leadership can build a reputation for truth-telling. This transparency ensures that the team remains unified and that everyone is working toward the same mission in good faith, making the organization more than just the sum of its parts.
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>