<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - February 03, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        .tag-company {
            background: var(--green-subtle);
            color: var(--green);
        }

        .tag-event {
            background: var(--yellow-subtle);
            color: var(--yellow);
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-card:hover {
            border-color: var(--accent);
        }

        .day-card a {
            display: block;
            padding: 1.25rem 1.5rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.75rem;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            gap: 0.6rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.15rem;
            padding: 0.5rem 0;
            border-bottom: 1px solid var(--border);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-meta {
            display: flex;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-channel-icon {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-title {
            font-size: 0.9rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.3;
        }

        .preview-tldr {
            font-size: 0.8rem;
            color: var(--text-tertiary);
            line-height: 1.4;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">February 03, 2026</p>
            <div class="stats">
                <span><span class="stat-value">2</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=OtevzCuhEzQ" target="_blank" rel="noopener">Building the Future of Industrial AI with NVIDIA</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/ytc/AIdro_mvdJx2QT4WkxWNyS5VhmvRft5eFFV8tkyzrjDEvfZUABg=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Dassault Systèmes</span><span class="channel-subs">(88.0K)</span></span>
                        <span class="meta-sep">·</span><span>41:40</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-03</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Jensen Huang</span> <span class="tag tag-person">Howard Marks</span> <span class="tag tag-company">NVIDIA</span> <span class="tag tag-company">Amazon</span> <span class="tag tag-event">Keynote</span></div>
                </div>
                <div class="tldr">Dassault Systèmes and NVIDIA are forging their deepest partnership yet, combining Dassault Systèmes' virtual twin technology with NVIDIA's accelerated computing and AI to power a new &quot;generative economy&quot; and &quot;knowledge factories,&quot; enabling real-time,...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">TL;DR Dassault Systèmes and NVIDIA are forging their deepest partnership yet, combining Dassault Systèmes' virtual twin technology with NVIDIA's accelerated computing and AI to power a new &quot;generative economy&quot; and &quot;knowledge factories,&quot; enabling real-time, AI-driven design,...</div>
                    <div class="summary-full" id="full-0">
                        <p><strong>TL;DR</strong></p>
<p>Dassault Systèmes and NVIDIA are forging their deepest partnership yet, combining Dassault Systèmes' virtual twin technology with NVIDIA's accelerated computing and AI to power a new "generative economy" and "knowledge factories," enabling real-time, AI-driven design, simulation, and operation across all industries.</p>
<h3>A New Era of Industrial AI</h3>
<ul>
<li><strong>Shifting Paradigms:</strong> The 21st century's industry is moving from producing physical objects to generating knowledge and know-how, which then creates objects, representing the true source of value.</li>
<li><strong>Knowledge Factories:</strong> Dassault Systèmes' virtual twins and 3D universes are evolving into "knowledge factories" where insights are enriched, know-how is scaled, and results are trusted.</li>
<li><strong>Real World AI:</strong> This transformation is supercharged by a "real world AI" grounded in industry, engineering, and science, moving beyond generic AI and Large Language Models (LLMs) to create "world models" capable of designing complex systems like aircraft or discovering cancer therapies.</li>
<li><strong>Accelerated Computing:</strong> The fusion of virtual twin power with accelerated computing is critical to realizing this vision.</li>
<li><strong>AI as Infrastructure:</strong> Jensen Huang posits that AI is becoming foundational infrastructure, akin to water, electricity, or the internet, impacting every industry and country globally.</li>
</ul>
<h3>Deepening a Quarter-Century Partnership</h3>
<ul>
<li><strong>Historical Roots:</strong> The collaboration between Dassault Systèmes and NVIDIA spans over a quarter-century, originating during the personal computing revolution with technologies like OpenGL and CGFX (precursor to CUDA).</li>
<li><strong>Largest Collaboration:</strong> This new phase marks the largest partnership between the two companies, aiming to reinvent the computing platform for an AI-driven era.</li>
<li><strong>Integrated Technologies:</strong> Dassault Systèmes will integrate NVIDIA CUDA-X acceleration libraries, NVIDIA AI for physical and agentic AI, and NVIDIA Omniverse (NVIDIA's digital twin technology) into its platforms.</li>
<li><strong>Unprecedented Scale:</strong> This integration promises 100x to 1,000,000x greater scale and real-time capabilities for engineers and designers, enabling processes that were previously impossible.</li>
</ul>
<h3>Generative Power: From Life Sciences to Factories</h3>
<ul>
<li><strong>Generative Economy:</strong> The partners envision a "generative economy" where virtual twins are infused with accelerated AI to transform design and manufacturing.</li>
<li><strong>Life Sciences &amp; World Models:</strong></li>
<ul>
<ul>
<li><strong>Understanding Life's Language:</strong> NVIDIA AI integrates with Dassault Systèmes' Biovia to understand the "language of life" – DNA, proteins, cells – and their interactions.</li>
<li><strong>Generative Biology:</strong> This understanding enables the generation of new proteins for drugs, novel chemicals, and advanced materials (e.g., stronger, lighter, heat-resistant).</li>
<li><strong>Case Study: Bell Group:</strong> The Bell Group uses biological world models within virtual twins to automatically generate proteins, accelerating healthier food innovation and ensuring certified decisions.</li>
</ul>
</ul>
<li><strong>Generative Engineering &amp; PhysicsNemo:</strong></li>
<ul>
<ul>
<li><strong>Augmenting Simulation:</strong> The fusion of simulation and AI allows virtual twins to explore infinite design possibilities and predict outcomes 10,000 times faster using "surrogate and emulation models."</li>
<li><strong>Physics-Aware AI:</strong> NVIDIA's PhysicsNemo is a physics-aware AI model system, grounded in physical laws but capable of rapid prediction, transforming engineering design.</li>
<li><strong>Case Study: Lucid Motors:</strong> Lucid embeds complex behaviors like crash dynamics and aerodynamics early in vehicle development, enabling engineers to design behavior and certify performance concurrently.</li>
</ul>
</ul>
<li><strong>Software-Defined Factories:</strong></li>
<ul>
<ul>
<li><strong>Virtual Operations:</strong> Factories are becoming hybrid virtual and physical assets, simulated and operated entirely within virtual twins.</li>
<li><strong>Complex Systems:</strong> These virtual factories manage millions of objects, optimize manufacturing lines, orchestrate robot AIs, and ensure safety, all within a software-defined environment.</li>
<li><strong>Case Study: Omron:</strong> Omron uses virtual twins to engineer "software-defined factories," designing autonomous capabilities from day one, leading to more flexible, resilient, and adaptive production systems.</li>
</ul>
</ul>
</ul>
<h3>The Future Engineer with AI Companions</h3>
<ul>
<li><strong>AI Factories Infrastructure:</strong> The world is undergoing the largest industrial infrastructure buildout in history, with "AI factories" (composed of chip, computer, and AI factories) costing tens of billions of dollars per gigawatt.</li>
<li><strong>Model-Based Design for AI Factories:</strong> NVIDIA uses Dassault Systèmes' Model-Based Systems Engineering (MBSE) to design, plan, and simulate these complex AI factories in virtual twins before construction, saving significant time and money.</li>
<li><strong>Virtual Companions:</strong> AI is enabling a new workplace revolution where engineers will work with "virtual companions." These companions can translate unstructured information (like sketches) into precise 3D parametric models automatically.</li>
<li><strong>Augmenting Human Creativity:</strong> Rather than replacing engineers, AI companions will serve as a team, trained by the designer, to explore and optimize designs, freeing human engineers for strategic, creative, and fine-tuning tasks.</li>
<li><strong>Knowledge Protection:</strong> These AI companions will codify individual designers' preferences, skills, habits, and domain expertise, acting as private, personalized extensions of their knowledge.</li>
<li><strong>Compliance by Design:</strong> Virtual companions can automatically ingest requirements and continuously verify conformity (e.g., for aircraft certification with 10,000+ requirements), shifting compliance upstream to become a competitive advantage rather than a cost.</li>
<li><strong>World Models for Compliance:</strong> Moving from language models to world models means integrating the laws of physics, causality, manufacturability, and societal values directly into the design process, ensuring constant compliance.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"In this new century, industry is producing knowledge and knowhow and the knowledge and knowhow are generating the objects. This is where the true value lies."
— <strong>Pascal Daloz, CEO, Dassault Systèmes</strong>
"AI is foundational to every single industry, it is going to become an infrastructure. Just as water was infrastructure, electricity is infrastructure, internet was infrastructure, now artificial intelligence will be infrastructure."
— <strong>Jensen Huang, Founder and CEO, NVIDIA</strong>
"We can't compute infinity but we can imagine infinity which is the reason why these surrogate and emulation models the fusion of simulation and artificial intelligence is so powerful."
— <strong>Jensen Huang, Founder and CEO, NVIDIA</strong>
"The number of users of the soul tools is going to go from biological to biological as well as AI based. And so the number of tool use will ex will explode."
— <strong>Jensen Huang, Founder and CEO, NVIDIA</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        Hey, thank you so much for the warm welcome and welcome back. Today is a special day, but before we dive in, let me do a quick summary of what I discussed with you yesterday. If you remember, we talked about the future, but more importantly, we talked about how we are building it. The future is not only about empowerment; it's also about inventing new things, new openings, new possibilities with you and for you.

If we step back for a moment, the previous century, the 20th century, was really about industry using and producing objects. In this new century, industry is producing knowledge and knowhow, and that knowledge and knowhow are generating the objects. This is where the true value lies. This is where the power is, and that's why we bring together the virtual twins and the 3D universes. 3D universes are not applications; they are knowledge factories—factories where knowledge is enriched, knowhow is scaled, and the results are trusted. To supercharge this, we are using AI. Not a generic AI, not a surface-level AI, but what we call a real-world AI, grounded in industry, engineering, and science. So it's not only about large language models; it's about what we call the world models, because LLMs do not build satellites, they don't design aircraft, and they don't discover cancer therapies. You do, and we help you to certify it. The world model, in fact, makes the virtual twin truly generative. To make this possible, we combine the power of a virtual twin with accelerated computing.

To continue these conversations, I'm now very pleased and honored to invite on stage someone who is defining, someone who is shaping the foundation of artificial intelligence. Please give a warm welcome to Jensen Huang, founder and CEO of Nvidia.

Pascal. Hey everybody! Are you all solid workers? Hard workers. Hard workers. So, welcome on stage, Jensen.

Thank you.

It's always a pleasure to have you. I don't know if people realize, but we have a long-standing relationship. I think we almost started the collaboration 30 years ago, over a quarter century ago. Do you remember how it started?

Well, we started during the last computing platform revolution. The personal computer revolution, and what used to be Unix workstations was migrating to Windows-based workstations. The technology that made it possible for us to collaborate was based on OpenGL, and we invented a technology called CGFX, which is the precursor of CUDA. OpenGL became RTX today, fully path-traced and physically based, and CGFX, of course, became CUDA. Here we are, working together again as we reinvent the computing platform. Everything that we do is in the digital world. Forty years ago, Dassault Systèmes revolutionized the idea of virtual twins. The idea of a virtual twin, of course, is to represent the physical world in a computer. Now we're going to represent the physical world at a much, much larger scale in a completely revolutionized computer, an AI computer. This is a really, really fantastic time.

You're right, it's an incredible journey. And as you said, now we are entering into a new chapter. We are now in what we call the generative economy, where we are empowering the virtual twin with accelerated artificial intelligence. From your perspective, Jensen, what is happening in the global industry right now?

We're reinventing the computing stack altogether. As you know, in the last generation, the representations of designs were structured representations, meaning we specified every geometry, every material, literally everything. Now, it's going to be a generative computing model. In the world of generative computing models, the entire computing stack is being reinvented. Because AI is foundational to every single industry, it is going to become an infrastructure. Just as water was infrastructure, electricity is infrastructure, and the internet was infrastructure, now artificial intelligence will be infrastructure. We're growing so fast because every single industry needs to build it. Every single country will be powered by it. Literally every society will have it. This is the beginning of a new industrialization, which is really fantastic for Dassault Systèmes, because as you know, it is the engine of the representation of everything that you want to build.

In the future, in the past, I would say that we spent a third of our time in design and digital, maybe two-thirds of the time in physical. It is very likely in the future, we're going to spend 100% of the time in digital. Even after we're done designing it, simulating it, and validating it, we have to integrate it with software. Everything that's inside the Dassault Systèmes (DS) systems, whether it's CATIA or SIMULIA or BIOVIA, or what are the other VAs we have? We have DELMIA, we have ENOVIA. And listen, all of those VAs are going to be built on top of Nvidia. Did we know that a quarter century ago? Anyhow, the design, the representation, all the simulation, and even the operations of it, because everything will be software-defined in the future. Everything from a pair of tennis shoes will be software-defined in the future. Cars are software-defined. The robots that build the cars are software-defined. The factories where the robots are orchestrated to build the cars are software-defined, and the cars themselves are software-defined. So everything will be software-defined. Everything will be represented inside DS, and so we'll be designing everything, operating everything really as a virtual twin, and realizing your vision for the first time.

Yes. Before we go further, if you look around the crowds, it's kind of a ruckus crowd. At Dassault Systèmes, we work with 45 million people around the world, 400,000 customers, more than 15 million engineers and researchers. So I think you have here probably one of the, if not the largest, engineering community in the world. They do more than half of the products surrounding us every day: robots, drones, planes, cars, medical devices, drugs, homes, cities, factories. This is an amazing community, don't you think so? I know they think so.

Absolutely. We're all engineers.

You are an engineer.

Yes, I'm still an engineer.

So you belong to this community.

I am. If I was to start all over again, I'd choose to use SolidWorks.

That's why the world model matters. Because for these communities, success is not about automation; they don't want to automate the past. They want to invent the future. This is the reason why we are announcing this new chapter in our partnership, because together we are bringing the virtual twin factory with the AI factory. This opportunity is really enormous for you guys and for us. To prove the power of this, we have some concrete examples. Jensen and I have selected some use cases we want to share with you. Let's start with research and engineering first.

Yes. I remember that almost everything we do together starts with the computing platform. When PCs went into the cloud, Dassault Systèmes reinvented itself again. Now, as we're extending from cloud to AI, we're reinventing again. Today, we're announcing a massive partnership. This is the largest collaboration our two companies have ever had in over a quarter century. Dassault Systèmes is going to integrate NVIDIA CUDA-X acceleration libraries, NVIDIA AI for physical AI and for agentic AI, and NVIDIA Omniverse, our version of digital twin technologies. All of these libraries represent our body of work over a quarter of a century. Now we're going to fuse these technologies into Dassault Systèmes so that all of you will have the benefit of accelerated computing and artificial intelligence, and be able to work at a scale that's a hundred times, a thousand times, and very soon a million times greater than what you were able to do before. What used to be pre-rendered or offline simulations will now be literally the virtual twin vision that you've always had. Everything will be done literally in real time. We'll design products and simulate them in a wind tunnel in real time. We'll interconnect these robots and let them operate in a factory in real time, and they'll be building your products literally in real time. All of this is going to be happening in the next five to ten years; this is going to be extraordinary.

Speaking about this, let's start with life. I think life is the most complex system ever created. When you think about it, how much knowledge is encoded in the living world? With our virtual twins, we are learning from life. We are also understanding it in order to replicate and to scale it. This is possible. This is NVIDIA AI integrating with BIOVIA.

Yes, BIOVIA, right? We will come back to this. But this is possible because we have this foundation. We call it the world model.

The world model, where it's grounded in biology, physics, and material sciences. So the key question I have for you is, what does it take to compute a world model for life?

Well, the most important thing, the first thing that we have to do, is understand the language of life. Of course, in the world of physical design, the design started with your imagination, and you represented that physical object using structured information, geometries, and textures that were designed by you. However, life is different. Life existed before us. So we have to go learn the language of DNA, learn the language of proteins, and learn the language of cells, and understand how they interact and their properties. That first stage of learning the meaning of life is what we are in the process of tackling.

The second part, of course, is generative. Once you can learn something, learn the meaning of something, we can translate it between languages. We can translate between human language and the language of biology, and interpret it so that we can understand it in human language. Beyond that, you can now translate and generate new proteins that could be used for a drug, or generate new chemicals that could be used for a drug. Then, of course, generate new materials that could be stronger, be more heat resistant, lighter, easier to manufacture, last longer. All of those properties are now within our grasp, and this is one of the reasons why this is likely going to be one of the most impactful areas of engineering in the next decade.

Exactly. And it is already happening. In fact, we have a case: the Bel Group. You know them, they make the famous Babybel. Their mission is very simple: they want to produce healthier foods for millions of consumers. But at the same time, they want to consume less water, and they want to progressively change or at least complement dairy protein with non-dairy proteins. That's the reason why they are inventing what we call food science. Before, there were hundreds of physical tests for one single product. Now they generate automatically – and this is what you can see on the screen – they generate automatically the protein from the virtual twins, because it's powered by the biological world model. The result is not only faster innovations, but also certified decisions, because you cannot play when you have the life of people in your hands. That's what we do.

Now let's move to something else you started to speak about. You have seen on screen this is changing the daily life of engineers. Now you define the specs, you run your simulations, and automatically the generative experience is producing and exploring the space of possibilities and finding the optimum solutions for you. Actually, the virtual twin is exploring an infinite of possibilities. So the question I have for you is, could we compute infinity?

We can't compute infinity, but we can imagine infinity, which is the reason why these surrogate and emulation models, the fusion of simulation and artificial intelligence, are so powerful. Eight years ago, I introduced the idea to scientific computing and simulations: the idea that in the future, not only will we use principled simulations where the equations, the laws of physics, are well understood and well represented (however, the simulation time takes way too long), why don't we augment that with generative methods of predicting the future using artificial intelligence? It's a little bit like the analogy I would give: it's a little bit like are dogs able to catch a ball out of the air? Yet they're not doing physics simulations of balls bouncing or the elastic nature of the ball. They're just literally watching us and predicting where it's going to go, and they snatch it out of the air. The idea that an AI could learn how to predict physics and learn how to predict very accurately how materials would crumble, what happens to a crash—those capabilities are within grasp. We have a technology called Physics-Nemo. Physics-Nemo is essentially a physics-aware AI model simulation system and AI framework that allows us to create these AI models that are either trained by principled simulators or work alongside principled simulators. So it's grounded in the laws of physics but able to predict 10,000 times faster. Now if everything is already running in real time, then you can predict it at 10,000 times greater scale. That's just where we are right now. Imagine where we're going to be in the future. The idea of simulation and emulation coming together to help you design is going to be truly revolutionary.

Again, this is exactly what you see here with a customer called Lucid. We know them; they are one of the most innovative car companies in the world. What do they do? They embed the crash behavior, the aerodynamics, and the vehicle performance upstream, early in the vehicle program's developments. So the engineers don't only design the shape, they design the behavior, and we certify it. This is exactly what you said: this is this grand vision, empowering designers and engineers, and also unlocking business people to develop delightful experiences for their customers.

Now let's talk about factories. You started to touch on this topic a little bit. Factories are not anymore today only physical assets. I think we are all in agreement with this. They are made of virtual and real at the same time. So let us know how physics AI is really used to run the factories.

Well, the way that people used to think about designing products is they design the product and they build the factory. In the future, it's very likely that the products you are able to design and build will be greatly impacted by the factories you design and build. So, it's very likely in the future—well, it will be; in fact, it is now—that every single factory is designing CAD. That's obvious, but it will be simulated and operated completely inside a virtual twin. Operating a factory of these gigantic scales inside a virtual twin is extraordinarily complex. A factory is not just one object; it's millions of objects. We want to also simulate or emulate how these factories will operate in the real world so that we could arrange the manufacturing lines properly, arrange them in the right sequence, space them properly, organize the robots within them, run the robot AIs so that these AI robots could be operating inside the factory, manipulating things, assembling things, moving things, keeping things safe. All of this is going to happen inside a virtual twin. So, the products that Dassault Systèmes is going to help people build and design are going to become gigantic in the future. These are going to be systems of objects, systems of AI, systems of robots all coming together into a giant factory. These are fast computers, is what I'm saying.

And again, this is exactly what we do with Omron. You have seen on the screen they don't use the virtual twin only to visualize the factories. In fact, they do much more. They engineer what we call a software-defined factory.

That's right.

And where the difference is coming from is that they are designing the autonomous part day one. It's not something they come to when the production system is already up and running and then try to infuse the autonomous part into it. As a result, those factories become much more flexible, resilient, and adaptive. But there is another kind of factory, and you talk a lot about this: the AI factories. They are building everywhere; they are extremely complex. What does it take to make them or to build them and to make them a reality?

Well, we're going through what clearly is a new industrial revolution, a fundamental technology that impacts the productivity of many industries. That's why it's an industrial revolution. Just as energy did that, just as mechanical energy and power did that, just as electricity and, of course, the internet did all that, we're now seeing artificial intelligence doing that. In order to make this possible, we need to industrialize and really scale three different giant industries. The first, of course, is building a lot of chips, which is why the number of chip factories are increasing. You're involved in a whole bunch of chip factories and packaging factories just to make all these semiconductor products. The second is computer factories. Once the chips are done, they go into another factory. What comes out of that is a supercomputer. Those supercomputers go into artificial intelligence factories. Right now, as we're speaking, these three entirely different industries are all growing incredibly fast so that we could create the infrastructure for intelligence and manufacturing the AIs.

While these factories are incredibly complex, a gigawatt AI factory is about $50 billion. And now we're building tens of gigawatts around the world. It's an enormous infrastructure buildout, the largest industrial infrastructure buildout in human history. The amount of technology that comes together inside these factories is extraordinary. We want to make sure that they work the first time. The way we're doing it, we're using MBSE – Dassault Systèmes product, Model-Based Systems Engineering. I wish you would have been something VIA. Not yet. Okay, alright, so MBVIA, that's it, Model-Based VIA. So what goes into these systems are giant data centers with lots of supercomputers. The amount of energy necessary, of course, is a gigawatt – the largest factories ever. And it costs so much money. So we design, we plan, we simulate everything in MBSE before we build it. Our expectation is, and we even run the network and run the supercomputers inside the virtual twin before we even break ground. That allows us to save tons of time and tons of money. And over time, of course, this data center has an AI that keeps it optimal. It's AIs that modulate the performance, modulate the power, modulate the temperature, modulate cooling, and in doing so, if you want to do so successfully, you need artificial intelligence. That operating loop – we're going to have these virtual twins of these AI factories running forever, training and updating our models.

So again, this is proving that the virtual twin is not only about 3D. As you say, it's about revealing the architecture, revealing the system underneath, and obviously revealing the knowledge at scale.

And it looks real, and it's real. It looks real, right? It looks real. It operates really. It integrates all industrial bill of material. The bill of material comes in from manufacturers and suppliers. We integrate everything physically. We have a very clear list of bill of material. We know exactly what we're going to buy. We know which part is going to integrate with another. We could see in advance whether something fits or doesn't fit. We know exactly how many parts. The inventory bill of material of this supercomputer comes out. This AI factory comes out, adds up to about a $50 billion bill of material. This is incredible, and we have everything digitally, so no mistakes will be made.

Now I'm counting on you to sell it to your ecosystem, right?

Absolutely. Well, you're, we're the first customer.

You are? You're the first customer.

Now the next topic I want to discuss with you is really how do we put the knowledge to work. This is exactly what our virtual companions do. We made a live demo yesterday just to showcase what is coming, and engineers spend too much time looking for information or doing something else. This is not engineering. So now, look at it. In a few seconds, we started from a sketch; we produced automatically, we moved from 2D to 3D. It's a full parametric model simulation already. I think this is revolutionizing everything people are doing, and it's changing the workflows completely. Now there is a question in this room, and the question is this: do you think this will replace engineers?

Well, before I answer that, one of the really revolutionary things that AI has made possible for us is the ability to go from an interchange between structured information and unstructured information. Unstructured information is essentially a photograph, or it could be a recording, a video. We want to take that unstructured information and now represent it in a structured way. We need artificial intelligence to go from 2D to 3D, image to 3D. Once you have it in 3D, that information is precise. It's controllable. It's interchangeable. We can enhance it. We can improve it. So it's now in our structured database. We can go from structured to unstructured very easily.

So now we have the representation, the ability to use agents and use AI to manage our information so that we can augment the design process. We could decide that this part I'm going to design specifically by hand here. I'm going to take an image, import it, and then modify it, and so forth. These agents are going to be companions of ours because we're going to essentially be their manager, their architect, the creator. We're going to have a lot of agents or companions help us perform different tasks. Whereas most people think that the number of designers, therefore, will be less than in the past, and the number of software tools you will use will be less than in the past, it's exactly the opposite. It is very likely, and I'm certain this is going to happen, that every designer, every SolidWorks designer, every designer in the future, will have a team of companions. You've trained these companions, and you've taught them different skills, and you've helped them coordinate and work with each other and work with you, and they're all going to be using Dassault Systèmes tools. So the number of users of Dassault Systèmes tools is going to go from biological to biological, as well as AI-based. The number of tool uses will explode. This, of course, is going to be great for the software industry. It's going to be great for all the designers because you have so many companions to help you do things. What would be really fantastic is that you're working with your companions, and then it's time for a cocktail, because it's solidly 4:30 somewhere, and so you kick off your team to go explore all these different areas. &quot;I want you to explore this, I want you to explore that, I want you to optimize for these areas and give me three designs. I want to optimize for these years. Give me 10 designs.&quot; When you come back, you have all those choices, and then you can go in and fine-tune it specifically yourself because you have the structured data, the 3D data. So I think the opportunities to reinvent how you think about design and creativity are going to be completely revolutionary for everybody.

That's also something we can showcase. For instance, take NIAR. NIAR is a national institute for the aviation industry. They are based in Wichita and they focus on research, testing, but also certifying. We know that certifying an airplane is a nightmare. It takes between three to five years; more than 10,000 requirements need to be fulfilled. Now, with virtual companions, what could we do? The regulations could be automatically ingested without having to read millions of pages, and conformity is constantly verified. This means we are moving to compliance by design, and it's not anymore a cost; it could become a competitive edge. So the question I have for you is, how does it take to move from a language model to a world model?

Well, the language model has to obviously understand syntax and vocabulary and the structure of language, and it has taste. What's a better way to compose a paragraph? And it has guardrails – what are the things it should talk about and things it should avoid talking about? In the world model, instead of taste and values, it has to obey the laws of physics. It has to understand causality: if you tip over a domino, all the dominoes that are connected to it or nearby it will be tipped over. It has to understand what comes after and what comes before. It understands inertia and friction, understands gravity, of course. It understands contact – all the things that you understand as you're designing things. We have to teach the AI that sensibility that's not necessarily captured in language, and all the language in the world won't capture that. So we have to use laws of physics and simulation and a whole bunch of examples to teach it the laws of physics.

Then, of course, one of the things you mentioned is that design for manufacturability today is integrated into the design process, instead of you coming up with the design and then another team decides whether it's manufacturable. Design for manufacturability is really upstreamed, shifted left. We want to shift left basically everything. One of the things that are very hard, as you mentioned, is compliance, because that's where machines meet society and humans. So that language model, where human values could be now integrated into or shifted left into the design process, means you're constantly in compliance. You're constantly obeying the laws of physics because of the world model. You're constantly designing for manufacturability. You're constantly designing to use components that are approved with vendor approval lists and whatever it is, so that by the time you're done with the design, it's good to go.

Now, I hope you have a better idea about what this partnership is about. I think together with Nvidia, we are delivering the knowledge factory to power the virtual twins with our virtual companions, with accelerated AI computing. This is more than performance. As you say, it's an acceleration, but more importantly, this is opening new possibilities. Whatever the size of the company, whatever the industry you are in, I think we help you to certify your decisions. We help you to eliminate bad choices before they become expensive mistakes. We also help you to create new categories of solutions. You call it the software-defined products, the software-defined factories, the software-defined objects at large. More importantly, we need to protect your knowledge as well. So how do you think we can protect the knowledge of all the millions of people using our software?

Well, first of all, before I go there, I think that our partnership today and what we're announcing is genuinely extraordinary. The type of things that you will be building in the future are simply impossible without accelerated computing. It's impossible without real-time simulation. It's impossible with artificial intelligence. Instead of thinking about what could be more productive – yes, productivity is going to be enhanced, and you'll be a lot more productive, and you'll be able to do things more quickly than in the past, just as PCs did that for us, just as the cloud did that for us, just as the internet has done that for us – every technology revolution has made us more productive. However, this time, the type of things that you'll be able to do, when you think about the scale, a hundred times, a thousand times, a million times, these are going to be things that are just simply impossible to do before.

Our partnership started with computer graphics, and our computer graphics, as you've seen, have become fully ray-traced and physically based, and it looks completely photorealistic, and it's real time. So the foundation of our partnership has always been RTX and computer graphics, but we've now extended it to CUDA-X, we've extended it to AI, and we've extended it to Omniverse. All of these computing platforms sitting on top of accelerated computing and Nvidia's GPUs are going to revolutionize the tools and revolutionize, therefore, how you design and what you can design, and ultimately how your companies operate. So I think that's number one.

The other part that's extraordinary, of course, is that in the future, almost everything we do will have AI in the loop. When people think about AI, they have humans in the loop, and that's important. But remember, you also now have your companion, your AI, in the loop. That AI is going to remember how you like to do your preferences. That AI, therefore, will codify your skills, codify your preferences, codify your habits, codify the domain expertise that you have. That is your companion. That companion sits with you. It's not going to be in the cloud, not going to be public, because it captures your expertise. If you look at my inbox, in a lot of ways, that's captured 33 years of my knowledge, of my expertise. It's not available for everybody. It's not open-sourced, of course, and it captures a lot of my sensibility, a lot of my knowledge. In the future, I will have companions that are going to continue to work with me. I wish I had it 33 years ago, to be honest. Now all of you will have companions that codify your knowledge, codify your sensibility.

Last word about why you think this partnership is unique. You already said a few words, but you are also partnering with other companies, especially in our space. Why do you think what we are doing together is something unique?

Well, Dassault Systèmes, your place in the world of virtual twins, your vision that started it all. CATIA will always be CATIA. SolidWorks will always be SolidWorks. SIMULIA will always be SIMULIA. All the other EAS will always be, and you'll come up with other EAS, and they'll all be built on top of Nvidia. That's the part that I like the best. But the ecosystem that you serve, the ecosystem, and all of you here that are so passionate about the Dassault Systèmes products, and all of your companies that are built on top of the Dassault Systèmes products, are now going to be accelerated and amplified by accelerated computing and AI. That's really what's exciting here. And it happened at precisely the time when the world is re-industrializing, reinventing, starting the largest industrial infrastructure buildout in human history. Trillions of dollars, tens of trillions of dollars. Estimates have it close to $100 trillion, $85 trillion, in the next 10 years. All of that needs to be designed, simulated, validated, prototyped. And of course, because everything is going to be software-defined and everything will be AI-driven, all of that needs to have virtual twins. So I think that the vision that Dassault Systèmes had 40 years ago is coming true.

It's coming true.

Yes, and it's coming true right now. This partnership brings it to life. So I'm delighted to be partnering with you, Pascal. Our quarter-century partnership means a lot to me. CATIA brought Nvidia into the industrial workstation world, and today, CATIA and SolidWorks are to us very, very personal and really important to all of us. Without all of you and the amazing work that you do, many of the things that our engineering and scientists pursue wouldn't have an opportunity to come to life. So I want to thank all of you for all the incredible things that you do, and Pascal for the great partnership, and all of my friends at Dassault Systèmes. Thank you for everything.

Thank you.

Thank you. Now you belong to this community.

Oh, so make sure I am definitely a SolidWorks user.

Make sure you come back. And if you're not coming back, send your virtual twin.

No, I'm coming back. My virtual twin gets to stay home and work.

Alright. Take care, guys.

Take care, guys.

A unique partnership combining Dassault Systèmes' virtual twin factory and NVIDIA's AI factory for all industries, where scientific and industrial knowledge and knowhow meet global-scale computing technologies to form a shared industrial architecture. Model, simulate, reveal, validate with the precision, trust, speed, and context to turn scientific results into industrial decisions. Molecular and protein simulations accelerated 200 times. Expanded engineering possibilities with real-time simulation for every designer. Agile and rapid adaptation of industrial processes through seamless integration and training of autonomous robots in the virtual twin of production systems. Test manufacturing scenarios and validate them instantly. Deploy them within days in the real world. A new infrastructure emerges: the AI factory, a system that produces intelligence understood, controlled, and optimized through its own virtual twin. Driving a new workplace revolution through an agentic platform of skilled virtual companions to enable strategic human-machine collaboration at every stage of work. Together, we are making world models for industry a reality, where virtual twins and accelerated computing work as one. Trusted decisions grounded in science at scale. This is the future of industrial AI.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=fnUlwL0UUJ8" target="_blank" rel="noopener">Fei Fei Li, World Labs CEO: A Fortt Knox Update</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/ytc/AIdro_mimj_qpJ9zIz6FX3wJb9PWDRiip7NS73uW9xRtXy2RZL0=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Fortt Knox</span><span class="channel-subs">(10.7K)</span></span>
                        <span class="meta-sep">·</span><span>10:58</span>
                        
                        <span class="meta-sep">·</span>
                        <span>2026-02-03</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-event">Summit</span></div>
                </div>
                <div class="tldr">&gt; &quot;This is a civilizational technology...</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-1">TL;DR Dr. Fei Fei Li, CEO of World Labs, asserts AI's status as a pervasive &quot;civilizational technology&quot; impacting every aspect of life, underscoring the critical need for diverse global participation and localized understanding, while identifying spatial intelligence as the next...</div>
                    <div class="summary-full" id="full-1">
                        <p><strong>TL;DR</strong> Dr. Fei Fei Li, CEO of World Labs, asserts AI's status as a pervasive "civilizational technology" impacting every aspect of life, underscoring the critical need for diverse global participation and localized understanding, while identifying spatial intelligence as the next major frontier beyond current language models.</p>
<h3>The Pervasive Nature of AI</h3>
<ul>
<li><strong>Transformational Speed:</strong> While AI's potential was always recognized, its breathtaking speed of development over the past decade, especially the last few years, has surpassed expectations, leading to widespread industry adoption and societal discourse.</li>
<li><strong>Civilizational Technology:</strong> AI is a foundational technology akin to the invention of chips, influencing healthcare, agriculture, education, robotics, energy, and sustainability, impacting every aspect of human life and work.</li>
<li><strong>AI as "New Compute":</strong> Dr. Li explains that just as chips are the hardware foundation for computing in virtually every device (from light bulbs to cars), AI represents the "new compute," meaning any system reliant on chip-based computing will eventually depend on AI.</li>
</ul>
<h3>The Imperative of Global &amp; Localized AI Development</h3>
<ul>
<li><strong>Universal Participation:</strong> It is crucial for the "entire global population" to participate in AI development, not just a variety of voices, given the technology's profound impact on shaping versions of the world.</li>
<li><strong>Localized AI Models:</strong> There's a vital need for AI to genuinely understand specific languages, cultures, and ways of life to ensure inclusivity and prevent large segments of the global population from being excluded.</li>
<ul>
<ul>
<li><strong>Example:</strong> The "Typhoon" project by SCB 10X in Bangkok, creating AI models in native Thai language, demonstrates this localized approach beyond reliance on English or Mandarin.</li>
</ul>
</ul>
<li><strong>Market-Driven Demand:</strong> Governments, regions, and markets worldwide are actively recognizing and driving the demand for localized AI, seeking to integrate specific cultural contexts and shared experiences into AI systems.</li>
</ul>
<h3>Spatial Intelligence: The Next Frontier for AI</h3>
<ul>
<li><strong>Beyond Language Models:</strong> While language models are significant, Dr. Li, whose career began in computer vision, identifies spatial perceptual intelligence as the next major frontier for AI.</li>
<ul>
<ul>
<li><strong>Human Intelligence Parallel:</strong> Human intelligence is fundamentally spatial, perceptual, and embodied (e.g., daily actions like making breakfast or driving), extending far beyond verbal communication.</li>
</ul>
</ul>
<li><strong>World Labs' Focus:</strong> World Labs, founded two years ago, is dedicated to developing "next-generation frontier models" for spatial intelligence.</li>
<ul>
<ul>
<li><strong>Capabilities:</strong> These models aim to reason, understand, interact with, and generate 3D/4D worlds.</li>
<li><strong>Applications:</strong> Key areas include simulation, robotics, creativity, design, education, healthcare, and manufacturing.</li>
</ul>
</ul>
<li><strong>Active World Modeling:</strong> This approach goes beyond passive image reasoning, enabling agentic, computed, and proactive interactions within the physical world, which language alone cannot fully describe (e.g., the nuances of cooking pasta).</li>
</ul>
<h3>Real-World Applications &amp; Gaming</h3>
<ul>
<li><strong>Gaming and Interactive Experiences:</strong> This sector is highlighted as a particularly exciting market for spatial intelligence applications.</li>
<li><strong>Marble by World Labs:</strong> The company released its first model and prototype, "Marble by World Labs," allowing game developers to create games and innovate with these new tools.</li>
<li><strong>Empowering Creativity:</strong> The early adoption by developers for smaller-scale games demonstrates the immediate potential for empowering creativity and innovation within the gaming industry.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"This is a civilizational technology... every aspect of our life to every aspect of our work will be impacted by this technology."
— Dr. Fei Fei Li
"AI is the new compute. That means any place, any piece of device, equipment or scenario that depends on chip computing on a chip, it depends on computing with AI."
— Dr. Fei Fei Li
"It's so important that at this point our community our society understand the profoundness of this technology."
— Dr. Fei Fei Li
"Beyond language model, I see the next chapter, next frontier of AI in spatial intelligence."
— Dr. Fei Fei Li
"So much of the physical world's process whether it's is initiated or or or or interacted with human or not human is beyond the description of language."
— Dr. Fei Fei Li
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-1" onclick="toggleSummary(1)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-1" onclick="toggleTranscript(1)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-1">
                        Dr. Fei-Fei Li, thanks for sitting down for Fort Knox and CNBC.
Thanks for inviting me.
They call you the godmother of AI because you have done so much foundational work in shaping this reality that the business world is moving into today. Is it working out the way you expected?
Yes and no. First of all, no one can singularly own any field. The transformation and revolution we are seeing in modern AI is a result of generations of scientists and technologists. For those of us who have been in this field long enough, we obviously believed in the power of AI and how incredible this science could be. It's a civilizational technology, but the breathtaking speed of development in the past almost 10 years, and especially in the past few years, has been just beyond many of our wildest dreams. Looking at the entire industry embracing it, and also society talking about AI from many different perspectives and dimensions with strong emotions, is something that still feels a little surreal, but also gives me the weight of responsibility.

You've done a lot of work to make sure a broad range of people and perspectives have input into how AI is being developed and the opportunity to work with it. You've talked about women in AI, for example, and I wonder if you can sketch out for me what you see the stakes being. In the past we've talked about representation of different perspectives in literature and in media, but now we're building pretty literally versions of the world that are going to influence how the real world works. Why is it important to have a variety of voices there?
It's not just a variety of voices; it's important to have the participation of the entire global population in AI because this is a civilizational technology. Whether we're talking about a healthcare application or agriculture, education transformation, robotics, energy, and sustainability, every aspect of our life and every aspect of our work will be impacted by this technology. People ask me what AI is and how to think about its reach and scope. It's not an analogy; one example I use is to think about where chips can be. We think about chips as if they're large, big energy consumption chips. That's not true. Almost every light bulb these days will have a tiny chip. Your fridge has a chip, cars have chips, airplanes have a lot of chips. Everywhere there is a chip, from the tiniest to the large ones, there's compute because a chip is the hardware foundation for computing. AI is the new compute. That means any place, any piece of device, equipment, or scenario that depends on computing on a chip, it depends on computing with AI. This is how profound this is. The stake is everything. Of course, it will come in different stages, but it is so important that at this point, our community, our society, understand the profoundness of this technology.

One of the ways I've been thinking about this: a few months ago, back in the summer, I had a chance to go to Bangkok for an event that we did at CNBC. An old friend of mine from high school, Casim Thorn Pipachai, was working with SCB 10X on a project called Typhoon, which uses AI models in native Thai language as opposed to relying on English, Mandarin, etc. After visiting there and talking to my friend from high school who has been working on this project, it got me thinking about the implications of localized AI differently. If it really genuinely understands your language, your culture, your way of life, and if it doesn't, if you don't have a role in building that out, who gets left out? Who gets included? Is there enough conversation about how much language and culture influences what AI understands and who potentially gets left out if that's not built in?

I do travel around the world and talk to people of all walks of background, governments from Europe to APAC regions to the rest of America. I think people, countries, and regions are absolutely aware of the need for localized AI. I know that we're focusing and talking about language models, which is very important. Your example is a language model. AI is not just language models, but even just focusing on language models, this need for localized AI is very important for people. The culture, the context, the shared experiences, the situational nuances for people in different parts of the world and for people coming from different backgrounds or different sectors, from artists to manufacturers, it's absolutely important. I think the market is driving this. It's not just a top-down, &quot;we think we must do this&quot; approach; I think the market and the people are asking for it. I'm seeing a very healthy interest from many regions and many governments in wanting to do that.

You mentioned AI is not just language. That's a good segue to World Labs. You're very focused on not just text prompts and responses, but immersive, three-dimensional, physics-influenced interactions between things. I imagine there are textures involved. You could even probably do cooking simulations at a certain point. What is that going to enable, you expect, five, 10 years from now? What kind of parallel might you draw to the image work that you did years back?
My career started in computer vision, which is a subfield of AI, just like some of my colleagues' careers started in natural language processing, which eventually, that field and the rest of AI, led to GPT-like technology. Having worked in vision-based AI all my career, I know that spatial perceptual intelligence is a lynchpin of intelligence from an evolutionary as well as human perspective. We don't just talk. We wake up in the morning hugging our children. We make breakfast for them. We drive them to school. We go to work ourselves. We order a cup of coffee and know how to drink it. So much of our daily life, as well as our civilization's work, is spatial, perceptual, and embodied intelligence. Beyond language models, I see the next chapter, the next frontier of AI, in spatial intelligence. This is why we founded World Labs barely two years ago. We are focusing on creating the next generation of frontier models that is going to help us to reason, to understand, to interact, and to generate 3D/4D worlds that would empower applications in simulation, robotics, creativity, design, education, healthcare, manufacturing, and many, many horizontal use cases of spatial intelligence.

Because it's the equivalent of image capture and what that can do for teaching a system how things move, what happens when they bump into each other, whether something shatters or is resilient—all of that you can't describe with just language.
No, you can't. First of all, it goes beyond just using an image to reason because that is still more passive. With world modeling and spatial intelligence, it can be agentic; it can be computed; it can be more proactive for embodied agents. Just the examples I give: even if you're making a meal, a simple meal of making pasta, that whole process—one could imagine using language to describe, let's say, 15 or 20 minutes of that process, but it's still a lossy representation. The nuance of how you cook the salt, how you put the pasta in the water, what the pasta does in the water, is impossible to use language alone to describe. So much of the physical world's process, whether it's initiated or interacted with by human or non-human, is beyond the description of language.

One last question for you. I know you have a lot to do and see, and a lot of people to talk to here today, so I appreciate the time. One particular application of what you're developing in World Labs that jumps to mind is gaming. There's a lot of profit, innovation, and teamwork to be had there. How much should we expect some of that work to be manifested in quicker, more effective development in spaces like that as a way of spreading its influence?
You're totally right. Gaming and interactive experiences is one of the markets that we're very excited by. Last year, about two months ago, as you know we're still in early February, we released our first model and a prototype of our product called Marble by World Labs. Already there are so many gaming developers using these tools and having fun, showing us the kind of right now still smaller level games they're making. It just excites us that we're already empowering that kind of creativity and innovation among game developers. Excited to see what happens next.
Dr. Fei-Fei Li, thank you for your time.
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>