<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Briefing - February 22, 2026</title>
    <style>
        :root {
            --bg: #0d1117;
            --bg-secondary: #161b22;
            --bg-tertiary: #21262d;
            --text: #e6edf3;
            --text-secondary: #8b949e;
            --text-tertiary: #6e7681;
            --accent: #58a6ff;
            --accent-subtle: #388bfd26;
            --border: #30363d;
            --green: #3fb950;
            --green-subtle: rgba(63, 185, 80, 0.15);
            --yellow: #d29922;
            --yellow-subtle: rgba(210, 153, 34, 0.15);
            --red: #f85149;
        }

        @media (prefers-color-scheme: light) {
            :root {
                --bg: #ffffff;
                --bg-secondary: #f6f8fa;
                --bg-tertiary: #eaeef2;
                --text: #1f2328;
                --text-secondary: #656d76;
                --text-tertiary: #8b949e;
                --accent: #0969da;
                --accent-subtle: #0969da1a;
                --border: #d0d7de;
                --green: #1a7f37;
                --green-subtle: rgba(26, 127, 55, 0.12);
                --yellow: #9a6700;
                --yellow-subtle: rgba(154, 103, 0, 0.12);
                --red: #cf222e;
            }
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            margin-bottom: 2.5rem;
            padding-bottom: 1.5rem;
            border-bottom: 1px solid var(--border);
        }

        h1 {
            font-size: 1.75rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .stats {
            display: flex;
            gap: 1.5rem;
            margin-top: 0.75rem;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .stat-value {
            color: var(--text);
            font-weight: 600;
        }

        .nav-links {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
        }

        .nav-links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
        }

        .nav-links a:hover {
            text-decoration: underline;
        }

        /* Video Cards */
        .video-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1.25rem;
            overflow: hidden;
            scroll-margin-top: 1rem;
        }

        .video-header {
            padding: 1.25rem 1.5rem 1rem;
        }

        .video-title {
            font-size: 1.05rem;
            font-weight: 600;
            margin-bottom: 0.6rem;
            line-height: 1.4;
        }

        .video-title a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.15s ease;
        }

        .video-title a:hover {
            color: var(--accent);
        }

        .video-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.6rem;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        .channel-info {
            display: inline-flex;
            align-items: center;
            gap: 0.45rem;
        }

        .channel-icon {
            width: 22px;
            height: 22px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
            background: var(--bg-tertiary);
        }

        .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.75rem;
        }

        /* Channel Pill */
        .channel-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            background: var(--bg-tertiary);
            padding: 0.3rem 0.7rem 0.3rem 0.4rem;
            border-radius: 20px;
            font-size: 0.8rem;
        }

        .channel-pill .channel-icon {
            width: 20px;
            height: 20px;
        }

        .channel-pill .channel-name {
            font-weight: 500;
            color: var(--text);
        }

        .channel-pill .channel-subs {
            color: var(--text-tertiary);
            font-size: 0.7rem;
            margin-left: 0.15rem;
        }

        /* Tags */
        .video-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.6rem;
        }

        .tag {
            display: inline-block;
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.72rem;
            font-weight: 500;
        }

        .tag-person {
            background: rgba(136, 87, 255, 0.15);
            color: #a371f7;
        }

        @media (prefers-color-scheme: light) {
            .tag-person {
                background: rgba(130, 80, 223, 0.12);
                color: #6639ba;
            }
        }

        .channel-badge {
            background: var(--accent-subtle);
            color: var(--accent);
            padding: 0.2rem 0.55rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 500;
        }

        .high-trust-badge {
            background: var(--green-subtle);
            color: var(--green);
        }

        .meta-sep {
            color: var(--border);
        }

        /* TL;DR Section */
        .tldr {
            padding: 0.9rem 1.5rem;
            background: var(--bg-tertiary);
            border-top: 1px solid var(--border);
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.55;
        }

        /* Summary Section */
        .summary-section {
            padding: 1rem 1.5rem 1.25rem;
            border-top: 1px solid var(--border);
        }

        .summary-preview {
            font-size: 0.92rem;
            line-height: 1.7;
            color: var(--text);
        }

        .summary-full {
            display: none;
            font-size: 0.92rem;
            line-height: 1.7;
        }

        .summary-full.expanded {
            display: block;
        }

        .summary-full h3 {
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text);
            margin: 1.25rem 0 0.6rem;
        }

        .summary-full h3:first-child {
            margin-top: 0;
        }

        .summary-full h4 {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
            margin: 1rem 0 0.4rem;
        }

        .summary-full ul {
            margin: 0.4rem 0;
            padding-left: 1.3rem;
        }

        .summary-full li {
            margin: 0.35rem 0;
        }

        /* Nested lists - indentation only, no color/size change */
        .summary-full ul ul {
            margin: 0.2rem 0;
        }

        .summary-full ul ul li {
            margin: 0.25rem 0;
        }

        .summary-full strong {
            color: var(--text);
            font-weight: 600;
        }

        .summary-full p {
            margin: 0.6rem 0;
            line-height: 1.65;
        }

        .summary-full blockquote {
            margin: 1rem 0;
            padding: 0.75rem 1rem;
            background: var(--bg-tertiary);
            border-left: 3px solid var(--accent);
            border-radius: 0 6px 6px 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        .summary-full em {
            font-style: italic;
        }

        /* Toggle Buttons */
        .toggle-btn {
            background: none;
            border: none;
            color: var(--accent);
            padding: 0;
            font-size: 0.85rem;
            font-weight: 500;
            cursor: pointer;
            margin-top: 0.6rem;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            transition: opacity 0.15s ease;
        }

        .toggle-btn:hover {
            opacity: 0.8;
        }

        .toggle-btn svg {
            width: 16px;
            height: 16px;
            transition: transform 0.2s ease;
        }

        .toggle-btn.expanded svg {
            transform: rotate(180deg);
        }

        /* Transcript Section */
        .transcript-section {
            padding: 0 1.5rem 1.25rem;
        }

        .transcript-toggle {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            color: var(--text-secondary);
            padding: 0.5rem 0.9rem;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.15s ease;
        }

        .transcript-toggle:hover {
            background: var(--border);
            color: var(--text);
        }

        .transcript-content {
            display: none;
            margin-top: 0.75rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 6px;
            font-size: 0.85rem;
            line-height: 1.75;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid var(--border);
            color: var(--text-secondary);
        }

        .transcript-content.expanded {
            display: block;
            animation: fadeIn 0.2s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* Empty State */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--text-secondary);
        }

        .empty-state h2 {
            font-size: 1.2rem;
            margin-bottom: 0.4rem;
            color: var(--text);
        }

        /* Index Page Styles */
        .day-list {
            list-style: none;
        }

        .day-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 10px;
            margin-bottom: 1rem;
            overflow: hidden;
            transition: border-color 0.15s ease;
        }

        .day-header-link {
            display: block;
            padding: 1.25rem 1.5rem 0.75rem;
            text-decoration: none;
            color: inherit;
        }

        .day-header-link:hover .day-date {
            color: var(--accent);
        }

        .day-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-date {
            font-weight: 600;
            font-size: 1rem;
            color: var(--text);
            transition: color 0.15s ease;
        }

        .day-count {
            color: var(--text-tertiary);
            font-size: 0.85rem;
        }

        .day-previews {
            display: flex;
            flex-direction: column;
            padding: 0 1.5rem 1rem;
        }

        .day-preview-item {
            display: flex;
            flex-direction: column;
            gap: 0.3rem;
            padding: 0.6rem 0;
            border-bottom: 1px solid var(--border);
            text-decoration: none;
            color: inherit;
            border-radius: 4px;
            transition: background 0.12s ease;
        }

        .day-preview-item:hover {
            background: var(--bg-tertiary);
        }

        .day-preview-item:last-child {
            border-bottom: none;
            padding-bottom: 0;
        }

        .preview-title {
            font-size: 0.88rem;
            font-weight: 500;
            color: var(--text);
            line-height: 1.35;
        }

        .preview-meta {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.75rem;
            color: var(--text-tertiary);
        }

        .preview-pill {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
            background: var(--bg-tertiary);
            padding: 0.15rem 0.5rem 0.15rem 0.25rem;
            border-radius: 14px;
        }

        .preview-channel-icon {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            object-fit: cover;
            flex-shrink: 0;
        }

        .preview-channel-name {
            font-weight: 500;
            color: var(--text-secondary);
            font-size: 0.72rem;
        }

        .preview-channel-subs {
            color: var(--text-tertiary);
            font-size: 0.68rem;
        }

        .preview-details {
            font-size: 0.72rem;
            color: var(--text-tertiary);
        }

        .preview-tags {
            display: inline-flex;
            gap: 0.3rem;
        }

        .tag-sm {
            padding: 0.1rem 0.45rem;
            font-size: 0.65rem;
        }

        .preview-tldr {
            font-size: 0.78rem;
            color: var(--text-tertiary);
            line-height: 1.45;
        }

        footer {
            margin-top: 3rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-tertiary);
            font-size: 0.8rem;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 1.25rem 1rem;
            }

            .video-header, .tldr, .summary-section, .transcript-section {
                padding-left: 1rem;
                padding-right: 1rem;
            }

            .video-title {
                font-size: 1rem;
            }

            .transcript-content {
                max-height: 300px;
            }
        }
        </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Daily Briefing</h1>
            <p class="subtitle">February 22, 2026</p>
            <div class="stats">
                <span><span class="stat-value">3</span> videos</span>
            </div>
            <nav class="nav-links">
                <a href="index.html">&larr; All Briefings</a>
            </nav>
        </header>

        <main>
            
            <article class="video-card" id="video-0">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=IiV9q73YUxI" target="_blank" rel="noopener">Fireside Chat: Sam Altman×Vinod Khosla and AMA at IIT Delhi | 20 February 2026</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/wXd69BlSS6v8lrVgFC-OrM3QGAifCfrGK2kjWi6JcIjAFoTiGYSTfJbwZ5Cc3inPmhp45MwM_A=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">IIT Delhi</span><span class="channel-subs">(25.6K)</span></span>
                        <span class="meta-sep">·</span><span>52:54</span>
                        <span class="meta-sep">·</span><span>23.8K views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-22</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Sam Altman (CEO, OpenAI)</span> <span class="tag tag-person">Vinod Khosla (Founder, Khosla Ventures)</span></div>
                </div>
                <div class="tldr">The advent of superintelligence marks a transition from a world of scarcity to one of extreme abundance and deflation, where human &quot;agency&quot; and &quot;resilience&quot; will become more valuable than technical expertise.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-0">TL;DR The advent of superintelligence marks a transition from a world of scarcity to one of extreme abundance and deflation, where human &quot;agency&quot; and &quot;resilience&quot; will become more valuable than technical expertise. India, already OpenAI's second-largest market, is positioned to...</div>
                    <div class="summary-full" id="full-0">
                        <p><strong>TL;DR</strong></p>
<p>The advent of superintelligence marks a transition from a world of scarcity to one of extreme abundance and deflation, where human "agency" and "resilience" will become more valuable than technical expertise. India, already OpenAI's second-largest market, is positioned to lead this shift through its high developer energy and potential for "zero-person" trillion-dollar companies.</p>
<h3>The Economic Shift: From Scarcity to Abundance</h3>
<ul>
<li><strong>Deflationary Pressure:</strong> Vinod Khosla and Sam Altman agree that AI will be "massively deflationary." Khosla suggests that by 2035, the world will face a deflationary economy that current financial institutions are not prepared for.</li>
<li><strong>Redefining GDP:</strong> Altman argues that GDP will become a "terrible metric" because it is measured in nominal dollars, which may not reflect the skyrocketing quality of life AI enables. </li>
<li><strong>The Cost of Intelligence:</strong> OpenAI has seen a <strong>1,000x reduction</strong> in the cost of solving hard reasoning problems via API over the last 18 months. The goal is to drive the cost of intelligence as close to zero as possible.</li>
<li><strong>Zero-Person Companies:</strong> Altman identified "zero-person companies" (highly automated, solo-entrepreneur ventures) as the most underrated opportunity in the current landscape.</li>
</ul>
<h3>Education and Skills for the Post-Technical Era</h3>
<ul>
<li><strong>The "Meta-Skill" Pivot:</strong> Technical skills (programming, math, engineering) will be performed better by AI. Altman and Khosla emphasize that the most critical skills for students now are <strong>Curiosity, Agency, and Resilience.</strong></li>
<ul>
<ul>
<li><strong>Agency as a Skill:</strong> Altman describes agency—the willpower to make things happen despite obstacles—as a learnable trait that the current education system often "beats out" of students.</li>
</ul>
</ul>
<li><strong>The Failure of Traditional Advice:</strong> Altman warned students against following traditional career advice from older generations, noting that even experts are "clueless" about the magnitude and rate of change coming by 2040.</li>
<li><strong>Forefront of Tools:</strong> The most valuable practical habit for students is staying on the "edge" of new AI tools, as this proficiency acts as a compounding accelerant for any career.</li>
</ul>
<h3>AI Safety: Technical Alignment vs. Global Resilience</h3>
<ul>
<li><strong>Three Pillars of Safety:</strong> Altman outlined a tripartite approach to managing AI risk:</li>
<ul>
<ul>
<li><strong>Technical Alignment:</strong> Developing methods to supervise systems that are smarter than humans.</li>
<li><strong>Security Infrastructure:</strong> Creating new architectures to prevent "insane things" from happening when users give AI agents root access to their devices.</li>
<li><strong>Resilience through Democratization:</strong> Rather than a "one AI to rule them all" approach, Altman favors putting powerful AI in everyone’s hands so that a "good" majority can check a "bad" minority.</li>
</ul>
</ul>
<li><strong>Environmental Context:</strong> Altman dismissed the "sticky meme" regarding AI's water consumption, stating that modern data centers no longer rely on heavy evaporative cooling, though he acknowledged that energy remains a significant long-term concern.</li>
</ul>
<h3>India’s Strategic Role in the AI Future</h3>
<ul>
<li><strong>Market Growth:</strong> India is currently OpenAI’s <strong>second-largest market</strong> with 100 million ChatGPT users (one-third of whom are students). It is also the fastest-growing market for Codex.</li>
<li><strong>Innovation Hub:</strong> Khosla highlighted the speed of Indian startups, citing "Immergent," which reached a <strong>$100 million ARR</strong> in just eight months.</li>
<li><strong>2047 Vision:</strong> By India’s 100th anniversary of independence, Altman predicts a world where the delta in technology will be greater than the gap between 1970 and today.</li>
</ul>
<blockquote>
"The world built up a lot of instincts and institutions... to deal with a world of scarcity. But almost none of that applies well to a world of abundance."
</blockquote>
<p>— <strong>Sam Altman</strong></p>
<blockquote>
"My willingness to fail allows me to succeed. I really encourage all of you to go be risk-taking... Agency is what matters when technology and tools make almost anything possible."
</blockquote>
<p>— <strong>Vinod Khosla</strong></p>
<blockquote>
"I think listening to old people is the biggest mistake young people make... For a predictor of what the world is going to be like going forward, I don't even think you should trust me."
</blockquote>
<p>— <strong>Sam Altman</strong></p>
                    </div>
                    <button class="toggle-btn" id="sum-btn-0" onclick="toggleSummary(0)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-0" onclick="toggleTranscript(0)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-0">
                        What an amazing day this is to be a part of the IIT Delhi community. Let's have another huge round of applause for our guests, guys. Come on. They say the best way to predict the future is by inventing it. And today, we have two stalwarts from different generations who have each foreseen the future for the world by building it themselves.

Our first guest is a name that resonates deeply within these walls. He's not just a global icon, but he's also our very own alumnus. In the early '80s, he co-founded Sun Microsystems, a company that fundamentally revamped the structure of Silicon Valley. At a time when computing was closed and proprietary, he championed open systems.

His vision led to workstations that powered the early internet and the creation of Java. Later, he founded Khosla Ventures. He has consistently backed ideas that aim to solve the society's largest problems, from clean energy to digital tech. And as the first institutional investor in OpenAI, ladies and gentlemen, let's have another huge round of applause for Mr. Vinod Khosla.

With him, we have arguably the most influential person in technology right now, steering the development of the most powerful AI models in history. As the CEO of OpenAI, he has kicked off the generative AI era, changing how the world interacts with information, creativity, and intelligence itself. A huge round of applause for Mr. Sam Altman.

To formally welcome our distinguished guests and set the context for this historic event, I would now like to call upon the stage the Director of IIT Delhi, Professor Rangan Banerjee.

Good morning. So nice to see so many of you here. And when it was known that Mr. Sam Altman and Vinod Khosla were going to come here, we quickly realized that the Dogra Hall was not going to be enough. And all of you are actually privileged. We could have filled two Dogra Halls here if we wanted to fit in all those who had registered from IIT Delhi itself.

We have the minor exams going on. I don't know how many of you have skipped the minor exams to come here. And I was told some people have finished the two-hour exam in an hour and come down here. How many of you are from outside IIT? Please raise your hands. Excellent. So we hope that all of you would also come for our student tech event, Trest, next week.

I'd like to just take this opportunity to say that as a higher educational institute, IIT Delhi, AI provides an opportunity but also a challenge. And we need to figure out how we train the future generation of people who are going into the workforce. Towards this, we created a committee of faculty members, students, and staff to look at how we integrate responsible AI and what is ethical use of AI by faculty and by students. This is an ongoing conversation.

We have a dedicated School of AI. We have an M.Tech program in Machine Intelligence and Data Sciences. We have a PhD program. We're also setting up this year the M.Tech program in Machine Intelligence and Data Sciences in our Abu Dhabi campus. We did a curriculum review last year, and in that curriculum review, we ensured that every student of the institute has exposure to AI in terms of courses, AI, and sustainability.

This was one of the features of the curriculum review. I'm not going to go on about this because we want to hear Mr. Sam Altman and Mr. Vinod Khosla. I just like to say that, to give you one example, we launched with the Ministry of Tribal Affairs a tool called Adibani, which is in four tribal languages: Santhali, Bhili, Mundari, and others. We are looking at AI for the community, in communities which currently do not have access to this kind of content.

We are looking at ways, and we're delighted that we are entering into a partnership with OpenAI. We are looking at ways where our students and our faculty will engage with both companies like OpenAI as well as with sovereign AI models so that we can co-develop and create responsible AI which makes a difference in people's lives.

I'd like to say that we are delighted to have Mr. Sam Altman here. He's a person who's been ahead of the curve in terms of thinking on AI and generative AI. We are also delighted to have with us one of our own, Mr. Vinod Khosla, who has always been ahead of the curve. And as a student here, I think from 1971 to 1976, during that time, he set up one of the first computer laboratories in the IIT system. So he was ahead of the curve at that time.

He was also ahead of the curve when in 2004, I think, he donated to our institute for setting up the School of IT, which is named after his parents. And we at IIT Delhi are now a 65-year-old institution, and we are in the process of reimagining our future. We want to be ahead of the curve in education.

We are looking at IIT Delhi 2035. We are looking at changing our infrastructure. We are going vertical, and we are hoping to have Mr. Khosla's support in the form of ideas as we do this reimagining. So with these few words, I'd like to just say that like all of you, I'm looking forward to this conversation. Thank you so much.

Thank you. I'd like to call upon the stage Mr. Vinod Khosla and Mr. Sam Altman. Where should we start? Hopefully somebody will keep us honest on time. Sam, maybe first, I'm always excited to see so many young people. So maybe you can talk about your observations here.

Yeah, this has been a wonderful trip to India for me and I have a lot more exciting stuff to do, but this is the thing I've been most looking forward to of the entire trip. Watching what's happening with young people around the world, especially in India though, building with incredible energy with AI. The new startups that are going to happen or are already happening. The new products and services that are going to get created.

The just total embrace of AI and the excitement and the desire to bring all of this agency and energy and, you know, speed to the future is awesome. I—I don't know about you Vinod, but I think this is the biggest shift that has happened in the landscape of what a young person can accomplish in my entire life. It's totally amazing to see, and watching what people are doing is just incredible.

India has its 100th anniversary of independence in 2047. And I can't imagine a larger shift by that date than anybody would imagine. So imagine 2047 and what India might be like by then. We haven't scripted our questions; we just wanted to have a conversation.

I mean, it's—it's going to depend on what all of these people do. You all will enter adulthood with superintelligence. And that's going to change things a lot, but that is an incredible opportunity. I have a one-year-old kid, and he is never going to know a world where he was smarter than a computer. Ever.

He was born just at the right time to never outrun a computer in raw intelligence. And you know, for him it'll be totally normal life. For us, it's a big adaptation. For you all, it's like a little strange, but you know, you're excited about it. What people can do with GPUs now will be the way that new value gets created in the world. So I don't know what that's going to look like. Vinod doesn't know what that's going to look like.

We got a bunch of high-level guesses, but we're not going to be the ones that build that into all of these incredible new companies that people will do with that. Examples that we both like are education is clearly going to totally change, healthcare is clearly going to totally change. What it means to do work is going to totally change. Companies may be a few people and a giant data center and build incredible new kinds of value.

What it means to do physical work will change as robots can automate more and more manufacturing. Certainly what it means to discover science is going to change. The growth rate of economic value in the world, the increase in quality of life—a quote that someone from OpenAI said to me recently that really stuck with me is we built up a lot of instincts and institutions, policies, structure to deal with a world of scarcity. But almost none of that applies well to a world of abundance.

In addition to building all of these new kinds of companies and products and services, society's going to have to get reimagined for this world of incredible abundance. You've thought about this a lot.

Yeah, I've spent a lot of time. Let's ask some practical questions. Do you think GDP rates, from whatever is projected by economists today—and every country has its 15 and 25-year forecasts—do you think they more than double, more than double? What happens?

I think GDP is going to turn out to be a terrible metric because AI is so deflationary. What we want to measure, and I think what GDP has meant to approximate, is sort of quality of life. Yeah, technically it's a definition of goods and services, but it's measured in dollars, which money will be a whole different thing.

Yeah, so I think a proper metric of what GDP is trying to approximate will growth rate will more than double for sure. GDP measured in nominal dollars—that probably gets kind of squirrelly. Actually, to ask you a weird question: interest rates in five more years, negative 2% or 20%?

I think by 2035 for sure we will have a hugely deflationary economy that the world isn't thinking about. It's interesting because Google just issued 100-year bonds and I said by 2035 you should own all those bonds because the world will be so deflationary that it's hard to imagine anybody pretending. And this is sort of this notion of—you know, the world doesn't yet know how large the change is and they're going on as business as usual. I think one of your engineers wrote a great manifesto. Can you talk about that a little bit?

Which manifesto? People do a few of them. The—I'm forgetting the name, I just mentioned it earlier in the conversation—essentially that the world is clueless about what's going on and the magnitude of the change. It'll come to me in just a second.

I think even people who work in AI, we feel a little bit clueless about the magnitude of the change. Codex is an example. By the way, Codex is growing in India faster than anywhere in the world and mostly with young people. But Codex is an example of where everyone's intuitions, even though we knew this intellectually, emotionally we were all hit by it.

We have like lots of Codex access inside of OpenAI and what it means to be an engineer, what it means to be a researcher changed so much so quickly. That is just going to happen again and again throughout the economy. And if you believe, which I do, that the top-level driver of the economy and of life getting better and better every year is scientific discovery, and then the second most important thing is the economic engine around that that brings these new capabilities out into the world.

And both of those are going to get automated at the same time. We're going to automate scientific progress, we're going to automate the whole economy. And you think about what that really would mean if these things can happen 10 times faster, 100 times faster than we've been able to do it on our own.

We were not—we did not evolve to have intuitions about that kind of a growth rate and that kind of compounding. So I don't know, but if you were back here as a student, what would you do tomorrow? No, I've thought about it a lot. The way I frame the minimum level of change to imagine 15 years from now—so imagine 2040—I have to say, I imagine life—the delta being the same between now and 2040 as it is between today and 1970.

So look back at technology in 1970. That's my assumption about delta and I think that's too conservative a notion. I think that's too conservative. Yeah, so that's the magnitude of change. And people ask me, &quot;So what should we do?&quot; I say learn how to learn really, really fast. Like your area of expertise doesn't matter. Whether you're an electrical engineer or a mechanical engineer is largely going to be irrelevant.

In fact, I scared the director a little bit saying nothing you learn will be relevant even in 2030. When the first-year students graduate, you won't have learned anything that the AI doesn't know better. I don't know Sam if you agree with me or not.

You won't know any technical field better. You may understand better what people want. You may understand much better how to interact with people, motivate people, how to come up with creative ideas, how to sort of adapt quickly, create value. But yeah, any technical skill that you learn, AI will be better at it. It's still worth learning.

You know, like someone asked me recently, &quot;Do I regret learning to program?&quot; Because you know, clearly the AI's a better programmer than me now. And the answer is not at all. I also don't regret learning math even though I never use math as an adult. Learning how to think, learning how to learn quickly—this was all a valuable skill, but it was all of the meta-skills that matter.

I mean, the one thing that I think we could say with confidence of a specific skill to learn is when I was in school learning to program was the obvious thing. Now learning to use these tools is the obvious thing, and the fluency that people pick up with each new generation if you sort of are pushing as much as possible on the edge, that seems very valuable.

If you're a college student, what do you think matters the most? What will matter when the technical knowledge they have doesn't matter and an electrical engineer can do a structural engineer's job quite easily? And by the way, we're building both structural engineers, chip designers, and electrical engineers today. That'll be used pervasive everywhere. So what do you think matters?

Well, I know I just said this, but I can't emphasize enough how important I think it is to stay on the forefront of the tools. I expect that to be a compounding accelerant. So building projects all of the time to just figure out what's going to be possible, and it's going to rapidly increase every couple of months from now on. That really matters.

The class that I wish my college had offered—the motto of Y Combinator is &quot;Make something people want.&quot; And it has been, for 21 years now, the best motto of any investor. And I wish my school had offered a class on that because I think that is a learnable skill, figuring that out, and that's going to be ever more important in a world where—in a world where you can sort of make anything happen. Figuring out how to get good ideas, which like anything else, deliberate practice seems to improve, that seems to matter a lot.

Yeah, so my personal view is what's most important to learn is curiosity and agency. Can you tell me if you agree, disagree, elaborate on that? I totally agree. I think agency is also a learnable skill. The world kind of beats it out of you, so you have to—you have to like resist and continue to believe that you can sort of figure out anything and make anything happen.

And the more times you do it, the more self-belief you develop. Many people learn this late in their careers. It is super valuable to learn early. Like other things, you just have to start and you have to keep doing it and you'll develop confidence in it. But the—the returns on agency clearly have never been higher.

You know, we've talked for a long time about what one person is going to be able to do with AI. We're finally seeing it now. A single person with drive and an idea and willpower can make incredible things happen. And in some sense, the most important learning of my entire career has been that if you are right on the idea, no matter how unpopular it is—in fact, it's often better to be unpopular because you have no one else you're competing with doing it—and you stick with unwavering conviction over a long time and you just knock down obstacle after obstacle with no loss of enthusiasm between each setback, you can accomplish amazing things.

This was certainly the story of OpenAI. Now it obviously looks like a great thing, but when we started it seemed totally crazy and it was just like a bunch of us were in a room with force of will and sort of an attitude that we were going to do it no matter what. And then even the first like four or five years of OpenAI, it was sort of it seemed like a very bad idea. Thank you for believing in it, by the way. And the agency that we had all developed earlier in our careers, which I wish we had developed even earlier, was critical to making it happen.

Yeah, I—I would say you heard a couple of quotes I think—one said the best way to predict the future is to invent it. I go on to add to it—that was Alan Kay who said that, and I say invent the future you want because now more than ever, that's possible. The key is agency and it's always been available where you can make the world you want happen.

The director said I was part of four students who started the first computer programming club at IIT Delhi, which was any programming in any IIT had never existed. We just wanted it, so we made it happen. I also with Professor Guha here in 1970s started the biomedical engineering program which is the other side, which is I got curious as an electrical engineer about electrical phenomena in the body and convinced Professor Guha to start the first biomedical program anywhere in India with the All India Institute of Medical Sciences.

I give that as example of I was 16 or 17. You can make anything happen if you want to. And that's what agency is about. And when technology and tools make almost anything possible, agency is what matters. Curiosity for learning and always staying at the leading edge and agency to make the world happen.

There's never been an opportunity to do startups. I'm very excited about this little company we invested in. They approached me a few months ago—Immergent. Launched a product in July or August. Last week they called me and said they'd exceeded a 100-million-dollar ARR rate in eight months. The fastest I've seen anybody grow, even Lovable or Replit or any of those companies. So that opportunity exists for all of you. I don't know if you want to do a finishing comment.

I can't really say anything better than that. This is like a special time. Like I—I think the best time ever to be starting off careers and yeah, the opportunity is incredible.

Yeah, I'll finish by a last quote I have. Most people, especially in India, are especially averse to risk. There's a Harvard Business School case that starts with a quote from me saying, &quot;My willingness to fail allows me to succeed.&quot; So I really encourage all of you to go be risk-taking. There's so much opportunity to take advantage of it, take advantage of tools, curiosity, agency, risk-taking, and then persistence because the path is never simple or smooth, so you have to persist through the hard times. Thank you. I think we're at the end of our talk.

Thank you so much for interacting with our students and this has indeed been a very memorable evening for all of us. And in order to ensure that you also remember us once you go out of this institute, we'd like to present our small token of gratitude. For that, I'd like to invite Mr. Vinod Khosla sir back on stage and also the Director to present our guest.

I—I want to finish, given you gave me a baseball cap, thank you, with one comment. I think in the next few—four years, this baseball cap will read my mind and input directly into computers. We may succeed or fail at that, but we are trying.

I'd like to request Sam now to capture this moment with the audience with a selfie. I'd like to call upon the stage the Associate Dean of Academic Outreach and New Initiatives, Professor Shilpi Sharma and Professor Deepak Jain for this. So we're doing a selfie, right, with—with everybody. Nice.

What a wonderful conversation, guys. We had Ms. Sunita Williams a month back and the idea that learning is such an important thing for such huge personas, for such huge stalwarts, I think that is one of the most humbling things we learn here today.

Now we'd like to open up the floor for students to ask their own questions. For this, I'd like to invite on stage Mr. Raghav Gupta, the Head of Education for OpenAI in India. He's currently leading partnerships with academic institutions, ensuring that AI is integrated responsibly across all dimensions. Mr. Raghav.

Good morning. It's incredible seeing such a packed hall. Sam, I know you have a packed few days in India and there are many senior meetings, but to me it seems like this is going to be the most exciting session. Would you—would you agree? I do.

And I'd love to ask the students as well. Are you all excited for this conversation with Sam? I mean, come on, you can do better. Are you all excited for this conversation with Sam?

So, so we have some of India's bright young minds here and they're studying engineering, they're studying computer science, I think we have health sciences, management, design, and so on. I think you all sent us like 800-plus questions. We can't take all 800, but I've shortlisted the broad themes and we'll invite you to ask them live.

I'll kick us off a little bit. Sam, you wrote this article in Times of India earlier this week and the headline kind of captured your message very nicely where it said that AI will define India's future and India will define AI's future as well. And I know at the AI Summit you've seen a lot of what's happening around development in AI. Would you like to talk a little bit about your impressions there?

India is already our second-largest market. There's 100 million ChatGPT users; a third of them are students. Fastest-growing Codex market in the world. India should be our largest market over time. More than just usage of products like ChatGPT, the building energy in India seems like it is growing faster than anywhere else, the desire to really create new kinds of products and services, brand-new companies that are all about AI. This is—yeah, it's just amazing and so it's been great to be here.

Wonderful. So we're going to go to the students next and we'll open it up live. I think we have Mukund who's going to ask the first question and Mukund is from IIT Delhi. Let's get—get started with Mukund then.

Hi Sam, I'm Mukund from the Department of Mathematics, IIT Delhi. I'm in my final year pursuing an integrated master's degree. So my question is, you have talked about intelligence becoming a cheap utility, but we are seeing specialized high-reasoning models being gated by premium subscriptions. So how do you reconcile the concept of broad access with the economic viability of these frontier models?

I think the most amazing thing, well, there's many amazing things, I can't say the most. One of the amazing things that is happening is the rate at which AI is getting cheaper at a given level of intelligence. We are—if you look at a hard reasoning problem, what it would have cost you to solve it using an OpenAI API a year and a half ago versus now, it's down about a thousand X.

A thousand X in 18 months is just—that doesn't happen very often. I don't think we'll be able to sustain another thousand X over the next 18 months, but maybe we will. But there will be a significant decrease in cost. So our goal here is to relentlessly drive the cost of intelligence down as close to zero as we can and then make that available to the world as a very low-cost asset.

And for a bunch of reasons, accessibility being one of them, that's a critical part of our mission. There are going to be a bunch of societal disruptions around that. Like part of society has maybe—we talked earlier about this issue of abundance versus scarcity, but society has been used to intelligence being a relatively scarce resource.

Also the ability to make things happen in the physical world, energy, robotics, whatever. If all of that changes, I don't think society yet has a consensus on how things are going to work and where the—the natural limits are going to be. But I do think the cost of intelligence is going to trend down and down and in terms of empowering the entire world, that's very important.

We'll go to Tejas next, who's also from IIT Delhi and I know the Director also spoke a little bit about safety and I think Tejas your question is related to that. So go ahead, please.

Hi Sam, I'm Tejas Raj Mangla. I'm currently a final-year student here at IIT Delhi. I'm pursuing my bachelors in Computational Mechanics. My question for you is: how do we keep AI safe without blocking innovation from things like prompt injection that are happening recently?

I think there's three things here. One, we have to figure out how to technically align AI. We have made better progress there than I thought we might have, but there's still things to do. As we get to these systems that are truly much smarter than we are, how we supervise those systems requires new ideas.

As we get to a world where AI is writing so much source code and doing so much research we can't review all of it, there's a bunch of things that used to feel like sci-fi that are now clear alignment challenges that we have to—that we have to address. We've been doing work here for a while; other labs have been doing work here for a while. On the whole, alignment has looked easier than I feared, but we're clearly not done.

So bucket one is technical safety work around alignment. Two is there's a whole new kind of security infrastructure that needs to get built. You mentioned prompt injection; I think that's a great example. OpenAI is an amazing thing, Codex is an amazing thing. I thought that I was going to be a very disciplined person and not let them run on my computer with root access because I thought that was an insane thing to do.

And that lasted about two hours. And then I was like, ugh, it's really annoying to approve everything, it's so convenient, I want to just I'm going to just like let it rip. And if I'm willing to do that, a lot of other people will be willing to do that. I should be one of the more conservative ones there.

So I think we need to develop a new kind of security architecture different from the model technical alignment to let people be able to use these agents without insane things happening. Like it is awesome that you can run something on your computer and it can get to know everything about your life and record your screen and use the web for you and everything else. It will be significantly less awesome if it starts like randomly telling your secrets to people it shouldn't.

And then third and most important, you mentioned not blocking innovation, I super agree. The kind of—these are caricatures because everybody is a little bit in the middle, but the kind of the two paths the world is looking at right now is either we accept an AI company or country or model having sort of effective totalitarian control over the world for no safety problems at all—you have one AI to rule them all, this has been people's vision over time.

The other is that we super democratize access and we put powerful AI in everyone's hands and we trust that if you, you know, out of a hundred people 99 are going to be good, one person's going to be bad, the good people will stop the bad. Some things are going to go wrong in that world, people are for sure going to misuse AI in small and probably in big ways.

But for a long time the world I think has shown that if most people are good and the good people stop the bad people as long as there's not a huge power imbalance, we can get to a world where we democratize AI, everybody lifts up and that kind of keeps the new powerful bad forces in check. This is the story of society for a long time.

It will be messy, things will go wrong, but I think empowering everyone and having a wide distribution of power is the best, fairest, and safest path forward. We call this resilience. So instead of just there's alignment, there's security, and then there's this newer idea of resilience where I think it no longer works for OpenAI to just say we will block our models from telling people how to make a pathogen because some open source model is going to help some bad guy make a pathogen. We have to have society ready to defend against that with rapid response vaccines, sort of new ways to block respiratory transmission, whatever else. Yeah, that's what I would say.

So the next question is from Yash and he's not here so I'll read it out on his behalf. I read that a lot of research behind study mode in ChatGPT happened in India last year. And so if OpenAI were to build a product specifically for India, not adapted but designed for India first, what problem would you want it to solve?

I would rather one of you figure out the answer to that. We—way more innovation is going to happen outside of OpenAI than inside of OpenAI. And our strategy is to build the core model and the basic way to use it—ChatGPT, the API, agents like Codex and the general agent—and really empower everybody else to build it. One of my learnings from OpenAI is that most innovation in the world comes from startups and we want to empower them.

We're going to go to—change gears a little bit and I was saying earlier we have students from creative industries as well. So the next question is around that and I think it's from Parisha. If you have the microphone, go ahead, please.

Hi Sam, I'm Parisha from Pearl Academy. I'm pursuing Interior and Architectural Design. So my question is, like AI became the tool that can generate images, space, and create entire concept. How designers can ensure and reflect their work still reflect the human emotions, cultural identity, and originality rather than becoming too machine-driven?

Great question. I used to be more worried about this and you know, I wasn't sure totally how it was going to go when models could sort of create anything. Watching what's happened in practice though and talking to creators, not everyone, but generally speaking people say this is the best thing ever to happen as a tool in their creative process.

If they can explore ideas and have a machine help them search the space and then pick at each layer which direction they want to go. And if we can make their creative ideation loop faster and faster and faster, where the time from idea to then seeing a result and coming up with a new idea from that gets shorter and shorter.

Talking to creators, whether they're visual artists or people making videos or music, they all care a lot as do I that the human spirit and the human direction and the human imprint is in this, but they all think they'll be able to create much better stuff than ever before.

Another thing for optimism back on this earlier point about people really are very hard-wired to care about other people: we are seeing a, I think predictable but still surprising to some people result, which is if you show someone an image, if you say I'll sell you this piece of art and an AI made it, and it's beautiful, but you know an AI made it, the value that people put on that effectively rounds to zero.

If a human made it, even with AI tools, and it's you know someone who you can connect to and has a story and put their creative energy into it and had something they were trying to express but AI helped them in their creative process, it's worth a lot. But without the person like effectively signing their name to it and saying this is my thing, we seem to not care. And I think that's another very positive sign for what it's going to be like for human creators.

I know you're on a discussion with Karan Johar later today, so some of this will come up a little bit more as well, and he's a very popular movie director as you know so I know this is going to be a conversation further up as well. I'm a little conscious we're maybe coming up a little bit on time. I'll take two more questions and then I want to do a little bit of rapid fire at the end as well, Sam, if you're open to that. I think we have Paridhi next. Paridhi, if you have the microphone, yeah, go ahead.

Hi Sam, I am Paridhi from Amity University. I'm currently in the third year of my artificial intelligence degree. My question to you is that recently there have been a lot of concerns regarding the use of water in cooling down the servers and that it's leading to water scarcity. So what is OpenAI doing to you know help people dismiss these concerns?

So the energy concern and the need to move to green energy I think is very real. That's something that at scale AI is developing can be a significant issue. The water concern I think is no longer real. There was a time when data centers were using evaporative cooling. That is not something that people are doing much anymore.

There is, you know, obviously some water consumption in producing semiconductors, but if you look at AI data centers they are not significant consumers of water. This has been an incredibly sticky meme. I don't totally understand why. You know, there's people who say well I don't use ChatGPT because each time you ask it a question it uses up seven gallons of water or whatever.

It's totally not true. We've tried to explain it's not true; it's been very sticky for whatever reason. But I think the focus on energy does make sense.

All right, I know we have a lot more questions, but I'm conscious we're coming up on time. So Oshin will come to you and please go ahead and ask your question.

Yeah hi Sam, my name is Oshin Agarwal. I'm a PhD scholar at the Transportation Research and Injury Prevention Centre here. So my question is: what is the biggest mistake you see young people make right now when they apparently prepare for AI?

Man, I'm going to answer this. I hope this talk is not recorded. I think listening to old people is the biggest mistake young people make. I think your parents obviously love you more than anyone, they're extremely well-meaning; for advice about how to live a happy life or how to be a good person, there is no one you should listen to more than your parents.

But for a predictor of what the world is going to be like going forward, I don't even think you should trust me for having good intuition of the rate of change. Young people always figure this out the best. And the world you are inheriting is going to be very different and you'll have to quickly develop your own intuitions and trust them. But I think traditional career advice is probably not going to work as well.

Wonderful. Thank you for taking all those questions. Let's do a quick rapid fire. And you can choose to answer with one word or one sentence, but that's what you need to kind of keep to. And I have like four or five questions. So will the next trillion-dollar AI company come from India?

I hope so.

Most overrated fear about AI?

Like killer robots in the streets.

Most underrated opportunity?

Zero-person companies.

Education or healthcare?

Education. I'll take it back, healthcare. But close though.

One skill every IIT student should build this year?

Resilience.

Wonderful. Thank you all. Thank you.

Thank you so much for interacting with our students and this has indeed been a very memorable evening for all of us. And in order to ensure that you also remember us once you go out of this institute, we'd like to present our small token of gratitude. For that, I'd like to invite Mr. Vinod Khosla sir back on stage and also the director to present our guest.

I—I want to finish, given you gave me a baseball cap, thank you, with one comment. I think in the next four years this baseball cap will read my mind and input directly into computers. We may succeed or fail at that, but we are trying. Four years.

I'd like to request Sam now to capture this moment with the audience with a selfie. I'd like to call upon the stage the Associate Dean of Academic Outreach and New Initiatives, Professor Shilpi Sharma and Professor Deepak Jain for this.

So we're doing a selfie, right, with—with everybody. Nice. Thank you, thank you.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-1">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=yYOv2RXs8Es" target="_blank" rel="noopener">The Conveyor Belt That Ruins Your Life | Bill Gurley - Benchmark Partner (Uber, Zillow, Stitch Fix)</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/6XdgiX_61NmH-M_vXm3Xhof-_xPoinAR8IVXIkohvUYbFgoAEMWBFrkIXndOM1dAfg2qLia0Uw=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">Scott D. Clary - Success Story Podcast</span><span class="channel-subs">(374.0K)</span></span>
                        <span class="meta-sep">·</span><span>68:20</span>
                        <span class="meta-sep">·</span><span>28 views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-22</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Bill Gurley (Partner, Benchmark)</span> <span class="tag tag-person">Scott D. Clary (Host, Success Story Podcast)</span></div>
                </div>
                <div class="tldr">Venture Capitalist Bill Gurley argues that the majority of professionals are trapped on a &quot;conveyor belt&quot; of unfulfilling, safe career paths.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-1">TL;DR Venture Capitalist Bill Gurley argues that the majority of professionals are trapped on a &quot;conveyor belt&quot; of unfulfilling, safe career paths. To achieve extraordinary success and personal fulfillment, individuals must cultivate a &quot;founder-level&quot; obsession with...</div>
                    <div class="summary-full" id="full-1">
                        <p><strong>TL;DR</strong></p>
<p>Venture Capitalist Bill Gurley argues that the majority of professionals are trapped on a "conveyor belt" of unfulfilling, safe career paths. To achieve extraordinary success and personal fulfillment, individuals must cultivate a "founder-level" obsession with self-learning, combining a deep mastery of history with a rigorous study of the technological edge.</p>
<h3>The "Conveyor Belt" of Career Regret</h3>
<ul>
<li><strong>The Engagement Crisis:</strong> Current data indicates a profound lack of professional fulfillment. Gurley cites a Wharton study showing that 60% of people would change careers if they could start over. Furthermore, Gallup data suggests 58% of people are disengaged at work, with 15% actively "quiet quitting."</li>
<li><strong>The Resume Arms Race:</strong> Gurley describes a systemic "conveyor belt" that begins in middle school, where parents and counselors push children toward "safe" majors and prestigious resumes rather than exploring natural interests.</li>
<ul>
<ul>
<li><strong>Early Specialization:</strong> Many universities now require high school juniors to declare majors, forcing them into career paths before they have any lived experience.</li>
<li><strong>The Illusion of Safety:</strong> Well-intentioned mentors often steer people toward high-paying, "safe" jobs, unaware that fulfillment generally correlates more with passion than with wealth.</li>
</ul>
</ul>
<li><strong>The Persistence of the Status Quo:</strong> Most people stay in "expired" careers due to financial obligations (mortgages, family) and the lack of a "disinhibiting" moment—the realization that it is socially acceptable to pivot.</li>
</ul>
<h3>The Litmus Test for Professional Passion</h3>
<ul>
<li><strong>Curiosity vs. Entertainment:</strong> Gurley offers a simple test to determine if a field is your "dream job": *Would you spend your free time learning about this topic instead of seeking entertainment?*</li>
<ul>
<ul>
<li>If reading a technical paper or researching a market shift competes with watching a show like *Breaking Bad*, you have found your "thing."</li>
</ul>
</ul>
<li><strong>Fascination as a Competitive Edge:</strong> Drawing on examples like MrBeast and Jerry Seinfeld, Gurley notes that top performers are "fascinated" by the minutiae of their craft.</li>
<ul>
<ul>
<li><strong>Example:</strong> Jimmy Donaldson (MrBeast) spent years in obsessive group chats deconstructing the first three seconds of YouTube clips to maximize retention.</li>
</ul>
</ul>
<li><strong>The Role of Intuition:</strong> High-achievers like Rick Rubin often follow an inner voice that contradicts the advice of "well-intentioned chaperones" who prioritize safety over risk.</li>
</ul>
<h3>A Framework for Excellence: History and the Edge</h3>
<ul>
<li><strong>The Mastery of Bedrock Principles:</strong> To innovate, one must first master the history of their field. Gurley highlights that Picasso had mastered perfect realism by age 14 before moving into cubism.</li>
<ul>
<ul>
<li><strong>The Magnus Carlsen Effect:</strong> In a global chess tournament, the world champion also won the trivia contest regarding the history of chess. Obsessives know the "useless" details of their craft.</li>
</ul>
</ul>
<li><strong>Living on the Edge:</strong> Great founders and professionals live in constant fear of missing the next technological shift. </li>
<ul>
<ul>
<li><strong>Technological Rigor:</strong> Most people stop studying after they leave the office; elite performers study what is "new on the edge" (e.g., AI, LLMs) to become "superhuman" versions of themselves.</li>
</ul>
</ul>
<li><strong>The Microsoft Example:</strong> Gurley cites Satya Nadella’s turnaround of Microsoft as a "unit of one" success story built on a culture of self-learning. Nadella shifted the organization from a "know-it-all" culture to a "learn-it-all" culture.</li>
</ul>
<h3>Strategic Pivoting and Risk Management</h3>
<ul>
<li><strong>Regret Minimization Framework:</strong> Gurley references Jeff Bezos’s decision to leave a lucrative Wall Street career at D.E. Shaw to start Amazon. Bezos projected himself to age 80 and realized he wouldn't regret failing at a startup, but he would deeply regret never trying.</li>
<li><strong>The "Never Too Late" Mindset:</strong> While it is easier to pivot early, Gurley argues that mid-career professionals (age 40+) often have higher success rates because they possess better business acumen and can spot industry gaps more accurately.</li>
<li><strong>Agency and Responsibility:</strong> The most difficult step in a career pivot is accepting internal locus of control. One must acknowledge that staying in an unfulfilling job is a choice, and the responsibility to learn a new skill lies entirely with the individual.</li>
</ul>
<h3>Notable Quotes</h3>
<blockquote>
"If we lived in a socialist world where everyone got paid the same for a job, I would still want this one [Venture Capital]. That’s how much fun I had doing it." — <strong>Bill Gurley</strong>
</blockquote>
<blockquote>
"Does learning in this field compete with entertainment for you? If that answer is yes, I really think this is your thing. If you're in a field where you have that level of curiosity, you're going to do extremely well, almost whatever the field." — <strong>Bill Gurley</strong>
</blockquote>
<blockquote>
"Boldness regrets are the things you didn't do. Over your life, you get to the end and think, 'Boy, I wish I had changed careers; I wish I had done this thing.' Life is a use-it-or-lose-it proposition." — <strong>Bill Gurley</strong> (referencing David Pink)
</blockquote>
<blockquote>
"If you are not learning new things, you stop being great, you stop doing great and useful things." — <strong>Satya Nadella</strong> (as quoted by Bill Gurley)
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-1" onclick="toggleSummary(1)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-1" onclick="toggleTranscript(1)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-1">
                        I was an engineer. I had an engineering degree in undergrad. In my second year, we were starting the third project I had worked on and I thought to myself, &quot;Is this what I want to do my whole life?&quot; And I got to &quot;no.&quot; 

What does it take to spot the next big thing before anyone else does? Bill Gurley is the venture capitalist whose intuition has shaped the modern tech landscape. As a general partner at Benchmark, he backed companies like Uber, OpenTable, and Grubhub long before they became household names. 

58% of people say they're not engaged at work. Fifteen of those 58 say they're quiet quitting. These are horrible numbers. Founders live on the edge of a new technological shift constantly, and they can't not know what's happening next. 

It requires a level of studying that is foreign in other industries and other fields. Most people, when they go home from their job, they don't study more about what's next in their job. He's not driven by hype; he's driven by insight, discipline, and a deep understanding of how markets evolve. 

His career is proof that great investing isn't luck; it's vision sharpened by rigor. If you're in your dream job already, embrace AI. You want to become the superhuman that is what's new on the edge. You should be self-learning. If you're not in your dream job and it's threatened by AI, all the more urgency to jump out.

Bill, so you spent 25 years investing in the best founders in the world and then you chose to write a book that has nothing to do with venture capital. So why? You know, it's funny. A lot of people ask me that question. 

And when we went out, when I decided to write the book and I went out and talked to agents and publishers, I'd say 80% to 90% of them ended up in a non-connection. This was because they would constantly steer back towards, &quot;Don't you want to write a venture capital or a tell-all or a how-to-invest book?&quot; And I didn't have any motivation to do that. 

I can't explain why, but I didn't have any motivation to do that. This started about 10 years ago. I was at a moment of my life where I was consuming tons of biographies, which I think lots of people have—that thing where they read a great biography and they want more and more and more of them. 

And I was reading a biography and noticed certain patterns about this individual's process and how they went about learning, how they went about connecting, and how they went about executing their career. And I noticed similarities between three backgrounds that were very unique and different in the industry they were tackling, but the process and points were very similar.

Venture capital is a game of pattern recognition, so you're constantly out there trying to look at how the new world's evolving and what the key patterns are. And I've been a writer since I was a sell-side analyst. I've had a blog post for a long time, and I would constantly try to see patterns and then bring them together and write about them. 

And so that process was something I'd done a lot. When this clicked for me, so first of all, the three people were: one was a folk singer, one was a basketball coach, and one was a restaurateur. So they're not even, you know, they're not in the same domain category. 

They're not in the same domain and they're all in domains where your parents would tell you not to pursue this job. And they're all in domains where people would tell you you can't make money. And yet these people went on to exceptional greatness. Wealth became a part of it. 

I don't think any of them started for wealth in those areas, and it touched me in a way where I was like, &quot;Wow, that's a cool unlock.&quot; Like, that there might be some things these people are doing that other people aren't doing and that haven't been written down. And so I initially thought this would be a great presentation to give to someone, maybe at like an MBA class.

Because that's a point in your life where people that go to MBA school have a very unique opportunity to shift careers if they wanted to. Anyway, I gave the talk at the University of Texas. They put that on YouTube. It got several hundred thousand views. I started to hear from people that had changed their lives. 

A few people who are in the personal development space, like James Clear, noticed it. And it gained momentum and people said to me, &quot;You should turn it into a book.&quot; And one person in particular, who is very outspoken about trying to encourage people to do creative things, when he heard I had this kind of &quot;in the can,&quot; he really pushed me. 

He does this with a lot of people. But like, so you started with a question: &quot;Why is a venture capitalist doing this non-venture capital thing?&quot; He really kind of shoved me in the back and said, &quot;No, this will be good for you to go do this non-venture capital thing.&quot; So it's a passion project. 

It's something that I've now spent six years working and studying and learning and enhancing from the presentation, working with a co-writer. And I think it's—I hope it's awesome. I've gotten a lot of early validation. The goal, the sole goal of it, is to unlock human potential.

The goal is to get people who maybe didn't have the gumption to go do this thing, particularly if it's in a field that doesn't feel like you're supposed to be doing it, and see if they can go change the world. And not only change the world, but I think all of the stories we have in the book are of people who, once they're successful, have a huge impact on others. 

And so it's a passion project with hopefully a very noble objective function. Oh, I think there is a hugely noble objective with this and I think that that's also why it resonates with so many people. Because the question that you asked me, like &quot;Do you enjoy what you're doing for a living?&quot; and the question of &quot;Do you like your job, do you like your career?&quot;

You did research on this, and 70% of people that you researched in this 10,000-person study that you did for this book did not say that they enjoyed what they were doing, that they wanted to sort of—like if they could sort of restart, right? Yeah. And I think, I think I'm very fortunate because I said like yes, I do enjoy what I'm doing, but that's obviously not the majority. 

So this is why this idea resonates with so many people because I think a lot of people... I've thought about this a lot. I feel like people start in a career and time just flies, like time really just flies. And then they look up and they're 40, 50 plus sometimes, and they're like, &quot;Where did my life go? What am I actually doing with my life?&quot; 

Is the career that I'm in even something I want to do, or is it what I was pushed into after college or university, or what my parents wanted? Is it what just like pays the bills and I'm scared to do something else? So I think that that's why it hits home with so many people. 

I have to ask you, like was there a point in your life where you were in a career that you absolutely hated? Was that like—did any of writing this book like take you back to a point in your life? Yeah, I think there was an undertone. First of all, my career as a venture capitalist I adored, and I'm still kind of at the tail end of it.

But I loved every minute of it and I would often say in interviews, &quot;You know, if we lived in a socialist world where everyone got paid the same for a job, I would still want this one,&quot; because I had so much fun doing it. And I had two jobs before that. 

I wouldn't say I hated them, but I was an engineer. I had an engineering degree in undergrad, and you know, in my second year as an engineer, we were starting the third project I had worked on and it looked like the second and it looked like the first. 

I was seeing a bigger, broader world out there and it was like, &quot;You know, this probably isn't what I want to do.&quot; And so I went to MBA at the University of Texas, thought about venture a little bit while I was there, but it looked very hard to break into. And I went to Wall Street and I was a Wall Street analyst on the sell side. 

I had a great time, met a lot of amazing people. The sell-side analyst gets connected immediately to CEOs and CFOs, which is insanity. You're 27, like that shouldn't happen. But after a couple years, I walked around the office and I thought to myself, &quot;Is this what I want to do my whole life?&quot; 

And I got to &quot;no,&quot; I got to &quot;no,&quot; and that eventually led to me getting into venture. So I do think one of the things that's important, and I want to come back to some of the data that we stirred up, but one of the things that's important is letting young adults know that it's okay to try a career and stop. 

Dave Evans, who wrote Designing Your Life, talks about this a lot. They have data in that book where, I won't get it exactly right, but like five years post-college, 40% of people are no longer in the career that their major was, and then 10 years after, it's like 60%. 

And no one tells you that when you start and it all feels like you're on this kind of treadmill—we call it a conveyor belt—and like you don't know that you have that flexibility. And so the weight of the direction you're running feels very heavy on young adults.

And then I think that also there's all these expectations that they feel they have to live up to. And they don't know where those expectations are coming from; maybe like I mentioned it is your parents or your peers or your guidance counselor or your professors or whatever. 

But you have all these expectations and then you actually start running a race that isn't even your own. And that's what I think a lot of—if we talk about the data, the data is shocking but also kind of sad. And I think that you probably felt the same way because you ran this survey twice because you didn't believe the data when you first ran this survey.

That's right. And by the way, we started reading much academic research. There wasn't much data on career regret. We launched a SurveyMonkey survey of a thousand, but eventually to make sure it was hardened, great academic work, we partnered with Wharton and did a much broader one. 

Ours was seven in 10, theirs came back six in 10. I mean, it's still... the majority don't like what they do for a living. Well, the question was, &quot;If you could start over, would you do something different?&quot; The Gallup poll does an employee engagement survey every year. 

Those numbers are at 15-year lows right now. There's this whole phrase &quot;quiet quitting&quot; you may have heard about, which they say like 58% of people say they're not engaged at work and 15 of those 58 say they're quiet quitting—they're like intentionally trying to undermine the organization. But these are horrible numbers.

Of course. But I do think part of the problem is the very well-intentioned people that want the child to be as successful as they can possibly be. In the book Coddling of the American Mind, Lukianoff and Haidt call it the resume arms race. 

But like around sixth grade, parents take on an enormous amount of anxiety about their college application and whether it's going to be full or not. And so when... people always say when I was young, but like when people were younger, they came home and they left the house and they went and ran around the neighborhood and nobody said anything. 

These kids today have their life scheduled from when they wake up to when they go to bed. And it's lacrosse and it's cello lessons and it's the foreign language and it's volunteering, all to build up that resume. And then it just starts compounding and going faster and faster and faster. 

One other thing that's happened that I think is unfortunate is many universities now require you to apply to a major as part of your application. So you used to go take core classes for two years and then at the end of your sophomore year declare a major. 

Now you're telling a junior in high school, &quot;Do you know what you'd want to do, do you know what you love?&quot; Like they really don't know. And I've watched people ask these kids and they're not... they really don't know, so they just want to say, &quot;I'm sorry, I don't know,&quot; but they're not allowed to have that answer.

You get thrown into these situations where, first of all, it's very expensive and there's a lot of pressure, and again your whole circle and peer group is saying this is what you have to do. Like in my family, the expectation was just get a degree, like just get a degree, doesn't really matter what you do, but then that shapes it. 

When you just get a degree, that does shape to an extent where you're going to end up in your career. And there's so much pressure early on and you're trying to navigate it; your parents come from a different generation where there wasn't the same kind of pressure. 

Like now, I feel there's so much pressure to pursue higher education, and it's not just pressure but there's so many different choices too in career, right? So there's pressure with choices and it just makes for a very stressful environment.

By the way, we talk about this in the book where up through like 10th grade, 11th grade, you don't make a lot of choices, and then all of a sudden there's 2,000 colleges to choose from and all these majors. Like it just opens up like crazy and you don't know what to do. 

I found this great quote from Rick Rubin's book, but he says, &quot;As children, few of us are taught to understand and prioritize our feelings. For the most part, the education system doesn't ask us to access our sensitivity but to be obedient, to do what's expected. Our natural independent spirit is tamed, free thought is constrained. There is a set of rules and expectations put upon us that are not about exploring who we are or what we're capable of.&quot; 

I love this. And I don't think that that's intentional. Like I'm not mad at the parents or at the college counselors or any of that. I just think it's a big system that has evolved to this place. And I'm hopeful that we can get a few parents and career counselors as readers of the book just to open the aperture of what's possible, to start thinking about things in a different way.

If you look at, was it a personality trait? Was it exposure to people? Was it this inflection point in your life where you had the courage to pivot careers and to make different choices because you were on a path and then you pivoted and then you pivoted? 

I mean, why did you do this? Why did, for example, even I do this when so many people stay stuck in one thing far after it's sort of expired? One thing I give a lot of credit to—my father grew up on a rural farm in North Carolina, fell in love with model airplanes, and that took him to NC State where he got an aeronautical engineering degree. 

He was working at Langley Air Force Base and he got invited to move to Houston and help be a part of the launch of NASA. And he took the leap. And he's still here—I was just with him last week—but knowing that he did that and knowing the outcome from it and how it shaped his whole life and our community, I mean just so much came from that. 

I think it just gave me permission. That word's a word I use a lot talking about the book; like I want to give people permission to do something that feels a little bit risky, that feels a little bit ambitious, and feels like maybe it's something they shouldn't be doing, you know?

Do you feel like there's traits that people can borrow from successful founders in their own career? Sure. One of the things we get into in the book a lot is just how you think about learning. You know, founders live on the edge of a new technological shift constantly and they can't not know what's happening next. 

And it requires a level of studying that is foreign in other industries and other fields. Not to the people we profile, but to most people. Like most people when they go home from their job, they don't study more about what's next in their job. It's just not what they do. 

It's not a common trait. All the people in this book and all founders have to live in constant fear that there's something new on the edge that they don't know. One thing that I've always—this is like a working thesis and you work with a lot more founders than me, so bear with me if you agree with this or not—but I've always thought that the best employees could be founders in another life. 

For whatever reason, that's just not the season of the life that they're in right now. So when you hire somebody, the people that are going to kill it in their career are ambitious, they are curious, they are self-taught individuals. 

They're people that are always trying to do the next thing or even break what's working now so to build something better even in their own job or in their own life. Like they adopt a lot of the same traits that a successful founder would have but they just do it in a work environment because that's the place they want to play in right now. 

So I think that when I think about the most successful people who have had the careers that are fulfilling, that they actually enjoy, they act like founders even if they don't have the title. And you touch on something that I spend a lot of time on in the book, which is I think that in order to be great, you want to learn all the bedrock principles you possibly can. 

But then once you know those, have the independence of thought and the confidence to innovate on top of those principles. So it's not ignorance of the past, it's full understanding of the past with an appreciation of self-learning and the ability to do something different. 

One of the things that I think would make many employees bad choices of founders is if they get the first-level rote knowledge and then they just apply it all the time. And they don't have curiosity and they don't evolve. But I see a lot of people execute that way in life. And you can get through, you know, but it's... you're not very dynamic.

When somebody is in a career right now and they're very aware that they're not happy, they're unfulfilled, they're in the 70% or the 60% depending on which study they're part of, what is the new mental model they have to adopt, or how do they change the way they view the world? 

Like what's the action step they gotta take? Because the first question is, &quot;Oh, this is great. I'm not thriving in my career. I have a mortgage, I have a spouse, I have kids, I have all these payments. I have been doing only the one thing for the past 30 years.&quot; 

It's great to pontificate on a podcast that I should be learning all these new skills, but how do I actually change my life? And I think that that's where the theory, at some point, has to come in contact with reality. I think that it's obviously easier for people younger in their career.

And that's the same for starting a company; the more you get locked into obligations like you described, you do start to reduce your own flexibility. Although I want to come back to that. So I do think it's better for young people. But what... three or four things I would say. 

One, recognize that lots of people, lots of successful people start in one place and move to another. This is the stuff that Dave Evans talks a lot about, like it's okay to change because you need the permission to do it and you need to think that it's possible. 

The hardest part I think of all the stuff we talk about in the book—we have a chapter titled Chase Your Curiosity—people talk like &quot;find your passion.&quot; I think it's the hardest part. If you don't have a calling, it could be forced. It's like some entrepreneurs say, &quot;I'm going to start a company,&quot; and they just kind of force-start a company versus like really having an &quot;aha&quot; moment. 

And I think you need the &quot;aha&quot; moment. But I have a test that I think is the right test for whether something is the type of passion where the tools in this book could help you be successful. And that is simply: would you spend time outside of work learning about this topic? 

Like would you pick up a new paper on this topic and not watch Breaking Bad? Like does learning in this field compete with entertainment for you? And if that answer is yes, I think you're... this is your thing. Like I really think this is your thing. And I think if you're in a field where you have that level of curiosity, you're going to do extremely well, almost whatever the field.

I like to talk about obsession a lot, because obsession for me is such a fun idea—in a good way, like a good obsession. It's like, okay, so if I'm running a podcast, like I'm up until 3 or 4 in the morning researching how to ask the best question, what does the setup look like, what are the clips, the hook, the first three seconds of a clip, and how does that perform on social media so I can market this show better? 

I just get obsessed with it. So I know that I'm doing my thing, I know that I hopefully am thriving in a career that I love. We have a section in the book about Jimmy Donaldson, who's MrBeast, and he was on a group Skype with these other four individuals and they were talking about those exact things you just described. 

Because I love it, yeah. Yeah, and I think that, I mean if I think about where I started my career—it's so funny that you clocked it, I don't know if you looked into what I did for a living—but when I first started, I was in B2B enterprise SaaS sales and just sales in general. 

And you know, you finish work and like, I didn't feel like researching better enterprise sales techniques. But I suspect there are some people that do. I'm sure they do. And it's a useful skill; you can make a lot of money doing that too. 

But that's why this is the test I love. And there's a clip you can go watch on YouTube of a graduation talk that Seinfeld gave at Duke and he uses the word &quot;fascination&quot; where you use obsession. I think curiosity, fascination, obsession—all those things get back to this point: would you spend your free time learning more about it? 

And you know, that's a high test, that's a high bar. But I certainly did that in my field. I was going to ask you, so when was your pivot into venture capital? Because there was a question Frank Quattrone asked you about your dream job. 

Yes. And he basically asked what was it, and then you answered, &quot;I've always dreamed of being a venture capitalist,&quot; and then Frank said he'd make it happen, and then within 13 months you were a VC. So what was that interaction, what did that trigger? 

Let me give you some context on that. So I was in my third year as a sell-side analyst in New York and Frank Quattrone, who's a very famous investment banker in the high-tech world, left Morgan Stanley and was starting a new investment bank. 

I knew I didn't want to be a sell-side analyst anymore. I had been approached to be a buy-side investor at a really great firm called Capital Group and was interviewing there. And I got this call out of the blue from Frank. And I talked to someone who knew him well and he said, &quot;You have to take the meeting.&quot; 

This other individual said, &quot;You have to take the meeting.&quot; So I took the meeting. And he asked that question, he said, &quot;What's your dream job?&quot; and I said, &quot;Well, I've always dreamed of being a venture capitalist.&quot; You know, and that goes back to I worked at Compaq, which was venture-backed. 

As I studied companies on Wall Street, I could see the young, up-and-coming disruption interesting to me. I've always been fascinated with gambling and &quot;edge&quot; and those notions. And so I was going to go on the buy side, but that's what I wanted. 

And he said, &quot;Come work for me,&quot; because I told him I didn't want to do the job he wanted to hire me for. And he said, &quot;Come work for me and I'll introduce you to every venture capitalist I know.&quot; Which was a very fortunate moment. 

And that word &quot;fortune&quot; comes up a lot when you study great people, but I do believe the famous saying that preparation meets opportunity. You get these chances in life, but you got to take them. You have to be able to even recognize them; that's huge. 

Some people don't even recognize them when these opportunities occur. It was funny, someone sent me something the other day—this is so far away from everything we were talking about—but there's an up-and-coming country singer named Charley Crockett who's starting to really bubble up. 

Apparently, he was outside of Gruene Hall in New Braunfels handing out his own CD and handed one to Evan Felker of the Turnpike Troubadours. And that led to him starting to get tour dates and stuff. And people go, &quot;Wow, that's super fortunate.&quot; 

And I'm like, you know what? Most people aren't handing out CDs at Gruene Hall. No, you got to, to a degree, you got to make your own luck in life. Like you do got to make your own luck in life. 

And that's—if it's career, if it's entrepreneurship, whatever—if you take enough shots and if you take enough action, I think you do start to actually create your own luck just through pure volume of things done. Something's going to work out in your favor. 

I think that the people that are again in the majority of being unfulfilled in their career and saying, &quot;I would start over if I could,&quot; it's because for a period of time—for like 5, 10, 15 years—they haven't really taken any ambitious shots that could lead to the result they want. 

Listen to this, this is also from Rick Rubin's book, which if you haven't read it, it's very different but it's really good. Rick Rubin's a really interesting guy. But he said, &quot;To the best of my ability, I've followed my intuition to make career turns and been recommended against doing so every time.&quot; 

It's funny, every time. And I just think that that's fascinating, right? This trusting your inner voice and what it's telling you versus what society or these well-intentioned, once again, well-intentioned chaperones... That's the thing, it's always well-intentioned.

But it's because they are speaking from their frame or their perspective. So if you had somebody in your circle, like if you were speaking to Rick Rubin about career change, Rick Rubin's going to tell you go take the career change, go do the crazy thing. 

He unquestionably will. And that book, you know, it's targeted at more creative individuals. It's funny, I reread it thinking about my book; my book's more targeted at professional career type things and he's more focused on creative individuals.

But he's unquestionably urging people to have more permission, to take more risk, to be more of themselves. But the majority again have never done that, so they're speaking to you and they're giving advice from their reference point. Fair enough. 

But that's the issue; if your parents say, &quot;Well, maybe don't switch careers, you just got this new job,&quot; they mean well, they want safety and security. There's this also famous video you can find on the internet where Jeff Bezos talks about his career regret minimization framework. 

Have you heard of this? Yes, yeah. And you can go watch it, it's like five minutes, it's not long. But when he was thinking about starting Amazon—and this is exactly what we're talking about, like a hard pivot—he is working at D.E. Shaw, and David Shaw does not want him to leave. 

He's young and highly successful. He's walking away from a career most people would dream of having. And he said he went and walked around Central Park and he asked himself the question, &quot;If I'm 80 and looking back, am I going to be more upset that I left D.E. Shaw or that I didn't try this thing that was tugging on my ear telling me you got to go do this thing?&quot; 

And he said that made it simple. Like in his mind, it was abundantly clear. David Pink has a book on regret and he says that there's tons of academic studies that &quot;boldness regrets&quot; are the ones that weigh on people the most. 

And boldness regrets are the things you didn't do. Like over your life you get to the end and think, &quot;Boy, I wish I had done this, I wish I had asked this girl out, I wish I had changed careers, I wish I had done this thing.&quot; 

And life is a use-it-or-lose-it proposition; you go through once. And so having that mindset from these other great individuals, I think that can help with that question you asked a while ago about how do you get off the snide—how do you get out of this thing if you know you don't like it. 

So you studied a few different success stories: Bob Dylan, you mentioned MrBeast, Bobby Knight, Jen Atkin. And you are a master of pattern recognition. So explain to me why you were studying these people in the first place—how does studying MrBeast sort of play into having a theory? 

Well, some of the stories were the inspiration for the book and some of them were to fill out the book and make it even better. And so some of them we went looking for after the fact and some of them fell upon me. You noticed things when you started, yes. 

Yeah, the ones that fell upon me were from reading biographies. And it's so funny—when I was... I had a horrible verbal SAT score, I never read. And then somehow when I got to graduate school to my MBA program, I just started reading. 

And I don't know why the bit flipped—maybe I had free time while I was there—and I started consuming. And I have a list of books at the back of the book of all these books I consumed. But like a lot of the people that I studied along the way, I picked up a lot of the personal development books.

The Seven Habits of Highly Effective People, you know, the Dale Carnegie book. Warren Buffett said the Dale Carnegie book had more influence on him than anything. And so I think right after those type books or Tony Robbins, you start to fall into the biographies. 

And they're fun; you learn a lot of things reading about these other successful people and what they've done. That's why I got into them. Then we started looking for stories of people who made an intentional choice to take a career change, you know, who had this &quot;aha&quot; moment: &quot;I'm going to go do this.&quot;

And they set about it intentionally because that's the type of framework that can be helpful to someone that wants to go do this. And what was the thing that you noticed in these people? I mean, pattern recognition, because you did this for 25 plus years looking at founders. 

So like one skill is easily transferable, I know this for sure. So if you notice what makes a successful founder, then you start to notice what just makes a successful person. And we sort of touched on a few different points and attributes and personality traits and whatnot. 

But when you study the most successful people in the world, the most successful people that have made career pivots, what are some of the patterns that you start to recognize? So first of all, you have to know that you're going to... you have to have this intentionality. 

You have to know that this is something I'm excited about and determined to go do. Danny Meyer, when he walked away from a sales job—this company that sold these devices that hook into clothes so that you can't steal them from stores—he was making over $200,000 a year. 

And this was 40 years ago, and so that's a lot of money for a young person. And he took a job that was less than one-tenth that salary in a restaurant to start the learning process. And so the level of determination you need is ultra-high. 

But then he set about a learning journey. So he enrolled in a restaurant management class, he enrolled in a concierge class, he worked at this restaurant for almost nothing to get exposure. And then he went to Europe and worked for free. 

He set up a series of sessions where he could learn at different restaurants. And so this learning part is something that I see over and over and over again. And I would divide it into two components that are critical. 

The first one is learning the history. And by the way, I think this is a piece of advice that could help anybody that's trying to get hired for any job. Most people... there are few fields like American literature where you study... it's like you have to study the greats. 

But in most fields people don't know—there's no one going into an accounting job that studied the great early accountants. But if you went into an interview and there's 20 candidates and it's quite clear you know the history, you're going to be highly differentiated. 

So it immediately helps with peers and mentors and all these other things if you know that history. And if it's too boring for you to go read the history, you failed test one; you go back to the start and find something else. 

There's this thing we uncovered that we put in the book. There was this big chess tournament, a global chess tournament, and during the middle of it they did something for fun—they did a trivia contest in the middle of it for the history of chess. 

And Magnus Carlsen won. Of course he did, because he's obsessed with it. See, but you say that—of course he did, right? And here's another insane thing: a friend of mine won at a charity auction dinner with John Lasseter at his house. 

He's the creative genius behind Pixar. And when we showed up, they put us in his screening room and served a 10-course meal to 10 of his favorite cartoons of his life and he walked through and described why they mattered to him and how they impacted him. 

And most of them were from 40 years ago. And you sit there and you say, &quot;Holy shit, the guy that's innovating at the top of his field has this kind of understanding of the history of the field.&quot; So that's one. 

The other edge where you can highly differentiate yourself is what's brand new. So a lot of people go into careers... you go into work in a marketing organization, you go into work at a finance organization. Most of those people don't know how social media works or how podcasts work. 

And if you're in those orgs and have that knowledge of what's on the edge, you're once again highly differentiated. So I love learning on both sides, like where's innovation in this area and understanding all the bedrock history of the field. 

We talk about a picture in the book that Picasso did when he was 14. If you go to the museum in Barcelona, you're shocked—or I was shocked—to find out that Picasso had nailed perfect realism by like 13 or 14. 

He was winning awards for how amazing his pictures were. And so you can go find—we included a description of one called The Altar. But everyone thinks about this cubist and oh this thing and oh anyone could do that, but it came from a place of fully understanding the art form first. 

It was this fascination—Seinfeld calls it fascination, I was calling it obsession or curiosity, whatever you call it. Because I think that when you look at somebody like a Picasso, you'd say, &quot;Well, he's a savant, he's naturally gifted or talented.&quot; 

I think that that actually just is almost like a compass, like that maybe that first little bit of talent or gift points you in a direction, but then the obsession, to use what I call it, it's what actually allows you to be successful at that thing. 

Like if you look at any great—I mean, it could be Picasso, could be LeBron or MJ, pick a great from any field, any industry. Even founders that I speak with, and I'm sure that you recognize this as well, they know so much about what they do. 

It's like it's disgusting, the amount of knowledge they know—useless knowledge that they sometimes know about what they do for a living, right? They just know to the intricate detail. And by the way, look at the tools we have today to get knowledgeable. 

It's never been easier. I mean, I started writing this before LLMs took off. Like you can just sit there and talk to OpenAI. You want to learn about the history of a field? Just you could spend the next two days talking to OpenAI and know more than most. 

Like there's no excuse to not have this bedrock level of information because it's never been easier to get. When you do make a pivot in your life, in your career, what allows you to be successful? 

Well, the... you brought up earlier like this is harder if you're older. We have a chapter near the end of the book called Never Too Late where we profile several people that made post-40 changes and drastically impacted the world. 

It's kind of fun to know that it's still possible. You know, I don't know that the techniques are any different. I think the amount of gumption that's required is so much higher and harder. Society, you know, doesn't... I don't think... 

I think for whatever reason, I think we've evolved to a place in society where if you're 40 and have three children, you don't leave your job and go chase a dream. Like it just looks reckless, right? I think that's sad though. 

I think it's sad because I think that that's actually when you have like the life experience where you actually could have a higher success rate than somebody who's just like a, you know, the Stanford dropout—the typical entrepreneur, right? 

Sort of like the Hollywood version of entrepreneurship. But think about somebody who's 45 who's worked in a career or a business their whole life—they recognize the gaps in that industry better than anybody else. 

They have like the lived experience, the business acumen, and then they can either strategically pivot their career or they can go build something in that industry at 45. Like I feel like their success rate is much higher. 

I'm just making these assumptions up, but I feel like just intuitively, this person... I would assume that they would have a higher likelihood of success because of what they've gone through in life and what they know. 

I am, the reason I'm smiling as you say that is like I have a lot of ambitions for the book. It's obviously, you know, more targeted at young adults and, as we talked about, the people that serve in like mentor roles for that group. 

But I would be thrilled—like I'd be tickled pink—if stories, as the book launches, if I start to get inbound stories from people just like you described, who this book gives them that permission. My co-writer uses the phrase &quot;disinhibiting.&quot; 

And there we found stories like Seinfeld decided he loved stand-up and wanted to give it a try, but it wasn't until he read this book—someone wrote a book about 20 successful stand-up comedians and here they are and here's their profile and they all make money. 

And like that book gave him this disinhibiting moment where he said, &quot;Oh you can actually, one can do this, right? One can go do this.&quot; And I hope, I hope, I hope I hear from a ton of the people you just described and I hope they go on to do really amazing things. 

When you look at all the people, like even like the founders that you work with, because outside of this study you work with founders on a day to day. Do you find that people that are more entrepreneurial are more in love with the work they do? 

Even if they're not—say they're not like founders by name, say they're people that work within like an early-stage startup and they build from scratch? Do you feel like they're a little bit more in love, they're thriving more often than not in their career? 

Is there anything else that sort of is a good signal for... I would say this because you're making me smile once again. Like there are more smiles in a startup than I've ever seen in a non-startup. In that you're coming up with all these theories like in an unknown world. 

Like you're saying, &quot;Well, what if we did this or what if we did this or what if we did this product or changed this pricing?&quot; And when something works—and many of those theories don't, like maybe it's one in five, one in 10 or whatever—but they keep tilting at it. 

But when it does work, there is this massive smile. I mean I can just look, I see founders in my brain. Like they want to call you and tell you, &quot;Guess what, guess what just happened, like what just came, what happened!&quot; 

So yeah, I do, I do think that. Like I do think they're constantly experimenting, constantly learning, and constantly thrilled when when something comes together. So that being said, now I'm trying to really unlock why people have so much regret. 

And it's like it's not just one thing that leads to regret, right? It could be that the job you're working in was something that you just thought you had to do. It could be and you've just been doing it for forever. 

But I think it's also because you feel like you stopped winning in your career. Like you stopped doing anything interesting, you stop taking shots, you stop taking any kind of risk, you stop growing, you stop achieving anything as an individual or even as a team. 

And you're just in—you know, you're just in this routine, this comfort zone routine that you've been doing for X amount of years and there's no newness. Like at least in a startup environment there's super high risk but a lot of newness. 

And I think that that can also create a lot of career satisfaction. I think that's a great point that you're making. And look, I do want to acknowledge there are many people in this life that have decided that their career's their career and their fulfillment is outside their career. 

They view one as a means to an end and they don't want to hear about it. And this book's not for them. I'm not judging them—this book's not for them. If you are in that situation you just talked about and feel frustrated, pick up the book. This is who I want to speak to and talk to. 

Do you, do you have any career regret? No, but you know, I don't because I fell into that spot. Had I not fallen into that spot, yeah I might. But I but I don't. And by the way, one thing I harp on in the book: those two jobs that I had for three years each, I don't regret those. 

Like they were a part of the path that got me where I was going, you know? And I'm glad that I had both of those stops along the way. I feel like people always think they have more time than they actually do. 

I don't know, I've noticed this even more since COVID. I don't know why, but I just feel like time flies now. I think it's because you're getting older. I think time moves slow when you're young and gets fast when you're old. 

But like years are flying by. Like years are flying by. I have this theory that it relates to your storage capacity in your brain. When you're young, you get to store everything so everything feels slow, but but your brain fills up and then you're not storing much new. 

No, it's true. Well, I think that I've actually read—I can't remember where I read this—but there's this idea, a few different ideas as to why like time moves faster when you're older. But one of them is like you don't experience as many new things. 

Kind of like what you're speaking; you don't experience as many new things, there's not as much newness. So routine—like life is routine, you do the same things day in day out, day in day out. And if you actually took time to do something new every single day, time would feel like it's moving slower. 

By the way, that ties really nicely back to this thing I said where if you're chasing your dream job, you learn at night as an alternative to entertainment. And so the newness kind of comes with it, you know? I was talking to Danny Meyer recently and he had just come back from yet another European learning trip with books full of notes. 

Like, who goes on learning trips? How many, what percentage of people in their career go on learning trips? But this is what, this is what differentiates you. No doubt. This is what differentiates you. I think you have a Satya Nadella quote in the book. 

&quot;I buy more books than I can finish, I sign up for more online courses than I can complete, I fundamentally believe that if you are not learning new things you stop being great, you stop doing great and useful things.&quot; 

I mean, whether or not it's learning through reading, learning through podcasts, learning through exposure of just trying something—it doesn't work out, it failed, you learned the lesson, you try something else. 

There's not a single person who I know who's successful, happy, and fulfilled who is not constantly exploring new ideas. And there's no end like up until the point, you know, when you're no longer on this earth. Like you are always, always learning new information. 

By the way, Satya's turnaround at Microsoft may be a unit of one. Like it may be the most successful business turnaround ever. I don't think many people know that story. Yeah, and in that, when he was talking about that, someone asked him how he led so much change there. 

He intentionally took that mindset and said, &quot;This is going to be the mindset of the org, and are you in or out? Like are you going to become a self-learner and be a part of the new Microsoft? And if not, you know, this probably isn't a place for you.&quot; And that's really cool and innovative and new. 

First of all, hats off to him for accomplishing this. I feel like a lot of CEOs wish they could do that with their companies. It's not easy, though. It's not easy because it pushes people outside their comfort zone. 

Yes, no doubt. To become a self-taught individual. Because then you start to realize—I think this is probably the scariest part—when somebody is not happy with their work, and I love the idea of agency and of internal locus of control and of taking responsibility for your own outcomes. 

But you start to realize that, &quot;Oh, I'm not in a job I love, it is entirely my fault that I'm still in this job.&quot; Or fault, or responsibility, or whatever word you want to call it. And then the responsibility becomes yours to learn the skill or to do the thing or to make the move or to take the action. 

So then it becomes quite scary because you realize that whatever you actually want to achieve is on the other side of your action and your agency. And I think that that puts a lot of people in an uncomfortable position if they are not used to adopting that mindset and that mental model. 

Whereas I think a good founder or even forget founder, a successful executive that has worked his or her way up through the corporate ladder—they understand that most of their success has been contingent on them and they are personally responsible for all outcomes good and bad. 

And I think it's a very scary idea for people to adopt. Well, I think the book can be super helpful for people that feel that way. So the structure of the book I think is somewhat unique. We divide it half between what I call profiles, which are stories of success, and principles, which are tools or methods of success. 

And you know, in addition to giving people permission, I want them to read about other people doing this so that they feel the possibility, and I think the stories will really help on that front. And then give you very straightforward tools and processes to go about the journey. 

And you know, once again these aren't really mine; I've studied other people that have been wildly successful. I see some mirrors in my own success but I've brought them together and synthesized them in a way that I think it could give someone like you just described confidence to take the leap and to have some conviction that they'll be successful as they go forward. 

One last idea that I think is really important, and not to throw AI into every single conversation I have, but you mentioned that AI is about to eliminate some of sort of the more safe careers. Correct. 

So this conversation, this book, some of these ideas, the need for somebody to take action in their own life is probably becoming a little bit more relevant now than it even was five years ago. Because if it's not—if it's not just, you know, we're looking at it from the angle of you are doing it for fulfillment and you're doing it so that you love your life and there's no regret. 

But like if you look at it from the other angle of: maybe the job that you have right now is not around in five years. Or maybe maybe it's downsized or the people that are doing your job are specialists in AI and they can 10x the efficiency of every single person in that business unit because they know how to use LLMs and different sort of AI tools and generative chat tools or whatever. 

If you don't—if you don't learn new shit, if you if you don't if you don't find a way to either move into a career you love or if you don't find a way to become even significantly better and more forward-looking in the career that you're doing right now, at some point you're going to get replaced. 

Which is just a hard truth whether or not you you love it or not. It's just the truth. So I think that the mindset of learning new shit, understanding that that can either be applied to make you more—probably secure your career in the job that you're doing right now and or set you up for a potential successful pivot if you're just like again a self-taught person—I think that idea is one of the most important things. 

Yeah, and I would say three things to that. One, if you are in your dream job already, embrace AI. You want to become the superhuman that is what's new on the edge. You should be self-learning. Like that's what you should go do if you're in your dream job. 

If you're not in your dream job and it's threatened by AI, yes, all the more urgency to jump out. And then lastly I would just say, I think those well-intentioned parents and coaches send people towards the &quot;safe&quot; jobs because they think that if you make enough money you'll be happy in life. 

There's all kind of surveys that show that not to be true—that fulfillment matters way more than than wealth. And so you know, I didn't think it was right, but now that all those jobs are in question, hopefully some of these people will stop cramming kids down these conveyor belts towards computer science or or whatever because now it's not as certain. 

No, now nothing's—now nothing is certain, right? So the only thing that's certain is you have to be somebody who's adaptable, who is a self-taught individual.

If if you have those skill sets and that mindset, I think then your career is always going to be fine. And you're much more likely to have that mindset if you have found something where you where you are highly curious about it. I stumbled upon this podcast with Angela Duckworth, who has obviously written this famous book Grit, and she took some time to talk with us as we were writing this. Her book said there's two things that lead to success: passion and perseverance. And that's what grit is all about.

And she says if she were rewriting the book today, she'd focus way more on the passion side because what she discovered is we've taught a lot of these kids how to grind. You know, just like you teach a kid how to practice piano for four hours a day. And what ends up happening is, you know, you crush your SATs, you get into the best school possible, you get one degree, maybe two, but you run out of steam if you don't have this this passion that drives this curiosity. You you've been trained to run, you know, but eventually you run you just run out of energy.

You mentioned something interesting and I just want to touch on that. You shouldn't be racing towards money, you should be racing towards fulfillment. How do you measure fulfillment? How do you know if you are truly fulfilled? Is it a feeling, is it like when you look at some of the people you've interviewed, what's the what's the metric?

I have to believe that there are other academics or authors who have written books specifically on that topic. Probably, I'm going to go talk to ChatGPT after this so I can have a better answer. You know, I really have found that people that have this self-learning element to their job are the ones that are fulfilled. And I don't know if it's for the reason you said where there's just constant newness in their life. 

I think you know, all the people we profile, I mentioned this earlier, but all the people we profile end up touching a lot of other people's lives in a positive way. You know, if you become extraordinary in your field and at least if you're following the principles I talk about, you're you're co-evolving with your peers, you're you know, these kind of things. You're building relationships, you're having success, you're impacting people's lives. I think those are, you know, the elements of fulfillment that matter the most.

So Running Down a Dream, that'll be available wherever you get your books and we'll put links in the show notes and everything like that. Where do you want to send people? Is there any other socials or websites that you want people to go to?

There's one thing I'll mention, and we're just putting it up right now, but I'm going to take all the proceeds that I would get from the book and more and launch a foundation called Running Down a Dream. And we're going to take applications for microgrants for people that are kind of stuck financially that want to go chase their dreams. And you know, we'll we'll take those applications in and I'll create a committee and make some choices and we're going to hand out some grants to see if if you know, because some people came to me and said, &quot;Well what if someone just is too stuck financially to make a pivot?&quot; Which is valid. But which is valid. So hopefully we can do that and hopefully some of those people will be successful and then we'll tell those stories.

I love that. When someone's finished reading, what's the first thing you want them to do? There's two things that have already happened in the handful of people that have read the book. One is they immediately want three or four copies because they have a mind in their in their mind someone they want to read this. So I think they know of a kid that's got too much pressure or hasn't really isn't happy or feels like maybe they started down the wrong major or you know, they they know someone they want to hand it to. 

That has... I'm very optimistic about the fact that the book may have a viral loop built into it already from that. And then the second one I heard is like... you know, I've even had like a 60-year-old read this and say, &quot;Shit, I thought I was retired. There's something I need to go do.&quot; Which is fun. Like fun that because that's what I'll finish where we started, like unlocking human potential. If I can get, I mean if I could get a hundred people to go be extraordinary that that were otherwise not going to be, I'd feel like this was a huge success. Hopefully it can be way more than that.
                    </div>
                </div>
                
            </article>
            

            <article class="video-card" id="video-2">
                <div class="video-header">
                    <h2 class="video-title">
                        <a href="https://www.youtube.com/watch?v=2Hy9c1XV6NQ" target="_blank" rel="noopener">&amp;quot;AI Will Reshape Geopolitics&amp;quot; – Sam Altman’s Warning to World Leaders</a>
                    </h2>
                    <div class="video-meta">
                        <span class="channel-pill"><img class="channel-icon" src="https://yt3.ggpht.com/uxf8fUitVuLiZgHIONcME8dhduUOHWjeVwsY1DX19AMQwLhmvkqb8TI1SKpRc8T8MZU5sE0fyw=s240-c-k-c0x00ffffff-no-rj" alt="" loading="lazy"><span class="channel-name">The Indian Express</span><span class="channel-subs">(4.3M)</span></span>
                        <span class="meta-sep">·</span><span>46:41</span>
                        <span class="meta-sep">·</span><span>525 views</span>
                        <span class="meta-sep">·</span>
                        <span>2026-02-22</span>
                    </div>
                    <div class="video-tags"><span class="tag tag-person">Sam Altman (CEO, OpenAI)</span></div>
                </div>
                <div class="tldr">The build-out of AI compute capacity represents the most expensive and complex infrastructure project in human history, requiring a shift from &quot;libertarian&quot; tech ideals toward deep government partnerships to ensure superintelligence remains decentralized and democratically governed.</div>
                <div class="summary-section">
                    <div class="summary-preview" id="preview-2">TL;DR The build-out of AI compute capacity represents the most expensive and complex infrastructure project in human history, requiring a shift from &quot;libertarian&quot; tech ideals toward deep government partnerships to ensure superintelligence remains decentralized and democratically...</div>
                    <div class="summary-full" id="full-2">
                        <p><strong>TL;DR</strong></p>
<p>The build-out of AI compute capacity represents the most expensive and complex infrastructure project in human history, requiring a shift from "libertarian" tech ideals toward deep government partnerships to ensure superintelligence remains decentralized and democratically governed.</p>
<h3>Global Infrastructure and the Compute Challenge</h3>
<ul>
<li><strong>The "Most Expensive" Project:</strong> Sam Altman characterizes the build-out of compute capacity as the world's most significant collective infrastructure undertaking for human welfare.</li>
<ul>
<ul>
<li><strong>Robotic Assistance:</strong> He predicts that future AI and robots will be necessary to build the very infrastructure required to run them, as traditional construction methods will be insufficient.</li>
</ul>
</ul>
<li><strong>The "Space Race" Myth:</strong> Altman dismisses current talk of orbital data centers as "ridiculous" for this decade.</li>
<ul>
<ul>
<li><strong>Economic Constraints:</strong> High launch costs and the difficulty of repairing broken GPUs in space make Earth-based cooling and power much more viable for the near term.</li>
</ul>
</ul>
<li><strong>Energy vs. Water:</strong> Altman clarifies misconceptions regarding resource consumption.</li>
<ul>
<ul>
<li><strong>Water Usage:</strong> He labels high-water-usage claims as "totally fake" due to modern cooling techniques that avoid evaporation.</li>
<li><strong>Energy Needs:</strong> He acknowledges total energy consumption is a real concern, advocating for a rapid global shift toward nuclear, wind, and solar power.</li>
</ul>
</ul>
</ul>
<h3>Geopolitics and the Distribution of Power</h3>
<ul>
<li><strong>China vs. The West:</strong> Altman notes that China is "significantly ahead" in physical robotics, manufacturing (motors/magnets), and energy build-out, while the US leads in other areas.</li>
<ul>
<ul>
<li><strong>Avoidance of a "Super-State":</strong> He argues against any single country, including the US, having sole control over superintelligence.</li>
<li><strong>The Authoritarian Risk:</strong> Altman defines the "authoritarian" threat as a world where one person or entity holds a singular AI that "rules" the world.</li>
</ul>
</ul>
<li><strong>The Surveillance State:</strong> A primary concern is that governments will use the "fear of AI" to justify the expansion of surveillance states without considering the long-term democratic downsides.</li>
<li><strong>Evolving Government Relations:</strong> The tech industry is moving away from its historically libertarian roots. Altman believes close cooperation with governments (such as the US and India) is now mandatory due to the scale of required infrastructure and societal impact.</li>
</ul>
<h3>The Future of Labor and Education</h3>
<ul>
<li><strong>One-Person Startups:</strong> Altman highlights a shift in economic power where "one-person startups" can now achieve enormous success using general-purpose agents and tools like Code Interpreter—a feat impossible only years ago.</li>
<li><strong>Vulnerable Professions:</strong> </li>
<ul>
<ul>
<li><strong>Software Engineering:</strong> Altman notes his own training is becoming "irrelevant," stating that writing manual C++ code is essentially over, though the role of a "software engineer" will evolve.</li>
<li><strong>Graphic Arts:</strong> He observes that while AI-generated art has a price of zero, the value of high-end human-generated art has actually increased, suggesting human connection remains a valuable commodity.</li>
</ul>
</ul>
<li><strong>Education Reform:</strong> While acknowledging some students use AI to "cheat," Altman argues the education system must move past rote memorization (like birth dates) toward teaching students how to think and create using new tools.</li>
</ul>
<h3>OpenAI’s Strategy and Industry Dynamics</h3>
<ul>
<li><strong>Research-First Identity:</strong> Altman maintains that OpenAI remains a "research-first" company, where the product (like ChatGPT) is simply a delivery mechanism for underlying research breakthroughs.</li>
<li><strong>Corporate Errors:</strong> He criticizes large corporations for taking multi-year "planning" approaches to AI, stating that a 2028 deployment goal is a "catastrophic mistake" given the speed of the field.</li>
<li><strong>Industry Relationships:</strong></li>
<ul>
<ul>
<li><strong>Microsoft:</strong> Describes Satya Nadella as a "friend," rather than a "frenemy."</li>
<li><strong>Google:</strong> Praises Google DeepMind's Demis Hassabis for starting early and commends Google's recent ability to scale models quickly after falling behind.</li>
<li><strong>Elon Musk:</strong> Admits that reconciling with Musk is "less likely" than breaking the world's semiconductor manufacturing monopoly.</li>
</ul>
</ul>
<li><strong>New Hardware:</strong> Confirms a partnership with Jony Ive to develop a new "family of products" designed around AI context and natural language, potentially moving away from the traditional smartphone form factor (updates expected late 2024).</li>
</ul>
<blockquote>
"I don't think there should be any single superintelligence in the world. I don't think there should be any one person or any one country or any one company in charge... I think the world is at its best when power is widely distributed." — <strong>Sam Altman</strong>
</blockquote>
<blockquote>
"The tech industry started out as this extremely libertarian... view. I think that has changed a lot... maybe never before has [government partnership] been this important, just given the scale of the infrastructure that needs to happen." — <strong>Sam Altman</strong>
</blockquote>
<blockquote>
"I was trained as a software engineer and the way I learned to write software is now effectively completely irrelevant... Writing C++ code by hand, that’s over." — <strong>Sam Altman</strong>
</blockquote>
                    </div>
                    <button class="toggle-btn" id="sum-btn-2" onclick="toggleSummary(2)">
                        Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>
                    </button>
                </div>
                
                <div class="transcript-section">
                    <button class="transcript-toggle" id="trans-btn-2" onclick="toggleTranscript(2)">
                        View transcript
                    </button>
                    <div class="transcript-content" id="transcript-2">
                        It points to the level of ambition we need to have about how much compute capacity we're going to build out. And this will be the most expensive, complex infrastructure project the world has ever collectively taken on for all of our welfare. So we're going to need a lot of compute capacity. 

The good news is it would be impossible to build this out the old-fashioned way, but we'll have AI and robots helping us do this and, you know, we'll figure it out. And is that why space keeps coming up nowadays as another space race then that I keep hearing about?

I honestly think the idea with the current landscape of putting data centers in space is ridiculous. It will make sense someday. But if you just do like the very rough math of launch costs relative to the cost of power we can do on Earth, to say nothing of how you're going to fix a broken GPU in space—and they do break a lot still unfortunately—we are not there yet. 

There will come a time. Space is great for a lot of things. Orbital data centers are not something that's going to matter at scale this decade. But then all this infrastructure build-out, Sam, it feels like it kind of forces you, organizations like yours, to have a very intimate relationship with government. 

And is that something that's kind of changing with AI, this whole power structure? At one point, big tech was a very privatized force with a very complicated relationship with government. Now it seems to be that you need to have a good relationship with government, whether it's Indian companies with the Indian government or companies like yours with the US government. Is the government a big enabler? 

Yeah, I think it's going to be really important, not just for building out infrastructure, but just given the level of impact this is going to have on society and the need to truly democratize this technology, governments are going to have to be involved, and companies like ours are going to have to partner with governments. 

And how has that... I mean, have you ever thought, paused and thought about that evolution of that relationship between big tech and government? By the way, can I call you big tech or not really? I don't think most... I don't feel like big tech. I don't think we're there yet. Okay, alright. 

But tech companies like yours and government, I mean... I think the tech industry started out as this extremely libertarian, you know, &quot;we don't need the government, the government doesn't need us&quot; sort of view. I think that has changed a lot even before AI, like the last couple of decades as the companies have got bigger and more central to the economy and the way the whole world works. 

That's changed significantly. But maybe never before has it been this important, just given the scale of the infrastructure that needs to happen. And how do you feel about that? Because one of the theories, one of the things we keep hearing, is that this White House is very close to Silicon Valley. 

Silicon Valley was a very close sponsor of JD Vance. That whole relationship is a very intimate one. Is that true? Is that good? Is that bad? I would say close in some ways and not close in others. You know, there are some tight ties and then also this administration has had some big criticisms of tech. 

And is that good or bad? I think a close cooperation between tech companies and the government is going to become increasingly important over time. It obviously won't be a perfectly smooth relationship, but the better it can be, I think the better for all of us. 

And what about government-to-government relationships? You know, what got announced today was very interesting, a partnership of several countries who are thinking about AI in a very advanced way. Is it all these countries versus China? Is that what's kind of playing out? Or are we all kind of in a race and somewhere China is also in that race? 

I suspect it'll turn out to be way more complex than that. I think it will shift over time. I do sort of think that AI will become one of the most important political issues in the world, one of the highest order bits of geopolitical tension and cooperation. But I don't think it'll be a fixed thing. 

I think as it develops and as... I mean, this has always happened, that sort of political alliances shift over time. I expect them to shift more in the future, not less as things move faster. But how do you think about China in all of this? We keep hearing that China is leap years ahead and China's got all this energy and all this renewable energy and robotics and technology. 

Are we hearing the right thing? And why are they leap years ahead? What have they done? I would say they are very ahead in some areas and not ahead in others. I think this is like... I mean, that sounds like a boring statement; that's probably always true in the world. 

In terms of manufacturing physical robots, they are clearly ahead. They have a big edge on things like electric motors, magnets, stuff like that. They are clearly ahead on energy build-out. So there are places where China is significantly ahead of other countries and then there are places where I think we're ahead of them. 

And my guess is that that's sort of always what it's been like and what it will continue to be like. It's hard to be ahead on everything or behind on everything. Maybe if you have the only superintelligence in the world you could do it. I think that would actually be bad for other reasons. 

But is it a race, Sam? We keep framing it as a race. Sort of. Is it a collaborative journey or is it a race? Yeah, I mean, both. That's the hard part of this, right? There are always ways in which the global economy is interdependent and very collaborative, and then there are always ways in which it's a competition. 

Reality is always messier than that. But I do think it's important to look at the net differences in power and the impact that could have. And I think it's really important that democracy leads with AI. And when you say democracy leads with AI, you mean China should not lead with AI? 

It was a little bit more nuanced of a comment than that, but if you want to reduce it to that... No, because in your speech yesterday you mentioned &quot;authoritarian&quot; a couple of times. So I was just kind of... how do we think about China? How do we unpack China as well? 

What I meant more is I don't think there should be any single superintelligence in the world. I don't think there should be any one person or any one country or any one company in charge of superintelligence. Including the United States, I think that would also be bad. 

I think the world is at its best when power is widely distributed, when people have a lot of different ideas, and when there's enough of a balance in power that we can all—countries, individuals, companies, whatever—sort of keep each other in check and all have input. 

Over time, even though we'll do some dumb things along the way, you know, people kind of get to pick the best ideas and let those rise up. So what I meant by authoritarian here is you don't literally want one AI in charge of the world. No matter who has it. I think that'd be bad. 

Yeah, but do you think if you compare to the big tech era of seven years ago, AI is going to fragment power more or is it going to concentrate it more? Because it seems that big tech, the old big tech, is equally keeping pace. That is, at some point, one of the most important questions in front of us right now. 

You can totally imagine a world where AI massively concentrates power, where say a single company or country is able to hold on to AI and use that to amass a gigantic amount of power and wealth in the world. You can imagine another extreme where everybody on Earth has a superintelligence with no rules whatsoever and some pretty terrible things and chaos happen. 

You can imagine many worlds there in the middle. I personally think something way more towards the democratized version of that is good. We of course will need some regulation, we of course will need some guardrails, but I think putting this technology in the hands of lots of people is possible and that will be a decentralization of economic power. 

The clearest example of this you can see is in the last six and especially three months: the power that a one or two or three-person company can have. This just didn't happen a few years ago. It was impossible. 

In this new world of things like Code Interpreter and general-purpose knowledge working agents, we're going to have to get used very quickly to one-person startups that have enormous amounts of success or two-person, three-person startups. And I think this is great. 

Yeah. And how competitive is all of this from your seat? I mean, you know, we saw a little awkward moment on stage yesterday. There are several memes about it going around. You gotta give the internet something to laugh at. It is definitely competitive, but I will say that I think it's also very incestuous. 

I mean, because a lot of people who are building out stuff were working with you at one point and everybody knows everybody. Nvidia's investing in you, you're buying Nvidia chips, and then it's just... there's so much. It is a weirdly small world, for sure. 

I think it's very competitive commercially, but almost all of the efforts that have a very advanced model feel the gravity of what's happening. They're very committed to getting safety and alignment right and willing to cooperate there. A little bit more about what happened yesterday if you want to share? This is a good opportunity. 

I don't really have that much more to add. I won't push him. Okay, you know, there's just so much to cover, Sam, and I learned so much. I have to... I'm very grateful for you because I learned so much to prep for this conversation. It was like three days of just being knee-deep into it. 

So I thought I'll just kind of break it up into a game. Great. And we can have... you know, I can just try to cover more and more stuff rather than having a conversation about it, and we'll see what we kind of do. So it's not a rapid fire because it's just too long to be a rapid fire. 

I tried to make it shorter but I couldn't. Is there any one thing you admire about Google's catch-up in the AI race? Because 10 years ago they were out of the water. Well, 10 years ago Google was the only serious AI effort. Five years ago, maybe. Maybe three years ago when we launched ChatGPT, they were then somewhat out of it. 

But the first thing I admire about Google is Demis and the Google team started working on AI before anyone else in the modern era with a lot of conviction. And, you know, I think without their inspiration we certainly wouldn't be here. So that's one thing I admire. 

And then a second thing more recently is their relentless focus and execution and ability to really scale up a model after being pretty far behind is quite impressive. Okay. Were you surprised when Apple partnered with Google for Siri? Not particularly. 

Okay. The one country that is by and large on the right path for regulation on AI? I don't think any of us know the answer to that yet. A thing that I'm happy about is countries are trying different approaches. And I think this is a good thing about many sovereign powers in the world. 

We will get to observe over the next few years very different approaches and see what works and what doesn't. And pretty quickly I believe the world will move towards more of what works. But I'm grateful for the experimentation and different countries trying different things. 

Okay. Short game: I'll give you some criticisms of AI and you give me a short defense of each of these criticisms. I might not have one for some. That's fine. And there's so many questions that you can always duck or pass. Too much concentration of power. 

Fair, unless we push super hard to democratize. And I think everyone in the world needs to hold countries and companies to this threshold of: you don't get to say concentration of power in the name of safety. We don't want that trade. It's got to be democratized. 

Okay. The amount of natural resources that are going into the data centers, the amount of water... Water is totally fake. It used to be true; we used to do evaporative cooling in data centers. But now that we don't do that, you know, you see these things on the internet where they say &quot;don't use ChatGPT, it's 17 gallons of water for each query.&quot; 

This is completely untrue, totally insane, no connection to reality. What is fair, though, is the energy consumption—not per query, but in total because the world is now using so much AI—is real, and we need to move towards nuclear or wind and solar very quickly. 

There was a thing... we had Bill Gates last year and I asked him this question and he gave a very interesting statistic. At that time, apparently, we calculated that 10 iPhones' worth of battery would go for every ChatGPT query. And now it's come down to one or one and a half iPhone battery life's worth of energy. Is that correct? 

There's no way it's anything close to that much. It's much less than that? Way, way, way less. Okay. Alright. But his theory was that the AIs will learn from human evolution to be more efficient in how much energy they consume. 

One of the things that is always unfair in this comparison is people talk about how much energy it takes to train an AI model relative to how much it costs a human to do one inference query. But it also takes a lot of energy to train a human. It takes like 20 years of life and all of the food you eat during that time before you get smart. 

And not only that, it took the very widespread evolution of the 100 billion people that have ever lived and learned not to get eaten by predators and learned how to figure out science to produce you. So the fair comparison is if you ask ChatGPT a question, how much energy does it take once its model is trained to answer that question versus a human? And probably AI has already caught up on an energy efficiency basis measured that way. 

Wow, okay. Fantastic. AI's making my kids dumber. True for some kids. Look, when I hear kids talk about AI, there are definitely some kids who are like, &quot;this is great, I cheated my way through all of high school, I never did any homework, thank you.&quot; And I'm like, hmm, what's your plan for the rest of your life? 

And they're like, &quot;well, I assume I can still use ChatGPT to do my job.&quot; This is very bad. We absolutely have to still teach our kids to learn and to think and to be creative and to use these tools. That's not what most kids say though. 

Most kids say, &quot;I can't believe what I can accomplish now. Look at this thing that I've just made.&quot; I've built these incredible new workflows. Sure, I may use ChatGPT in the way you used Google when you were in high school to help with your homework, but now that I have this new tool I'm doing these amazing things. 

I think we will need to find new ways to teach and evaluate in school to make sure every kid is brought along. But the potential of this technology, the ability to learn more and do more, I have no doubt about that. When I was in school, Google had just come out. 

And my middle school teacher was like, &quot;this is the worst thing ever, there's no point to teaching anymore.&quot; Why do you have to memorize the date that someone in history was born if you could just look it up on Google? And my answer was: I think it's a complete waste of time to memorize what year someone was born. 

I will just go look that up on Google if I ever need to know it again, which usually you don't that often. And then I watched over the next few years teachers come to peace with this, the education system evolve, and like always happens with new tools, the potential goes up and expectations go up. 

And we'll have to teach people to think harder, create more, and I'm pretty sure that a kid born today when they're 18 graduating high school will be able to do things that no one today can, and I think that's great. The other criticism is that it's just not democratic enough, as in the people who want to pause AI don't have a voice. 

I want to double-click on this question: where do you see the resistance coming from? Is it coming from the people who have experienced technology at its highest levels and then they say we're nervous, we want to pause? Or do you see the resistance coming from those who have never experienced it and are nervous? 

I mean, it kind of comes from everywhere. Although as more people use the technology, I think there's less of a &quot;let's totally pause it.&quot; People like it. And there's more of a &quot;what is this going to mean? Can we have more of a voice? Can this go a little more slowly?&quot; 

The one thing Silicon Valley should learn from Chinese technology? Move fast. The one thing Silicon Valley can learn from Indian technology? Move faster. The one real and one imagined fear of Chinese dominance in AI? 

I think the imagined fear is that the Chinese military is going to send a billion humanoid robots marching through the streets and overpower the US Army or something like that. I think that's an example of fighting the last war and thinking it's going to be the same. 

I think the real fear is a new kind of war between nations that gets fought over the internet where you influence people and hack into a bunch of critical infrastructure. That feels totally possible. That's a very scary reality where we have a surveillance state. 

Super worried about that. I think increasingly people are using fear of AI going wrong to justify a surveillance state, and I don't think the people doing that have fully thought through the downsides of the surveillance state. Okay, you urgently need to look something up. Your phone is discharged. 

You borrow my phone. The letter T on my touchpad doesn't work. So you can only key in Grok, Claude, Gemini, or DeepSeek. I guess if I have to look something up I pick Gemini. Okay. For other things I'd pick other models. 

The most compelling reason you have moved from a not-for-profit to a capped profit to pretty much any revenue including ads? The need to democratize AI and the need to stay at the forefront of research, both of those require huge amounts of capital. And do you think you are a research-first company or product-first company? 

Research-first company. The coolest thing about AI I think is that the great majority of making a good product is doing good research. We make a great model, the product is already pretty good. The early version of ChatGPT was almost no product at all. 

It was like a text box that fed into a model and then put the output on the screen. So research to continue to push what a model is capable of is what enables everything else. The one criticism about you that bothers you when you hear it? 

I've heard basically every possible criticism and at some point none of them bother you because you're just like &quot;this has gotten so insane, so detached from truth.&quot; I guess the one that makes me the most sad is that &quot;he's just doing it for the power, he doesn't really care about trying to do something that's going to be helpful to the world.&quot; 

What were you thinking when you decided not to take any equity in OpenAI? That was truly one of the dumbest things—I say this as someone who's made a lot of dumb decisions. The conspiracy theory that that brought about, like the one I just mentioned, was totally not worth it. 

We were like a non-profit, and there was a quirk where to be on the board of a non-profit you had to be sort of disinterested. I had been very fortunate to have a successful career and I was like, &quot;eh, I don't really care here either way.&quot; But it was a very dumb thing. 

And if somebody today were to offer and figure out a way for you to get into the cap table with wet equity, would you take it? I mean at this point I feel so tired of the whole conversation and so trapped, I'm not sure what to do. It's like a lose-lose thing for me. 

Okay. So one thing in spite of all the differences you have with Elon Musk, the one thing you admire about him. I'm going to think of something but give me a minute. He's extremely good at physical engineering and also extremely good at getting people to perform incredibly well at their jobs. 

Okay, superb. ChatGPT is not known for its opinions, it's known for giving facts and factual answers back. So I'm going to ask your opinion on the news. There have been a lot of things in the news this last week. So we want your views on: would you support the government-ordered ban on social media for kids under 16? 

I don't know if a total ban is right, maybe it is. I think at least heavy restrictions would be good. I have a young child; I'm more interested in what I think are the very negative impacts of infinite scroll. I would like my kid not to just be one of those iPad kids going like this all the time. 

So that seems very important. But yeah, probably social media for kids is something we have to be very careful with. It seems the clouds of war are again upon us, with a lot of talk about Iran. If the government were to ask or use AI companies like yours to help figure out how to get into war, how would you respond? 

Is the Pentagon just another client for you? I don't think AI systems should be used to make war-fighting decisions. I don't think they're at a level of sophistication and reliability where this is a good idea. That said, we certainly want to support the government. 

And there's a lot of things we can do already. Someday there will be really important applications of this to defense, but right now the models have clear limitations. It was used in Maduro's capture, I believe—is that true? I just don't know. I'm sure it was used in some ways. 

There are things that AI can do a great job of today, like analyzing a huge amount of intelligence reports. That is probably a great use of AI and maybe it was used some way like that. Your views on Claude safety chief Mrinank Sharma's dramatic resignation? 

I heard something about it. Like they resigned and sent a letter about it being all useless or something. Yeah, the world's going to go to hell, I want to go write poetry. But a lot of safety people are getting overwhelmed. The part of it I agree with is the inside view at the companies of looking what's going to happen. 

The world is not prepared. We are going to have extremely capable models soon. It's going to be a faster takeoff than I originally thought. And that is stressful and anxiety-inducing. Reflect a bit on the future of love and relationships. 

We keep hearing of people using AI agents to open up conversations on dating apps. How much authenticity are we losing? My bet would be that in the future we value human relationships much more. I think we are wired to do that. 

There will be some people who fall in love with an AI or talk about their AI boyfriend or girlfriend. There will be some small percentage of the world that does that and there will be a lot of breathless articles written about the end of society. 

But I think for almost everyone in a world with more abundance, human connection, human attention, and human warmth will be one of the most valuable commodities. We will care much more about that in a world with AI. 

You've invested in over 400 companies? Counting Y Combinator, like 3,000. Wow, okay. But given the speed of AI growth and the disruption, where would you advise people in this room to invest today? 

The cool thing about a moment like this when the ground is shaking is sort of everything is up for grabs. Things are going to change so fast. As we talked about earlier, you can have these one-person companies doing the things that used to take much bigger companies, but they can move faster. 

So there will be the &quot;do the existing things better&quot; and then there's a whole set of new things we just couldn't imagine before. It feels like the investment landscape is more open than it's ever been in any of my time as an adult. 

Now it feels like you can kind of do whatever you want. How far are we from ASI? You said AGI we're a few years away, how far from ASI? No, I said from ASI we're a few years away. So AGI how far then? I mean, AGI feels pretty close at this point. 

If you had asked most people six years ago what they would think if we had systems that could do new research or make an entire complex computer program on their own, they'd say that sounds pretty general and pretty intelligent. We get used to whatever we have. 

But just watching how much the technology we already have is accelerating us internally, I would say it's pretty close. And given what I now expect to be a faster takeoff, I think superintelligence is not that far off. 

The one thing you'll never ask ChatGPT? I think I would never ask it how to be happy. I would rather ask a wise person than... that's interesting because one of the most common uses is for companionship or therapy. I think for things like therapy or life advice it can be pretty good. I think for life philosophy I'm still not going to take it. 

Which is less likely to happen? That TSMC loses its monopoly over world chip manufacturing or Musk and you become friends again? I think Musk and I becoming friends again is less likely. I feel like I have more control over that one. But both are very unlikely things. 

What is it about TSMC that makes it so... I mean, the whole world is kind of just... They have this relentless focus on getting better at what they do. This incredibly complex process and they are just a machine at how they optimize and get better at every level. 

The most recent update you can share with us about your partnership with Jony Ive? We have basically used computers for the same way for like 50 years. The work that Xerox PARC did to invent the concepts of windows and pointing devices is amazing. 

Putting it on a phone and adding multi-touch was also amazing. But fundamentally it's been a similar kind of idea. And then AI came along and AI is stuck in that same form factor. But AI is a quite different thing. You can talk to a computer in natural language and it can understand context. 

And the form factor of computers does not quite work for this. I want a piece of technology that is observing my whole life and has all the context and is maximally useful and is in my way the least. We may fail at this, this is very hard. 

But I think we have a chance to make a new family of products that were really designed around AI that are kind of participating in your life and not in the way of it. So that's the theory, but what is the product? You'll have to wait and see. 

I mean, we hope to talk about it late this year, but hardware is hard. The one thing that governments should regulate and one thing they should avoid regulating? This is not a confident answer. Generally speaking, I think it's probably a good idea for governments to focus on regulating the really potentially catastrophic issues. 

Any one introspection from your professional disagreements with co-founders? It's hard to reduce that to a single soundbite. One thing that Greg and I have disagreed on a lot over the years is how much the company should focus versus do a lot of things. 

I think I've been wrong about trying to do so many things and I've really learned from him the importance of extremely narrow, deep focus. The biggest mistake you have seen corporates making in adopting AI? I was in a meeting yesterday with a big company who was planning to spend 2026 strategizing, 2027 getting ready, and 2028 deploying. 

That may work for other kinds of technology, like a giant ERP migration. Doing that for AI will be a catastrophic mistake. The nimbleness required, the speed, the commitment required is just totally different. 

Xi Jinping, Narendra Modi, Putin, Trump. What's the one thing you tell each of them they should do? I would say the same thing to everyone, which is: you got to democratize this technology and put it in the hands of people. They're not all going to listen to that, obviously. 

I feel increasingly radicalized on this point. I don't think any other strategy is going to work. How would you describe your relationship with Satya Nadella? He calls OpenAI a frenemy. I would just say friends. Your most expensive hire ever? We are no comparison to Meta here. 

Which of these four statements do you regret? Statement one: India building a foundation model with $10 million is hopeless. Statement two: you'll remain a not-for-profit. Statement three: too much AI regulation can stifle innovation. Statement four: OpenAI won't accept advertising. 

I don't think I ever said we won't accept advertising. I think maybe I said I had misgivings. I guess I'll pick the non-profit one. It's been great... I've tried to cover as much as I could. You only gave me an hour, man. 

We'll take a few questions from the audience? Yeah. I would love another meme so if anyone wants to ask me about Indian foundation models, let's run it back. Rajesh is a founder of MakeMyTrip; he makes money when we are holidaying. 

Thank you. Incredible one-hour chat. You did a great job keeping yourself calm while Anant did a great job on provoking you hell of a lot. I just have one question: given the power of AI, do you think equal amount of focus needs to be on responsible AI as well? 

Yes, I do think that, and I think it's one of the things I'm most proud of with our research team. As we get closer and closer to superintelligence, they of course feel it more and more. It's been a core part of our DNA from the very beginning. 

The race for talent, where do you think it's heading? As AI does more and more of research and engineering, I suspect teams will do much more with smaller amounts of people. The race for talent should ease somewhat and you'll see small teams in research labs do a huge amount of work. 

Hi Sam, this is Stuti. My question to you is as a creator: will AI become too powerful or will humans become very passive? I don't think humans will become too passive, so I guess I'll take the other one. Watching what creators are doing with these tools to have a tighter iteration loop, I think we'll get better stuff. 

I don't think we're going to be passive in that process. I used to worry about it, but it doesn't seem like it's what's happening. Abhishek Khaitan is here. First of all, it's a very interesting session. What I wanted to ask is: which profession because of ChatGPT and AI will be most under threat? 

I think a lot of professions will almost go away, or a lot of the current ones. We will find new things to do for sure. I was trained as a software engineer and the way I learned to write software is now effectively completely irrelevant. Writing C++ code by hand? That's over. 

Sam let's flip the question, what's the least vulnerable job? One thing that I think is interesting is when AI started generating images, people said graphic artist, that's over. That might be true for the kind of graphic artist job that was to make someone's birthday card invitation. 

But for fine art, the price of AI-generated art is zero and the price of human-generated graphic art has continued to go up. I really care about the nurse that was taking care of me when I went to the hospital. If that were like a robot, I think I would have been pretty unhappy no matter how smart the robot was. 

Hi Sam, I'm from Chitkara University. Taking from the previous question on responsible AI, how do you see your role in checks and balances? It's a huge focus of ours as a company. Sometimes we overdo it, sometimes we're too conservative with a new technology, sometimes we put in too many checks. 

There is a tension between democratizing AI and enough safety. But I think our principle of starting conservative and then broadening access has served us well. Sam we're completely out of time. Sam, thank you so much for your time. 

I now invite Raj Kamal Jha, Chief Editor of The Indian Express, to present a memento. Request everyone to please remain seated. This illustration is by Indian Express cartoonist E.P. Unny and he wanted you to know that it is not AI generated. 

I now invite Abhishek Khaitan, Managing Director, Radico Khaitan to present Sam with a bouquet. I request the other partners to also join on stage for a group photograph: Miss Hazel, Prasun Tripathi, Rajesh Nambiar, Anupama Sharma, and Corel Lahiri. 

Thank you everyone for joining us today. I would like to thank our partners: presenting partner Radico Khaitan, co-presented by 361, associate partner IMS Ghaziabad, Chitkara University, ICFAI Hyderabad, FRR Immigration, and broadcast partner NDTV.
                    </div>
                </div>
                
            </article>
            
        </main>

        <footer>
            Generated by Follower Tool
        </footer>
    </div>
    <script>
        function toggleSummary(id) {
            const preview = document.getElementById('preview-' + id);
            const full = document.getElementById('full-' + id);
            const btn = document.getElementById('sum-btn-' + id);

            if (full.classList.contains('expanded')) {
                full.classList.remove('expanded');
                preview.style.display = 'block';
                btn.classList.remove('expanded');
                btn.innerHTML = 'Read more <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            } else {
                full.classList.add('expanded');
                preview.style.display = 'none';
                btn.classList.add('expanded');
                btn.innerHTML = 'Show less <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M6 9l6 6 6-6"/></svg>';
            }
        }

        function toggleTranscript(id) {
            const content = document.getElementById('transcript-' + id);
            const btn = document.getElementById('trans-btn-' + id);

            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                btn.textContent = 'View transcript';
            } else {
                content.classList.add('expanded');
                btn.textContent = 'Hide transcript';
            }
        }
        </script>
</body>
</html>